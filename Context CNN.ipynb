{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy.io import loadmat\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import classifier_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_classifier' from 'cnn_classifier.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cnn_classifier\n",
    "reload(cnn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import context_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1559 patches because too close to image border\n",
      "Dropped 523 patches because too close to image border\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'epithelial',\n",
    "    'fibroblast',\n",
    "    'inflammatory',\n",
    "    'others',\n",
    "]\n",
    "\n",
    "train, test = utils.get_augmented_dataset_divided_per_image(categories)\n",
    "\n",
    "# Carve out a validation set from our test set\n",
    "# Split it 50/50\n",
    "# Need to shuffle the test set before splitting\n",
    "np.random.seed(8080) # repeatability\n",
    "N = len(test['patches'])\n",
    "new_N = N/2\n",
    "perm = np.random.permutation(N)\n",
    "validation = {}\n",
    "for k in list(test.iterkeys()):\n",
    "    values = test[k]\n",
    "    test[k], validation[k] = np.split(values[perm], [new_N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train hsv_factors (60000, 3)\n",
      "train deltas (60000, 2)\n",
      "train patches (60000, 27, 27, 3)\n",
      "train rots (60000,)\n",
      "train labels (60000, 4)\n",
      "train flips (60000,)\n",
      "train centres (60000, 2)\n",
      "train img_ids (60000,)\n",
      "test img_ids (2296,)\n",
      "test labels (2296, 4)\n",
      "test patches (2296, 27, 27, 3)\n",
      "test centres (2296, 2)\n",
      "validation img_ids (2297,)\n",
      "validation labels (2297, 4)\n",
      "validation patches (2297, 27, 27, 3)\n",
      "validation centres (2297, 2)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in train.iteritems():\n",
    "    print \"train\", k, v.shape\n",
    "for (k, v) in test.iteritems():\n",
    "    print \"test\", k, v.shape\n",
    "for (k, v) in validation.iteritems():\n",
    "    print \"validation\", k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99]\n",
      "Test: [9, 12, 21, 25, 36, 37, 39, 44, 46, 47, 58, 64, 65, 67, 70, 81, 83, 87, 88, 96]\n",
      "Intersection: []\n"
     ]
    }
   ],
   "source": [
    "# Sanity-check that the test and train data come from different images\n",
    "test_img_ids = set(test['img_ids'])\n",
    "train_img_ids = set(train['img_ids'])\n",
    "print \"Train:\", sorted(train_img_ids)\n",
    "print \"Test:\", sorted(test_img_ids)\n",
    "print \"Intersection:\", sorted(train_img_ids.intersection(test_img_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(all_imgs, _, _) = utils.get_dataset(100, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Softmax CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass # sess doesn't exist yet!\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "with tf.device('cpu:0'):\n",
    "    patch_model = cnn_classifier.SoftmaxCNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From cnn_classifier.py:86 in train_loop.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0, step 0, training loss 1.386460, test_loss 1.387063, accuracy = 0.207272/0.250163, f1 = nan\n",
      "Epoch 0, step 25, training loss 1.386188, test_loss 1.387260, accuracy = 0.230786/0.259525, f1 = nan\n",
      "Epoch 0, step 50, training loss 1.384773, test_loss 1.387609, accuracy = 0.238189/0.249946, f1 = nan\n",
      "Epoch 0, step 75, training loss 1.386149, test_loss 1.388587, accuracy = 0.238842/0.251034, f1 = nan\n",
      "Epoch 0, step 100, training loss 1.385368, test_loss 1.388743, accuracy = 0.241890/0.266057, f1 = nan\n",
      "Epoch 0, step 125, training loss 1.384659, test_loss 1.388955, accuracy = 0.204224/0.246897, f1 = nan\n",
      "Epoch 0, step 150, training loss 1.385288, test_loss 1.390291, accuracy = 0.209885/0.249075, f1 = nan\n",
      "Epoch 0, step 175, training loss 1.384866, test_loss 1.389790, accuracy = 0.223166/0.249728, f1 = nan\n",
      "Epoch 0, step 200, training loss 1.382402, test_loss 1.388770, accuracy = 0.224907/0.250163, f1 = nan\n",
      "Epoch 0, step 225, training loss 1.382191, test_loss 1.389419, accuracy = 0.248204/0.249728, f1 = nan\n",
      "Epoch 0, step 250, training loss 1.381043, test_loss 1.388842, accuracy = 0.253211/0.249728, f1 = nan\n",
      "Epoch 0, step 275, training loss 1.379149, test_loss 1.389566, accuracy = 0.246680/0.250599, f1 = nan\n",
      "Epoch 0, step 300, training loss 1.380347, test_loss 1.392835, accuracy = 0.238624/0.253865, f1 = nan\n",
      "Epoch 0, step 325, training loss 1.381823, test_loss 1.390499, accuracy = 0.146092/0.094927, f1 = nan\n",
      "Epoch 0, step 350, training loss 1.380241, test_loss 1.393183, accuracy = 0.166558/0.124537, f1 = nan\n",
      "Epoch 0, step 375, training loss 1.384148, test_loss 1.388877, accuracy = 0.175702/0.132593, f1 = 0.084149\n",
      "Epoch 0, step 400, training loss 1.386673, test_loss 1.390580, accuracy = 0.216416/0.255824, f1 = 0.132885\n",
      "Epoch 0, step 425, training loss 1.379036, test_loss 1.394514, accuracy = 0.212280/0.253865, f1 = 0.118529\n",
      "Epoch 0, step 450, training loss 1.373980, test_loss 1.378196, accuracy = 0.325495/0.376878, f1 = 0.402153\n",
      "Epoch 0, step 475, training loss 1.363669, test_loss 1.380568, accuracy = 0.279338/0.332898, f1 = 0.275373\n",
      "Epoch 0, step 500, training loss 1.350486, test_loss 1.374401, accuracy = 0.287829/0.261703, f1 = 0.290430\n",
      "Epoch 0, step 525, training loss 1.336582, test_loss 1.349814, accuracy = 0.409536/0.443719, f1 = 0.469767\n",
      "Epoch 0, step 550, training loss 1.336406, test_loss 1.297770, accuracy = 0.531461/0.550620, f1 = 0.477718\n",
      "Epoch 0, step 575, training loss 1.303578, test_loss 1.513431, accuracy = 0.263009/0.279991, f1 = nan\n",
      "End of epoch 0, training loss 1.246720, test_loss 1.248178, accuracy = 0.461572/0.468321, f1 = 0.481906\n",
      "Confusion matrix:\n",
      "[[1009  145  757    0]\n",
      " [  53  633  453    8]\n",
      " [  81  552  474   15]\n",
      " [   9  298   71   35]]\n",
      "Epoch 1, step 0, training loss 1.276942, test_loss 1.212122, accuracy = 0.482038/0.502504, f1 = 0.506036\n",
      "Epoch 1, step 25, training loss 1.226034, test_loss 1.186796, accuracy = 0.482038/0.518398, f1 = 0.515885\n",
      "Epoch 1, step 50, training loss 1.259481, test_loss 1.337368, accuracy = 0.349663/0.342478, f1 = 0.370396\n",
      "Epoch 1, step 75, training loss 1.320439, test_loss 1.245132, accuracy = 0.433268/0.438493, f1 = 0.458351\n",
      "Epoch 1, step 100, training loss 1.264940, test_loss 1.163975, accuracy = 0.524929/0.541476, f1 = 0.550156\n",
      "Epoch 1, step 125, training loss 1.300692, test_loss 1.242020, accuracy = 0.388853/0.381450, f1 = 0.385592\n",
      "Epoch 1, step 150, training loss 1.231230, test_loss 1.230110, accuracy = 0.461572/0.487045, f1 = 0.498851\n",
      "Epoch 1, step 175, training loss 1.413474, test_loss 1.296912, accuracy = 0.415632/0.436969, f1 = 0.457942\n",
      "Epoch 1, step 200, training loss 1.289042, test_loss 1.235997, accuracy = 0.473547/0.484433, f1 = 0.504073\n",
      "Epoch 1, step 225, training loss 1.181049, test_loss 1.135432, accuracy = 0.545831/0.567385, f1 = 0.568751\n",
      "Epoch 1, step 250, training loss 1.354496, test_loss 1.115469, accuracy = 0.554757/0.570869, f1 = 0.566425\n",
      "Epoch 1, step 275, training loss 1.190600, test_loss 1.276713, accuracy = 0.367080/0.366645, f1 = 0.373561\n",
      "Epoch 1, step 300, training loss 1.259583, test_loss 1.182765, accuracy = 0.426954/0.428043, f1 = 0.431610\n",
      "Epoch 1, step 325, training loss 1.270161, test_loss 1.021815, accuracy = 0.587851/0.596125, f1 = 0.545862\n",
      "Epoch 1, step 350, training loss 1.210265, test_loss 1.081088, accuracy = 0.607011/0.627477, f1 = 0.631164\n",
      "Epoch 1, step 375, training loss 1.137500, test_loss 1.002884, accuracy = 0.621380/0.630742, f1 = 0.624739\n",
      "Epoch 1, step 400, training loss 1.170973, test_loss 1.030918, accuracy = 0.603092/0.629218, f1 = 0.631931\n",
      "Epoch 1, step 425, training loss 1.226030, test_loss 1.007832, accuracy = 0.642935/0.652515, f1 = 0.651236\n",
      "Epoch 1, step 450, training loss 1.267530, test_loss 1.017716, accuracy = 0.642282/0.663401, f1 = 0.657708\n",
      "Epoch 1, step 475, training loss 1.108221, test_loss 0.945388, accuracy = 0.658829/0.662094, f1 = 0.636456\n",
      "Epoch 1, step 500, training loss 1.090078, test_loss 1.004292, accuracy = 0.621163/0.636839, f1 = 0.641807\n",
      "Epoch 1, step 525, training loss 1.057306, test_loss 1.021885, accuracy = 0.601568/0.613107, f1 = 0.611092\n",
      "Epoch 1, step 550, training loss 1.105320, test_loss 0.972471, accuracy = 0.650773/0.661441, f1 = 0.667233\n",
      "Epoch 1, step 575, training loss 1.205214, test_loss 1.311538, accuracy = 0.462007/0.466144, f1 = 0.450006\n",
      "End of epoch 1, training loss 1.086401, test_loss 1.112216, accuracy = 0.554757/0.566514, f1 = 0.578757\n",
      "Confusion matrix:\n",
      "[[925 697 260  29]\n",
      " [ 17 553 270 307]\n",
      " [  9  57 878 178]\n",
      " [  5  44 118 246]]\n",
      "Epoch 2, step 0, training loss 1.161716, test_loss 1.063974, accuracy = 0.586762/0.597866, f1 = 0.607000\n",
      "Epoch 2, step 25, training loss 1.064130, test_loss 0.879105, accuracy = 0.686915/0.689963, f1 = 0.688352\n",
      "Epoch 2, step 50, training loss 1.025201, test_loss 1.054811, accuracy = 0.606140/0.610712, f1 = 0.607149\n",
      "Epoch 2, step 75, training loss 1.126813, test_loss 1.037734, accuracy = 0.601132/0.602439, f1 = 0.593923\n",
      "Epoch 2, step 100, training loss 1.018319, test_loss 0.925388, accuracy = 0.652950/0.661224, f1 = 0.658926\n",
      "Epoch 2, step 125, training loss 1.126041, test_loss 0.949307, accuracy = 0.639234/0.646418, f1 = 0.645926\n",
      "Epoch 2, step 150, training loss 1.160683, test_loss 0.868390, accuracy = 0.678641/0.687350, f1 = 0.666748\n",
      "Epoch 2, step 175, training loss 1.097866, test_loss 0.827946, accuracy = 0.698019/0.711300, f1 = 0.695766\n",
      "Epoch 2, step 200, training loss 1.104402, test_loss 0.874465, accuracy = 0.682560/0.689092, f1 = 0.694139\n",
      "Epoch 2, step 225, training loss 1.001872, test_loss 0.983025, accuracy = 0.595471/0.612889, f1 = 0.632719\n",
      "Epoch 2, step 250, training loss 1.213957, test_loss 0.991587, accuracy = 0.613542/0.622469, f1 = 0.631502\n",
      "Epoch 2, step 275, training loss 1.131680, test_loss 0.868000, accuracy = 0.669497/0.677553, f1 = 0.681932\n",
      "Epoch 2, step 300, training loss 1.176559, test_loss 1.220179, accuracy = 0.453299/0.459612, f1 = 0.490218\n",
      "Epoch 2, step 325, training loss 1.087659, test_loss 0.823498, accuracy = 0.698672/0.702373, f1 = 0.683376\n",
      "Epoch 2, step 350, training loss 1.080558, test_loss 0.898444, accuracy = 0.656869/0.657087, f1 = 0.666546\n",
      "Epoch 2, step 375, training loss 1.051497, test_loss 0.891011, accuracy = 0.656869/0.660353, f1 = 0.674857\n",
      "Epoch 2, step 400, training loss 0.982699, test_loss 0.840466, accuracy = 0.690834/0.697583, f1 = 0.693169\n",
      "Epoch 2, step 425, training loss 1.041759, test_loss 0.843968, accuracy = 0.687350/0.690616, f1 = 0.692371\n",
      "Epoch 2, step 450, training loss 1.046906, test_loss 1.062970, accuracy = 0.593294/0.595036, f1 = 0.590833\n",
      "Epoch 2, step 475, training loss 1.099475, test_loss 0.803631, accuracy = 0.703462/0.706292, f1 = 0.694720\n",
      "Epoch 2, step 500, training loss 0.961690, test_loss 0.954990, accuracy = 0.626170/0.628783, f1 = 0.632848\n",
      "Epoch 2, step 525, training loss 0.901901, test_loss 0.916335, accuracy = 0.657087/0.658393, f1 = 0.659718\n",
      "Epoch 2, step 550, training loss 0.992557, test_loss 0.859488, accuracy = 0.677770/0.681690, f1 = 0.686534\n",
      "Epoch 2, step 575, training loss 1.164375, test_loss 1.264543, accuracy = 0.486392/0.484433, f1 = 0.474389\n",
      "End of epoch 2, training loss 0.986793, test_loss 0.991141, accuracy = 0.606575/0.616373, f1 = 0.623616\n",
      "Confusion matrix:\n",
      "[[1028  632  231   20]\n",
      " [  28  666  263  190]\n",
      " [   8   51  954  109]\n",
      " [   8   71  151  183]]\n",
      "Epoch 3, step 0, training loss 1.038434, test_loss 1.044958, accuracy = 0.579360/0.587198, f1 = 0.594246\n",
      "Epoch 3, step 25, training loss 0.984690, test_loss 0.838698, accuracy = 0.682560/0.688439, f1 = 0.694297\n",
      "Epoch 3, step 50, training loss 0.931356, test_loss 0.965236, accuracy = 0.650120/0.649467, f1 = 0.649629\n",
      "Epoch 3, step 75, training loss 1.104674, test_loss 1.061080, accuracy = 0.589593/0.595471, f1 = 0.589267\n",
      "Epoch 3, step 100, training loss 0.968934, test_loss 0.820547, accuracy = 0.703680/0.705204, f1 = 0.696364\n",
      "Epoch 3, step 125, training loss 1.067223, test_loss 0.884964, accuracy = 0.673416/0.681254, f1 = 0.681339\n",
      "Epoch 3, step 150, training loss 1.040252, test_loss 0.812841, accuracy = 0.688221/0.695188, f1 = 0.661830\n",
      "Epoch 3, step 175, training loss 1.062288, test_loss 0.767783, accuracy = 0.721315/0.724799, f1 = 0.710670\n",
      "Epoch 3, step 200, training loss 1.109430, test_loss 0.865219, accuracy = 0.684520/0.689528, f1 = 0.688945\n",
      "Epoch 3, step 225, training loss 0.952108, test_loss 0.902500, accuracy = 0.658611/0.663183, f1 = 0.666359\n",
      "Epoch 3, step 250, training loss 1.177659, test_loss 0.821641, accuracy = 0.708687/0.712388, f1 = 0.705628\n",
      "Epoch 3, step 275, training loss 1.047324, test_loss 0.991831, accuracy = 0.603963/0.610712, f1 = 0.623538\n",
      "Epoch 3, step 300, training loss 1.118716, test_loss 0.934046, accuracy = 0.600261/0.610059, f1 = 0.636517\n",
      "Epoch 3, step 325, training loss 1.015528, test_loss 0.777722, accuracy = 0.716743/0.721968, f1 = 0.704505\n",
      "Epoch 3, step 350, training loss 1.063661, test_loss 0.886616, accuracy = 0.664054/0.670150, f1 = 0.674672\n",
      "Epoch 3, step 375, training loss 0.955661, test_loss 0.813337, accuracy = 0.701285/0.705639, f1 = 0.711063\n",
      "Epoch 3, step 400, training loss 0.949900, test_loss 0.804644, accuracy = 0.705857/0.709123, f1 = 0.707383\n",
      "Epoch 3, step 425, training loss 1.021734, test_loss 0.800582, accuracy = 0.703244/0.711953, f1 = 0.712466\n",
      "Epoch 3, step 450, training loss 1.012461, test_loss 1.057983, accuracy = 0.603963/0.606575, f1 = 0.604404\n",
      "Epoch 3, step 475, training loss 0.937369, test_loss 0.764448, accuracy = 0.723928/0.726105, f1 = 0.700321\n",
      "Epoch 3, step 500, training loss 0.916922, test_loss 0.826260, accuracy = 0.682343/0.686262, f1 = 0.677817\n",
      "Epoch 3, step 525, training loss 0.840589, test_loss 0.844544, accuracy = 0.694971/0.696059, f1 = 0.692484\n",
      "Epoch 3, step 550, training loss 0.982263, test_loss 0.804963, accuracy = 0.701720/0.713695, f1 = 0.713348\n",
      "Epoch 3, step 575, training loss 1.026965, test_loss 1.079101, accuracy = 0.581755/0.584585, f1 = 0.583161\n",
      "End of epoch 3, training loss 0.949053, test_loss 0.888281, accuracy = 0.655345/0.655998, f1 = 0.658424\n",
      "Confusion matrix:\n",
      "[[1149  542  208   12]\n",
      " [  42  724  268  113]\n",
      " [   8   69  996   49]\n",
      " [  12   79  178  144]]\n",
      "Epoch 4, step 0, training loss 0.978497, test_loss 0.941274, accuracy = 0.630525/0.633791, f1 = 0.638494\n",
      "Epoch 4, step 25, training loss 0.989974, test_loss 0.818546, accuracy = 0.693447/0.702591, f1 = 0.704734\n",
      "Epoch 4, step 50, training loss 0.893400, test_loss 0.879902, accuracy = 0.676900/0.687786, f1 = 0.690869\n",
      "Epoch 4, step 75, training loss 1.001814, test_loss 1.173802, accuracy = 0.536251/0.539952, f1 = 0.552008\n",
      "Epoch 4, step 100, training loss 0.985017, test_loss 0.755120, accuracy = 0.726540/0.732637, f1 = 0.720620\n",
      "Epoch 4, step 125, training loss 1.026837, test_loss 1.013479, accuracy = 0.599173/0.609188, f1 = 0.614529\n",
      "Epoch 4, step 150, training loss 0.936472, test_loss 0.781433, accuracy = 0.718920/0.719356, f1 = 0.704468\n",
      "Epoch 4, step 175, training loss 0.994031, test_loss 0.737841, accuracy = 0.732637/0.731983, f1 = 0.715209\n",
      "Epoch 4, step 200, training loss 1.040558, test_loss 0.830360, accuracy = 0.691269/0.695841, f1 = 0.696866\n",
      "Epoch 4, step 225, training loss 0.942309, test_loss 0.871080, accuracy = 0.656216/0.659264, f1 = 0.650268\n",
      "Epoch 4, step 250, training loss 1.093742, test_loss 0.860699, accuracy = 0.686044/0.689092, f1 = 0.690960\n",
      "Epoch 4, step 275, training loss 1.076470, test_loss 0.868112, accuracy = 0.661659/0.663183, f1 = 0.666685\n",
      "Epoch 4, step 300, training loss 1.134863, test_loss 1.036948, accuracy = 0.532767/0.542347, f1 = 0.580815\n",
      "Epoch 4, step 325, training loss 0.966918, test_loss 0.772376, accuracy = 0.713259/0.718485, f1 = 0.700202\n",
      "Epoch 4, step 350, training loss 1.033444, test_loss 0.804770, accuracy = 0.685173/0.689963, f1 = 0.682782\n",
      "Epoch 4, step 375, training loss 0.976491, test_loss 0.798088, accuracy = 0.699543/0.705204, f1 = 0.710695\n",
      "Epoch 4, step 400, training loss 0.898920, test_loss 0.753793, accuracy = 0.719791/0.723275, f1 = 0.717110\n",
      "Epoch 4, step 425, training loss 0.975887, test_loss 0.776713, accuracy = 0.713042/0.717178, f1 = 0.714916\n",
      "Epoch 4, step 450, training loss 1.026528, test_loss 0.833154, accuracy = 0.696277/0.704333, f1 = 0.695813\n",
      "Epoch 4, step 475, training loss 0.935244, test_loss 0.813812, accuracy = 0.691269/0.689745, f1 = 0.674858\n",
      "Epoch 4, step 500, training loss 0.975116, test_loss 0.892133, accuracy = 0.648596/0.650337, f1 = 0.643414\n",
      "Epoch 4, step 525, training loss 0.757423, test_loss 0.805280, accuracy = 0.706945/0.709340, f1 = 0.705735\n",
      "Epoch 4, step 550, training loss 0.934346, test_loss 0.774710, accuracy = 0.711953/0.715219, f1 = 0.713686\n",
      "Epoch 4, step 575, training loss 0.978011, test_loss 0.930491, accuracy = 0.643806/0.642935, f1 = 0.639646\n",
      "End of epoch 4, training loss 0.905207, test_loss 0.824080, accuracy = 0.680165/0.684302, f1 = 0.690548\n",
      "Confusion matrix:\n",
      "[[1279  439  173   20]\n",
      " [  60  747  214  126]\n",
      " [  12   85  935   90]\n",
      " [  15   76  140  182]]\n",
      "Epoch 5, step 0, training loss 0.944948, test_loss 0.840883, accuracy = 0.670586/0.673416, f1 = 0.681862\n",
      "Epoch 5, step 25, training loss 0.956249, test_loss 0.810839, accuracy = 0.692576/0.692576, f1 = 0.690879\n",
      "Epoch 5, step 50, training loss 0.813188, test_loss 0.830427, accuracy = 0.669715/0.679730, f1 = 0.693829\n",
      "Epoch 5, step 75, training loss 0.940649, test_loss 1.059493, accuracy = 0.578489/0.590899, f1 = 0.602545\n",
      "Epoch 5, step 100, training loss 0.949476, test_loss 0.729976, accuracy = 0.733290/0.733072, f1 = 0.719013\n",
      "Epoch 5, step 125, training loss 1.042769, test_loss 1.093048, accuracy = 0.554540/0.555628, f1 = 0.554070\n",
      "Epoch 5, step 150, training loss 0.899796, test_loss 0.728585, accuracy = 0.725452/0.730895, f1 = 0.703823\n",
      "Epoch 5, step 175, training loss 0.996689, test_loss 0.753739, accuracy = 0.713695/0.718702, f1 = 0.719615\n",
      "Epoch 5, step 200, training loss 0.965776, test_loss 0.809482, accuracy = 0.683867/0.681254, f1 = 0.678220\n",
      "Epoch 5, step 225, training loss 0.895121, test_loss 0.776692, accuracy = 0.697366/0.697366, f1 = 0.687581\n",
      "Epoch 5, step 250, training loss 1.133028, test_loss 0.861127, accuracy = 0.644459/0.650991, f1 = 0.670210\n",
      "Epoch 5, step 275, training loss 1.108709, test_loss 0.752674, accuracy = 0.721533/0.725234, f1 = 0.720015\n",
      "Epoch 5, step 300, training loss 1.036071, test_loss 0.873969, accuracy = 0.649902/0.654256, f1 = 0.663956\n",
      "Epoch 5, step 325, training loss 0.911400, test_loss 0.781131, accuracy = 0.708687/0.710864, f1 = 0.698649\n",
      "Epoch 5, step 350, training loss 0.993043, test_loss 0.843673, accuracy = 0.667973/0.668844, f1 = 0.670041\n",
      "Epoch 5, step 375, training loss 0.948576, test_loss 0.768976, accuracy = 0.705204/0.708905, f1 = 0.708155\n",
      "Epoch 5, step 400, training loss 0.892026, test_loss 0.730075, accuracy = 0.726323/0.728064, f1 = 0.724061\n",
      "Epoch 5, step 425, training loss 0.914888, test_loss 0.837066, accuracy = 0.660788/0.668844, f1 = 0.681990\n",
      "Epoch 5, step 450, training loss 0.966774, test_loss 0.824897, accuracy = 0.686044/0.690398, f1 = 0.675896\n",
      "Epoch 5, step 475, training loss 0.914432, test_loss 0.790463, accuracy = 0.696495/0.708252, f1 = 0.714480\n",
      "Epoch 5, step 500, training loss 0.972725, test_loss 0.791378, accuracy = 0.690616/0.698890, f1 = 0.686787\n",
      "Epoch 5, step 525, training loss 0.750023, test_loss 0.755438, accuracy = 0.715654/0.720662, f1 = 0.717988\n",
      "Epoch 5, step 550, training loss 0.917785, test_loss 0.747216, accuracy = 0.721750/0.726976, f1 = 0.726155\n",
      "Epoch 5, step 575, training loss 0.941226, test_loss 0.878272, accuracy = 0.662965/0.667102, f1 = 0.667360\n",
      "End of epoch 5, training loss 0.863565, test_loss 0.797403, accuracy = 0.679295/0.687133, f1 = 0.692232\n",
      "Confusion matrix:\n",
      "[[1313  403  173   22]\n",
      " [  73  732  219  123]\n",
      " [  12   78  943   89]\n",
      " [  17   74  154  168]]\n",
      "Epoch 6, step 0, training loss 0.918551, test_loss 0.811921, accuracy = 0.679948/0.680819, f1 = 0.687644\n",
      "Epoch 6, step 25, training loss 0.929511, test_loss 0.793280, accuracy = 0.692140/0.691052, f1 = 0.687059\n",
      "Epoch 6, step 50, training loss 0.803847, test_loss 0.822086, accuracy = 0.659264/0.672110, f1 = 0.690855\n",
      "Epoch 6, step 75, training loss 0.912044, test_loss 0.973725, accuracy = 0.615502/0.620074, f1 = 0.627352\n",
      "Epoch 6, step 100, training loss 0.904900, test_loss 0.719691, accuracy = 0.726758/0.728064, f1 = 0.715245\n",
      "Epoch 6, step 125, training loss 1.014714, test_loss 0.947171, accuracy = 0.620074/0.617679, f1 = 0.615102\n",
      "Epoch 6, step 150, training loss 0.876003, test_loss 0.722333, accuracy = 0.725887/0.724799, f1 = 0.703122\n",
      "Epoch 6, step 175, training loss 0.944514, test_loss 0.726561, accuracy = 0.713695/0.718485, f1 = 0.721015\n",
      "Epoch 6, step 200, training loss 0.950351, test_loss 0.751361, accuracy = 0.714130/0.718702, f1 = 0.713357\n",
      "Epoch 6, step 225, training loss 0.919596, test_loss 0.733392, accuracy = 0.721315/0.723057, f1 = 0.710085\n",
      "Epoch 6, step 250, training loss 1.152854, test_loss 0.851982, accuracy = 0.647725/0.661877, f1 = 0.678846\n",
      "Epoch 6, step 275, training loss 1.092989, test_loss 0.741659, accuracy = 0.709993/0.726323, f1 = 0.727642\n",
      "Epoch 6, step 300, training loss 1.016798, test_loss 0.845784, accuracy = 0.662312/0.666449, f1 = 0.672265\n",
      "Epoch 6, step 325, training loss 0.862365, test_loss 0.747748, accuracy = 0.716743/0.725016, f1 = 0.711375\n",
      "Epoch 6, step 350, training loss 0.981681, test_loss 0.843792, accuracy = 0.670368/0.667320, f1 = 0.668121\n",
      "Epoch 6, step 375, training loss 0.925027, test_loss 0.758817, accuracy = 0.706074/0.707599, f1 = 0.707928\n",
      "Epoch 6, step 400, training loss 0.847126, test_loss 0.731681, accuracy = 0.714130/0.721533, f1 = 0.718850\n",
      "Epoch 6, step 425, training loss 0.927066, test_loss 0.848149, accuracy = 0.648160/0.654692, f1 = 0.669903\n",
      "Epoch 6, step 450, training loss 0.917124, test_loss 0.794279, accuracy = 0.700631/0.704550, f1 = 0.693826\n",
      "Epoch 6, step 475, training loss 0.907476, test_loss 0.785883, accuracy = 0.692140/0.702155, f1 = 0.712475\n",
      "Epoch 6, step 500, training loss 0.971839, test_loss 0.762586, accuracy = 0.707163/0.712171, f1 = 0.702405\n",
      "Epoch 6, step 525, training loss 0.693054, test_loss 0.737444, accuracy = 0.721968/0.720880, f1 = 0.716936\n",
      "Epoch 6, step 550, training loss 0.932627, test_loss 0.715825, accuracy = 0.726976/0.734378, f1 = 0.731604\n",
      "Epoch 6, step 575, training loss 0.899616, test_loss 0.859389, accuracy = 0.674722/0.674722, f1 = 0.673182\n",
      "End of epoch 6, training loss 0.806413, test_loss 0.767326, accuracy = 0.699325/0.701285, f1 = 0.705687\n",
      "Confusion matrix:\n",
      "[[1389  333  168   21]\n",
      " [  81  729  212  125]\n",
      " [  18   74  936   94]\n",
      " [  21   69  156  167]]\n",
      "Epoch 7, step 0, training loss 0.872226, test_loss 0.805154, accuracy = 0.681472/0.681254, f1 = 0.688802\n",
      "Epoch 7, step 25, training loss 0.905056, test_loss 0.793224, accuracy = 0.688003/0.690616, f1 = 0.685179\n",
      "Epoch 7, step 50, training loss 0.771536, test_loss 0.801582, accuracy = 0.667973/0.681690, f1 = 0.698980\n",
      "Epoch 7, step 75, training loss 0.907132, test_loss 0.969717, accuracy = 0.618550/0.619856, f1 = 0.618845\n",
      "Epoch 7, step 100, training loss 0.867614, test_loss 0.712818, accuracy = 0.728500/0.733072, f1 = 0.720259\n",
      "Epoch 7, step 125, training loss 0.993304, test_loss 0.912754, accuracy = 0.639016/0.641629, f1 = 0.642398\n",
      "Epoch 7, step 150, training loss 0.861612, test_loss 0.718687, accuracy = 0.729589/0.731983, f1 = 0.714509\n",
      "Epoch 7, step 175, training loss 0.939680, test_loss 0.721983, accuracy = 0.714130/0.720226, f1 = 0.722872\n",
      "Epoch 7, step 200, training loss 0.947914, test_loss 0.757671, accuracy = 0.709558/0.719791, f1 = 0.717946\n",
      "Epoch 7, step 225, training loss 0.893800, test_loss 0.726245, accuracy = 0.720226/0.731113, f1 = 0.718331\n",
      "Epoch 7, step 250, training loss 1.159467, test_loss 0.812383, accuracy = 0.674505/0.682343, f1 = 0.692307\n",
      "Epoch 7, step 275, training loss 1.041926, test_loss 0.731447, accuracy = 0.718920/0.728500, f1 = 0.726566\n",
      "Epoch 7, step 300, training loss 1.014439, test_loss 0.808479, accuracy = 0.676682/0.679295, f1 = 0.684626\n",
      "Epoch 7, step 325, training loss 0.852797, test_loss 0.732331, accuracy = 0.728935/0.728282, f1 = 0.716020\n",
      "Epoch 7, step 350, training loss 0.951834, test_loss 0.814780, accuracy = 0.679512/0.683214, f1 = 0.681068\n",
      "Epoch 7, step 375, training loss 0.894828, test_loss 0.715774, accuracy = 0.730242/0.732201, f1 = 0.728958\n",
      "Epoch 7, step 400, training loss 0.843384, test_loss 0.736646, accuracy = 0.710211/0.717178, f1 = 0.716049\n",
      "Epoch 7, step 425, training loss 0.928834, test_loss 0.879288, accuracy = 0.636839/0.642282, f1 = 0.650676\n",
      "Epoch 7, step 450, training loss 0.899738, test_loss 0.762240, accuracy = 0.711518/0.718920, f1 = 0.712594\n",
      "Epoch 7, step 475, training loss 0.907133, test_loss 0.788366, accuracy = 0.703680/0.711735, f1 = 0.714729\n",
      "Epoch 7, step 500, training loss 0.967796, test_loss 0.751581, accuracy = 0.715437/0.721097, f1 = 0.714666\n",
      "Epoch 7, step 525, training loss 0.702725, test_loss 0.723270, accuracy = 0.726105/0.734161, f1 = 0.730823\n",
      "Epoch 7, step 550, training loss 0.904710, test_loss 0.698675, accuracy = 0.740475/0.745047, f1 = 0.740616\n",
      "Epoch 7, step 575, training loss 0.868813, test_loss 0.817431, accuracy = 0.692576/0.701285, f1 = 0.700732\n",
      "End of epoch 7, training loss 0.808428, test_loss 0.764974, accuracy = 0.693664/0.702373, f1 = 0.706139\n",
      "Confusion matrix:\n",
      "[[1337  392  165   17]\n",
      " [  63  810  183   91]\n",
      " [  17   95  923   87]\n",
      " [  21   82  154  156]]\n",
      "Epoch 8, step 0, training loss 0.852782, test_loss 0.779011, accuracy = 0.689310/0.694971, f1 = 0.701037\n",
      "Epoch 8, step 25, training loss 0.895345, test_loss 0.772344, accuracy = 0.696059/0.697148, f1 = 0.691843\n",
      "Epoch 8, step 50, training loss 0.731605, test_loss 0.801756, accuracy = 0.671674/0.682778, f1 = 0.699811\n",
      "Epoch 8, step 75, training loss 0.918712, test_loss 0.927093, accuracy = 0.634008/0.637710, f1 = 0.636923\n",
      "Epoch 8, step 100, training loss 0.760283, test_loss 0.696897, accuracy = 0.735902/0.740910, f1 = 0.727313\n",
      "Epoch 8, step 125, training loss 0.988567, test_loss 0.872760, accuracy = 0.654256/0.660353, f1 = 0.664102\n",
      "Epoch 8, step 150, training loss 0.836289, test_loss 0.692902, accuracy = 0.747224/0.748966, f1 = 0.732133\n",
      "Epoch 8, step 175, training loss 0.888755, test_loss 0.716238, accuracy = 0.723928/0.726976, f1 = 0.730692\n",
      "Epoch 8, step 200, training loss 0.929885, test_loss 0.724623, accuracy = 0.724581/0.732201, f1 = 0.730080\n",
      "Epoch 8, step 225, training loss 0.836581, test_loss 0.701930, accuracy = 0.736556/0.736120, f1 = 0.724135\n",
      "Epoch 8, step 250, training loss 1.176650, test_loss 0.781690, accuracy = 0.687133/0.696495, f1 = 0.704615\n",
      "Epoch 8, step 275, training loss 0.973710, test_loss 0.696609, accuracy = 0.739168/0.740910, f1 = 0.734143\n",
      "Epoch 8, step 300, training loss 0.976470, test_loss 0.851023, accuracy = 0.654692/0.661441, f1 = 0.673658\n",
      "Epoch 8, step 325, training loss 0.814767, test_loss 0.736407, accuracy = 0.714348/0.720880, f1 = 0.711200\n",
      "Epoch 8, step 350, training loss 0.902738, test_loss 0.835278, accuracy = 0.665143/0.679730, f1 = 0.681401\n",
      "Epoch 8, step 375, training loss 0.915750, test_loss 0.738116, accuracy = 0.716525/0.716090, f1 = 0.718000\n",
      "Epoch 8, step 400, training loss 0.853680, test_loss 0.742867, accuracy = 0.712388/0.721533, f1 = 0.724491\n",
      "Epoch 8, step 425, training loss 0.933038, test_loss 0.817515, accuracy = 0.673198/0.678424, f1 = 0.682043\n",
      "Epoch 8, step 450, training loss 0.848616, test_loss 0.749172, accuracy = 0.720226/0.721968, f1 = 0.717100\n",
      "Epoch 8, step 475, training loss 0.883900, test_loss 0.743219, accuracy = 0.713259/0.723492, f1 = 0.731018\n",
      "Epoch 8, step 500, training loss 0.958404, test_loss 0.710517, accuracy = 0.734814/0.734378, f1 = 0.726338\n",
      "Epoch 8, step 525, training loss 0.713504, test_loss 0.722696, accuracy = 0.730459/0.738080, f1 = 0.737173\n",
      "Epoch 8, step 550, training loss 0.865803, test_loss 0.694388, accuracy = 0.736991/0.745265, f1 = 0.745352\n",
      "Epoch 8, step 575, training loss 0.836594, test_loss 0.848144, accuracy = 0.674287/0.682996, f1 = 0.686022\n",
      "End of epoch 8, training loss 0.810488, test_loss 0.772376, accuracy = 0.696930/0.697366, f1 = 0.701979\n",
      "Confusion matrix:\n",
      "[[1297  434  161   19]\n",
      " [  52  821  178   96]\n",
      " [  16   95  922   89]\n",
      " [  21   82  147  163]]\n",
      "Epoch 9, step 0, training loss 0.798230, test_loss 0.781371, accuracy = 0.692358/0.693229, f1 = 0.699882\n",
      "Epoch 9, step 25, training loss 0.862727, test_loss 0.719224, accuracy = 0.720880/0.722186, f1 = 0.714933\n",
      "Epoch 9, step 50, training loss 0.734803, test_loss 0.786780, accuracy = 0.679730/0.689528, f1 = 0.705019\n",
      "Epoch 9, step 75, training loss 0.918469, test_loss 0.930293, accuracy = 0.632920/0.639451, f1 = 0.637978\n",
      "Epoch 9, step 100, training loss 0.778524, test_loss 0.679813, accuracy = 0.744394/0.748095, f1 = 0.737066\n",
      "Epoch 9, step 125, training loss 0.937718, test_loss 0.821149, accuracy = 0.679512/0.684520, f1 = 0.684473\n",
      "Epoch 9, step 150, training loss 0.778644, test_loss 0.686503, accuracy = 0.742434/0.747877, f1 = 0.738033\n",
      "Epoch 9, step 175, training loss 0.883424, test_loss 0.709108, accuracy = 0.724363/0.732854, f1 = 0.737647\n",
      "Epoch 9, step 200, training loss 0.890442, test_loss 0.707011, accuracy = 0.734378/0.742434, f1 = 0.742927\n",
      "Epoch 9, step 225, training loss 0.875155, test_loss 0.676029, accuracy = 0.747442/0.751143, f1 = 0.739424\n",
      "Epoch 9, step 250, training loss 1.123994, test_loss 0.788595, accuracy = 0.683431/0.692793, f1 = 0.701365\n",
      "Epoch 9, step 275, training loss 0.951375, test_loss 0.690378, accuracy = 0.742216/0.751796, f1 = 0.747831\n",
      "Epoch 9, step 300, training loss 0.975197, test_loss 0.816207, accuracy = 0.678424/0.684520, f1 = 0.694334\n",
      "Epoch 9, step 325, training loss 0.784659, test_loss 0.726410, accuracy = 0.725016/0.728282, f1 = 0.720100\n",
      "Epoch 9, step 350, training loss 0.858533, test_loss 0.845290, accuracy = 0.667538/0.673416, f1 = 0.674598\n",
      "Epoch 9, step 375, training loss 0.858680, test_loss 0.709831, accuracy = 0.730895/0.734161, f1 = 0.733936\n",
      "Epoch 9, step 400, training loss 0.828613, test_loss 0.734541, accuracy = 0.713477/0.723275, f1 = 0.730461\n",
      "Epoch 9, step 425, training loss 0.928358, test_loss 0.799166, accuracy = 0.681254/0.683214, f1 = 0.687693\n",
      "Epoch 9, step 450, training loss 0.848222, test_loss 0.724457, accuracy = 0.724799/0.729806, f1 = 0.726659\n",
      "Epoch 9, step 475, training loss 0.895336, test_loss 0.761546, accuracy = 0.709123/0.719138, f1 = 0.728458\n",
      "Epoch 9, step 500, training loss 0.908407, test_loss 0.708690, accuracy = 0.731330/0.736338, f1 = 0.728806\n",
      "Epoch 9, step 525, training loss 0.688700, test_loss 0.700960, accuracy = 0.739386/0.741781, f1 = 0.741943\n",
      "Epoch 9, step 550, training loss 0.837977, test_loss 0.683498, accuracy = 0.741346/0.745265, f1 = 0.747509\n",
      "Epoch 9, step 575, training loss 0.772382, test_loss 0.818508, accuracy = 0.685826/0.691052, f1 = 0.697261\n",
      "End of epoch 9, training loss 0.758015, test_loss 0.724139, accuracy = 0.722839/0.724581, f1 = 0.726170\n",
      "Confusion matrix:\n",
      "[[1411  327  159   14]\n",
      " [  68  826  182   71]\n",
      " [  22   85  938   77]\n",
      " [  22   84  154  153]]\n",
      "Epoch 10, step 0, training loss 0.769960, test_loss 0.737954, accuracy = 0.715219/0.722621, f1 = 0.726428\n",
      "Epoch 10, step 25, training loss 0.853145, test_loss 0.711845, accuracy = 0.725887/0.729806, f1 = 0.725800\n",
      "Epoch 10, step 50, training loss 0.767527, test_loss 0.790145, accuracy = 0.674505/0.685826, f1 = 0.701788\n",
      "Epoch 10, step 75, training loss 0.855034, test_loss 0.773582, accuracy = 0.699760/0.705639, f1 = 0.703479\n",
      "Epoch 10, step 100, training loss 0.779951, test_loss 0.684335, accuracy = 0.740257/0.747006, f1 = 0.739430\n",
      "Epoch 10, step 125, training loss 0.847376, test_loss 0.925128, accuracy = 0.621598/0.628347, f1 = 0.636008\n",
      "Epoch 10, step 150, training loss 0.767778, test_loss 0.684418, accuracy = 0.741999/0.744176, f1 = 0.731402\n",
      "Epoch 10, step 175, training loss 0.838266, test_loss 0.678792, accuracy = 0.742434/0.749184, f1 = 0.749474\n",
      "Epoch 10, step 200, training loss 0.902700, test_loss 0.677006, accuracy = 0.750490/0.756586, f1 = 0.754414\n",
      "Epoch 10, step 225, training loss 0.874446, test_loss 0.661121, accuracy = 0.755715/0.758763, f1 = 0.750669\n",
      "Epoch 10, step 250, training loss 1.142608, test_loss 0.769078, accuracy = 0.697366/0.703462, f1 = 0.714798\n",
      "Epoch 10, step 275, training loss 0.897460, test_loss 0.695803, accuracy = 0.735032/0.741999, f1 = 0.739347\n",
      "Epoch 10, step 300, training loss 0.921752, test_loss 0.752874, accuracy = 0.703462/0.713042, f1 = 0.721450\n",
      "Epoch 10, step 325, training loss 0.764910, test_loss 0.694662, accuracy = 0.736773/0.738515, f1 = 0.730813\n",
      "Epoch 10, step 350, training loss 0.837231, test_loss 0.799868, accuracy = 0.683649/0.689963, f1 = 0.691219\n",
      "Epoch 10, step 375, training loss 0.798179, test_loss 0.684723, accuracy = 0.745265/0.752449, f1 = 0.751536\n",
      "Epoch 10, step 400, training loss 0.865254, test_loss 0.744795, accuracy = 0.709123/0.721097, f1 = 0.728430\n",
      "Epoch 10, step 425, training loss 0.886991, test_loss 0.810193, accuracy = 0.676464/0.682560, f1 = 0.691698\n",
      "Epoch 10, step 450, training loss 0.811246, test_loss 0.731867, accuracy = 0.723492/0.727411, f1 = 0.722109\n",
      "Epoch 10, step 475, training loss 0.833814, test_loss 0.726264, accuracy = 0.721968/0.726540, f1 = 0.731778\n",
      "Epoch 10, step 500, training loss 0.946483, test_loss 0.681960, accuracy = 0.745265/0.746789, f1 = 0.738139\n",
      "Epoch 10, step 525, training loss 0.684304, test_loss 0.685120, accuracy = 0.737209/0.744829, f1 = 0.742579\n",
      "Epoch 10, step 550, training loss 0.781744, test_loss 0.675668, accuracy = 0.744394/0.752014, f1 = 0.751092\n",
      "Epoch 10, step 575, training loss 0.808802, test_loss 0.823321, accuracy = 0.683649/0.684955, f1 = 0.690089\n",
      "End of epoch 10, training loss 0.776249, test_loss 0.732959, accuracy = 0.719791/0.722621, f1 = 0.724148\n",
      "Confusion matrix:\n",
      "[[1406  325  164   16]\n",
      " [  64  791  203   89]\n",
      " [  19   69  968   66]\n",
      " [  22   82  155  154]]\n",
      "Epoch 11, step 0, training loss 0.731195, test_loss 0.778600, accuracy = 0.697148/0.702809, f1 = 0.709217\n",
      "Epoch 11, step 25, training loss 0.811234, test_loss 0.696997, accuracy = 0.733508/0.738733, f1 = 0.733975\n",
      "Epoch 11, step 50, training loss 0.739516, test_loss 0.780676, accuracy = 0.679948/0.691705, f1 = 0.706804\n",
      "Epoch 11, step 75, training loss 0.904816, test_loss 0.786209, accuracy = 0.690834/0.694753, f1 = 0.696664\n",
      "Epoch 11, step 100, training loss 0.711635, test_loss 0.659516, accuracy = 0.748095/0.760505, f1 = 0.755634\n",
      "Epoch 11, step 125, training loss 0.844696, test_loss 0.859803, accuracy = 0.656434/0.656651, f1 = 0.661615\n",
      "Epoch 11, step 150, training loss 0.762876, test_loss 0.675616, accuracy = 0.743305/0.749837, f1 = 0.741167\n",
      "Epoch 11, step 175, training loss 0.779480, test_loss 0.679962, accuracy = 0.739604/0.749401, f1 = 0.750635\n",
      "Epoch 11, step 200, training loss 0.839952, test_loss 0.702180, accuracy = 0.730677/0.743740, f1 = 0.744744\n",
      "Epoch 11, step 225, training loss 0.851591, test_loss 0.644403, accuracy = 0.757457/0.766384, f1 = 0.756565\n",
      "Epoch 11, step 250, training loss 1.142527, test_loss 0.742970, accuracy = 0.707599/0.722186, f1 = 0.729185\n",
      "Epoch 11, step 275, training loss 0.909098, test_loss 0.659109, accuracy = 0.751143/0.762900, f1 = 0.758034\n",
      "Epoch 11, step 300, training loss 0.908244, test_loss 0.769378, accuracy = 0.696277/0.705857, f1 = 0.714858\n",
      "Epoch 11, step 325, training loss 0.715604, test_loss 0.683952, accuracy = 0.740475/0.742652, f1 = 0.733073\n",
      "Epoch 11, step 350, training loss 0.813984, test_loss 0.768282, accuracy = 0.700631/0.704550, f1 = 0.707356\n",
      "Epoch 11, step 375, training loss 0.768393, test_loss 0.694000, accuracy = 0.735467/0.740475, f1 = 0.739136\n",
      "Epoch 11, step 400, training loss 0.802895, test_loss 0.706283, accuracy = 0.731766/0.739821, f1 = 0.741954\n",
      "Epoch 11, step 425, training loss 0.840330, test_loss 0.804991, accuracy = 0.682343/0.691487, f1 = 0.704868\n",
      "Epoch 11, step 450, training loss 0.843618, test_loss 0.704150, accuracy = 0.726540/0.731766, f1 = 0.724076\n",
      "Epoch 11, step 475, training loss 0.821474, test_loss 0.731667, accuracy = 0.720444/0.728500, f1 = 0.732063\n",
      "Epoch 11, step 500, training loss 0.865289, test_loss 0.688364, accuracy = 0.737862/0.741128, f1 = 0.737639\n",
      "Epoch 11, step 525, training loss 0.678291, test_loss 0.704479, accuracy = 0.731983/0.742216, f1 = 0.745802\n",
      "Epoch 11, step 550, training loss 0.772655, test_loss 0.649199, accuracy = 0.754191/0.764424, f1 = 0.762816\n",
      "Epoch 11, step 575, training loss 0.794354, test_loss 0.810439, accuracy = 0.689092/0.696712, f1 = 0.703288\n",
      "End of epoch 11, training loss 0.737661, test_loss 0.718886, accuracy = 0.718702/0.733725, f1 = 0.734238\n",
      "Confusion matrix:\n",
      "[[1433  314  149   15]\n",
      " [  73  816  188   70]\n",
      " [  23   77  964   58]\n",
      " [  23   88  145  157]]\n",
      "Epoch 12, step 0, training loss 0.682064, test_loss 0.745621, accuracy = 0.711735/0.722621, f1 = 0.726459\n",
      "Epoch 12, step 25, training loss 0.821724, test_loss 0.671131, accuracy = 0.736338/0.749837, f1 = 0.744809\n",
      "Epoch 12, step 50, training loss 0.694213, test_loss 0.744042, accuracy = 0.709558/0.719138, f1 = 0.726343\n",
      "Epoch 12, step 75, training loss 0.839361, test_loss 0.768848, accuracy = 0.699107/0.702155, f1 = 0.704258\n",
      "Epoch 12, step 100, training loss 0.709549, test_loss 0.656695, accuracy = 0.752885/0.754409, f1 = 0.746471\n",
      "Epoch 12, step 125, training loss 0.775944, test_loss 0.860503, accuracy = 0.656434/0.661006, f1 = 0.671490\n",
      "Epoch 12, step 150, training loss 0.759145, test_loss 0.666857, accuracy = 0.751143/0.755280, f1 = 0.746371\n",
      "Epoch 12, step 175, training loss 0.799561, test_loss 0.667705, accuracy = 0.745482/0.755933, f1 = 0.757007\n",
      "Epoch 12, step 200, training loss 0.846902, test_loss 0.673280, accuracy = 0.745047/0.757239, f1 = 0.756260\n",
      "Epoch 12, step 225, training loss 0.823180, test_loss 0.651323, accuracy = 0.759634/0.762465, f1 = 0.753881\n",
      "Epoch 12, step 250, training loss 1.135059, test_loss 0.739419, accuracy = 0.707816/0.719791, f1 = 0.724500\n",
      "Epoch 12, step 275, training loss 0.904996, test_loss 0.649688, accuracy = 0.759417/0.763989, f1 = 0.762026\n",
      "Epoch 12, step 300, training loss 0.843975, test_loss 0.740141, accuracy = 0.717831/0.722186, f1 = 0.729855\n",
      "Epoch 12, step 325, training loss 0.725097, test_loss 0.680749, accuracy = 0.746135/0.746135, f1 = 0.741262\n",
      "Epoch 12, step 350, training loss 0.775481, test_loss 0.787804, accuracy = 0.684955/0.691269, f1 = 0.693130\n",
      "Epoch 12, step 375, training loss 0.752737, test_loss 0.676734, accuracy = 0.747660/0.748313, f1 = 0.749158\n",
      "Epoch 12, step 400, training loss 0.839593, test_loss 0.703722, accuracy = 0.724145/0.735685, f1 = 0.738083\n",
      "Epoch 12, step 425, training loss 0.857330, test_loss 0.801451, accuracy = 0.682343/0.684084, f1 = 0.695288\n",
      "Epoch 12, step 450, training loss 0.813199, test_loss 0.696137, accuracy = 0.727194/0.731330, f1 = 0.723468\n",
      "Epoch 12, step 475, training loss 0.773485, test_loss 0.724731, accuracy = 0.720444/0.724799, f1 = 0.732088\n",
      "Epoch 12, step 500, training loss 0.801775, test_loss 0.679158, accuracy = 0.735685/0.742652, f1 = 0.740948\n",
      "Epoch 12, step 525, training loss 0.606511, test_loss 0.689037, accuracy = 0.733072/0.741128, f1 = 0.742952\n",
      "Epoch 12, step 550, training loss 0.717475, test_loss 0.654716, accuracy = 0.752449/0.758328, f1 = 0.757103\n",
      "Epoch 12, step 575, training loss 0.740353, test_loss 0.775187, accuracy = 0.696712/0.704768, f1 = 0.711110\n",
      "End of epoch 12, training loss 0.701757, test_loss 0.704700, accuracy = 0.727411/0.739821, f1 = 0.743823\n",
      "Confusion matrix:\n",
      "[[1507  250  131   23]\n",
      " [  87  798  168   94]\n",
      " [  27   82  898  115]\n",
      " [  24   79  115  195]]\n",
      "Epoch 13, step 0, training loss 0.675435, test_loss 0.732802, accuracy = 0.714130/0.727194, f1 = 0.735763\n",
      "Epoch 13, step 25, training loss 0.808944, test_loss 0.672075, accuracy = 0.741781/0.755498, f1 = 0.751900\n",
      "Epoch 13, step 50, training loss 0.695307, test_loss 0.760049, accuracy = 0.694753/0.703026, f1 = 0.715703\n",
      "Epoch 13, step 75, training loss 0.830648, test_loss 0.797904, accuracy = 0.687350/0.688657, f1 = 0.696066\n",
      "Epoch 13, step 100, training loss 0.710721, test_loss 0.647667, accuracy = 0.758110/0.759852, f1 = 0.754720\n",
      "Epoch 13, step 125, training loss 0.760072, test_loss 0.779803, accuracy = 0.700196/0.703244, f1 = 0.710587\n",
      "Epoch 13, step 150, training loss 0.765018, test_loss 0.667880, accuracy = 0.749619/0.754627, f1 = 0.749869\n",
      "Epoch 13, step 175, training loss 0.788918, test_loss 0.678828, accuracy = 0.735685/0.749184, f1 = 0.750617\n",
      "Epoch 13, step 200, training loss 0.781215, test_loss 0.663468, accuracy = 0.748095/0.760070, f1 = 0.758576\n",
      "Epoch 13, step 225, training loss 0.795707, test_loss 0.635393, accuracy = 0.765295/0.769214, f1 = 0.761248\n",
      "Epoch 13, step 250, training loss 1.031054, test_loss 0.718139, accuracy = 0.719356/0.727847, f1 = 0.734292\n",
      "Epoch 13, step 275, training loss 0.787079, test_loss 0.646546, accuracy = 0.754844/0.760287, f1 = 0.761340\n",
      "Epoch 13, step 300, training loss 0.837467, test_loss 0.763427, accuracy = 0.702155/0.711518, f1 = 0.723801\n",
      "Epoch 13, step 325, training loss 0.668249, test_loss 0.667085, accuracy = 0.741563/0.753973, f1 = 0.745764\n",
      "Epoch 13, step 350, training loss 0.705899, test_loss 0.735345, accuracy = 0.717396/0.718485, f1 = 0.719094\n",
      "Epoch 13, step 375, training loss 0.683136, test_loss 0.663089, accuracy = 0.750272/0.749619, f1 = 0.750647\n",
      "Epoch 13, step 400, training loss 0.759881, test_loss 0.713140, accuracy = 0.717831/0.729371, f1 = 0.734174\n",
      "Epoch 13, step 425, training loss 0.856979, test_loss 0.754567, accuracy = 0.702155/0.706945, f1 = 0.711381\n",
      "Epoch 13, step 450, training loss 0.795257, test_loss 0.702297, accuracy = 0.724145/0.726540, f1 = 0.718103\n",
      "Epoch 13, step 475, training loss 0.813137, test_loss 0.725436, accuracy = 0.720226/0.728935, f1 = 0.736684\n",
      "Epoch 13, step 500, training loss 0.767143, test_loss 0.694117, accuracy = 0.728718/0.735902, f1 = 0.733281\n",
      "Epoch 13, step 525, training loss 0.605131, test_loss 0.695141, accuracy = 0.737862/0.741346, f1 = 0.745953\n",
      "Epoch 13, step 550, training loss 0.741279, test_loss 0.686983, accuracy = 0.731330/0.745047, f1 = 0.746115\n",
      "Epoch 13, step 575, training loss 0.764609, test_loss 0.808315, accuracy = 0.686915/0.691922, f1 = 0.702652\n",
      "End of epoch 13, training loss 0.686253, test_loss 0.682764, accuracy = 0.737209/0.741999, f1 = 0.745465\n",
      "Confusion matrix:\n",
      "[[1501  256  130   24]\n",
      " [  77  821  171   78]\n",
      " [  27   81  901  113]\n",
      " [  26   85  117  185]]\n",
      "Epoch 14, step 0, training loss 0.690982, test_loss 0.713621, accuracy = 0.722621/0.732201, f1 = 0.737934\n",
      "Epoch 14, step 25, training loss 0.728332, test_loss 0.655824, accuracy = 0.750272/0.762029, f1 = 0.759663\n",
      "Epoch 14, step 50, training loss 0.634787, test_loss 0.741484, accuracy = 0.705639/0.716525, f1 = 0.727018\n",
      "Epoch 14, step 75, training loss 0.830202, test_loss 0.764053, accuracy = 0.701285/0.706728, f1 = 0.713899\n",
      "Epoch 14, step 100, training loss 0.650234, test_loss 0.648048, accuracy = 0.754627/0.765077, f1 = 0.759571\n",
      "Epoch 14, step 125, training loss 0.717983, test_loss 0.795324, accuracy = 0.689963/0.695624, f1 = 0.701763\n",
      "Epoch 14, step 150, training loss 0.697686, test_loss 0.661007, accuracy = 0.751361/0.758110, f1 = 0.753410\n",
      "Epoch 14, step 175, training loss 0.778387, test_loss 0.691566, accuracy = 0.729589/0.738515, f1 = 0.741614\n",
      "Epoch 14, step 200, training loss 0.771025, test_loss 0.659152, accuracy = 0.752014/0.760941, f1 = 0.762480\n",
      "Epoch 14, step 225, training loss 0.783065, test_loss 0.636886, accuracy = 0.757239/0.766166, f1 = 0.761527\n",
      "Epoch 14, step 250, training loss 1.068870, test_loss 0.748626, accuracy = 0.700196/0.706510, f1 = 0.714608\n",
      "Epoch 14, step 275, training loss 0.763004, test_loss 0.641891, accuracy = 0.756586/0.760287, f1 = 0.760383\n",
      "Epoch 14, step 300, training loss 0.766198, test_loss 0.703368, accuracy = 0.726976/0.739386, f1 = 0.745129\n",
      "Epoch 14, step 325, training loss 0.643899, test_loss 0.662973, accuracy = 0.747224/0.753103, f1 = 0.747816\n",
      "Epoch 14, step 350, training loss 0.770193, test_loss 0.756120, accuracy = 0.700196/0.712388, f1 = 0.714221\n",
      "Epoch 14, step 375, training loss 0.657653, test_loss 0.696283, accuracy = 0.733290/0.738080, f1 = 0.742442\n",
      "Epoch 14, step 400, training loss 0.765262, test_loss 0.743858, accuracy = 0.707163/0.713912, f1 = 0.721323\n",
      "Epoch 14, step 425, training loss 0.857885, test_loss 0.747683, accuracy = 0.705857/0.715872, f1 = 0.722688\n",
      "Epoch 14, step 450, training loss 0.744033, test_loss 0.708865, accuracy = 0.723710/0.727629, f1 = 0.723069\n",
      "Epoch 14, step 475, training loss 0.731494, test_loss 0.719789, accuracy = 0.721315/0.728282, f1 = 0.737350\n",
      "Epoch 14, step 500, training loss 0.779896, test_loss 0.667990, accuracy = 0.748966/0.753538, f1 = 0.750865\n",
      "Epoch 14, step 525, training loss 0.588112, test_loss 0.668493, accuracy = 0.738080/0.752014, f1 = 0.753659\n",
      "Epoch 14, step 550, training loss 0.671887, test_loss 0.663506, accuracy = 0.745047/0.748530, f1 = 0.746505\n",
      "Epoch 14, step 575, training loss 0.760165, test_loss 0.778982, accuracy = 0.704550/0.706728, f1 = 0.710598\n",
      "End of epoch 14, training loss 0.695474, test_loss 0.703916, accuracy = 0.724799/0.738297, f1 = 0.744832\n",
      "Confusion matrix:\n",
      "[[1515  240  120   36]\n",
      " [  88  798  163   98]\n",
      " [  26   80  853  163]\n",
      " [  27   76   85  225]]\n",
      "Epoch 15, step 0, training loss 0.647605, test_loss 0.731337, accuracy = 0.714348/0.720880, f1 = 0.730739\n",
      "Epoch 15, step 25, training loss 0.719256, test_loss 0.669683, accuracy = 0.745482/0.752449, f1 = 0.752956\n",
      "Epoch 15, step 50, training loss 0.633281, test_loss 0.746352, accuracy = 0.707816/0.719138, f1 = 0.731314\n",
      "Epoch 15, step 75, training loss 0.780322, test_loss 0.761331, accuracy = 0.699760/0.713259, f1 = 0.722592\n",
      "Epoch 15, step 100, training loss 0.662363, test_loss 0.656762, accuracy = 0.747442/0.760070, f1 = 0.754680\n",
      "Epoch 15, step 125, training loss 0.696858, test_loss 0.779665, accuracy = 0.694535/0.707816, f1 = 0.715269\n",
      "Epoch 15, step 150, training loss 0.731683, test_loss 0.652045, accuracy = 0.752449/0.757892, f1 = 0.750618\n",
      "Epoch 15, step 175, training loss 0.746681, test_loss 0.679891, accuracy = 0.735032/0.748530, f1 = 0.752142\n",
      "Epoch 15, step 200, training loss 0.771962, test_loss 0.685067, accuracy = 0.731330/0.746789, f1 = 0.751391\n",
      "Epoch 15, step 225, training loss 0.731192, test_loss 0.636577, accuracy = 0.759417/0.765730, f1 = 0.763481\n",
      "Epoch 15, step 250, training loss 0.998579, test_loss 0.756137, accuracy = 0.699760/0.709993, f1 = 0.719595\n",
      "Epoch 15, step 275, training loss 0.828852, test_loss 0.637597, accuracy = 0.756804/0.766384, f1 = 0.766030\n",
      "Epoch 15, step 300, training loss 0.741216, test_loss 0.720198, accuracy = 0.721315/0.733943, f1 = 0.740875\n",
      "Epoch 15, step 325, training loss 0.661131, test_loss 0.658743, accuracy = 0.741346/0.752885, f1 = 0.747953\n",
      "Epoch 15, step 350, training loss 0.720898, test_loss 0.746643, accuracy = 0.707599/0.713912, f1 = 0.716804\n",
      "Epoch 15, step 375, training loss 0.639213, test_loss 0.671441, accuracy = 0.741999/0.748095, f1 = 0.750167\n",
      "Epoch 15, step 400, training loss 0.737201, test_loss 0.721397, accuracy = 0.715001/0.721315, f1 = 0.729060\n",
      "Epoch 15, step 425, training loss 0.816677, test_loss 0.697019, accuracy = 0.729806/0.737209, f1 = 0.740671\n",
      "Epoch 15, step 450, training loss 0.785297, test_loss 0.680741, accuracy = 0.733290/0.741781, f1 = 0.738134\n",
      "Epoch 15, step 475, training loss 0.744959, test_loss 0.744889, accuracy = 0.709340/0.718702, f1 = 0.731488\n",
      "Epoch 15, step 500, training loss 0.701622, test_loss 0.672316, accuracy = 0.743740/0.749619, f1 = 0.748136\n",
      "Epoch 15, step 525, training loss 0.657065, test_loss 0.667326, accuracy = 0.733725/0.751796, f1 = 0.754874\n",
      "Epoch 15, step 550, training loss 0.679513, test_loss 0.659898, accuracy = 0.744611/0.755280, f1 = 0.752428\n",
      "Epoch 15, step 575, training loss 0.729164, test_loss 0.778308, accuracy = 0.698890/0.706728, f1 = 0.712577\n",
      "End of epoch 15, training loss 0.716716, test_loss 0.682909, accuracy = 0.740257/0.757892, f1 = 0.759769\n",
      "Confusion matrix:\n",
      "[[1530  244  103   34]\n",
      " [  85  855  150   57]\n",
      " [  26   90  913   93]\n",
      " [  26   93  111  183]]\n",
      "Epoch 16, step 0, training loss 0.630096, test_loss 0.720028, accuracy = 0.727411/0.740039, f1 = 0.747306\n",
      "Epoch 16, step 25, training loss 0.681874, test_loss 0.658954, accuracy = 0.749619/0.760070, f1 = 0.758926\n",
      "Epoch 16, step 50, training loss 0.631069, test_loss 0.801577, accuracy = 0.678206/0.694100, f1 = 0.713092\n",
      "Epoch 16, step 75, training loss 0.693313, test_loss 0.729516, accuracy = 0.715219/0.731766, f1 = 0.740204\n",
      "Epoch 16, step 100, training loss 0.691458, test_loss 0.634509, accuracy = 0.762029/0.768125, f1 = 0.760928\n",
      "Epoch 16, step 125, training loss 0.683907, test_loss 0.767614, accuracy = 0.699107/0.701285, f1 = 0.707182\n",
      "Epoch 16, step 150, training loss 0.691226, test_loss 0.648376, accuracy = 0.748313/0.763553, f1 = 0.758833\n",
      "Epoch 16, step 175, training loss 0.710992, test_loss 0.673063, accuracy = 0.735467/0.745918, f1 = 0.749983\n",
      "Epoch 16, step 200, training loss 0.752417, test_loss 0.686275, accuracy = 0.735032/0.740692, f1 = 0.746858\n",
      "Epoch 16, step 225, training loss 0.667814, test_loss 0.629951, accuracy = 0.759634/0.770738, f1 = 0.767974\n",
      "Epoch 16, step 250, training loss 0.934457, test_loss 0.713607, accuracy = 0.720880/0.728935, f1 = 0.736289\n",
      "Epoch 16, step 275, training loss 0.726540, test_loss 0.619047, accuracy = 0.762247/0.772262, f1 = 0.772019\n",
      "Epoch 16, step 300, training loss 0.720689, test_loss 0.757010, accuracy = 0.706510/0.723928, f1 = 0.737440\n",
      "Epoch 16, step 325, training loss 0.654451, test_loss 0.664949, accuracy = 0.741999/0.750054, f1 = 0.744967\n",
      "Epoch 16, step 350, training loss 0.715163, test_loss 0.775968, accuracy = 0.695406/0.706728, f1 = 0.709056\n",
      "Epoch 16, step 375, training loss 0.589610, test_loss 0.644931, accuracy = 0.751796/0.758328, f1 = 0.759016\n",
      "Epoch 16, step 400, training loss 0.701714, test_loss 0.713607, accuracy = 0.722839/0.728500, f1 = 0.736094\n",
      "Epoch 16, step 425, training loss 0.773796, test_loss 0.708124, accuracy = 0.722404/0.731548, f1 = 0.735325\n",
      "Epoch 16, step 450, training loss 0.698559, test_loss 0.696406, accuracy = 0.730677/0.735032, f1 = 0.729305\n",
      "Epoch 16, step 475, training loss 0.695065, test_loss 0.709039, accuracy = 0.720662/0.730459, f1 = 0.740944\n",
      "Epoch 16, step 500, training loss 0.714402, test_loss 0.665147, accuracy = 0.746135/0.758763, f1 = 0.757699\n",
      "Epoch 16, step 525, training loss 0.609596, test_loss 0.659418, accuracy = 0.750054/0.757892, f1 = 0.759570\n",
      "Epoch 16, step 550, training loss 0.667331, test_loss 0.647234, accuracy = 0.749619/0.760941, f1 = 0.759306\n",
      "Epoch 16, step 575, training loss 0.685176, test_loss 0.781235, accuracy = 0.697801/0.708252, f1 = 0.717034\n",
      "End of epoch 16, training loss 0.631800, test_loss 0.662207, accuracy = 0.751579/0.760723, f1 = 0.762472\n",
      "Confusion matrix:\n",
      "[[1586  207   86   32]\n",
      " [ 109  839  127   72]\n",
      " [  34  112  878   98]\n",
      " [  31   90  101  191]]\n",
      "Epoch 17, step 0, training loss 0.639194, test_loss 0.691081, accuracy = 0.735032/0.743305, f1 = 0.749016\n",
      "Epoch 17, step 25, training loss 0.670348, test_loss 0.653967, accuracy = 0.754409/0.757457, f1 = 0.758056\n",
      "Epoch 17, step 50, training loss 0.612255, test_loss 0.781449, accuracy = 0.690398/0.703680, f1 = 0.721524\n",
      "Epoch 17, step 75, training loss 0.749759, test_loss 0.733271, accuracy = 0.721968/0.729806, f1 = 0.739952\n",
      "Epoch 17, step 100, training loss 0.664313, test_loss 0.617483, accuracy = 0.767255/0.773133, f1 = 0.766482\n",
      "Epoch 17, step 125, training loss 0.639893, test_loss 0.742549, accuracy = 0.708687/0.723492, f1 = 0.726763\n",
      "Epoch 17, step 150, training loss 0.640637, test_loss 0.651489, accuracy = 0.749184/0.762900, f1 = 0.758475\n",
      "Epoch 17, step 175, training loss 0.677807, test_loss 0.676639, accuracy = 0.742434/0.751361, f1 = 0.754325\n",
      "Epoch 17, step 200, training loss 0.788037, test_loss 0.712370, accuracy = 0.720880/0.730459, f1 = 0.737725\n",
      "Epoch 17, step 225, training loss 0.766304, test_loss 0.633143, accuracy = 0.766601/0.769214, f1 = 0.766058\n",
      "Epoch 17, step 250, training loss 1.019687, test_loss 0.745619, accuracy = 0.705857/0.717178, f1 = 0.725660\n",
      "Epoch 17, step 275, training loss 0.719328, test_loss 0.624127, accuracy = 0.768343/0.769214, f1 = 0.766433\n",
      "Epoch 17, step 300, training loss 0.725697, test_loss 0.704175, accuracy = 0.729806/0.740475, f1 = 0.747548\n",
      "Epoch 17, step 325, training loss 0.593559, test_loss 0.658625, accuracy = 0.744611/0.750708, f1 = 0.747395\n",
      "Epoch 17, step 350, training loss 0.731506, test_loss 0.764895, accuracy = 0.702809/0.711518, f1 = 0.716096\n",
      "Epoch 17, step 375, training loss 0.586403, test_loss 0.673614, accuracy = 0.740910/0.749837, f1 = 0.750770\n",
      "Epoch 17, step 400, training loss 0.675790, test_loss 0.730452, accuracy = 0.708905/0.724363, f1 = 0.731331\n",
      "Epoch 17, step 425, training loss 0.805270, test_loss 0.701623, accuracy = 0.721968/0.732201, f1 = 0.736505\n",
      "Epoch 17, step 450, training loss 0.730602, test_loss 0.704466, accuracy = 0.727847/0.732854, f1 = 0.732015\n",
      "Epoch 17, step 475, training loss 0.697717, test_loss 0.741819, accuracy = 0.702373/0.716307, f1 = 0.730335\n",
      "Epoch 17, step 500, training loss 0.650290, test_loss 0.679539, accuracy = 0.743958/0.758110, f1 = 0.757476\n",
      "Epoch 17, step 525, training loss 0.567648, test_loss 0.663982, accuracy = 0.739168/0.754191, f1 = 0.755406\n",
      "Epoch 17, step 550, training loss 0.655434, test_loss 0.640290, accuracy = 0.748748/0.759199, f1 = 0.756040\n",
      "Epoch 17, step 575, training loss 0.721854, test_loss 0.779867, accuracy = 0.698672/0.708469, f1 = 0.718760\n",
      "End of epoch 17, training loss 0.610990, test_loss 0.674073, accuracy = 0.745918/0.753103, f1 = 0.755202\n",
      "Confusion matrix:\n",
      "[[1510  258  110   33]\n",
      " [  90  852  148   57]\n",
      " [  27   97  908   90]\n",
      " [  29   86  109  189]]\n",
      "Epoch 18, step 0, training loss 0.622828, test_loss 0.698936, accuracy = 0.726540/0.741128, f1 = 0.745964\n",
      "Epoch 18, step 25, training loss 0.658388, test_loss 0.660234, accuracy = 0.748313/0.756586, f1 = 0.755095\n",
      "Epoch 18, step 50, training loss 0.581111, test_loss 0.776567, accuracy = 0.690398/0.705204, f1 = 0.722499\n",
      "Epoch 18, step 75, training loss 0.700411, test_loss 0.726050, accuracy = 0.713477/0.731548, f1 = 0.741952\n",
      "Epoch 18, step 100, training loss 0.676710, test_loss 0.629797, accuracy = 0.763118/0.772480, f1 = 0.764139\n",
      "Epoch 18, step 125, training loss 0.719263, test_loss 0.702726, accuracy = 0.734161/0.740692, f1 = 0.740109\n",
      "Epoch 18, step 150, training loss 0.651465, test_loss 0.672316, accuracy = 0.744611/0.759634, f1 = 0.757009\n",
      "Epoch 18, step 175, training loss 0.702824, test_loss 0.692943, accuracy = 0.727411/0.744829, f1 = 0.750593\n",
      "Epoch 18, step 200, training loss 0.761517, test_loss 0.714978, accuracy = 0.715437/0.730024, f1 = 0.738064\n",
      "Epoch 18, step 225, training loss 0.764891, test_loss 0.628997, accuracy = 0.764206/0.773351, f1 = 0.766733\n",
      "Epoch 18, step 250, training loss 0.886161, test_loss 0.742632, accuracy = 0.704115/0.720880, f1 = 0.729070\n",
      "Epoch 18, step 275, training loss 0.735440, test_loss 0.629688, accuracy = 0.757239/0.770738, f1 = 0.768120\n",
      "Epoch 18, step 300, training loss 0.713575, test_loss 0.717538, accuracy = 0.724581/0.736338, f1 = 0.742203\n",
      "Epoch 18, step 325, training loss 0.591692, test_loss 0.661047, accuracy = 0.741999/0.750490, f1 = 0.748812\n",
      "Epoch 18, step 350, training loss 0.716351, test_loss 0.710986, accuracy = 0.727847/0.738515, f1 = 0.741673\n",
      "Epoch 18, step 375, training loss 0.545611, test_loss 0.659529, accuracy = 0.749401/0.755933, f1 = 0.758045\n",
      "Epoch 18, step 400, training loss 0.660280, test_loss 0.751994, accuracy = 0.707816/0.716307, f1 = 0.726868\n",
      "Epoch 18, step 425, training loss 0.704016, test_loss 0.679598, accuracy = 0.740692/0.746571, f1 = 0.749295\n",
      "Epoch 18, step 450, training loss 0.694917, test_loss 0.792748, accuracy = 0.687133/0.698672, f1 = 0.703823\n",
      "Epoch 18, step 475, training loss 0.669648, test_loss 0.735329, accuracy = 0.714783/0.721315, f1 = 0.734313\n",
      "Epoch 18, step 500, training loss 0.621011, test_loss 0.672338, accuracy = 0.747006/0.757022, f1 = 0.756487\n",
      "Epoch 18, step 525, training loss 0.570678, test_loss 0.648165, accuracy = 0.751361/0.760941, f1 = 0.761866\n",
      "Epoch 18, step 550, training loss 0.657930, test_loss 0.665239, accuracy = 0.743087/0.752014, f1 = 0.752115\n",
      "Epoch 18, step 575, training loss 0.656160, test_loss 0.707461, accuracy = 0.731983/0.743087, f1 = 0.747225\n",
      "End of epoch 18, training loss 0.590699, test_loss 0.670183, accuracy = 0.747224/0.757022, f1 = 0.758579\n",
      "Confusion matrix:\n",
      "[[1533  228  113   37]\n",
      " [  99  830  152   66]\n",
      " [  30   82  924   86]\n",
      " [  30   82  111  190]]\n",
      "Epoch 19, step 0, training loss 0.624076, test_loss 0.687994, accuracy = 0.741999/0.748966, f1 = 0.753196\n",
      "Epoch 19, step 25, training loss 0.637699, test_loss 0.683148, accuracy = 0.740910/0.755933, f1 = 0.758815\n",
      "Epoch 19, step 50, training loss 0.522555, test_loss 0.822308, accuracy = 0.672327/0.687568, f1 = 0.709923\n",
      "Epoch 19, step 75, training loss 0.661002, test_loss 0.696586, accuracy = 0.727847/0.742216, f1 = 0.750906\n",
      "Epoch 19, step 100, training loss 0.601344, test_loss 0.638100, accuracy = 0.763989/0.767908, f1 = 0.762443\n",
      "Epoch 19, step 125, training loss 0.620895, test_loss 0.703519, accuracy = 0.731113/0.744394, f1 = 0.743533\n",
      "Epoch 19, step 150, training loss 0.651952, test_loss 0.687114, accuracy = 0.738951/0.750490, f1 = 0.747628\n",
      "Epoch 19, step 175, training loss 0.661939, test_loss 0.712422, accuracy = 0.730024/0.738297, f1 = 0.746362\n",
      "Epoch 19, step 200, training loss 0.821070, test_loss 0.722728, accuracy = 0.712171/0.732419, f1 = 0.738938\n",
      "Epoch 19, step 225, training loss 0.634190, test_loss 0.663985, accuracy = 0.753320/0.750490, f1 = 0.747598\n",
      "Epoch 19, step 250, training loss 0.942224, test_loss 0.785472, accuracy = 0.697583/0.704115, f1 = 0.719067\n",
      "Epoch 19, step 275, training loss 0.680060, test_loss 0.673617, accuracy = 0.736991/0.745265, f1 = 0.746030\n",
      "Epoch 19, step 300, training loss 0.659705, test_loss 0.726089, accuracy = 0.720880/0.727411, f1 = 0.734538\n",
      "Epoch 19, step 325, training loss 0.592237, test_loss 0.672140, accuracy = 0.745482/0.752667, f1 = 0.753243\n",
      "Epoch 19, step 350, training loss 0.662133, test_loss 0.765232, accuracy = 0.711300/0.720226, f1 = 0.725260\n",
      "Epoch 19, step 375, training loss 0.538620, test_loss 0.687905, accuracy = 0.741128/0.747442, f1 = 0.751469\n",
      "Epoch 19, step 400, training loss 0.635384, test_loss 0.750034, accuracy = 0.709340/0.715654, f1 = 0.726903\n",
      "Epoch 19, step 425, training loss 0.745215, test_loss 0.715640, accuracy = 0.717178/0.728500, f1 = 0.734597\n",
      "Epoch 19, step 450, training loss 0.650116, test_loss 0.827763, accuracy = 0.675376/0.685391, f1 = 0.692462\n",
      "Epoch 19, step 475, training loss 0.594753, test_loss 0.727718, accuracy = 0.715001/0.729371, f1 = 0.739847\n",
      "Epoch 19, step 500, training loss 0.623782, test_loss 0.656714, accuracy = 0.751361/0.763336, f1 = 0.761429\n",
      "Epoch 19, step 525, training loss 0.557512, test_loss 0.646433, accuracy = 0.754627/0.763989, f1 = 0.763938\n",
      "Epoch 19, step 550, training loss 0.604525, test_loss 0.683967, accuracy = 0.735685/0.748966, f1 = 0.745262\n",
      "Epoch 19, step 575, training loss 0.667358, test_loss 0.717957, accuracy = 0.727194/0.734378, f1 = 0.737665\n",
      "End of epoch 19, training loss 0.564958, test_loss 0.667312, accuracy = 0.750272/0.758763, f1 = 0.760798\n",
      "Confusion matrix:\n",
      "[[1568  201  108   34]\n",
      " [ 116  809  149   73]\n",
      " [  33   76  904  109]\n",
      " [  32   76  101  204]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "tr_loss, tst_loss = patch_model.train_loop(sess,\n",
    "                                           train['patches']*255,\n",
    "                                           train['labels'],\n",
    "                                           test['patches']*255,\n",
    "                                           test['labels'],\n",
    "                                           num_epochs,\n",
    "                                           batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Saved to: context_models/patch_models/v2/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "saver = tf.train.Saver(write_version=1)\n",
    "save_path = saver.save(sess, \"context_models/patch_models/v2/model.ckpt\")\n",
    "print \"Saved to:\", save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore the model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"context_models/patch_models/v2/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76079822"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we get the expected f1\n",
    "sess.run(patch_model.f1, feed_dict={\n",
    "        patch_model.patch_tensor:np.concatenate([test['patches'], validation['patches']], axis=0)*255,\n",
    "        patch_model.label_tensor:np.concatenate([test['labels'], validation['labels']], axis=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Non-Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1559 patches because too close to image border\n",
      "Dropped 523 patches because too close to image border\n"
     ]
    }
   ],
   "source": [
    "(train_vanilla, _) = utils.get_dataset_divided_per_image(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply NEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nep_test_probabilities = context_classifier.get_all_NEP_predictions(sess, test, patch_model, all_imgs)\n",
    "nep_validation_probabilities = context_classifier.get_all_NEP_predictions(sess, validation, patch_model, all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777003\n"
     ]
    }
   ],
   "source": [
    "# Okay cool, let's try applying it to everything\n",
    "print sess.run(patch_model.f1, feed_dict={\n",
    "        patch_model.inference_predictions: np.concatenate([nep_test_probabilities, nep_validation_probabilities], axis=0),\n",
    "        patch_model.label_tensor: np.concatenate([test['labels'], validation['labels']], axis=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Probability Weight Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_size = 27\n",
    "context = 5\n",
    "test['probabilities'], test['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods_with_NEP(sess, test, patch_model, all_imgs, bin_size=bin_size, context_length=context)\n",
    "validation['probabilities'], validation['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods_with_NEP(sess, validation, patch_model, all_imgs, bin_size=bin_size, context_length=context)\n",
    "train_vanilla['probabilities'], train_vanilla['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods_with_NEP(sess, train_vanilla, patch_model, all_imgs, bin_size=bin_size, context_length=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's just try to balance out the classes a little\n",
    "selectors = []\n",
    "for c in xrange(train_vanilla['labels'].shape[1]):\n",
    "    selectors.append(np.nonzero(train_vanilla['labels'][:,c])[0])\n",
    "largest_class_size = max([len(s) for s in selectors])\n",
    "#print largest_class_size\n",
    "expanded_selectors = []\n",
    "for s in selectors:\n",
    "    expansion_factor = largest_class_size / len(s) + 1\n",
    "    expanded_selectors.append(np.repeat(s, expansion_factor)[:largest_class_size])\n",
    "    \n",
    "np.random.seed(649) # repeatability\n",
    "balanced_train_vanilla = {}\n",
    "N = len(selectors) * largest_class_size\n",
    "perm = np.random.permutation(N)\n",
    "for (k, v) in train_vanilla.iteritems():\n",
    "    new = np.concatenate([v[s] for s in expanded_selectors], axis=0)\n",
    "    #print new.shape\n",
    "    balanced_train_vanilla[k] = new[perm]\n",
    "    #print balanced_train_vanilla[k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches (20696, 27, 27, 3)\n",
      "probabilities (20696, 4)\n",
      "labels (20696, 4)\n",
      "weight_neighbourhoods (20696, 5, 5, 4)\n",
      "centres (20696, 2)\n",
      "img_ids (20696,)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in balanced_train_vanilla.iteritems():\n",
    "    print k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174\n",
      "5174\n",
      "5174\n",
      "5174\n"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,0])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,1])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,2])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327541378654\n",
      "0.253408586467\n",
      "0.328112118714\n",
      "0.0909379161646\n"
     ]
    }
   ],
   "source": [
    "N = len(train_vanilla['labels'])\n",
    "print np.count_nonzero(train_vanilla['labels'][:,0]) / float(N)\n",
    "print np.count_nonzero(train_vanilla['labels'][:,1]) / float(N)\n",
    "print np.count_nonzero(train_vanilla['labels'][:,2]) / float(N)\n",
    "print np.count_nonzero(train_vanilla['labels'][:,3]) / float(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'context_classifier' from 'context_classifier.pyc'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(context_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass # sess doesn't exist yet!\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "learning_rate = tf.Variable(0.001, trainable=False)\n",
    "context_model = context_classifier.ContextModel(learning_rate=learning_rate, context_length=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From context_classifier.py:248 in train_loop.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0, step 0, training loss 1.684377, test_loss 1.695666, accuracy = 0.237701/0.240749, f1 = nan\n",
      "Epoch 0, step 25, training loss 1.226206, test_loss 1.331736, accuracy = 0.383108/0.261210, f1 = nan\n",
      "Epoch 0, step 50, training loss 1.043262, test_loss 1.107194, accuracy = 0.532434/0.276448, f1 = nan\n",
      "Epoch 0, step 75, training loss 0.959183, test_loss 1.038253, accuracy = 0.587723/0.261210, f1 = nan\n",
      "Epoch 0, step 100, training loss 0.902463, test_loss 0.987363, accuracy = 0.608620/0.261210, f1 = nan\n",
      "Epoch 0, step 125, training loss 0.912469, test_loss 0.945487, accuracy = 0.653026/0.261210, f1 = nan\n",
      "Epoch 0, step 150, training loss 0.890530, test_loss 0.936905, accuracy = 0.655638/0.261210, f1 = nan\n",
      "Epoch 0, step 175, training loss 0.921026, test_loss 0.929619, accuracy = 0.675229/0.261210, f1 = nan\n",
      "Epoch 0, step 200, training loss 0.772902, test_loss 0.925850, accuracy = 0.678276/0.261210, f1 = nan\n",
      "End of epoch 0, training loss 0.830646, test_loss 0.918681, accuracy = 0.681759/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 1, step 0, training loss 0.805151, test_loss 0.924754, accuracy = 0.678711/0.261210, f1 = nan\n",
      "Epoch 1, step 25, training loss 0.813373, test_loss 0.907999, accuracy = 0.689595/0.261210, f1 = nan\n",
      "Epoch 1, step 50, training loss 0.822063, test_loss 0.887233, accuracy = 0.702656/0.261210, f1 = nan\n",
      "Epoch 1, step 75, training loss 0.820188, test_loss 0.880739, accuracy = 0.697867/0.261210, f1 = nan\n",
      "Epoch 1, step 100, training loss 0.824400, test_loss 0.886655, accuracy = 0.705268/0.261210, f1 = nan\n",
      "Epoch 1, step 125, training loss 0.778299, test_loss 0.895844, accuracy = 0.694819/0.261210, f1 = nan\n",
      "Epoch 1, step 150, training loss 0.825770, test_loss 0.877703, accuracy = 0.705703/0.261210, f1 = nan\n",
      "Epoch 1, step 175, training loss 0.862010, test_loss 0.867080, accuracy = 0.710057/0.261210, f1 = nan\n",
      "Epoch 1, step 200, training loss 0.740397, test_loss 0.872800, accuracy = 0.708315/0.261210, f1 = nan\n",
      "End of epoch 1, training loss 0.758993, test_loss 0.867008, accuracy = 0.716152/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 2, step 0, training loss 0.781704, test_loss 0.884399, accuracy = 0.717458/0.261210, f1 = nan\n",
      "Epoch 2, step 25, training loss 0.737297, test_loss 0.858901, accuracy = 0.719199/0.261210, f1 = nan\n",
      "Epoch 2, step 50, training loss 0.783486, test_loss 0.866865, accuracy = 0.722246/0.261210, f1 = nan\n",
      "Epoch 2, step 75, training loss 0.773914, test_loss 0.853214, accuracy = 0.710927/0.261210, f1 = nan\n",
      "Epoch 2, step 100, training loss 0.748922, test_loss 0.835521, accuracy = 0.734872/0.261210, f1 = nan\n",
      "Epoch 2, step 125, training loss 0.807168, test_loss 0.852322, accuracy = 0.715281/0.261210, f1 = nan\n",
      "Epoch 2, step 150, training loss 0.762115, test_loss 0.846223, accuracy = 0.734001/0.261210, f1 = nan\n",
      "Epoch 2, step 175, training loss 0.820639, test_loss 0.841763, accuracy = 0.729212/0.261210, f1 = nan\n",
      "Epoch 2, step 200, training loss 0.688969, test_loss 0.851445, accuracy = 0.723117/0.261210, f1 = nan\n",
      "End of epoch 2, training loss 0.735994, test_loss 0.842076, accuracy = 0.730953/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 3, step 0, training loss 0.737385, test_loss 0.835071, accuracy = 0.737919/0.261210, f1 = nan\n",
      "Epoch 3, step 25, training loss 0.706536, test_loss 0.829930, accuracy = 0.734001/0.261210, f1 = nan\n",
      "Epoch 3, step 50, training loss 0.784436, test_loss 0.818428, accuracy = 0.739225/0.261210, f1 = nan\n",
      "Epoch 3, step 75, training loss 0.757112, test_loss 0.826146, accuracy = 0.737048/0.261210, f1 = nan\n",
      "Epoch 3, step 100, training loss 0.761146, test_loss 0.827898, accuracy = 0.740096/0.261210, f1 = nan\n",
      "Epoch 3, step 125, training loss 0.772611, test_loss 0.826836, accuracy = 0.742708/0.261210, f1 = nan\n",
      "Epoch 3, step 150, training loss 0.728458, test_loss 0.818984, accuracy = 0.736613/0.261210, f1 = nan\n",
      "Epoch 3, step 175, training loss 0.792591, test_loss 0.832473, accuracy = 0.736613/0.261210, f1 = nan\n",
      "Epoch 3, step 200, training loss 0.712508, test_loss 0.829708, accuracy = 0.742708/0.261210, f1 = nan\n",
      "End of epoch 3, training loss 0.698418, test_loss 0.824661, accuracy = 0.730953/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 4, step 0, training loss 0.724395, test_loss 0.823726, accuracy = 0.734872/0.261210, f1 = nan\n",
      "Epoch 4, step 25, training loss 0.690453, test_loss 0.820711, accuracy = 0.745320/0.261210, f1 = nan\n",
      "Epoch 4, step 50, training loss 0.740841, test_loss 0.812842, accuracy = 0.748803/0.261210, f1 = nan\n",
      "Epoch 4, step 75, training loss 0.732413, test_loss 0.825716, accuracy = 0.732695/0.261210, f1 = nan\n",
      "Epoch 4, step 100, training loss 0.673199, test_loss 0.815398, accuracy = 0.744014/0.261210, f1 = nan\n",
      "Epoch 4, step 125, training loss 0.774180, test_loss 0.833358, accuracy = 0.734872/0.261210, f1 = nan\n",
      "Epoch 4, step 150, training loss 0.686564, test_loss 0.818404, accuracy = 0.746626/0.261210, f1 = nan\n",
      "Epoch 4, step 175, training loss 0.807603, test_loss 0.831542, accuracy = 0.730083/0.261210, f1 = nan\n",
      "Epoch 4, step 200, training loss 0.714122, test_loss 0.829024, accuracy = 0.737919/0.261210, f1 = nan\n",
      "End of epoch 4, training loss 0.663517, test_loss 0.824922, accuracy = 0.734872/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 5, step 0, training loss 0.723675, test_loss 0.832736, accuracy = 0.742272/0.261210, f1 = nan\n",
      "Epoch 5, step 25, training loss 0.736368, test_loss 0.822876, accuracy = 0.750109/0.261210, f1 = nan\n",
      "Epoch 5, step 50, training loss 0.777592, test_loss 0.810699, accuracy = 0.742272/0.261210, f1 = nan\n",
      "Epoch 5, step 75, training loss 0.729913, test_loss 0.803017, accuracy = 0.750980/0.261210, f1 = nan\n",
      "Epoch 5, step 100, training loss 0.658592, test_loss 0.821121, accuracy = 0.745320/0.261210, f1 = nan\n",
      "Epoch 5, step 125, training loss 0.737426, test_loss 0.815629, accuracy = 0.738790/0.261210, f1 = nan\n",
      "Epoch 5, step 150, training loss 0.737391, test_loss 0.813127, accuracy = 0.747932/0.261210, f1 = nan\n",
      "Epoch 5, step 175, training loss 0.880008, test_loss 0.826046, accuracy = 0.741402/0.261210, f1 = nan\n",
      "Epoch 5, step 200, training loss 0.679630, test_loss 0.827225, accuracy = 0.741402/0.261210, f1 = nan\n",
      "End of epoch 5, training loss 0.665303, test_loss 0.820807, accuracy = 0.739660/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 6, step 0, training loss 0.696171, test_loss 0.811774, accuracy = 0.745320/0.261210, f1 = nan\n",
      "Epoch 6, step 25, training loss 0.685531, test_loss 0.830593, accuracy = 0.736178/0.261210, f1 = nan\n",
      "Epoch 6, step 50, training loss 0.740741, test_loss 0.806533, accuracy = 0.749673/0.261210, f1 = nan\n",
      "Epoch 6, step 75, training loss 0.742052, test_loss 0.810901, accuracy = 0.749238/0.261210, f1 = nan\n",
      "Epoch 6, step 100, training loss 0.664405, test_loss 0.812796, accuracy = 0.747932/0.261210, f1 = nan\n",
      "Epoch 6, step 125, training loss 0.700024, test_loss 0.808570, accuracy = 0.742273/0.261210, f1 = nan\n",
      "Epoch 6, step 150, training loss 0.680153, test_loss 0.806385, accuracy = 0.754898/0.261210, f1 = nan\n",
      "Epoch 6, step 175, training loss 0.758737, test_loss 0.818042, accuracy = 0.735742/0.261210, f1 = nan\n",
      "Epoch 6, step 200, training loss 0.651643, test_loss 0.816418, accuracy = 0.744449/0.261210, f1 = nan\n",
      "End of epoch 6, training loss 0.688345, test_loss 0.812958, accuracy = 0.744014/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 7, step 0, training loss 0.724119, test_loss 0.813014, accuracy = 0.737919/0.261210, f1 = nan\n",
      "Epoch 7, step 25, training loss 0.674798, test_loss 0.810806, accuracy = 0.740531/0.261210, f1 = nan\n",
      "Epoch 7, step 50, training loss 0.715239, test_loss 0.791308, accuracy = 0.759251/0.261210, f1 = nan\n",
      "Epoch 7, step 75, training loss 0.703042, test_loss 0.802245, accuracy = 0.744449/0.261210, f1 = nan\n",
      "Epoch 7, step 100, training loss 0.595574, test_loss 0.805095, accuracy = 0.752286/0.261210, f1 = nan\n",
      "Epoch 7, step 125, training loss 0.728134, test_loss 0.798056, accuracy = 0.751850/0.261210, f1 = nan\n",
      "Epoch 7, step 150, training loss 0.640259, test_loss 0.803235, accuracy = 0.749673/0.261210, f1 = nan\n",
      "Epoch 7, step 175, training loss 0.702107, test_loss 0.810063, accuracy = 0.745320/0.261210, f1 = nan\n",
      "Epoch 7, step 200, training loss 0.683267, test_loss 0.814383, accuracy = 0.745320/0.261210, f1 = nan\n",
      "End of epoch 7, training loss 0.683321, test_loss 0.813387, accuracy = 0.744014/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 8, step 0, training loss 0.754879, test_loss 0.821910, accuracy = 0.733130/0.261210, f1 = nan\n",
      "Epoch 8, step 25, training loss 0.687703, test_loss 0.813445, accuracy = 0.744885/0.261210, f1 = nan\n",
      "Epoch 8, step 50, training loss 0.747754, test_loss 0.799224, accuracy = 0.747932/0.261210, f1 = nan\n",
      "Epoch 8, step 75, training loss 0.691475, test_loss 0.812441, accuracy = 0.744449/0.261210, f1 = nan\n",
      "Epoch 8, step 100, training loss 0.632733, test_loss 0.806165, accuracy = 0.743143/0.261210, f1 = nan\n",
      "Epoch 8, step 125, training loss 0.705977, test_loss 0.800601, accuracy = 0.753156/0.261210, f1 = nan\n",
      "Epoch 8, step 150, training loss 0.658655, test_loss 0.815115, accuracy = 0.747497/0.261210, f1 = nan\n",
      "Epoch 8, step 175, training loss 0.742985, test_loss 0.823977, accuracy = 0.738790/0.261210, f1 = nan\n",
      "Epoch 8, step 200, training loss 0.654586, test_loss 0.822166, accuracy = 0.737484/0.262516, f1 = nan\n",
      "End of epoch 8, training loss 0.630371, test_loss 0.803496, accuracy = 0.739660/0.261646, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  1 936   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 9, step 0, training loss 0.684390, test_loss 0.821800, accuracy = 0.742273/0.261646, f1 = nan\n",
      "Epoch 9, step 25, training loss 0.682965, test_loss 0.820305, accuracy = 0.740966/0.262081, f1 = nan\n",
      "Epoch 9, step 50, training loss 0.695383, test_loss 0.792860, accuracy = 0.751415/0.261210, f1 = nan\n",
      "Epoch 9, step 75, training loss 0.630503, test_loss 0.816592, accuracy = 0.736178/0.263387, f1 = nan\n",
      "Epoch 9, step 100, training loss 0.645916, test_loss 0.803858, accuracy = 0.752721/0.262516, f1 = nan\n",
      "Epoch 9, step 125, training loss 0.716019, test_loss 0.816511, accuracy = 0.735742/0.265128, f1 = nan\n",
      "Epoch 9, step 150, training loss 0.642794, test_loss 0.801060, accuracy = 0.753156/0.279060, f1 = nan\n",
      "Epoch 9, step 175, training loss 0.764514, test_loss 0.816291, accuracy = 0.740096/0.289943, f1 = nan\n",
      "Epoch 9, step 200, training loss 0.642705, test_loss 0.811168, accuracy = 0.745755/0.305181, f1 = nan\n",
      "End of epoch 9, training loss 0.615195, test_loss 0.812465, accuracy = 0.739661/0.306051, f1 = nan\n",
      "Confusion matrix:\n",
      "[[103 834   0   0]\n",
      " [  0 600   0   0]\n",
      " [  1 552   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 10, step 0, training loss 0.736483, test_loss 0.813268, accuracy = 0.743143/0.306051, f1 = nan\n",
      "Epoch 10, step 25, training loss 0.646528, test_loss 0.809796, accuracy = 0.744449/0.315194, f1 = nan\n",
      "Epoch 10, step 50, training loss 0.696719, test_loss 0.793135, accuracy = 0.750544/0.312582, f1 = nan\n",
      "Epoch 10, step 75, training loss 0.658325, test_loss 0.789467, accuracy = 0.757945/0.317806, f1 = nan\n",
      "Epoch 10, step 100, training loss 0.565292, test_loss 0.789038, accuracy = 0.745320/0.328690, f1 = nan\n",
      "Epoch 10, step 125, training loss 0.653904, test_loss 0.812044, accuracy = 0.746626/0.339138, f1 = nan\n",
      "Epoch 10, step 150, training loss 0.715375, test_loss 0.801842, accuracy = 0.745320/0.355681, f1 = nan\n",
      "Epoch 10, step 175, training loss 0.754573, test_loss 0.815384, accuracy = 0.743143/0.354375, f1 = nan\n",
      "Epoch 10, step 200, training loss 0.653083, test_loss 0.811486, accuracy = 0.740531/0.368742, f1 = nan\n",
      "End of epoch 10, training loss 0.617445, test_loss 0.814047, accuracy = 0.737048/0.367436, f1 = nan\n",
      "Confusion matrix:\n",
      "[[244 693   0   0]\n",
      " [  0 600   0   0]\n",
      " [  1 552   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 11, step 0, training loss 0.716593, test_loss 0.808290, accuracy = 0.735742/0.368307, f1 = nan\n",
      "Epoch 11, step 25, training loss 0.656391, test_loss 0.803912, accuracy = 0.742272/0.398346, f1 = nan\n",
      "Epoch 11, step 50, training loss 0.721999, test_loss 0.796771, accuracy = 0.753592/0.397910, f1 = nan\n",
      "Epoch 11, step 75, training loss 0.669890, test_loss 0.809917, accuracy = 0.749238/0.402264, f1 = nan\n",
      "Epoch 11, step 100, training loss 0.632710, test_loss 0.810771, accuracy = 0.740096/0.419243, f1 = nan\n",
      "Epoch 11, step 125, training loss 0.672513, test_loss 0.808920, accuracy = 0.747497/0.445364, f1 = nan\n",
      "Epoch 11, step 150, training loss 0.653663, test_loss 0.803932, accuracy = 0.746626/0.454071, f1 = nan\n",
      "Epoch 11, step 175, training loss 0.703906, test_loss 0.811727, accuracy = 0.747497/0.473226, f1 = nan\n",
      "Epoch 11, step 200, training loss 0.601467, test_loss 0.803741, accuracy = 0.738790/0.471485, f1 = nan\n",
      "End of epoch 11, training loss 0.676810, test_loss 0.818938, accuracy = 0.730083/0.469743, f1 = nan\n",
      "Confusion matrix:\n",
      "[[473 464   0   0]\n",
      " [  1 599   0   0]\n",
      " [  3 550   0   0]\n",
      " [  0 200   0   7]]\n",
      "Epoch 12, step 0, training loss 0.611453, test_loss 0.810382, accuracy = 0.749673/0.469743, f1 = nan\n",
      "Epoch 12, step 25, training loss 0.637578, test_loss 0.806081, accuracy = 0.737919/0.480192, f1 = nan\n",
      "Epoch 12, step 50, training loss 0.652510, test_loss 0.802910, accuracy = 0.739225/0.479756, f1 = nan\n",
      "Epoch 12, step 75, training loss 0.660924, test_loss 0.812202, accuracy = 0.737048/0.483239, f1 = nan\n",
      "Epoch 12, step 100, training loss 0.607837, test_loss 0.796219, accuracy = 0.747497/0.496300, f1 = nan\n",
      "Epoch 12, step 125, training loss 0.763804, test_loss 0.794173, accuracy = 0.751850/0.508054, f1 = nan\n",
      "Epoch 12, step 150, training loss 0.666135, test_loss 0.816480, accuracy = 0.742708/0.515890, f1 = nan\n",
      "Epoch 12, step 175, training loss 0.716653, test_loss 0.812795, accuracy = 0.744449/0.538964, f1 = nan\n",
      "Epoch 12, step 200, training loss 0.629606, test_loss 0.805095, accuracy = 0.738790/0.534175, f1 = nan\n",
      "End of epoch 12, training loss 0.690135, test_loss 0.807083, accuracy = 0.744449/0.534175, f1 = nan\n",
      "Confusion matrix:\n",
      "[[603 334   0   0]\n",
      " [  2 598   0   0]\n",
      " [  4 545   0   4]\n",
      " [  3 178   0  26]]\n",
      "Epoch 13, step 0, training loss 0.716160, test_loss 0.801184, accuracy = 0.740966/0.534175, f1 = nan\n",
      "Epoch 13, step 25, training loss 0.667616, test_loss 0.816840, accuracy = 0.737919/0.546800, f1 = nan\n",
      "Epoch 13, step 50, training loss 0.746134, test_loss 0.801463, accuracy = 0.753156/0.543753, f1 = nan\n",
      "Epoch 13, step 75, training loss 0.689843, test_loss 0.809375, accuracy = 0.737048/0.540705, f1 = nan\n",
      "Epoch 13, step 100, training loss 0.617471, test_loss 0.806704, accuracy = 0.740096/0.548542, f1 = nan\n",
      "Epoch 13, step 125, training loss 0.674824, test_loss 0.818140, accuracy = 0.740096/0.557249, f1 = nan\n",
      "Epoch 13, step 150, training loss 0.661985, test_loss 0.811638, accuracy = 0.738354/0.557249, f1 = nan\n",
      "Epoch 13, step 175, training loss 0.721767, test_loss 0.800719, accuracy = 0.744449/0.569438, f1 = nan\n",
      "Epoch 13, step 200, training loss 0.635227, test_loss 0.808370, accuracy = 0.740531/0.577710, f1 = nan\n",
      "End of epoch 13, training loss 0.686343, test_loss 0.827437, accuracy = 0.729647/0.581193, f1 = nan\n",
      "Confusion matrix:\n",
      "[[686 251   0   0]\n",
      " [  6 594   0   0]\n",
      " [  5 540   0   8]\n",
      " [  5 147   0  55]]\n",
      "Epoch 14, step 0, training loss 0.645760, test_loss 0.810127, accuracy = 0.737048/0.581193, f1 = nan\n",
      "Epoch 14, step 25, training loss 0.652259, test_loss 0.812770, accuracy = 0.727471/0.590335, f1 = nan\n",
      "Epoch 14, step 50, training loss 0.689983, test_loss 0.802366, accuracy = 0.748367/0.579016, f1 = 0.519291\n",
      "Epoch 14, step 75, training loss 0.719385, test_loss 0.817565, accuracy = 0.733130/0.580322, f1 = 0.521776\n",
      "Epoch 14, step 100, training loss 0.597980, test_loss 0.801380, accuracy = 0.736178/0.580757, f1 = 0.522732\n",
      "Epoch 14, step 125, training loss 0.643651, test_loss 0.809724, accuracy = 0.741837/0.583370, f1 = 0.525113\n",
      "Epoch 14, step 150, training loss 0.642578, test_loss 0.808846, accuracy = 0.741837/0.590335, f1 = 0.533749\n",
      "Epoch 14, step 175, training loss 0.709833, test_loss 0.809091, accuracy = 0.744885/0.604266, f1 = 0.547630\n",
      "Epoch 14, step 200, training loss 0.658555, test_loss 0.804427, accuracy = 0.735742/0.616892, f1 = 0.566352\n",
      "End of epoch 14, training loss 0.623993, test_loss 0.801969, accuracy = 0.738790/0.614715, f1 = 0.562776\n",
      "Confusion matrix:\n",
      "[[730 206   0   1]\n",
      " [  9 590   0   1]\n",
      " [  6 523  14  10]\n",
      " [  8 120   1  78]]\n",
      "Epoch 15, step 0, training loss 0.668015, test_loss 0.806358, accuracy = 0.735307/0.614715, f1 = 0.562356\n",
      "Epoch 15, step 25, training loss 0.634127, test_loss 0.808413, accuracy = 0.747061/0.612538, f1 = 0.556197\n",
      "Epoch 15, step 50, training loss 0.683872, test_loss 0.804636, accuracy = 0.743579/0.618633, f1 = 0.576170\n",
      "Epoch 15, step 75, training loss 0.647304, test_loss 0.807089, accuracy = 0.738354/0.626469, f1 = 0.583905\n",
      "Epoch 15, step 100, training loss 0.631073, test_loss 0.805098, accuracy = 0.745320/0.617762, f1 = 0.570486\n",
      "Epoch 15, step 125, training loss 0.710210, test_loss 0.810680, accuracy = 0.742272/0.629517, f1 = 0.589937\n",
      "Epoch 15, step 150, training loss 0.669574, test_loss 0.796489, accuracy = 0.742708/0.642577, f1 = 0.605524\n",
      "Epoch 15, step 175, training loss 0.710488, test_loss 0.811316, accuracy = 0.740531/0.648672, f1 = 0.609203\n",
      "Epoch 15, step 200, training loss 0.658191, test_loss 0.807495, accuracy = 0.730083/0.663909, f1 = 0.636650\n",
      "End of epoch 15, training loss 0.660458, test_loss 0.815353, accuracy = 0.737484/0.660862, f1 = 0.631825\n",
      "Confusion matrix:\n",
      "[[759 174   0   4]\n",
      " [ 10 586   0   4]\n",
      " [  6 456  78  13]\n",
      " [  9  99   4  95]]\n",
      "Epoch 16, step 0, training loss 0.612070, test_loss 0.813243, accuracy = 0.734436/0.660862, f1 = 0.631825\n",
      "Epoch 16, step 25, training loss 0.630785, test_loss 0.808068, accuracy = 0.732695/0.666957, f1 = 0.636280\n",
      "Epoch 16, step 50, training loss 0.737167, test_loss 0.799866, accuracy = 0.740966/0.677405, f1 = 0.658878\n",
      "Epoch 16, step 75, training loss 0.656921, test_loss 0.796696, accuracy = 0.746626/0.680453, f1 = 0.659755\n",
      "Epoch 16, step 100, training loss 0.550941, test_loss 0.797410, accuracy = 0.744014/0.680888, f1 = 0.662215\n",
      "Epoch 16, step 125, training loss 0.671314, test_loss 0.807607, accuracy = 0.747061/0.682194, f1 = 0.664652\n",
      "Epoch 16, step 150, training loss 0.627398, test_loss 0.814003, accuracy = 0.737048/0.691772, f1 = 0.677219\n",
      "Epoch 16, step 175, training loss 0.656884, test_loss 0.811450, accuracy = 0.729647/0.691772, f1 = 0.669955\n",
      "Epoch 16, step 200, training loss 0.632173, test_loss 0.810635, accuracy = 0.741402/0.705268, f1 = 0.690086\n",
      "End of epoch 16, training loss 0.665364, test_loss 0.801940, accuracy = 0.736613/0.702220, f1 = 0.686781\n",
      "Confusion matrix:\n",
      "[[787 142   0   8]\n",
      " [ 14 576   4   6]\n",
      " [  8 381 144  20]\n",
      " [ 14  76  11 106]]\n",
      "Epoch 17, step 0, training loss 0.666131, test_loss 0.814300, accuracy = 0.732260/0.702656, f1 = 0.687416\n",
      "Epoch 17, step 25, training loss 0.626187, test_loss 0.809179, accuracy = 0.738790/0.706574, f1 = 0.689596\n",
      "Epoch 17, step 50, training loss 0.666299, test_loss 0.817662, accuracy = 0.729647/0.721811, f1 = 0.712420\n",
      "Epoch 17, step 75, training loss 0.620811, test_loss 0.817318, accuracy = 0.743579/0.716587, f1 = 0.706326\n",
      "Epoch 17, step 100, training loss 0.602637, test_loss 0.796616, accuracy = 0.742272/0.710927, f1 = 0.699630\n",
      "Epoch 17, step 125, training loss 0.749690, test_loss 0.815453, accuracy = 0.733130/0.713104, f1 = 0.702277\n",
      "Epoch 17, step 150, training loss 0.640793, test_loss 0.813493, accuracy = 0.744885/0.722246, f1 = 0.713984\n",
      "Epoch 17, step 175, training loss 0.772678, test_loss 0.803597, accuracy = 0.739661/0.723988, f1 = 0.714505\n",
      "Epoch 17, step 200, training loss 0.614466, test_loss 0.810467, accuracy = 0.734001/0.737919, f1 = 0.729963\n",
      "End of epoch 17, training loss 0.554558, test_loss 0.786292, accuracy = 0.745755/0.739225, f1 = 0.732381\n",
      "Confusion matrix:\n",
      "[[811 113   2  11]\n",
      " [ 20 563   5  12]\n",
      " [ 10 304 212  27]\n",
      " [ 14  67  14 112]]\n",
      "Epoch 18, step 0, training loss 0.686860, test_loss 0.800698, accuracy = 0.737919/0.737484, f1 = 0.730975\n",
      "Epoch 18, step 25, training loss 0.594181, test_loss 0.816544, accuracy = 0.728777/0.738354, f1 = 0.730302\n",
      "Epoch 18, step 50, training loss 0.690245, test_loss 0.798926, accuracy = 0.747932/0.754462, f1 = 0.751368\n",
      "Epoch 18, step 75, training loss 0.622962, test_loss 0.803794, accuracy = 0.731824/0.752721, f1 = 0.749793\n",
      "Epoch 18, step 100, training loss 0.602871, test_loss 0.799437, accuracy = 0.745320/0.745320, f1 = 0.741472\n",
      "Epoch 18, step 125, training loss 0.674318, test_loss 0.800628, accuracy = 0.737048/0.745320, f1 = 0.741829\n",
      "Epoch 18, step 150, training loss 0.632681, test_loss 0.809900, accuracy = 0.738790/0.749673, f1 = 0.747886\n",
      "Epoch 18, step 175, training loss 0.698523, test_loss 0.812466, accuracy = 0.733566/0.751850, f1 = 0.747761\n",
      "Epoch 18, step 200, training loss 0.649702, test_loss 0.813689, accuracy = 0.739225/0.764911, f1 = 0.762435\n",
      "End of epoch 18, training loss 0.601042, test_loss 0.812624, accuracy = 0.741402/0.767087, f1 = 0.765025\n",
      "Confusion matrix:\n",
      "[[817  96   3  21]\n",
      " [ 20 553  10  17]\n",
      " [ 12 240 271  30]\n",
      " [ 15  51  20 121]]\n",
      "Epoch 19, step 0, training loss 0.676385, test_loss 0.811480, accuracy = 0.734001/0.767523, f1 = 0.765933\n",
      "Epoch 19, step 25, training loss 0.589523, test_loss 0.803881, accuracy = 0.740096/0.759251, f1 = 0.756149\n",
      "Epoch 19, step 50, training loss 0.620194, test_loss 0.803457, accuracy = 0.742708/0.764040, f1 = 0.763233\n",
      "Epoch 19, step 75, training loss 0.660144, test_loss 0.820701, accuracy = 0.735742/0.760993, f1 = 0.759302\n",
      "Epoch 19, step 100, training loss 0.567491, test_loss 0.800149, accuracy = 0.739660/0.764475, f1 = 0.763940\n",
      "Epoch 19, step 125, training loss 0.674524, test_loss 0.788140, accuracy = 0.743143/0.766217, f1 = 0.766153\n",
      "Epoch 19, step 150, training loss 0.634210, test_loss 0.808216, accuracy = 0.734436/0.760122, f1 = 0.759592\n",
      "Epoch 19, step 175, training loss 0.780807, test_loss 0.816006, accuracy = 0.727035/0.765346, f1 = 0.764143\n",
      "Epoch 19, step 200, training loss 0.507830, test_loss 0.807937, accuracy = 0.735307/0.771441, f1 = 0.769906\n",
      "End of epoch 19, training loss 0.641271, test_loss 0.812103, accuracy = 0.733130/0.772747, f1 = 0.771251\n",
      "Confusion matrix:\n",
      "[[822  92   3  20]\n",
      " [ 21 548  13  18]\n",
      " [ 12 221 284  36]\n",
      " [ 15  49  22 121]]\n",
      "Epoch 20, step 0, training loss 0.674642, test_loss 0.816150, accuracy = 0.732695/0.773618, f1 = 0.772244\n",
      "Epoch 20, step 25, training loss 0.592161, test_loss 0.814527, accuracy = 0.732260/0.771441, f1 = 0.769364\n",
      "Epoch 20, step 50, training loss 0.654726, test_loss 0.801583, accuracy = 0.739225/0.769264, f1 = 0.768788\n",
      "Epoch 20, step 75, training loss 0.626925, test_loss 0.820635, accuracy = 0.737484/0.774924, f1 = 0.775153\n",
      "Epoch 20, step 100, training loss 0.593087, test_loss 0.809940, accuracy = 0.734872/0.769264, f1 = 0.769321\n",
      "Epoch 20, step 125, training loss 0.633340, test_loss 0.805786, accuracy = 0.730953/0.775359, f1 = 0.775416\n",
      "Epoch 20, step 150, training loss 0.595869, test_loss 0.815125, accuracy = 0.737484/0.774924, f1 = 0.774382\n",
      "Epoch 20, step 175, training loss 0.697297, test_loss 0.815319, accuracy = 0.731389/0.777536, f1 = 0.776524\n",
      "Epoch 20, step 200, training loss 0.601297, test_loss 0.813492, accuracy = 0.725729/0.781454, f1 = 0.781168\n",
      "End of epoch 20, training loss 0.662237, test_loss 0.820273, accuracy = 0.733565/0.781019, f1 = 0.780661\n",
      "Confusion matrix:\n",
      "[[825  89   3  20]\n",
      " [ 22 540  14  24]\n",
      " [ 13 201 300  39]\n",
      " [ 15  41  22 129]]\n",
      "Epoch 21, step 0, training loss 0.663479, test_loss 0.800357, accuracy = 0.738354/0.781454, f1 = 0.781150\n",
      "Epoch 21, step 25, training loss 0.633812, test_loss 0.814015, accuracy = 0.732695/0.779713, f1 = 0.778873\n",
      "Epoch 21, step 50, training loss 0.699480, test_loss 0.799146, accuracy = 0.742272/0.783195, f1 = 0.782801\n",
      "Epoch 21, step 75, training loss 0.683852, test_loss 0.801839, accuracy = 0.739225/0.784502, f1 = 0.784479\n",
      "Epoch 21, step 100, training loss 0.555492, test_loss 0.806790, accuracy = 0.738790/0.784066, f1 = 0.784732\n",
      "Epoch 21, step 125, training loss 0.657375, test_loss 0.806046, accuracy = 0.740096/0.787984, f1 = 0.789041\n",
      "Epoch 21, step 150, training loss 0.670488, test_loss 0.804986, accuracy = 0.736613/0.787114, f1 = 0.788556\n",
      "Epoch 21, step 175, training loss 0.723142, test_loss 0.821093, accuracy = 0.733130/0.790596, f1 = 0.791291\n",
      "Epoch 21, step 200, training loss 0.580076, test_loss 0.811074, accuracy = 0.745320/0.795821, f1 = 0.797338\n",
      "End of epoch 21, training loss 0.618375, test_loss 0.816192, accuracy = 0.734872/0.795821, f1 = 0.797382\n",
      "Confusion matrix:\n",
      "[[822  86   7  22]\n",
      " [ 21 532  21  26]\n",
      " [ 13 158 343  39]\n",
      " [ 15  37  24 131]]\n",
      "Epoch 22, step 0, training loss 0.680783, test_loss 0.806341, accuracy = 0.745755/0.794950, f1 = 0.796563\n",
      "Epoch 22, step 25, training loss 0.608805, test_loss 0.813261, accuracy = 0.735307/0.789726, f1 = 0.790231\n",
      "Epoch 22, step 50, training loss 0.644065, test_loss 0.807403, accuracy = 0.734872/0.789726, f1 = 0.791054\n",
      "Epoch 22, step 75, training loss 0.643141, test_loss 0.807254, accuracy = 0.742272/0.792773, f1 = 0.793742\n",
      "Epoch 22, step 100, training loss 0.563581, test_loss 0.804088, accuracy = 0.738790/0.789726, f1 = 0.790851\n",
      "Epoch 22, step 125, training loss 0.681868, test_loss 0.817500, accuracy = 0.735307/0.793209, f1 = 0.795115\n",
      "Epoch 22, step 150, training loss 0.616777, test_loss 0.801258, accuracy = 0.743579/0.791903, f1 = 0.793330\n",
      "Epoch 22, step 175, training loss 0.709849, test_loss 0.810328, accuracy = 0.738354/0.795385, f1 = 0.796040\n",
      "Epoch 22, step 200, training loss 0.620403, test_loss 0.801366, accuracy = 0.740966/0.803657, f1 = 0.804936\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "End of epoch 22, training loss 0.616432, test_loss 0.817940, accuracy = 0.734001/0.803222, f1 = 0.804571\n",
      "Confusion matrix:\n",
      "[[835  72   8  22]\n",
      " [ 27 519  27  27]\n",
      " [ 14 134 362  43]\n",
      " [ 17  36  25 129]]\n",
      "Epoch 23, step 0, training loss 0.601372, test_loss 0.810552, accuracy = 0.735742/0.803222, f1 = 0.804567\n",
      "Epoch 23, step 25, training loss 0.617521, test_loss 0.824621, accuracy = 0.729647/0.797127, f1 = 0.798723\n",
      "Epoch 23, step 50, training loss 0.629436, test_loss 0.810029, accuracy = 0.737919/0.803222, f1 = 0.805126\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 23, step 75, training loss 0.662407, test_loss 0.813971, accuracy = 0.737919/0.794950, f1 = 0.796120\n",
      "Epoch 23, step 100, training loss 0.587901, test_loss 0.808515, accuracy = 0.736613/0.797997, f1 = 0.799354\n",
      "Epoch 23, step 125, training loss 0.673760, test_loss 0.809898, accuracy = 0.737048/0.804528, f1 = 0.806368\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 23, step 150, training loss 0.610784, test_loss 0.814096, accuracy = 0.732695/0.797127, f1 = 0.798917\n",
      "Epoch 23, step 175, training loss 0.735577, test_loss 0.813919, accuracy = 0.726165/0.805398, f1 = 0.806418\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 23, step 200, training loss 0.584315, test_loss 0.797586, accuracy = 0.742272/0.804528, f1 = 0.805794\n",
      "End of epoch 23, training loss 0.591070, test_loss 0.808885, accuracy = 0.737048/0.802786, f1 = 0.803969\n",
      "Confusion matrix:\n",
      "[[832  72   8  25]\n",
      " [ 25 523  26  26]\n",
      " [ 15 141 361  36]\n",
      " [ 17  35  27 128]]\n",
      "Epoch 24, step 0, training loss 0.684315, test_loss 0.808129, accuracy = 0.733565/0.803222, f1 = 0.804448\n",
      "Epoch 24, step 25, training loss 0.662026, test_loss 0.804102, accuracy = 0.734001/0.803657, f1 = 0.805211\n",
      "Epoch 24, step 50, training loss 0.645223, test_loss 0.796902, accuracy = 0.743143/0.804528, f1 = 0.805951\n",
      "Epoch 24, step 75, training loss 0.608385, test_loss 0.809194, accuracy = 0.733566/0.804528, f1 = 0.806133\n",
      "Epoch 24, step 100, training loss 0.598341, test_loss 0.809513, accuracy = 0.738354/0.804092, f1 = 0.805634\n",
      "Epoch 24, step 125, training loss 0.649734, test_loss 0.826156, accuracy = 0.725294/0.805834, f1 = 0.807568\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 24, step 150, training loss 0.607095, test_loss 0.811458, accuracy = 0.744014/0.800174, f1 = 0.802020\n",
      "Epoch 24, step 175, training loss 0.668364, test_loss 0.817140, accuracy = 0.734872/0.804963, f1 = 0.806264\n",
      "Epoch 24, step 200, training loss 0.581704, test_loss 0.813288, accuracy = 0.734001/0.805834, f1 = 0.807670\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "End of epoch 24, training loss 0.637970, test_loss 0.822027, accuracy = 0.725294/0.804092, f1 = 0.805939\n",
      "Confusion matrix:\n",
      "[[831  73  11  22]\n",
      " [ 26 511  33  30]\n",
      " [ 15 120 379  39]\n",
      " [ 15  38  28 126]]\n",
      "Epoch 25, step 0, training loss 0.635942, test_loss 0.819249, accuracy = 0.729647/0.804528, f1 = 0.806440\n",
      "Epoch 25, step 25, training loss 0.661320, test_loss 0.811855, accuracy = 0.733130/0.807575, f1 = 0.809713\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 25, step 50, training loss 0.653264, test_loss 0.809714, accuracy = 0.734436/0.808446, f1 = 0.810428\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 25, step 75, training loss 0.582383, test_loss 0.803412, accuracy = 0.731824/0.807575, f1 = 0.809414\n",
      "Epoch 25, step 100, training loss 0.615756, test_loss 0.819294, accuracy = 0.732695/0.808011, f1 = 0.810332\n",
      "Epoch 25, step 125, training loss 0.596776, test_loss 0.803692, accuracy = 0.736178/0.809752, f1 = 0.812204\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 25, step 150, training loss 0.619634, test_loss 0.814829, accuracy = 0.728777/0.801045, f1 = 0.803480\n",
      "Epoch 25, step 175, training loss 0.700023, test_loss 0.804722, accuracy = 0.731824/0.803222, f1 = 0.804924\n",
      "Epoch 25, step 200, training loss 0.658645, test_loss 0.807424, accuracy = 0.736178/0.807140, f1 = 0.809079\n",
      "End of epoch 25, training loss 0.666390, test_loss 0.834875, accuracy = 0.715281/0.808881, f1 = 0.810648\n",
      "Confusion matrix:\n",
      "[[833  67  11  26]\n",
      " [ 26 513  31  30]\n",
      " [ 15 115 386  37]\n",
      " [ 15  35  31 126]]\n",
      "Epoch 26, step 0, training loss 0.622351, test_loss 0.823857, accuracy = 0.729212/0.808011, f1 = 0.809803\n",
      "Epoch 26, step 25, training loss 0.625775, test_loss 0.812976, accuracy = 0.731824/0.806269, f1 = 0.808135\n",
      "Epoch 26, step 50, training loss 0.645934, test_loss 0.819306, accuracy = 0.730953/0.810187, f1 = 0.812734\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 26, step 75, training loss 0.584664, test_loss 0.802446, accuracy = 0.736613/0.809317, f1 = 0.811653\n",
      "Epoch 26, step 100, training loss 0.618302, test_loss 0.807885, accuracy = 0.737048/0.811058, f1 = 0.813313\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 26, step 125, training loss 0.657444, test_loss 0.811288, accuracy = 0.740096/0.806704, f1 = 0.809363\n",
      "Epoch 26, step 150, training loss 0.597593, test_loss 0.798412, accuracy = 0.739225/0.806704, f1 = 0.809284\n",
      "Epoch 26, step 175, training loss 0.652262, test_loss 0.825212, accuracy = 0.735307/0.809317, f1 = 0.811216\n",
      "Epoch 26, step 200, training loss 0.610095, test_loss 0.816344, accuracy = 0.731389/0.813235, f1 = 0.815334\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "End of epoch 26, training loss 0.593345, test_loss 0.826607, accuracy = 0.712233/0.813235, f1 = 0.815253\n",
      "Confusion matrix:\n",
      "[[835  64  11  27]\n",
      " [ 28 505  36  31]\n",
      " [ 15  95 402  41]\n",
      " [ 15  33  33 126]]\n",
      "Epoch 27, step 0, training loss 0.649982, test_loss 0.814662, accuracy = 0.735307/0.814105, f1 = 0.816181\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 27, step 25, training loss 0.642733, test_loss 0.822933, accuracy = 0.726600/0.808446, f1 = 0.810697\n",
      "Epoch 27, step 50, training loss 0.659373, test_loss 0.795826, accuracy = 0.744885/0.810623, f1 = 0.812336\n",
      "Epoch 27, step 75, training loss 0.614722, test_loss 0.812189, accuracy = 0.728341/0.808881, f1 = 0.811205\n",
      "Epoch 27, step 100, training loss 0.577866, test_loss 0.804050, accuracy = 0.736613/0.809752, f1 = 0.811967\n",
      "Epoch 27, step 125, training loss 0.692596, test_loss 0.803153, accuracy = 0.739660/0.811058, f1 = 0.813430\n",
      "Epoch 27, step 150, training loss 0.581167, test_loss 0.807579, accuracy = 0.745755/0.808011, f1 = 0.810389\n",
      "Epoch 27, step 175, training loss 0.760096, test_loss 0.815788, accuracy = 0.729647/0.810623, f1 = 0.813010\n",
      "Epoch 27, step 200, training loss 0.579763, test_loss 0.831719, accuracy = 0.725729/0.809752, f1 = 0.812364\n",
      "End of epoch 27, training loss 0.602055, test_loss 0.813471, accuracy = 0.734436/0.811493, f1 = 0.814143\n",
      "Confusion matrix:\n",
      "[[836  64   9  28]\n",
      " [ 28 505  33  34]\n",
      " [ 15 101 390  47]\n",
      " [ 13  33  28 133]]\n",
      "Epoch 28, step 0, training loss 0.659265, test_loss 0.817243, accuracy = 0.734001/0.810623, f1 = 0.813125\n",
      "Epoch 28, step 25, training loss 0.552767, test_loss 0.819637, accuracy = 0.732260/0.808881, f1 = 0.811219\n",
      "Epoch 28, step 50, training loss 0.581300, test_loss 0.804977, accuracy = 0.726600/0.810623, f1 = 0.813075\n",
      "Epoch 28, step 75, training loss 0.619958, test_loss 0.813711, accuracy = 0.727035/0.811058, f1 = 0.813903\n",
      "Epoch 28, step 100, training loss 0.614320, test_loss 0.808540, accuracy = 0.733130/0.811058, f1 = 0.813599\n",
      "Epoch 28, step 125, training loss 0.704415, test_loss 0.820664, accuracy = 0.730083/0.811058, f1 = 0.813537\n",
      "Epoch 28, step 150, training loss 0.559810, test_loss 0.814950, accuracy = 0.740531/0.810623, f1 = 0.812741\n",
      "Epoch 28, step 175, training loss 0.632495, test_loss 0.815460, accuracy = 0.735307/0.811058, f1 = 0.812778\n",
      "Epoch 28, step 200, training loss 0.610541, test_loss 0.820398, accuracy = 0.732260/0.812799, f1 = 0.815216\n",
      "End of epoch 28, training loss 0.590197, test_loss 0.810832, accuracy = 0.730518/0.816282, f1 = 0.818965\n",
      "Confusion matrix:\n",
      "[[835  65  11  26]\n",
      " [ 27 500  39  34]\n",
      " [ 13  91 406  43]\n",
      " [ 13  31  29 134]]\n",
      "Epoch 29, step 0, training loss 0.639431, test_loss 0.818083, accuracy = 0.734872/0.815847, f1 = 0.818535\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 29, step 25, training loss 0.616162, test_loss 0.820467, accuracy = 0.725729/0.812364, f1 = 0.814713\n",
      "Epoch 29, step 50, training loss 0.649997, test_loss 0.822320, accuracy = 0.737484/0.814976, f1 = 0.817487\n",
      "Epoch 29, step 75, training loss 0.615956, test_loss 0.802964, accuracy = 0.734872/0.812364, f1 = 0.814983\n",
      "Epoch 29, step 100, training loss 0.559300, test_loss 0.820592, accuracy = 0.731389/0.809317, f1 = 0.812100\n",
      "Epoch 29, step 125, training loss 0.670675, test_loss 0.819455, accuracy = 0.731824/0.808881, f1 = 0.812319\n",
      "Epoch 29, step 150, training loss 0.597066, test_loss 0.812288, accuracy = 0.723988/0.810187, f1 = 0.813269\n",
      "Epoch 29, step 175, training loss 0.672989, test_loss 0.821262, accuracy = 0.732695/0.807575, f1 = 0.809965\n",
      "Epoch 29, step 200, training loss 0.585795, test_loss 0.809107, accuracy = 0.731824/0.813235, f1 = 0.815499\n",
      "End of epoch 29, training loss 0.629088, test_loss 0.826941, accuracy = 0.723117/0.811493, f1 = 0.813784\n",
      "Confusion matrix:\n",
      "[[838  61  11  27]\n",
      " [ 32 493  40  35]\n",
      " [ 16  91 402  44]\n",
      " [ 15  29  32 131]]\n",
      "Epoch 30, step 0, training loss 0.659829, test_loss 0.816297, accuracy = 0.730083/0.811058, f1 = 0.813353\n",
      "Epoch 30, step 25, training loss 0.548737, test_loss 0.821823, accuracy = 0.729212/0.807140, f1 = 0.809726\n",
      "Epoch 30, step 50, training loss 0.651703, test_loss 0.808761, accuracy = 0.734001/0.814105, f1 = 0.816144\n",
      "Epoch 30, step 75, training loss 0.635583, test_loss 0.823856, accuracy = 0.728777/0.814541, f1 = 0.816477\n",
      "Epoch 30, step 100, training loss 0.547116, test_loss 0.818649, accuracy = 0.734001/0.815411, f1 = 0.817577\n",
      "Epoch 30, step 125, training loss 0.629349, test_loss 0.818705, accuracy = 0.728777/0.815847, f1 = 0.817860\n",
      "Epoch 30, step 150, training loss 0.705533, test_loss 0.814795, accuracy = 0.737048/0.812364, f1 = 0.814794\n",
      "Epoch 30, step 175, training loss 0.677043, test_loss 0.830305, accuracy = 0.723117/0.811929, f1 = 0.813772\n",
      "Epoch 30, step 200, training loss 0.639831, test_loss 0.823786, accuracy = 0.724423/0.812799, f1 = 0.814707\n",
      "End of epoch 30, training loss 0.648350, test_loss 0.817392, accuracy = 0.727035/0.814105, f1 = 0.816001\n",
      "Confusion matrix:\n",
      "[[837  59  13  28]\n",
      " [ 31 495  43  31]\n",
      " [ 16  89 409  39]\n",
      " [ 15  29  34 129]]\n",
      "Epoch 31, step 0, training loss 0.598914, test_loss 0.823734, accuracy = 0.730953/0.814541, f1 = 0.816404\n",
      "Epoch 31, step 25, training loss 0.605447, test_loss 0.816749, accuracy = 0.728341/0.811493, f1 = 0.813653\n",
      "Epoch 31, step 50, training loss 0.631314, test_loss 0.806717, accuracy = 0.730083/0.814105, f1 = 0.816405\n",
      "Epoch 31, step 75, training loss 0.579406, test_loss 0.802842, accuracy = 0.743143/0.814105, f1 = 0.816339\n",
      "Epoch 31, step 100, training loss 0.538121, test_loss 0.818908, accuracy = 0.733130/0.812799, f1 = 0.814709\n",
      "Epoch 31, step 125, training loss 0.680360, test_loss 0.814946, accuracy = 0.727471/0.812364, f1 = 0.815266\n",
      "Epoch 31, step 150, training loss 0.593269, test_loss 0.823920, accuracy = 0.728341/0.816282, f1 = 0.818759\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 31, step 175, training loss 0.664260, test_loss 0.824920, accuracy = 0.727471/0.811493, f1 = 0.813460\n",
      "Epoch 31, step 200, training loss 0.599339, test_loss 0.811219, accuracy = 0.730083/0.813670, f1 = 0.815993\n",
      "End of epoch 31, training loss 0.640886, test_loss 0.819079, accuracy = 0.725729/0.813235, f1 = 0.815591\n",
      "Confusion matrix:\n",
      "[[835  61  13  28]\n",
      " [ 31 491  44  34]\n",
      " [ 16  86 410  41]\n",
      " [ 13  28  34 132]]\n",
      "Epoch 32, step 0, training loss 0.632440, test_loss 0.822575, accuracy = 0.734872/0.814105, f1 = 0.816493\n",
      "Epoch 32, step 25, training loss 0.620472, test_loss 0.820959, accuracy = 0.736613/0.811929, f1 = 0.814111\n",
      "Epoch 32, step 50, training loss 0.696424, test_loss 0.808215, accuracy = 0.738790/0.815411, f1 = 0.817193\n",
      "Epoch 32, step 75, training loss 0.614326, test_loss 0.812373, accuracy = 0.734872/0.813670, f1 = 0.815613\n",
      "Epoch 32, step 100, training loss 0.566762, test_loss 0.818046, accuracy = 0.730518/0.816282, f1 = 0.818241\n",
      "Epoch 32, step 125, training loss 0.675578, test_loss 0.813563, accuracy = 0.731389/0.814105, f1 = 0.816337\n",
      "Epoch 32, step 150, training loss 0.634768, test_loss 0.809814, accuracy = 0.731389/0.814105, f1 = 0.816288\n",
      "Epoch 32, step 175, training loss 0.694929, test_loss 0.829721, accuracy = 0.722682/0.810623, f1 = 0.811958\n",
      "Epoch 32, step 200, training loss 0.597252, test_loss 0.820164, accuracy = 0.734436/0.813670, f1 = 0.815654\n",
      "End of epoch 32, training loss 0.622223, test_loss 0.826277, accuracy = 0.723988/0.814976, f1 = 0.816930\n",
      "Confusion matrix:\n",
      "[[836  61  14  26]\n",
      " [ 29 494  46  31]\n",
      " [ 15  88 413  37]\n",
      " [ 13  30  35 129]]\n",
      "Epoch 33, step 0, training loss 0.594725, test_loss 0.815397, accuracy = 0.730953/0.814976, f1 = 0.816965\n",
      "Epoch 33, step 25, training loss 0.634569, test_loss 0.822746, accuracy = 0.722246/0.811929, f1 = 0.813375\n",
      "Epoch 33, step 50, training loss 0.622961, test_loss 0.820182, accuracy = 0.737048/0.817588, f1 = 0.819315\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 33, step 75, training loss 0.620580, test_loss 0.815135, accuracy = 0.738354/0.816282, f1 = 0.818536\n",
      "Epoch 33, step 100, training loss 0.608469, test_loss 0.823505, accuracy = 0.732260/0.813670, f1 = 0.815584\n",
      "Epoch 33, step 125, training loss 0.646739, test_loss 0.812396, accuracy = 0.737484/0.815411, f1 = 0.817506\n",
      "Epoch 33, step 150, training loss 0.581261, test_loss 0.804922, accuracy = 0.735307/0.817153, f1 = 0.819836\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 33, step 175, training loss 0.702912, test_loss 0.817088, accuracy = 0.725294/0.812799, f1 = 0.814662\n",
      "Epoch 33, step 200, training loss 0.597509, test_loss 0.825232, accuracy = 0.730953/0.811929, f1 = 0.815093\n",
      "End of epoch 33, training loss 0.579387, test_loss 0.819163, accuracy = 0.719199/0.812364, f1 = 0.815339\n",
      "Confusion matrix:\n",
      "[[837  56  14  30]\n",
      " [ 34 477  48  41]\n",
      " [ 16  77 415  45]\n",
      " [ 12  23  35 137]]\n",
      "Epoch 34, step 0, training loss 0.640766, test_loss 0.820657, accuracy = 0.724423/0.812799, f1 = 0.815745\n",
      "Epoch 34, step 25, training loss 0.625425, test_loss 0.827014, accuracy = 0.720940/0.811058, f1 = 0.813724\n",
      "Epoch 34, step 50, training loss 0.637651, test_loss 0.804416, accuracy = 0.735307/0.812799, f1 = 0.815269\n",
      "Epoch 34, step 75, training loss 0.650720, test_loss 0.797409, accuracy = 0.741402/0.814105, f1 = 0.817001\n",
      "Epoch 34, step 100, training loss 0.585245, test_loss 0.812623, accuracy = 0.729212/0.816718, f1 = 0.819194\n",
      "Epoch 34, step 125, training loss 0.606512, test_loss 0.814309, accuracy = 0.730953/0.816282, f1 = 0.819190\n",
      "Epoch 34, step 150, training loss 0.619376, test_loss 0.818843, accuracy = 0.738790/0.814105, f1 = 0.816790\n",
      "Epoch 34, step 175, training loss 0.678857, test_loss 0.817437, accuracy = 0.734436/0.813670, f1 = 0.815583\n",
      "Epoch 34, step 200, training loss 0.641873, test_loss 0.814244, accuracy = 0.732695/0.815847, f1 = 0.818117\n",
      "End of epoch 34, training loss 0.586885, test_loss 0.825535, accuracy = 0.723117/0.815847, f1 = 0.818027\n",
      "Confusion matrix:\n",
      "[[835  60  14  28]\n",
      " [ 31 486  50  33]\n",
      " [ 15  78 422  38]\n",
      " [ 14  27  35 131]]\n",
      "Epoch 35, step 0, training loss 0.649836, test_loss 0.841036, accuracy = 0.721811/0.815411, f1 = 0.817510\n",
      "Epoch 35, step 25, training loss 0.630345, test_loss 0.819552, accuracy = 0.728341/0.813235, f1 = 0.815798\n",
      "Epoch 35, step 50, training loss 0.622014, test_loss 0.805156, accuracy = 0.731824/0.817153, f1 = 0.819390\n",
      "Epoch 35, step 75, training loss 0.612892, test_loss 0.800076, accuracy = 0.732695/0.815412, f1 = 0.818127\n",
      "Epoch 35, step 100, training loss 0.569755, test_loss 0.806444, accuracy = 0.734872/0.814976, f1 = 0.817513\n",
      "Epoch 35, step 125, training loss 0.645412, test_loss 0.812057, accuracy = 0.736178/0.812799, f1 = 0.815428\n",
      "Epoch 35, step 150, training loss 0.618000, test_loss 0.814437, accuracy = 0.735307/0.812364, f1 = 0.814757\n",
      "Epoch 35, step 175, training loss 0.651056, test_loss 0.831245, accuracy = 0.729647/0.812799, f1 = 0.815066\n",
      "Epoch 35, step 200, training loss 0.544813, test_loss 0.826622, accuracy = 0.727035/0.813235, f1 = 0.815999\n",
      "End of epoch 35, training loss 0.622911, test_loss 0.824534, accuracy = 0.732260/0.812799, f1 = 0.815567\n",
      "Confusion matrix:\n",
      "[[833  58  15  31]\n",
      " [ 31 479  54  36]\n",
      " [ 14  76 423  40]\n",
      " [ 11  27  37 132]]\n",
      "Epoch 36, step 0, training loss 0.606645, test_loss 0.818430, accuracy = 0.719634/0.813235, f1 = 0.815945\n",
      "Epoch 36, step 25, training loss 0.591148, test_loss 0.818492, accuracy = 0.725729/0.814105, f1 = 0.816547\n",
      "Epoch 36, step 50, training loss 0.668866, test_loss 0.811890, accuracy = 0.731824/0.814541, f1 = 0.816895\n",
      "Epoch 36, step 75, training loss 0.617468, test_loss 0.811117, accuracy = 0.732260/0.816717, f1 = 0.819558\n",
      "Epoch 36, step 100, training loss 0.584411, test_loss 0.807730, accuracy = 0.732260/0.815411, f1 = 0.818006\n",
      "Epoch 36, step 125, training loss 0.678338, test_loss 0.807933, accuracy = 0.733566/0.813670, f1 = 0.816075\n",
      "Epoch 36, step 150, training loss 0.652652, test_loss 0.811624, accuracy = 0.730953/0.816282, f1 = 0.818845\n",
      "Epoch 36, step 175, training loss 0.688435, test_loss 0.826348, accuracy = 0.730083/0.812799, f1 = 0.814343\n",
      "Epoch 36, step 200, training loss 0.582429, test_loss 0.809268, accuracy = 0.728777/0.813235, f1 = 0.815170\n",
      "End of epoch 36, training loss 0.612190, test_loss 0.835028, accuracy = 0.721376/0.812364, f1 = 0.814535\n",
      "Confusion matrix:\n",
      "[[837  58  14  28]\n",
      " [ 33 479  55  33]\n",
      " [ 14  76 422  41]\n",
      " [ 14  28  37 128]]\n",
      "Epoch 37, step 0, training loss 0.658191, test_loss 0.806261, accuracy = 0.738354/0.813235, f1 = 0.815401\n",
      "Epoch 37, step 25, training loss 0.577429, test_loss 0.823607, accuracy = 0.731389/0.807575, f1 = 0.810301\n",
      "Epoch 37, step 50, training loss 0.700593, test_loss 0.810273, accuracy = 0.734001/0.814541, f1 = 0.816979\n",
      "Epoch 37, step 75, training loss 0.613268, test_loss 0.815634, accuracy = 0.725294/0.814105, f1 = 0.816283\n",
      "Epoch 37, step 100, training loss 0.537549, test_loss 0.824022, accuracy = 0.725729/0.814976, f1 = 0.817189\n",
      "Epoch 37, step 125, training loss 0.694260, test_loss 0.807325, accuracy = 0.734001/0.813235, f1 = 0.815475\n",
      "Epoch 37, step 150, training loss 0.567839, test_loss 0.823521, accuracy = 0.729212/0.816718, f1 = 0.818688\n",
      "Epoch 37, step 175, training loss 0.712696, test_loss 0.814160, accuracy = 0.721811/0.813235, f1 = 0.814695\n",
      "Epoch 37, step 200, training loss 0.575255, test_loss 0.825167, accuracy = 0.718328/0.814541, f1 = 0.816423\n",
      "End of epoch 37, training loss 0.649384, test_loss 0.808954, accuracy = 0.729647/0.815411, f1 = 0.817567\n",
      "Confusion matrix:\n",
      "[[838  56  13  30]\n",
      " [ 32 484  51  33]\n",
      " [ 15  77 422  39]\n",
      " [ 14  28  36 129]]\n",
      "Epoch 38, step 0, training loss 0.635738, test_loss 0.822542, accuracy = 0.729647/0.814976, f1 = 0.817108\n",
      "Epoch 38, step 25, training loss 0.575194, test_loss 0.815762, accuracy = 0.735742/0.816282, f1 = 0.818450\n",
      "Epoch 38, step 50, training loss 0.649788, test_loss 0.800736, accuracy = 0.740096/0.814541, f1 = 0.815973\n",
      "Epoch 38, step 75, training loss 0.603539, test_loss 0.805307, accuracy = 0.739225/0.817153, f1 = 0.819166\n",
      "Epoch 38, step 100, training loss 0.529570, test_loss 0.797884, accuracy = 0.740966/0.814976, f1 = 0.817262\n",
      "Epoch 38, step 125, training loss 0.632768, test_loss 0.813121, accuracy = 0.735742/0.813670, f1 = 0.815826\n",
      "Epoch 38, step 150, training loss 0.589825, test_loss 0.803785, accuracy = 0.738790/0.815847, f1 = 0.817754\n",
      "Epoch 38, step 175, training loss 0.713681, test_loss 0.825176, accuracy = 0.726165/0.811929, f1 = 0.813447\n",
      "Epoch 38, step 200, training loss 0.613112, test_loss 0.815297, accuracy = 0.738354/0.816717, f1 = 0.818830\n",
      "End of epoch 38, training loss 0.595499, test_loss 0.806166, accuracy = 0.731824/0.818024, f1 = 0.820157\n",
      "Confusion matrix:\n",
      "[[838  55  15  29]\n",
      " [ 31 484  54  31]\n",
      " [ 14  74 427  38]\n",
      " [ 11  29  37 130]]\n",
      "Epoch 39, step 0, training loss 0.606715, test_loss 0.813139, accuracy = 0.733130/0.818024, f1 = 0.820157\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 39, step 25, training loss 0.678580, test_loss 0.823724, accuracy = 0.725729/0.814976, f1 = 0.816835\n",
      "Epoch 39, step 50, training loss 0.671230, test_loss 0.811262, accuracy = 0.734436/0.817153, f1 = 0.819256\n",
      "Epoch 39, step 75, training loss 0.615852, test_loss 0.824936, accuracy = 0.730518/0.814541, f1 = 0.816980\n",
      "Epoch 39, step 100, training loss 0.558186, test_loss 0.826651, accuracy = 0.719199/0.815847, f1 = 0.817795\n",
      "Epoch 39, step 125, training loss 0.631617, test_loss 0.820358, accuracy = 0.729212/0.814976, f1 = 0.817626\n",
      "Epoch 39, step 150, training loss 0.621075, test_loss 0.817516, accuracy = 0.727906/0.816282, f1 = 0.818837\n",
      "Epoch 39, step 175, training loss 0.645983, test_loss 0.826399, accuracy = 0.719634/0.815847, f1 = 0.817574\n",
      "Epoch 39, step 200, training loss 0.608748, test_loss 0.812023, accuracy = 0.729647/0.816718, f1 = 0.818910\n",
      "End of epoch 39, training loss 0.554580, test_loss 0.813195, accuracy = 0.724423/0.814105, f1 = 0.816473\n",
      "Confusion matrix:\n",
      "[[838  57  14  28]\n",
      " [ 32 481  52  35]\n",
      " [ 16  74 420  43]\n",
      " [ 13  26  37 131]]\n",
      "Epoch 40, step 0, training loss 0.623402, test_loss 0.818052, accuracy = 0.724423/0.814105, f1 = 0.816512\n",
      "Epoch 40, step 25, training loss 0.608032, test_loss 0.823057, accuracy = 0.723117/0.813670, f1 = 0.815831\n",
      "Epoch 40, step 50, training loss 0.651582, test_loss 0.791442, accuracy = 0.744014/0.817588, f1 = 0.819866\n",
      "Epoch 40, step 75, training loss 0.587957, test_loss 0.819170, accuracy = 0.728777/0.813235, f1 = 0.815582\n",
      "Epoch 40, step 100, training loss 0.584451, test_loss 0.810068, accuracy = 0.736613/0.813670, f1 = 0.816052\n",
      "Epoch 40, step 125, training loss 0.645501, test_loss 0.817572, accuracy = 0.729647/0.813235, f1 = 0.815963\n",
      "Epoch 40, step 150, training loss 0.575363, test_loss 0.818630, accuracy = 0.731389/0.813670, f1 = 0.816747\n",
      "Epoch 40, step 175, training loss 0.694021, test_loss 0.828560, accuracy = 0.730083/0.815847, f1 = 0.818549\n",
      "Epoch 40, step 200, training loss 0.620993, test_loss 0.810917, accuracy = 0.726600/0.812364, f1 = 0.815186\n",
      "End of epoch 40, training loss 0.699958, test_loss 0.815713, accuracy = 0.732260/0.813235, f1 = 0.816079\n",
      "Confusion matrix:\n",
      "[[839  51  14  33]\n",
      " [ 37 469  54  40]\n",
      " [ 15  70 425  43]\n",
      " [ 12  23  37 135]]\n",
      "Epoch 41, step 0, training loss 0.648259, test_loss 0.825329, accuracy = 0.726600/0.813235, f1 = 0.815993\n",
      "Epoch 41, step 25, training loss 0.632473, test_loss 0.833329, accuracy = 0.725729/0.807575, f1 = 0.810742\n",
      "Epoch 41, step 50, training loss 0.612069, test_loss 0.804434, accuracy = 0.727471/0.817588, f1 = 0.819641\n",
      "Epoch 41, step 75, training loss 0.635992, test_loss 0.816288, accuracy = 0.723988/0.814541, f1 = 0.817551\n",
      "Epoch 41, step 100, training loss 0.559262, test_loss 0.822320, accuracy = 0.727906/0.814541, f1 = 0.817699\n",
      "Epoch 41, step 125, training loss 0.636833, test_loss 0.811460, accuracy = 0.729212/0.814105, f1 = 0.817082\n",
      "Epoch 41, step 150, training loss 0.568784, test_loss 0.818565, accuracy = 0.731824/0.819330, f1 = 0.821990\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 41, step 175, training loss 0.716006, test_loss 0.829534, accuracy = 0.725729/0.814105, f1 = 0.816026\n",
      "Epoch 41, step 200, training loss 0.587859, test_loss 0.822170, accuracy = 0.734001/0.815411, f1 = 0.818270\n",
      "End of epoch 41, training loss 0.574160, test_loss 0.815922, accuracy = 0.732259/0.814541, f1 = 0.817336\n",
      "Confusion matrix:\n",
      "[[836  57  14  30]\n",
      " [ 31 476  54  39]\n",
      " [ 14  71 427  41]\n",
      " [ 12  24  39 132]]\n",
      "Epoch 42, step 0, training loss 0.645603, test_loss 0.805889, accuracy = 0.731824/0.815412, f1 = 0.818156\n",
      "Epoch 42, step 25, training loss 0.590488, test_loss 0.820814, accuracy = 0.738354/0.813670, f1 = 0.815312\n",
      "Epoch 42, step 50, training loss 0.649160, test_loss 0.806340, accuracy = 0.736613/0.814976, f1 = 0.816487\n",
      "Epoch 42, step 75, training loss 0.614355, test_loss 0.818383, accuracy = 0.733566/0.814541, f1 = 0.816844\n",
      "Epoch 42, step 100, training loss 0.606047, test_loss 0.814479, accuracy = 0.718328/0.814541, f1 = 0.816625\n",
      "Epoch 42, step 125, training loss 0.648872, test_loss 0.816172, accuracy = 0.728777/0.812799, f1 = 0.814517\n",
      "Epoch 42, step 150, training loss 0.600000, test_loss 0.813615, accuracy = 0.718764/0.814105, f1 = 0.815794\n",
      "Epoch 42, step 175, training loss 0.689761, test_loss 0.817504, accuracy = 0.721811/0.812364, f1 = 0.813511\n",
      "Epoch 42, step 200, training loss 0.612464, test_loss 0.817211, accuracy = 0.729647/0.814976, f1 = 0.816917\n",
      "End of epoch 42, training loss 0.596637, test_loss 0.827852, accuracy = 0.726165/0.816718, f1 = 0.818736\n",
      "Confusion matrix:\n",
      "[[839  53  18  27]\n",
      " [ 32 475  60  33]\n",
      " [ 15  68 432  38]\n",
      " [ 11  25  41 130]]\n",
      "Epoch 43, step 0, training loss 0.653273, test_loss 0.822804, accuracy = 0.729212/0.817153, f1 = 0.819168\n",
      "Epoch 43, step 25, training loss 0.567981, test_loss 0.816971, accuracy = 0.723988/0.816717, f1 = 0.818693\n",
      "Epoch 43, step 50, training loss 0.717827, test_loss 0.810252, accuracy = 0.726165/0.812364, f1 = 0.813892\n",
      "Epoch 43, step 75, training loss 0.604262, test_loss 0.818229, accuracy = 0.733566/0.812364, f1 = 0.814506\n",
      "Epoch 43, step 100, training loss 0.569683, test_loss 0.815732, accuracy = 0.734872/0.814976, f1 = 0.816945\n",
      "Epoch 43, step 125, training loss 0.702803, test_loss 0.817814, accuracy = 0.733566/0.816282, f1 = 0.818042\n",
      "Epoch 43, step 150, training loss 0.554744, test_loss 0.809838, accuracy = 0.736178/0.815847, f1 = 0.817715\n",
      "Epoch 43, step 175, training loss 0.620375, test_loss 0.800017, accuracy = 0.742272/0.814105, f1 = 0.815143\n",
      "Epoch 43, step 200, training loss 0.612414, test_loss 0.824818, accuracy = 0.723988/0.812364, f1 = 0.814659\n",
      "End of epoch 43, training loss 0.593623, test_loss 0.807525, accuracy = 0.727906/0.812799, f1 = 0.815256\n",
      "Confusion matrix:\n",
      "[[837  56  17  27]\n",
      " [ 31 475  58  36]\n",
      " [ 13  71 427  42]\n",
      " [ 12  27  40 128]]\n",
      "Epoch 44, step 0, training loss 0.630101, test_loss 0.825405, accuracy = 0.726600/0.812799, f1 = 0.815256\n",
      "Epoch 44, step 25, training loss 0.603695, test_loss 0.821118, accuracy = 0.730518/0.813670, f1 = 0.815609\n",
      "Epoch 44, step 50, training loss 0.646569, test_loss 0.805773, accuracy = 0.733130/0.817588, f1 = 0.819693\n",
      "Epoch 44, step 75, training loss 0.631094, test_loss 0.820013, accuracy = 0.730953/0.814105, f1 = 0.816650\n",
      "Epoch 44, step 100, training loss 0.540780, test_loss 0.811510, accuracy = 0.734872/0.815847, f1 = 0.818123\n",
      "Epoch 44, step 125, training loss 0.648991, test_loss 0.824896, accuracy = 0.723988/0.816282, f1 = 0.818313\n",
      "Epoch 44, step 150, training loss 0.550141, test_loss 0.822638, accuracy = 0.729212/0.816282, f1 = 0.818073\n",
      "Epoch 44, step 175, training loss 0.649552, test_loss 0.835102, accuracy = 0.715716/0.816718, f1 = 0.817708\n",
      "Epoch 44, step 200, training loss 0.633424, test_loss 0.826130, accuracy = 0.733130/0.814976, f1 = 0.816979\n",
      "End of epoch 44, training loss 0.600098, test_loss 0.818837, accuracy = 0.726600/0.815411, f1 = 0.817695\n",
      "Confusion matrix:\n",
      "[[839  53  16  29]\n",
      " [ 31 478  56  35]\n",
      " [ 15  70 428  40]\n",
      " [ 11  25  43 128]]\n",
      "Epoch 45, step 0, training loss 0.610386, test_loss 0.827745, accuracy = 0.719634/0.816282, f1 = 0.818538\n",
      "Epoch 45, step 25, training loss 0.639509, test_loss 0.821440, accuracy = 0.729212/0.815847, f1 = 0.818422\n",
      "Epoch 45, step 50, training loss 0.647767, test_loss 0.816849, accuracy = 0.732695/0.816718, f1 = 0.819093\n",
      "Epoch 45, step 75, training loss 0.574705, test_loss 0.804496, accuracy = 0.737484/0.811058, f1 = 0.814096\n",
      "Epoch 45, step 100, training loss 0.548280, test_loss 0.804054, accuracy = 0.737484/0.812799, f1 = 0.815466\n",
      "Epoch 45, step 125, training loss 0.687034, test_loss 0.821811, accuracy = 0.723552/0.814105, f1 = 0.816345\n",
      "Epoch 45, step 150, training loss 0.598171, test_loss 0.808488, accuracy = 0.735742/0.818024, f1 = 0.820508\n",
      "Epoch 45, step 175, training loss 0.674755, test_loss 0.817712, accuracy = 0.723117/0.814541, f1 = 0.816530\n",
      "Epoch 45, step 200, training loss 0.543709, test_loss 0.812091, accuracy = 0.739661/0.811058, f1 = 0.813108\n",
      "End of epoch 45, training loss 0.601659, test_loss 0.812948, accuracy = 0.724423/0.814105, f1 = 0.816105\n",
      "Confusion matrix:\n",
      "[[842  48  18  29]\n",
      " [ 36 466  63  35]\n",
      " [ 17  64 431  41]\n",
      " [ 14  24  38 131]]\n",
      "Epoch 46, step 0, training loss 0.649918, test_loss 0.813730, accuracy = 0.730953/0.814541, f1 = 0.816631\n",
      "Epoch 46, step 25, training loss 0.599711, test_loss 0.830615, accuracy = 0.718328/0.814105, f1 = 0.815903\n",
      "Epoch 46, step 50, training loss 0.663058, test_loss 0.813598, accuracy = 0.735742/0.814541, f1 = 0.816773\n",
      "Epoch 46, step 75, training loss 0.589168, test_loss 0.825332, accuracy = 0.726600/0.814541, f1 = 0.817325\n",
      "Epoch 46, step 100, training loss 0.580359, test_loss 0.808678, accuracy = 0.736613/0.814976, f1 = 0.817328\n",
      "Epoch 46, step 125, training loss 0.722039, test_loss 0.815280, accuracy = 0.727035/0.814105, f1 = 0.816500\n",
      "Epoch 46, step 150, training loss 0.627673, test_loss 0.817628, accuracy = 0.721811/0.812799, f1 = 0.814548\n",
      "Epoch 46, step 175, training loss 0.649379, test_loss 0.816226, accuracy = 0.736613/0.813670, f1 = 0.815358\n",
      "Epoch 46, step 200, training loss 0.606021, test_loss 0.823560, accuracy = 0.719634/0.814105, f1 = 0.817034\n",
      "End of epoch 46, training loss 0.645279, test_loss 0.823203, accuracy = 0.723552/0.816718, f1 = 0.819745\n",
      "Confusion matrix:\n",
      "[[843  48  16  30]\n",
      " [ 33 476  50  41]\n",
      " [ 14  70 422  47]\n",
      " [ 11  25  36 135]]\n",
      "Epoch 47, step 0, training loss 0.658727, test_loss 0.815984, accuracy = 0.722682/0.816282, f1 = 0.819338\n",
      "Epoch 47, step 25, training loss 0.666134, test_loss 0.819120, accuracy = 0.719199/0.813670, f1 = 0.816812\n",
      "Epoch 47, step 50, training loss 0.600348, test_loss 0.810482, accuracy = 0.730083/0.815411, f1 = 0.818015\n",
      "Epoch 47, step 75, training loss 0.628204, test_loss 0.816300, accuracy = 0.724859/0.814105, f1 = 0.817092\n",
      "Epoch 47, step 100, training loss 0.486240, test_loss 0.815283, accuracy = 0.725294/0.818024, f1 = 0.821100\n",
      "Epoch 47, step 125, training loss 0.678819, test_loss 0.809586, accuracy = 0.733130/0.815847, f1 = 0.818512\n",
      "Epoch 47, step 150, training loss 0.608650, test_loss 0.820743, accuracy = 0.723988/0.814105, f1 = 0.816598\n",
      "Epoch 47, step 175, training loss 0.701944, test_loss 0.830061, accuracy = 0.721376/0.814105, f1 = 0.816463\n",
      "Epoch 47, step 200, training loss 0.594336, test_loss 0.823566, accuracy = 0.721811/0.811493, f1 = 0.814546\n",
      "End of epoch 47, training loss 0.637643, test_loss 0.826656, accuracy = 0.722682/0.812799, f1 = 0.815809\n",
      "Confusion matrix:\n",
      "[[839  54  15  29]\n",
      " [ 33 470  54  43]\n",
      " [ 16  68 423  46]\n",
      " [ 13  23  36 135]]\n",
      "Epoch 48, step 0, training loss 0.664268, test_loss 0.811760, accuracy = 0.727035/0.813235, f1 = 0.816129\n",
      "Epoch 48, step 25, training loss 0.600354, test_loss 0.820173, accuracy = 0.719634/0.813670, f1 = 0.816829\n",
      "Epoch 48, step 50, training loss 0.600546, test_loss 0.801636, accuracy = 0.735742/0.818024, f1 = 0.820979\n",
      "Epoch 48, step 75, training loss 0.574516, test_loss 0.817927, accuracy = 0.731389/0.811058, f1 = 0.814860\n",
      "Epoch 48, step 100, training loss 0.574422, test_loss 0.825283, accuracy = 0.715281/0.813670, f1 = 0.816351\n",
      "Epoch 48, step 125, training loss 0.647801, test_loss 0.800675, accuracy = 0.740096/0.816718, f1 = 0.819095\n",
      "Epoch 48, step 150, training loss 0.580389, test_loss 0.810866, accuracy = 0.733130/0.816717, f1 = 0.818606\n",
      "Epoch 48, step 175, training loss 0.639827, test_loss 0.819174, accuracy = 0.725729/0.814541, f1 = 0.816217\n",
      "Epoch 48, step 200, training loss 0.651973, test_loss 0.829298, accuracy = 0.721811/0.818024, f1 = 0.820551\n",
      "End of epoch 48, training loss 0.670844, test_loss 0.818901, accuracy = 0.716152/0.816282, f1 = 0.818591\n",
      "Confusion matrix:\n",
      "[[840  54  14  29]\n",
      " [ 32 483  49  36]\n",
      " [ 17  72 422  42]\n",
      " [ 13  27  37 130]]\n",
      "Epoch 49, step 0, training loss 0.634718, test_loss 0.828357, accuracy = 0.730083/0.817153, f1 = 0.819446\n",
      "Epoch 49, step 25, training loss 0.580622, test_loss 0.818917, accuracy = 0.720505/0.814541, f1 = 0.816487\n",
      "Epoch 49, step 50, training loss 0.648380, test_loss 0.801702, accuracy = 0.745320/0.816718, f1 = 0.819022\n",
      "Epoch 49, step 75, training loss 0.585682, test_loss 0.807633, accuracy = 0.729212/0.814976, f1 = 0.817669\n",
      "Epoch 49, step 100, training loss 0.532624, test_loss 0.815647, accuracy = 0.728777/0.815412, f1 = 0.817972\n",
      "Epoch 49, step 125, training loss 0.644491, test_loss 0.808992, accuracy = 0.730518/0.815411, f1 = 0.817841\n",
      "Epoch 49, step 150, training loss 0.609693, test_loss 0.800715, accuracy = 0.739660/0.816718, f1 = 0.819287\n",
      "Epoch 49, step 175, training loss 0.706387, test_loss 0.811868, accuracy = 0.735742/0.817153, f1 = 0.819212\n",
      "Epoch 49, step 200, training loss 0.604831, test_loss 0.823558, accuracy = 0.720940/0.815847, f1 = 0.818257\n",
      "End of epoch 49, training loss 0.628933, test_loss 0.808536, accuracy = 0.728777/0.812364, f1 = 0.814363\n",
      "Confusion matrix:\n",
      "[[842  53  14  28]\n",
      " [ 39 470  52  39]\n",
      " [ 18  73 422  40]\n",
      " [ 16  24  35 132]]\n",
      "Epoch 50, step 0, training loss 0.671032, test_loss 0.803265, accuracy = 0.738790/0.812799, f1 = 0.814747\n",
      "Epoch 50, step 25, training loss 0.602505, test_loss 0.820977, accuracy = 0.724859/0.814976, f1 = 0.817713\n",
      "Epoch 50, step 50, training loss 0.631895, test_loss 0.808436, accuracy = 0.734001/0.818024, f1 = 0.820750\n",
      "Epoch 50, step 75, training loss 0.615781, test_loss 0.810841, accuracy = 0.731824/0.814105, f1 = 0.817301\n",
      "Epoch 50, step 100, training loss 0.548122, test_loss 0.816988, accuracy = 0.731389/0.814105, f1 = 0.817103\n",
      "Epoch 50, step 125, training loss 0.641349, test_loss 0.814557, accuracy = 0.740531/0.813235, f1 = 0.815635\n",
      "Epoch 50, step 150, training loss 0.547373, test_loss 0.811519, accuracy = 0.730953/0.816718, f1 = 0.818650\n",
      "Epoch 50, step 175, training loss 0.625117, test_loss 0.821986, accuracy = 0.713539/0.811058, f1 = 0.812612\n",
      "Epoch 50, step 200, training loss 0.617528, test_loss 0.819746, accuracy = 0.727906/0.816282, f1 = 0.818252\n",
      "End of epoch 50, training loss 0.583288, test_loss 0.821157, accuracy = 0.722246/0.816282, f1 = 0.818254\n",
      "Confusion matrix:\n",
      "[[837  58  17  25]\n",
      " [ 29 482  56  33]\n",
      " [ 17  72 426  38]\n",
      " [ 12  25  40 130]]\n",
      "Epoch 51, step 0, training loss 0.615810, test_loss 0.823535, accuracy = 0.721376/0.815412, f1 = 0.817418\n",
      "Epoch 51, step 25, training loss 0.667081, test_loss 0.822453, accuracy = 0.723117/0.814976, f1 = 0.817371\n",
      "Epoch 51, step 50, training loss 0.662581, test_loss 0.819781, accuracy = 0.725294/0.815411, f1 = 0.817707\n",
      "Epoch 51, step 75, training loss 0.568311, test_loss 0.810622, accuracy = 0.740096/0.815411, f1 = 0.818535\n",
      "Epoch 51, step 100, training loss 0.522376, test_loss 0.815760, accuracy = 0.723552/0.815847, f1 = 0.818211\n",
      "Epoch 51, step 125, training loss 0.638877, test_loss 0.820246, accuracy = 0.727906/0.816282, f1 = 0.818579\n",
      "Epoch 51, step 150, training loss 0.614134, test_loss 0.820522, accuracy = 0.731824/0.817588, f1 = 0.819885\n",
      "Epoch 51, step 175, training loss 0.649680, test_loss 0.824943, accuracy = 0.722682/0.817588, f1 = 0.819407\n",
      "Epoch 51, step 200, training loss 0.650450, test_loss 0.825081, accuracy = 0.729212/0.812799, f1 = 0.815390\n",
      "End of epoch 51, training loss 0.612798, test_loss 0.828967, accuracy = 0.721376/0.811929, f1 = 0.814532\n",
      "Confusion matrix:\n",
      "[[840  52  15  30]\n",
      " [ 33 466  60  41]\n",
      " [ 16  68 427  42]\n",
      " [ 15  24  36 132]]\n",
      "Epoch 52, step 0, training loss 0.663159, test_loss 0.819656, accuracy = 0.731389/0.811929, f1 = 0.814592\n",
      "Epoch 52, step 25, training loss 0.593362, test_loss 0.828844, accuracy = 0.725729/0.811058, f1 = 0.814122\n",
      "Epoch 52, step 50, training loss 0.633042, test_loss 0.809664, accuracy = 0.730083/0.816718, f1 = 0.819397\n",
      "Epoch 52, step 75, training loss 0.647771, test_loss 0.812899, accuracy = 0.727035/0.817153, f1 = 0.820639\n",
      "Epoch 52, step 100, training loss 0.550134, test_loss 0.816970, accuracy = 0.726165/0.815411, f1 = 0.818614\n",
      "Epoch 52, step 125, training loss 0.692076, test_loss 0.820848, accuracy = 0.727035/0.815411, f1 = 0.818502\n",
      "Epoch 52, step 150, training loss 0.650219, test_loss 0.816389, accuracy = 0.730083/0.814541, f1 = 0.817680\n",
      "Epoch 52, step 175, training loss 0.722647, test_loss 0.838308, accuracy = 0.716152/0.811929, f1 = 0.814489\n",
      "Epoch 52, step 200, training loss 0.600483, test_loss 0.817787, accuracy = 0.729212/0.813235, f1 = 0.816513\n",
      "End of epoch 52, training loss 0.572705, test_loss 0.815458, accuracy = 0.723117/0.812364, f1 = 0.815691\n",
      "Confusion matrix:\n",
      "[[838  52  16  31]\n",
      " [ 29 470  54  47]\n",
      " [ 15  71 424  43]\n",
      " [ 14  23  36 134]]\n",
      "Epoch 53, step 0, training loss 0.549294, test_loss 0.833901, accuracy = 0.718764/0.813235, f1 = 0.816628\n",
      "Epoch 53, step 25, training loss 0.536465, test_loss 0.815780, accuracy = 0.725729/0.811929, f1 = 0.815334\n",
      "Epoch 53, step 50, training loss 0.603625, test_loss 0.813743, accuracy = 0.727035/0.814541, f1 = 0.818122\n",
      "Epoch 53, step 75, training loss 0.605717, test_loss 0.810124, accuracy = 0.734436/0.812799, f1 = 0.816637\n",
      "Epoch 53, step 100, training loss 0.605379, test_loss 0.813962, accuracy = 0.731389/0.813670, f1 = 0.817122\n",
      "Epoch 53, step 125, training loss 0.668615, test_loss 0.812924, accuracy = 0.726165/0.811058, f1 = 0.814204\n",
      "Epoch 53, step 150, training loss 0.557938, test_loss 0.825121, accuracy = 0.733130/0.813235, f1 = 0.816760\n",
      "Epoch 53, step 175, training loss 0.614796, test_loss 0.827875, accuracy = 0.723553/0.813235, f1 = 0.815954\n",
      "Epoch 53, step 200, training loss 0.618498, test_loss 0.825461, accuracy = 0.728777/0.811058, f1 = 0.815090\n",
      "End of epoch 53, training loss 0.607182, test_loss 0.816646, accuracy = 0.734436/0.811058, f1 = 0.815133\n",
      "Confusion matrix:\n",
      "[[832  54  15  36]\n",
      " [ 32 470  52  46]\n",
      " [ 15  66 423  49]\n",
      " [ 11  22  36 138]]\n",
      "Epoch 54, step 0, training loss 0.609554, test_loss 0.829386, accuracy = 0.719634/0.811058, f1 = 0.815229\n",
      "Epoch 54, step 25, training loss 0.597562, test_loss 0.811264, accuracy = 0.728777/0.806704, f1 = 0.810252\n",
      "Epoch 54, step 50, training loss 0.665227, test_loss 0.813479, accuracy = 0.735742/0.815847, f1 = 0.818806\n",
      "Epoch 54, step 75, training loss 0.596090, test_loss 0.805681, accuracy = 0.733565/0.814105, f1 = 0.817082\n",
      "Epoch 54, step 100, training loss 0.558455, test_loss 0.817665, accuracy = 0.726165/0.810187, f1 = 0.813026\n",
      "Epoch 54, step 125, training loss 0.648859, test_loss 0.812940, accuracy = 0.731389/0.810623, f1 = 0.812943\n",
      "Epoch 54, step 150, training loss 0.563944, test_loss 0.808423, accuracy = 0.730083/0.814105, f1 = 0.816573\n",
      "Epoch 54, step 175, training loss 0.679680, test_loss 0.827669, accuracy = 0.717022/0.811929, f1 = 0.813999\n",
      "Epoch 54, step 200, training loss 0.579416, test_loss 0.829709, accuracy = 0.723117/0.808446, f1 = 0.811782\n",
      "End of epoch 54, training loss 0.598293, test_loss 0.824854, accuracy = 0.726165/0.808011, f1 = 0.811393\n",
      "Confusion matrix:\n",
      "[[836  54  16  31]\n",
      " [ 34 461  60  45]\n",
      " [ 13  66 427  47]\n",
      " [ 13  25  37 132]]\n",
      "Epoch 55, step 0, training loss 0.625449, test_loss 0.825167, accuracy = 0.720940/0.808010, f1 = 0.811393\n",
      "Epoch 55, step 25, training loss 0.589846, test_loss 0.830509, accuracy = 0.717022/0.806269, f1 = 0.809358\n",
      "Epoch 55, step 50, training loss 0.620050, test_loss 0.806407, accuracy = 0.739225/0.808881, f1 = 0.811787\n",
      "Epoch 55, step 75, training loss 0.548201, test_loss 0.811009, accuracy = 0.731389/0.808446, f1 = 0.811732\n",
      "Epoch 55, step 100, training loss 0.526765, test_loss 0.816468, accuracy = 0.728341/0.812364, f1 = 0.815175\n",
      "Epoch 55, step 125, training loss 0.628801, test_loss 0.824789, accuracy = 0.723988/0.814105, f1 = 0.816901\n",
      "Epoch 55, step 150, training loss 0.593443, test_loss 0.813007, accuracy = 0.725294/0.814105, f1 = 0.816687\n",
      "Epoch 55, step 175, training loss 0.702870, test_loss 0.818577, accuracy = 0.720070/0.811058, f1 = 0.813309\n",
      "Epoch 55, step 200, training loss 0.551188, test_loss 0.811237, accuracy = 0.730953/0.805398, f1 = 0.808376\n",
      "End of epoch 55, training loss 0.577021, test_loss 0.825516, accuracy = 0.717022/0.807575, f1 = 0.810581\n",
      "Confusion matrix:\n",
      "[[832  58  17  30]\n",
      " [ 34 462  62  42]\n",
      " [ 14  68 429  42]\n",
      " [ 12  26  37 132]]\n",
      "Epoch 56, step 0, training loss 0.651952, test_loss 0.813190, accuracy = 0.727906/0.808881, f1 = 0.811943\n",
      "Epoch 56, step 25, training loss 0.623301, test_loss 0.836175, accuracy = 0.712233/0.809317, f1 = 0.811796\n",
      "Epoch 56, step 50, training loss 0.618348, test_loss 0.815707, accuracy = 0.729212/0.814541, f1 = 0.816294\n",
      "Epoch 56, step 75, training loss 0.648145, test_loss 0.816489, accuracy = 0.728777/0.812364, f1 = 0.815110\n",
      "Epoch 56, step 100, training loss 0.559694, test_loss 0.816413, accuracy = 0.727471/0.814105, f1 = 0.816107\n",
      "Epoch 56, step 125, training loss 0.661735, test_loss 0.814649, accuracy = 0.731389/0.814976, f1 = 0.817535\n",
      "Epoch 56, step 150, training loss 0.542507, test_loss 0.825113, accuracy = 0.723988/0.815847, f1 = 0.818684\n",
      "Epoch 56, step 175, training loss 0.666414, test_loss 0.833696, accuracy = 0.717022/0.812364, f1 = 0.814594\n",
      "Epoch 56, step 200, training loss 0.588275, test_loss 0.829747, accuracy = 0.727035/0.813235, f1 = 0.816150\n",
      "End of epoch 56, training loss 0.630663, test_loss 0.818495, accuracy = 0.727035/0.812364, f1 = 0.815341\n",
      "Confusion matrix:\n",
      "[[836  57  15  29]\n",
      " [ 33 471  55  41]\n",
      " [ 15  69 425  44]\n",
      " [ 11  25  37 134]]\n",
      "Epoch 57, step 0, training loss 0.602064, test_loss 0.835178, accuracy = 0.722246/0.812799, f1 = 0.815682\n",
      "Epoch 57, step 25, training loss 0.596743, test_loss 0.819889, accuracy = 0.721376/0.810187, f1 = 0.813050\n",
      "Epoch 57, step 50, training loss 0.633574, test_loss 0.812043, accuracy = 0.733566/0.814105, f1 = 0.816239\n",
      "Epoch 57, step 75, training loss 0.647751, test_loss 0.814357, accuracy = 0.732695/0.814976, f1 = 0.817233\n",
      "Epoch 57, step 100, training loss 0.524367, test_loss 0.814372, accuracy = 0.728341/0.814541, f1 = 0.816491\n",
      "Epoch 57, step 125, training loss 0.629578, test_loss 0.821691, accuracy = 0.727035/0.813235, f1 = 0.815371\n",
      "Epoch 57, step 150, training loss 0.610293, test_loss 0.817120, accuracy = 0.721376/0.810187, f1 = 0.812654\n",
      "Epoch 57, step 175, training loss 0.704200, test_loss 0.826951, accuracy = 0.729647/0.813670, f1 = 0.815735\n",
      "Epoch 57, step 200, training loss 0.577048, test_loss 0.825903, accuracy = 0.720505/0.809317, f1 = 0.812369\n",
      "End of epoch 57, training loss 0.574087, test_loss 0.807510, accuracy = 0.727035/0.808881, f1 = 0.812050\n",
      "Confusion matrix:\n",
      "[[840  47  20  30]\n",
      " [ 36 450  66  48]\n",
      " [ 15  58 434  46]\n",
      " [ 12  21  40 134]]\n",
      "Epoch 58, step 0, training loss 0.618355, test_loss 0.815319, accuracy = 0.720940/0.808881, f1 = 0.812071\n",
      "Epoch 58, step 25, training loss 0.595096, test_loss 0.843112, accuracy = 0.715281/0.810187, f1 = 0.813068\n",
      "Epoch 58, step 50, training loss 0.641955, test_loss 0.801296, accuracy = 0.735742/0.815411, f1 = 0.818043\n",
      "Epoch 58, step 75, training loss 0.607180, test_loss 0.820427, accuracy = 0.727471/0.810187, f1 = 0.813802\n",
      "Epoch 58, step 100, training loss 0.501923, test_loss 0.825234, accuracy = 0.719634/0.811493, f1 = 0.813865\n",
      "Epoch 58, step 125, training loss 0.649090, test_loss 0.812371, accuracy = 0.721811/0.811058, f1 = 0.813721\n",
      "Epoch 58, step 150, training loss 0.675243, test_loss 0.817736, accuracy = 0.723988/0.815847, f1 = 0.818086\n",
      "Epoch 58, step 175, training loss 0.725537, test_loss 0.822130, accuracy = 0.726600/0.813235, f1 = 0.815476\n",
      "Epoch 58, step 200, training loss 0.539274, test_loss 0.825045, accuracy = 0.721376/0.808881, f1 = 0.812063\n",
      "End of epoch 58, training loss 0.586386, test_loss 0.801444, accuracy = 0.733566/0.809752, f1 = 0.812783\n",
      "Confusion matrix:\n",
      "[[842  48  17  30]\n",
      " [ 34 460  61  45]\n",
      " [ 15  67 425  46]\n",
      " [ 13  23  38 133]]\n",
      "Epoch 59, step 0, training loss 0.646718, test_loss 0.835780, accuracy = 0.714410/0.810187, f1 = 0.813255\n",
      "Epoch 59, step 25, training loss 0.608697, test_loss 0.811158, accuracy = 0.726600/0.813235, f1 = 0.815966\n",
      "Epoch 59, step 50, training loss 0.657925, test_loss 0.815368, accuracy = 0.725729/0.812364, f1 = 0.815275\n",
      "Epoch 59, step 75, training loss 0.590511, test_loss 0.807374, accuracy = 0.737484/0.809317, f1 = 0.811906\n",
      "Epoch 59, step 100, training loss 0.521832, test_loss 0.810404, accuracy = 0.731824/0.811058, f1 = 0.813246\n",
      "Epoch 59, step 125, training loss 0.631732, test_loss 0.825982, accuracy = 0.727471/0.811058, f1 = 0.813560\n",
      "Epoch 59, step 150, training loss 0.529904, test_loss 0.814067, accuracy = 0.735307/0.811058, f1 = 0.813961\n",
      "Epoch 59, step 175, training loss 0.652488, test_loss 0.820408, accuracy = 0.722247/0.813670, f1 = 0.815535\n",
      "Epoch 59, step 200, training loss 0.609051, test_loss 0.824098, accuracy = 0.727906/0.812799, f1 = 0.815352\n",
      "End of epoch 59, training loss 0.574467, test_loss 0.817336, accuracy = 0.725294/0.813670, f1 = 0.816209\n",
      "Confusion matrix:\n",
      "[[840  49  18  30]\n",
      " [ 34 463  65  38]\n",
      " [ 15  60 435  43]\n",
      " [ 12  24  40 131]]\n",
      "Epoch 60, step 0, training loss 0.603909, test_loss 0.831507, accuracy = 0.712669/0.813670, f1 = 0.816269\n",
      "Epoch 60, step 25, training loss 0.638890, test_loss 0.835595, accuracy = 0.706138/0.811058, f1 = 0.813495\n",
      "Epoch 60, step 50, training loss 0.594300, test_loss 0.811600, accuracy = 0.734436/0.813670, f1 = 0.815529\n",
      "Epoch 60, step 75, training loss 0.638473, test_loss 0.827761, accuracy = 0.735307/0.813235, f1 = 0.815946\n",
      "Epoch 60, step 100, training loss 0.534802, test_loss 0.816730, accuracy = 0.726600/0.813235, f1 = 0.815620\n",
      "Epoch 60, step 125, training loss 0.657503, test_loss 0.813508, accuracy = 0.729647/0.817153, f1 = 0.819626\n",
      "Epoch 60, step 150, training loss 0.598976, test_loss 0.811177, accuracy = 0.730518/0.814541, f1 = 0.817003\n",
      "Epoch 60, step 175, training loss 0.687566, test_loss 0.845959, accuracy = 0.713539/0.813670, f1 = 0.815314\n",
      "Epoch 60, step 200, training loss 0.616350, test_loss 0.817668, accuracy = 0.725729/0.811493, f1 = 0.814275\n",
      "End of epoch 60, training loss 0.634119, test_loss 0.826489, accuracy = 0.720505/0.812799, f1 = 0.815560\n",
      "Confusion matrix:\n",
      "[[834  58  16  29]\n",
      " [ 31 477  54  38]\n",
      " [ 14  73 424  42]\n",
      " [ 13  25  37 132]]\n",
      "Epoch 61, step 0, training loss 0.620117, test_loss 0.818893, accuracy = 0.724423/0.812364, f1 = 0.815143\n",
      "Epoch 61, step 25, training loss 0.585676, test_loss 0.816130, accuracy = 0.728341/0.812364, f1 = 0.814889\n",
      "Epoch 61, step 50, training loss 0.647716, test_loss 0.808427, accuracy = 0.730518/0.815847, f1 = 0.817800\n",
      "Epoch 61, step 75, training loss 0.565323, test_loss 0.823682, accuracy = 0.729647/0.814976, f1 = 0.817644\n",
      "Epoch 61, step 100, training loss 0.530802, test_loss 0.811190, accuracy = 0.735742/0.814976, f1 = 0.817026\n",
      "Epoch 61, step 125, training loss 0.663013, test_loss 0.813761, accuracy = 0.727906/0.813235, f1 = 0.815507\n",
      "Epoch 61, step 150, training loss 0.533755, test_loss 0.818386, accuracy = 0.727035/0.811493, f1 = 0.813670\n",
      "Epoch 61, step 175, training loss 0.625173, test_loss 0.825515, accuracy = 0.730083/0.812799, f1 = 0.814650\n",
      "Epoch 61, step 200, training loss 0.554834, test_loss 0.827151, accuracy = 0.723552/0.809752, f1 = 0.812497\n",
      "End of epoch 61, training loss 0.634558, test_loss 0.821258, accuracy = 0.719634/0.808446, f1 = 0.811264\n",
      "Confusion matrix:\n",
      "[[834  54  20  29]\n",
      " [ 32 470  58  40]\n",
      " [ 13  72 425  43]\n",
      " [ 13  25  41 128]]\n",
      "Epoch 62, step 0, training loss 0.667906, test_loss 0.824044, accuracy = 0.730083/0.808446, f1 = 0.811161\n",
      "Epoch 62, step 25, training loss 0.598488, test_loss 0.827885, accuracy = 0.725294/0.806269, f1 = 0.809382\n",
      "Epoch 62, step 50, training loss 0.687939, test_loss 0.815538, accuracy = 0.727906/0.813670, f1 = 0.816048\n",
      "Epoch 62, step 75, training loss 0.591317, test_loss 0.800883, accuracy = 0.727035/0.814541, f1 = 0.817147\n",
      "Epoch 62, step 100, training loss 0.543238, test_loss 0.824341, accuracy = 0.723117/0.811929, f1 = 0.814471\n",
      "Epoch 62, step 125, training loss 0.678172, test_loss 0.819017, accuracy = 0.720505/0.813670, f1 = 0.815946\n",
      "Epoch 62, step 150, training loss 0.559135, test_loss 0.816683, accuracy = 0.727906/0.812799, f1 = 0.815415\n",
      "Epoch 62, step 175, training loss 0.700547, test_loss 0.833106, accuracy = 0.719199/0.811929, f1 = 0.814279\n",
      "Epoch 62, step 200, training loss 0.573473, test_loss 0.832021, accuracy = 0.721376/0.808881, f1 = 0.811538\n",
      "End of epoch 62, training loss 0.613353, test_loss 0.813911, accuracy = 0.733130/0.809752, f1 = 0.812302\n",
      "Confusion matrix:\n",
      "[[835  58  17  27]\n",
      " [ 31 474  58  37]\n",
      " [ 14  72 424  43]\n",
      " [ 12  26  42 127]]\n",
      "Epoch 63, step 0, training loss 0.586590, test_loss 0.822359, accuracy = 0.724859/0.809752, f1 = 0.812296\n",
      "Epoch 63, step 25, training loss 0.633130, test_loss 0.836291, accuracy = 0.722246/0.811493, f1 = 0.813863\n",
      "Epoch 63, step 50, training loss 0.638797, test_loss 0.805479, accuracy = 0.720940/0.808446, f1 = 0.811091\n",
      "Epoch 63, step 75, training loss 0.556470, test_loss 0.822333, accuracy = 0.716587/0.810187, f1 = 0.813478\n",
      "Epoch 63, step 100, training loss 0.555802, test_loss 0.816336, accuracy = 0.725729/0.808881, f1 = 0.812089\n",
      "Epoch 63, step 125, training loss 0.656242, test_loss 0.809533, accuracy = 0.740096/0.811493, f1 = 0.814634\n",
      "Epoch 63, step 150, training loss 0.647760, test_loss 0.819408, accuracy = 0.723117/0.810187, f1 = 0.813163\n",
      "Epoch 63, step 175, training loss 0.701505, test_loss 0.822200, accuracy = 0.734001/0.809317, f1 = 0.811750\n",
      "Epoch 63, step 200, training loss 0.582857, test_loss 0.821964, accuracy = 0.727471/0.809752, f1 = 0.813284\n",
      "End of epoch 63, training loss 0.585841, test_loss 0.814028, accuracy = 0.725729/0.810623, f1 = 0.813904\n",
      "Confusion matrix:\n",
      "[[834  54  17  32]\n",
      " [ 32 471  58  39]\n",
      " [ 13  71 423  46]\n",
      " [ 10  24  39 134]]\n",
      "Epoch 64, step 0, training loss 0.622123, test_loss 0.824677, accuracy = 0.724859/0.811058, f1 = 0.814338\n",
      "Epoch 64, step 25, training loss 0.646727, test_loss 0.834115, accuracy = 0.719634/0.809317, f1 = 0.811673\n",
      "Epoch 64, step 50, training loss 0.649614, test_loss 0.813415, accuracy = 0.736178/0.811493, f1 = 0.813968\n",
      "Epoch 64, step 75, training loss 0.568900, test_loss 0.811468, accuracy = 0.730518/0.810623, f1 = 0.813392\n",
      "Epoch 64, step 100, training loss 0.543011, test_loss 0.824458, accuracy = 0.726165/0.810623, f1 = 0.813649\n",
      "Epoch 64, step 125, training loss 0.701967, test_loss 0.825052, accuracy = 0.729212/0.809317, f1 = 0.812352\n",
      "Epoch 64, step 150, training loss 0.549001, test_loss 0.813083, accuracy = 0.721376/0.810187, f1 = 0.813161\n",
      "Epoch 64, step 175, training loss 0.604690, test_loss 0.810750, accuracy = 0.733130/0.811929, f1 = 0.814600\n",
      "Epoch 64, step 200, training loss 0.608766, test_loss 0.824258, accuracy = 0.719634/0.808881, f1 = 0.812129\n",
      "End of epoch 64, training loss 0.644151, test_loss 0.838719, accuracy = 0.717458/0.810187, f1 = 0.813101\n",
      "Confusion matrix:\n",
      "[[836  51  17  33]\n",
      " [ 37 461  62  40]\n",
      " [ 13  66 432  42]\n",
      " [ 10  24  41 132]]\n",
      "Epoch 65, step 0, training loss 0.584050, test_loss 0.824170, accuracy = 0.721811/0.811058, f1 = 0.813866\n",
      "Epoch 65, step 25, training loss 0.576270, test_loss 0.817900, accuracy = 0.722682/0.808881, f1 = 0.811293\n",
      "Epoch 65, step 50, training loss 0.621431, test_loss 0.811105, accuracy = 0.734436/0.811058, f1 = 0.813407\n",
      "Epoch 65, step 75, training loss 0.544625, test_loss 0.815091, accuracy = 0.734436/0.813235, f1 = 0.816312\n",
      "Epoch 65, step 100, training loss 0.608030, test_loss 0.826528, accuracy = 0.723552/0.811058, f1 = 0.813985\n",
      "Epoch 65, step 125, training loss 0.648162, test_loss 0.822836, accuracy = 0.722246/0.811929, f1 = 0.814785\n",
      "Epoch 65, step 150, training loss 0.596950, test_loss 0.807378, accuracy = 0.730953/0.812799, f1 = 0.815997\n",
      "Epoch 65, step 175, training loss 0.615497, test_loss 0.821331, accuracy = 0.730953/0.809752, f1 = 0.812546\n",
      "Epoch 65, step 200, training loss 0.573385, test_loss 0.808412, accuracy = 0.737484/0.810623, f1 = 0.814110\n",
      "End of epoch 65, training loss 0.597371, test_loss 0.802494, accuracy = 0.731389/0.810187, f1 = 0.813708\n",
      "Confusion matrix:\n",
      "[[832  53  18  34]\n",
      " [ 32 462  66  40]\n",
      " [ 14  62 430  47]\n",
      " [ 10  22  38 137]]\n",
      "Epoch 66, step 0, training loss 0.592223, test_loss 0.815250, accuracy = 0.732259/0.810623, f1 = 0.814229\n",
      "Epoch 66, step 25, training loss 0.653507, test_loss 0.820518, accuracy = 0.723117/0.806704, f1 = 0.809846\n",
      "Epoch 66, step 50, training loss 0.619093, test_loss 0.800904, accuracy = 0.738354/0.811929, f1 = 0.814826\n",
      "Epoch 66, step 75, training loss 0.648469, test_loss 0.822661, accuracy = 0.721811/0.808011, f1 = 0.811793\n",
      "Epoch 66, step 100, training loss 0.503388, test_loss 0.825775, accuracy = 0.723552/0.809752, f1 = 0.812946\n",
      "Epoch 66, step 125, training loss 0.648538, test_loss 0.816490, accuracy = 0.727471/0.809317, f1 = 0.812910\n",
      "Epoch 66, step 150, training loss 0.543062, test_loss 0.825311, accuracy = 0.727471/0.810623, f1 = 0.814230\n",
      "Epoch 66, step 175, training loss 0.634997, test_loss 0.825398, accuracy = 0.720505/0.808881, f1 = 0.812061\n",
      "Epoch 66, step 200, training loss 0.617510, test_loss 0.825415, accuracy = 0.724859/0.804528, f1 = 0.808919\n",
      "End of epoch 66, training loss 0.558982, test_loss 0.822970, accuracy = 0.729212/0.807140, f1 = 0.811306\n",
      "Confusion matrix:\n",
      "[[831  51  18  37]\n",
      " [ 30 465  58  47]\n",
      " [ 13  71 423  46]\n",
      " [ 10  23  39 135]]\n",
      "Epoch 67, step 0, training loss 0.583835, test_loss 0.830012, accuracy = 0.723117/0.808011, f1 = 0.812013\n",
      "Epoch 67, step 25, training loss 0.602350, test_loss 0.830908, accuracy = 0.710057/0.809752, f1 = 0.813278\n",
      "Epoch 67, step 50, training loss 0.667328, test_loss 0.803045, accuracy = 0.737048/0.814105, f1 = 0.817003\n",
      "Epoch 67, step 75, training loss 0.572350, test_loss 0.821589, accuracy = 0.724859/0.812364, f1 = 0.815976\n",
      "Epoch 67, step 100, training loss 0.554793, test_loss 0.814662, accuracy = 0.727035/0.811929, f1 = 0.815027\n",
      "Epoch 67, step 125, training loss 0.622903, test_loss 0.831763, accuracy = 0.716587/0.813670, f1 = 0.816420\n",
      "Epoch 67, step 150, training loss 0.539843, test_loss 0.819455, accuracy = 0.716587/0.812364, f1 = 0.815226\n",
      "Epoch 67, step 175, training loss 0.638419, test_loss 0.819336, accuracy = 0.722246/0.810187, f1 = 0.812764\n",
      "Epoch 67, step 200, training loss 0.527216, test_loss 0.839745, accuracy = 0.715281/0.808881, f1 = 0.812189\n",
      "End of epoch 67, training loss 0.644980, test_loss 0.821014, accuracy = 0.719199/0.806704, f1 = 0.809897\n",
      "Confusion matrix:\n",
      "[[837  51  17  32]\n",
      " [ 35 459  63  43]\n",
      " [ 14  69 424  46]\n",
      " [ 12  23  39 133]]\n",
      "Epoch 68, step 0, training loss 0.646383, test_loss 0.830071, accuracy = 0.713539/0.807140, f1 = 0.810333\n",
      "Epoch 68, step 25, training loss 0.631756, test_loss 0.817663, accuracy = 0.730953/0.808446, f1 = 0.811521\n",
      "Epoch 68, step 50, training loss 0.659620, test_loss 0.801472, accuracy = 0.744014/0.811493, f1 = 0.814649\n",
      "Epoch 68, step 75, training loss 0.564866, test_loss 0.815076, accuracy = 0.731389/0.809752, f1 = 0.813122\n",
      "Epoch 68, step 100, training loss 0.519531, test_loss 0.822599, accuracy = 0.722246/0.811493, f1 = 0.813931\n",
      "Epoch 68, step 125, training loss 0.619667, test_loss 0.819705, accuracy = 0.714410/0.813670, f1 = 0.816286\n",
      "Epoch 68, step 150, training loss 0.639206, test_loss 0.818872, accuracy = 0.730953/0.811929, f1 = 0.813889\n",
      "Epoch 68, step 175, training loss 0.587512, test_loss 0.826293, accuracy = 0.727906/0.809317, f1 = 0.810703\n",
      "Epoch 68, step 200, training loss 0.562908, test_loss 0.823842, accuracy = 0.725294/0.809752, f1 = 0.811307\n",
      "End of epoch 68, training loss 0.590388, test_loss 0.828127, accuracy = 0.722246/0.811058, f1 = 0.812602\n",
      "Confusion matrix:\n",
      "[[839  56  17  25]\n",
      " [ 35 466  65  34]\n",
      " [ 13  72 433  35]\n",
      " [ 16  25  41 125]]\n",
      "Epoch 69, step 0, training loss 0.631030, test_loss 0.840491, accuracy = 0.714845/0.811929, f1 = 0.813536\n",
      "Epoch 69, step 25, training loss 0.587384, test_loss 0.823761, accuracy = 0.732260/0.811058, f1 = 0.813953\n",
      "Epoch 69, step 50, training loss 0.618289, test_loss 0.803736, accuracy = 0.730953/0.812364, f1 = 0.814999\n",
      "Epoch 69, step 75, training loss 0.594401, test_loss 0.826534, accuracy = 0.724423/0.809317, f1 = 0.811822\n",
      "Epoch 69, step 100, training loss 0.537823, test_loss 0.808609, accuracy = 0.729647/0.812364, f1 = 0.815245\n",
      "Epoch 69, step 125, training loss 0.626430, test_loss 0.814885, accuracy = 0.737048/0.811493, f1 = 0.814460\n",
      "Epoch 69, step 150, training loss 0.622191, test_loss 0.819628, accuracy = 0.722682/0.815411, f1 = 0.818169\n",
      "Epoch 69, step 175, training loss 0.659284, test_loss 0.816850, accuracy = 0.728341/0.814105, f1 = 0.816616\n",
      "Epoch 69, step 200, training loss 0.566977, test_loss 0.812382, accuracy = 0.725294/0.811058, f1 = 0.814357\n",
      "End of epoch 69, training loss 0.573854, test_loss 0.807222, accuracy = 0.732695/0.812364, f1 = 0.815496\n",
      "Confusion matrix:\n",
      "[[830  59  17  31]\n",
      " [ 28 474  61  37]\n",
      " [ 12  68 430  43]\n",
      " [ 12  23  40 132]]\n",
      "Epoch 70, step 0, training loss 0.615533, test_loss 0.821086, accuracy = 0.725294/0.812799, f1 = 0.815880\n",
      "Epoch 70, step 25, training loss 0.660249, test_loss 0.823456, accuracy = 0.727471/0.808881, f1 = 0.812148\n",
      "Epoch 70, step 50, training loss 0.585469, test_loss 0.806528, accuracy = 0.742708/0.814541, f1 = 0.817214\n",
      "Epoch 70, step 75, training loss 0.584215, test_loss 0.813772, accuracy = 0.734436/0.813670, f1 = 0.816640\n",
      "Epoch 70, step 100, training loss 0.509942, test_loss 0.821484, accuracy = 0.726600/0.814976, f1 = 0.817695\n",
      "Epoch 70, step 125, training loss 0.595780, test_loss 0.817141, accuracy = 0.731389/0.815411, f1 = 0.817686\n",
      "Epoch 70, step 150, training loss 0.605365, test_loss 0.818193, accuracy = 0.732260/0.811929, f1 = 0.814803\n",
      "Epoch 70, step 175, training loss 0.734553, test_loss 0.819115, accuracy = 0.721811/0.808446, f1 = 0.811369\n",
      "Epoch 70, step 200, training loss 0.577615, test_loss 0.827016, accuracy = 0.716587/0.810187, f1 = 0.812922\n",
      "End of epoch 70, training loss 0.583265, test_loss 0.830702, accuracy = 0.728777/0.809752, f1 = 0.812277\n",
      "Confusion matrix:\n",
      "[[837  55  16  29]\n",
      " [ 35 467  60  38]\n",
      " [ 13  68 428  44]\n",
      " [ 15  24  40 128]]\n",
      "Epoch 71, step 0, training loss 0.613213, test_loss 0.830282, accuracy = 0.721376/0.809752, f1 = 0.812277\n",
      "Epoch 71, step 25, training loss 0.639756, test_loss 0.823000, accuracy = 0.724423/0.810623, f1 = 0.813353\n",
      "Epoch 71, step 50, training loss 0.608116, test_loss 0.808558, accuracy = 0.731824/0.814105, f1 = 0.816628\n",
      "Epoch 71, step 75, training loss 0.584317, test_loss 0.818645, accuracy = 0.730518/0.809752, f1 = 0.813480\n",
      "Epoch 71, step 100, training loss 0.530123, test_loss 0.817450, accuracy = 0.726600/0.810623, f1 = 0.813743\n",
      "Epoch 71, step 125, training loss 0.661949, test_loss 0.824492, accuracy = 0.723117/0.811493, f1 = 0.815123\n",
      "Epoch 71, step 150, training loss 0.605890, test_loss 0.825364, accuracy = 0.727906/0.810623, f1 = 0.813946\n",
      "Epoch 71, step 175, training loss 0.699206, test_loss 0.849820, accuracy = 0.712233/0.810623, f1 = 0.813521\n",
      "Epoch 71, step 200, training loss 0.563425, test_loss 0.829781, accuracy = 0.720940/0.804963, f1 = 0.808969\n",
      "End of epoch 71, training loss 0.608638, test_loss 0.835150, accuracy = 0.720505/0.806704, f1 = 0.810760\n",
      "Confusion matrix:\n",
      "[[836  47  16  38]\n",
      " [ 33 457  59  51]\n",
      " [ 16  65 425  47]\n",
      " [ 14  22  36 135]]\n",
      "Epoch 72, step 0, training loss 0.553182, test_loss 0.834165, accuracy = 0.712233/0.807140, f1 = 0.811232\n",
      "Epoch 72, step 25, training loss 0.596360, test_loss 0.823513, accuracy = 0.723117/0.811493, f1 = 0.815126\n",
      "Epoch 72, step 50, training loss 0.615805, test_loss 0.803815, accuracy = 0.737919/0.814105, f1 = 0.817337\n",
      "Epoch 72, step 75, training loss 0.633508, test_loss 0.806424, accuracy = 0.732260/0.810623, f1 = 0.814208\n",
      "Epoch 72, step 100, training loss 0.525539, test_loss 0.808726, accuracy = 0.725729/0.812364, f1 = 0.815284\n",
      "Epoch 72, step 125, training loss 0.634872, test_loss 0.806413, accuracy = 0.730953/0.813670, f1 = 0.816727\n",
      "Epoch 72, step 150, training loss 0.572096, test_loss 0.816213, accuracy = 0.740096/0.812799, f1 = 0.816170\n",
      "Epoch 72, step 175, training loss 0.675327, test_loss 0.812706, accuracy = 0.725294/0.812364, f1 = 0.815726\n",
      "Epoch 72, step 200, training loss 0.577872, test_loss 0.810329, accuracy = 0.732260/0.808010, f1 = 0.811946\n",
      "End of epoch 72, training loss 0.601873, test_loss 0.824739, accuracy = 0.721811/0.808011, f1 = 0.811857\n",
      "Confusion matrix:\n",
      "[[836  45  19  37]\n",
      " [ 34 452  65  49]\n",
      " [ 15  62 430  46]\n",
      " [ 12  20  37 138]]\n",
      "Epoch 73, step 0, training loss 0.566261, test_loss 0.816892, accuracy = 0.732695/0.808011, f1 = 0.811897\n",
      "Epoch 73, step 25, training loss 0.615366, test_loss 0.818739, accuracy = 0.727035/0.809752, f1 = 0.813333\n",
      "Epoch 73, step 50, training loss 0.634104, test_loss 0.803796, accuracy = 0.732695/0.812364, f1 = 0.815542\n",
      "Epoch 73, step 75, training loss 0.575577, test_loss 0.806927, accuracy = 0.735307/0.811058, f1 = 0.814495\n",
      "Epoch 73, step 100, training loss 0.534376, test_loss 0.811150, accuracy = 0.734436/0.812799, f1 = 0.816180\n",
      "Epoch 73, step 125, training loss 0.664058, test_loss 0.800066, accuracy = 0.740531/0.813670, f1 = 0.816762\n",
      "Epoch 73, step 150, training loss 0.569705, test_loss 0.819578, accuracy = 0.729212/0.813670, f1 = 0.816808\n",
      "Epoch 73, step 175, training loss 0.645714, test_loss 0.823455, accuracy = 0.720940/0.810187, f1 = 0.811923\n",
      "Epoch 73, step 200, training loss 0.540588, test_loss 0.813490, accuracy = 0.726600/0.809752, f1 = 0.811810\n",
      "End of epoch 73, training loss 0.609876, test_loss 0.829536, accuracy = 0.724859/0.808881, f1 = 0.811005\n",
      "Confusion matrix:\n",
      "[[843  48  18  28]\n",
      " [ 36 460  62  42]\n",
      " [ 17  67 428  41]\n",
      " [ 16  24  40 127]]\n",
      "Epoch 74, step 0, training loss 0.646759, test_loss 0.819043, accuracy = 0.729212/0.808881, f1 = 0.811066\n",
      "Epoch 74, step 25, training loss 0.601666, test_loss 0.827700, accuracy = 0.721376/0.811493, f1 = 0.813919\n",
      "Epoch 74, step 50, training loss 0.624723, test_loss 0.819165, accuracy = 0.728341/0.806704, f1 = 0.809831\n",
      "Epoch 74, step 75, training loss 0.535415, test_loss 0.801376, accuracy = 0.736613/0.811058, f1 = 0.814131\n",
      "Epoch 74, step 100, training loss 0.529242, test_loss 0.825342, accuracy = 0.721811/0.813235, f1 = 0.815765\n",
      "Epoch 74, step 125, training loss 0.601796, test_loss 0.812169, accuracy = 0.718764/0.811929, f1 = 0.814929\n",
      "Epoch 74, step 150, training loss 0.575200, test_loss 0.832680, accuracy = 0.718764/0.810187, f1 = 0.812912\n",
      "Epoch 74, step 175, training loss 0.659388, test_loss 0.824602, accuracy = 0.732695/0.811929, f1 = 0.814083\n",
      "Epoch 74, step 200, training loss 0.535000, test_loss 0.823722, accuracy = 0.723988/0.811493, f1 = 0.814382\n",
      "End of epoch 74, training loss 0.588625, test_loss 0.828671, accuracy = 0.719199/0.811493, f1 = 0.814420\n",
      "Confusion matrix:\n",
      "[[839  51  16  31]\n",
      " [ 32 461  62  45]\n",
      " [ 15  64 433  41]\n",
      " [ 13  22  41 131]]\n",
      "Epoch 75, step 0, training loss 0.667985, test_loss 0.820726, accuracy = 0.726600/0.810187, f1 = 0.813222\n",
      "Epoch 75, step 25, training loss 0.555977, test_loss 0.828000, accuracy = 0.730518/0.811058, f1 = 0.814203\n",
      "Epoch 75, step 50, training loss 0.648283, test_loss 0.818809, accuracy = 0.730518/0.812799, f1 = 0.816048\n",
      "Epoch 75, step 75, training loss 0.576816, test_loss 0.816113, accuracy = 0.728341/0.811058, f1 = 0.814843\n",
      "Epoch 75, step 100, training loss 0.511637, test_loss 0.813035, accuracy = 0.726600/0.810623, f1 = 0.814097\n",
      "Epoch 75, step 125, training loss 0.677430, test_loss 0.822587, accuracy = 0.720940/0.811058, f1 = 0.814743\n",
      "Epoch 75, step 150, training loss 0.596623, test_loss 0.810472, accuracy = 0.732695/0.811929, f1 = 0.815451\n",
      "Epoch 75, step 175, training loss 0.638510, test_loss 0.817187, accuracy = 0.729212/0.809752, f1 = 0.812516\n",
      "Epoch 75, step 200, training loss 0.535455, test_loss 0.810217, accuracy = 0.735742/0.807140, f1 = 0.810323\n",
      "End of epoch 75, training loss 0.573736, test_loss 0.831987, accuracy = 0.720070/0.807575, f1 = 0.810538\n",
      "Confusion matrix:\n",
      "[[839  49  17  32]\n",
      " [ 39 456  60  45]\n",
      " [ 18  60 428  47]\n",
      " [ 14  23  38 132]]\n",
      "Epoch 76, step 0, training loss 0.592834, test_loss 0.817848, accuracy = 0.725729/0.808011, f1 = 0.810946\n",
      "Epoch 76, step 25, training loss 0.564876, test_loss 0.822355, accuracy = 0.727035/0.810623, f1 = 0.813428\n",
      "Epoch 76, step 50, training loss 0.619552, test_loss 0.808199, accuracy = 0.732695/0.814105, f1 = 0.816790\n",
      "Epoch 76, step 75, training loss 0.530219, test_loss 0.816389, accuracy = 0.733566/0.807140, f1 = 0.810533\n",
      "Epoch 76, step 100, training loss 0.554501, test_loss 0.825232, accuracy = 0.716587/0.812364, f1 = 0.815015\n",
      "Epoch 76, step 125, training loss 0.656090, test_loss 0.810651, accuracy = 0.734436/0.812364, f1 = 0.815117\n",
      "Epoch 76, step 150, training loss 0.622464, test_loss 0.806233, accuracy = 0.737048/0.813235, f1 = 0.816240\n",
      "Epoch 76, step 175, training loss 0.658380, test_loss 0.827887, accuracy = 0.722246/0.811058, f1 = 0.813389\n",
      "Epoch 76, step 200, training loss 0.576724, test_loss 0.819937, accuracy = 0.728777/0.809752, f1 = 0.813227\n",
      "End of epoch 76, training loss 0.630233, test_loss 0.834576, accuracy = 0.719634/0.811493, f1 = 0.814569\n",
      "Confusion matrix:\n",
      "[[836  52  16  33]\n",
      " [ 34 461  61  44]\n",
      " [ 16  61 434  42]\n",
      " [ 12  23  39 133]]\n",
      "Epoch 77, step 0, training loss 0.573104, test_loss 0.815409, accuracy = 0.727035/0.811493, f1 = 0.814415\n",
      "Epoch 77, step 25, training loss 0.548518, test_loss 0.820938, accuracy = 0.723117/0.810623, f1 = 0.813227\n",
      "Epoch 77, step 50, training loss 0.648268, test_loss 0.825297, accuracy = 0.721811/0.817153, f1 = 0.819321\n",
      "Epoch 77, step 75, training loss 0.621729, test_loss 0.812458, accuracy = 0.730083/0.810623, f1 = 0.813919\n",
      "Epoch 77, step 100, training loss 0.513580, test_loss 0.812633, accuracy = 0.730953/0.812799, f1 = 0.815663\n",
      "Epoch 77, step 125, training loss 0.710822, test_loss 0.812597, accuracy = 0.734872/0.811058, f1 = 0.814089\n",
      "Epoch 77, step 150, training loss 0.616007, test_loss 0.814780, accuracy = 0.724859/0.812364, f1 = 0.814960\n",
      "Epoch 77, step 175, training loss 0.618343, test_loss 0.825258, accuracy = 0.723988/0.812364, f1 = 0.814478\n",
      "Epoch 77, step 200, training loss 0.549000, test_loss 0.834601, accuracy = 0.714410/0.808881, f1 = 0.811726\n",
      "End of epoch 77, training loss 0.605347, test_loss 0.822259, accuracy = 0.723117/0.809752, f1 = 0.813120\n",
      "Confusion matrix:\n",
      "[[835  49  16  37]\n",
      " [ 37 463  58  42]\n",
      " [ 17  63 427  46]\n",
      " [ 11  22  39 135]]\n",
      "Epoch 78, step 0, training loss 0.607198, test_loss 0.822164, accuracy = 0.727035/0.809752, f1 = 0.813117\n",
      "Epoch 78, step 25, training loss 0.593502, test_loss 0.835774, accuracy = 0.721376/0.810623, f1 = 0.813733\n",
      "Epoch 78, step 50, training loss 0.728110, test_loss 0.823340, accuracy = 0.725294/0.811058, f1 = 0.814111\n",
      "Epoch 78, step 75, training loss 0.603206, test_loss 0.823703, accuracy = 0.722682/0.809752, f1 = 0.813125\n",
      "Epoch 78, step 100, training loss 0.578968, test_loss 0.807406, accuracy = 0.728777/0.813235, f1 = 0.816046\n",
      "Epoch 78, step 125, training loss 0.634877, test_loss 0.812773, accuracy = 0.724859/0.813235, f1 = 0.816227\n",
      "Epoch 78, step 150, training loss 0.562803, test_loss 0.815555, accuracy = 0.725729/0.812799, f1 = 0.815541\n",
      "Epoch 78, step 175, training loss 0.696779, test_loss 0.815706, accuracy = 0.725729/0.810187, f1 = 0.812999\n",
      "Epoch 78, step 200, training loss 0.586563, test_loss 0.807062, accuracy = 0.732695/0.807140, f1 = 0.811123\n",
      "End of epoch 78, training loss 0.616049, test_loss 0.824948, accuracy = 0.719634/0.810623, f1 = 0.814534\n",
      "Confusion matrix:\n",
      "[[834  47  18  38]\n",
      " [ 34 458  61  47]\n",
      " [ 15  61 431  46]\n",
      " [ 11  20  37 139]]\n",
      "Epoch 79, step 0, training loss 0.625746, test_loss 0.833237, accuracy = 0.720070/0.810623, f1 = 0.814531\n",
      "Epoch 79, step 25, training loss 0.583495, test_loss 0.835368, accuracy = 0.718764/0.808010, f1 = 0.812136\n",
      "Epoch 79, step 50, training loss 0.692494, test_loss 0.816532, accuracy = 0.720940/0.812364, f1 = 0.815053\n",
      "Epoch 79, step 75, training loss 0.567099, test_loss 0.826492, accuracy = 0.719199/0.811929, f1 = 0.814839\n",
      "Epoch 79, step 100, training loss 0.542424, test_loss 0.828681, accuracy = 0.714410/0.812364, f1 = 0.814291\n",
      "Epoch 79, step 125, training loss 0.683817, test_loss 0.804159, accuracy = 0.732695/0.806269, f1 = 0.809480\n",
      "Epoch 79, step 150, training loss 0.566500, test_loss 0.809880, accuracy = 0.733566/0.811929, f1 = 0.814914\n",
      "Epoch 79, step 175, training loss 0.643111, test_loss 0.814699, accuracy = 0.727906/0.810623, f1 = 0.812687\n",
      "Epoch 79, step 200, training loss 0.590379, test_loss 0.827514, accuracy = 0.717458/0.808446, f1 = 0.811294\n",
      "End of epoch 79, training loss 0.607816, test_loss 0.820486, accuracy = 0.730518/0.806704, f1 = 0.809580\n",
      "Confusion matrix:\n",
      "[[831  59  18  29]\n",
      " [ 34 460  63  43]\n",
      " [ 17  65 430  41]\n",
      " [ 11  23  41 132]]\n",
      "Epoch 80, step 0, training loss 0.611687, test_loss 0.827181, accuracy = 0.720505/0.807575, f1 = 0.810516\n",
      "Epoch 80, step 25, training loss 0.619187, test_loss 0.818790, accuracy = 0.726600/0.808881, f1 = 0.811531\n",
      "Epoch 80, step 50, training loss 0.673899, test_loss 0.800327, accuracy = 0.741402/0.809752, f1 = 0.812518\n",
      "Epoch 80, step 75, training loss 0.589623, test_loss 0.807141, accuracy = 0.729647/0.809752, f1 = 0.813443\n",
      "Epoch 80, step 100, training loss 0.526148, test_loss 0.825033, accuracy = 0.725729/0.809317, f1 = 0.812754\n",
      "Epoch 80, step 125, training loss 0.649646, test_loss 0.813512, accuracy = 0.724423/0.812364, f1 = 0.816096\n",
      "Epoch 80, step 150, training loss 0.546151, test_loss 0.806385, accuracy = 0.727035/0.808446, f1 = 0.812335\n",
      "Epoch 80, step 175, training loss 0.629627, test_loss 0.834609, accuracy = 0.716587/0.810187, f1 = 0.813518\n",
      "Epoch 80, step 200, training loss 0.606253, test_loss 0.820740, accuracy = 0.732259/0.810187, f1 = 0.814030\n",
      "End of epoch 80, training loss 0.569836, test_loss 0.825169, accuracy = 0.727035/0.809317, f1 = 0.812952\n",
      "Confusion matrix:\n",
      "[[837  46  18  36]\n",
      " [ 35 457  62  46]\n",
      " [ 18  60 427  48]\n",
      " [ 11  20  38 138]]\n",
      "Epoch 81, step 0, training loss 0.621744, test_loss 0.813550, accuracy = 0.731389/0.809752, f1 = 0.813454\n",
      "Epoch 81, step 25, training loss 0.605967, test_loss 0.801656, accuracy = 0.732695/0.808881, f1 = 0.812652\n",
      "Epoch 81, step 50, training loss 0.613890, test_loss 0.803516, accuracy = 0.732695/0.811929, f1 = 0.815038\n",
      "Epoch 81, step 75, training loss 0.600964, test_loss 0.805792, accuracy = 0.732695/0.811493, f1 = 0.815281\n",
      "Epoch 81, step 100, training loss 0.530949, test_loss 0.821609, accuracy = 0.720070/0.810623, f1 = 0.813295\n",
      "Epoch 81, step 125, training loss 0.700502, test_loss 0.816860, accuracy = 0.715716/0.809752, f1 = 0.812495\n",
      "Epoch 81, step 150, training loss 0.556124, test_loss 0.821424, accuracy = 0.717458/0.811929, f1 = 0.815088\n",
      "Epoch 81, step 175, training loss 0.601577, test_loss 0.817895, accuracy = 0.729212/0.809752, f1 = 0.811972\n",
      "Epoch 81, step 200, training loss 0.550381, test_loss 0.795364, accuracy = 0.728777/0.807575, f1 = 0.811347\n",
      "End of epoch 81, training loss 0.560954, test_loss 0.817499, accuracy = 0.718328/0.808881, f1 = 0.812725\n",
      "Confusion matrix:\n",
      "[[838  43  18  38]\n",
      " [ 33 447  70  50]\n",
      " [ 13  59 437  44]\n",
      " [ 12  20  39 136]]\n",
      "Epoch 82, step 0, training loss 0.605938, test_loss 0.811100, accuracy = 0.729212/0.808881, f1 = 0.812758\n",
      "Epoch 82, step 25, training loss 0.618229, test_loss 0.829913, accuracy = 0.723117/0.810623, f1 = 0.813854\n",
      "Epoch 82, step 50, training loss 0.683529, test_loss 0.799570, accuracy = 0.734001/0.813235, f1 = 0.816133\n",
      "Epoch 82, step 75, training loss 0.608933, test_loss 0.822785, accuracy = 0.728777/0.813670, f1 = 0.816600\n",
      "Epoch 82, step 100, training loss 0.510543, test_loss 0.821365, accuracy = 0.732259/0.812364, f1 = 0.814991\n",
      "Epoch 82, step 125, training loss 0.675579, test_loss 0.824470, accuracy = 0.727035/0.811058, f1 = 0.814090\n",
      "Epoch 82, step 150, training loss 0.552232, test_loss 0.817901, accuracy = 0.724859/0.814541, f1 = 0.817069\n",
      "Epoch 82, step 175, training loss 0.624835, test_loss 0.833211, accuracy = 0.721811/0.811493, f1 = 0.813445\n",
      "Epoch 82, step 200, training loss 0.558823, test_loss 0.825167, accuracy = 0.720070/0.808446, f1 = 0.811249\n",
      "End of epoch 82, training loss 0.565017, test_loss 0.805578, accuracy = 0.746191/0.812364, f1 = 0.814684\n",
      "Confusion matrix:\n",
      "[[840  53  15  29]\n",
      " [ 40 462  58  40]\n",
      " [ 18  65 429  41]\n",
      " [ 11  22  39 135]]\n",
      "Epoch 83, step 0, training loss 0.612342, test_loss 0.822727, accuracy = 0.720505/0.812799, f1 = 0.815023\n",
      "Epoch 83, step 25, training loss 0.574310, test_loss 0.804637, accuracy = 0.728777/0.811058, f1 = 0.813396\n",
      "Epoch 83, step 50, training loss 0.594585, test_loss 0.812746, accuracy = 0.734436/0.814541, f1 = 0.816958\n",
      "Epoch 83, step 75, training loss 0.552353, test_loss 0.811350, accuracy = 0.733130/0.812364, f1 = 0.815874\n",
      "Epoch 83, step 100, training loss 0.538448, test_loss 0.813825, accuracy = 0.727471/0.815411, f1 = 0.818140\n",
      "Epoch 83, step 125, training loss 0.630722, test_loss 0.815706, accuracy = 0.727471/0.814105, f1 = 0.816767\n",
      "Epoch 83, step 150, training loss 0.596398, test_loss 0.824982, accuracy = 0.725294/0.810623, f1 = 0.813811\n",
      "Epoch 83, step 175, training loss 0.631647, test_loss 0.815526, accuracy = 0.719634/0.813235, f1 = 0.815807\n",
      "Epoch 83, step 200, training loss 0.608795, test_loss 0.828834, accuracy = 0.722246/0.807140, f1 = 0.811029\n",
      "End of epoch 83, training loss 0.617086, test_loss 0.828413, accuracy = 0.723988/0.807575, f1 = 0.811146\n",
      "Confusion matrix:\n",
      "[[834  53  15  35]\n",
      " [ 33 457  64  46]\n",
      " [ 15  62 432  44]\n",
      " [ 10  22  43 132]]\n",
      "Epoch 84, step 0, training loss 0.544832, test_loss 0.813261, accuracy = 0.717893/0.808010, f1 = 0.811571\n",
      "Epoch 84, step 25, training loss 0.588355, test_loss 0.814326, accuracy = 0.733566/0.809317, f1 = 0.812258\n",
      "Epoch 84, step 50, training loss 0.656726, test_loss 0.816355, accuracy = 0.729212/0.810623, f1 = 0.814128\n",
      "Epoch 84, step 75, training loss 0.624025, test_loss 0.819055, accuracy = 0.719634/0.812799, f1 = 0.816180\n",
      "Epoch 84, step 100, training loss 0.485613, test_loss 0.809580, accuracy = 0.723988/0.813670, f1 = 0.816652\n",
      "Epoch 84, step 125, training loss 0.684275, test_loss 0.805410, accuracy = 0.736613/0.810187, f1 = 0.813228\n",
      "Epoch 84, step 150, training loss 0.604442, test_loss 0.813510, accuracy = 0.735742/0.812364, f1 = 0.815358\n",
      "Epoch 84, step 175, training loss 0.665022, test_loss 0.812684, accuracy = 0.731389/0.811058, f1 = 0.813700\n",
      "Epoch 84, step 200, training loss 0.571121, test_loss 0.825106, accuracy = 0.724859/0.806269, f1 = 0.809581\n",
      "End of epoch 84, training loss 0.574363, test_loss 0.831811, accuracy = 0.721376/0.808010, f1 = 0.811480\n",
      "Confusion matrix:\n",
      "[[838  47  18  34]\n",
      " [ 34 452  66  48]\n",
      " [ 17  63 428  45]\n",
      " [ 11  18  40 138]]\n",
      "Epoch 85, step 0, training loss 0.609156, test_loss 0.832384, accuracy = 0.720940/0.808446, f1 = 0.811865\n",
      "Epoch 85, step 25, training loss 0.611667, test_loss 0.825699, accuracy = 0.727035/0.811058, f1 = 0.813704\n",
      "Epoch 85, step 50, training loss 0.613804, test_loss 0.815607, accuracy = 0.731389/0.812364, f1 = 0.815266\n",
      "Epoch 85, step 75, training loss 0.544351, test_loss 0.812057, accuracy = 0.730518/0.810187, f1 = 0.813458\n",
      "Epoch 85, step 100, training loss 0.601622, test_loss 0.826857, accuracy = 0.717022/0.811493, f1 = 0.813674\n",
      "Epoch 85, step 125, training loss 0.650128, test_loss 0.814367, accuracy = 0.720940/0.814105, f1 = 0.816678\n",
      "Epoch 85, step 150, training loss 0.576361, test_loss 0.824470, accuracy = 0.722246/0.813670, f1 = 0.816410\n",
      "Epoch 85, step 175, training loss 0.613229, test_loss 0.845093, accuracy = 0.715281/0.813670, f1 = 0.815791\n",
      "Epoch 85, step 200, training loss 0.609985, test_loss 0.829988, accuracy = 0.720940/0.811058, f1 = 0.813903\n",
      "End of epoch 85, training loss 0.619693, test_loss 0.828395, accuracy = 0.718764/0.809317, f1 = 0.812288\n",
      "Confusion matrix:\n",
      "[[837  51  18  31]\n",
      " [ 34 463  59  44]\n",
      " [ 19  63 426  45]\n",
      " [ 13  21  40 133]]\n",
      "Epoch 86, step 0, training loss 0.582648, test_loss 0.823428, accuracy = 0.717022/0.808446, f1 = 0.811400\n",
      "Epoch 86, step 25, training loss 0.520287, test_loss 0.813684, accuracy = 0.727035/0.810623, f1 = 0.813473\n",
      "Epoch 86, step 50, training loss 0.626603, test_loss 0.809656, accuracy = 0.727035/0.814105, f1 = 0.816739\n",
      "Epoch 86, step 75, training loss 0.563410, test_loss 0.812319, accuracy = 0.729212/0.809752, f1 = 0.812994\n",
      "Epoch 86, step 100, training loss 0.487482, test_loss 0.816733, accuracy = 0.727906/0.809752, f1 = 0.813168\n",
      "Epoch 86, step 125, training loss 0.659745, test_loss 0.817954, accuracy = 0.724859/0.812799, f1 = 0.815844\n",
      "Epoch 86, step 150, training loss 0.523566, test_loss 0.812874, accuracy = 0.725729/0.813670, f1 = 0.816442\n",
      "Epoch 86, step 175, training loss 0.654747, test_loss 0.817977, accuracy = 0.727035/0.813670, f1 = 0.815737\n",
      "Epoch 86, step 200, training loss 0.568770, test_loss 0.818771, accuracy = 0.723988/0.813670, f1 = 0.816582\n",
      "End of epoch 86, training loss 0.561993, test_loss 0.820729, accuracy = 0.724859/0.814541, f1 = 0.817681\n",
      "Confusion matrix:\n",
      "[[835  52  17  33]\n",
      " [ 32 471  56  41]\n",
      " [ 14  64 432  43]\n",
      " [ 12  23  39 133]]\n",
      "Epoch 87, step 0, training loss 0.614322, test_loss 0.812092, accuracy = 0.726600/0.814976, f1 = 0.818188\n",
      "Epoch 87, step 25, training loss 0.583148, test_loss 0.817295, accuracy = 0.715281/0.812364, f1 = 0.815846\n",
      "Epoch 87, step 50, training loss 0.638000, test_loss 0.811525, accuracy = 0.742273/0.815847, f1 = 0.819152\n",
      "Epoch 87, step 75, training loss 0.574540, test_loss 0.815318, accuracy = 0.731824/0.814105, f1 = 0.817350\n",
      "Epoch 87, step 100, training loss 0.565619, test_loss 0.808614, accuracy = 0.725294/0.814541, f1 = 0.817250\n",
      "Epoch 87, step 125, training loss 0.612738, test_loss 0.821472, accuracy = 0.727035/0.812364, f1 = 0.815788\n",
      "Epoch 87, step 150, training loss 0.612212, test_loss 0.811757, accuracy = 0.721811/0.811929, f1 = 0.814779\n",
      "Epoch 87, step 175, training loss 0.613177, test_loss 0.835473, accuracy = 0.720505/0.811493, f1 = 0.814028\n",
      "Epoch 87, step 200, training loss 0.576262, test_loss 0.834662, accuracy = 0.716587/0.804963, f1 = 0.808313\n",
      "End of epoch 87, training loss 0.648467, test_loss 0.835311, accuracy = 0.714846/0.806704, f1 = 0.810182\n",
      "Confusion matrix:\n",
      "[[839  43  16  39]\n",
      " [ 38 454  59  49]\n",
      " [ 20  63 426  44]\n",
      " [ 12  21  40 134]]\n",
      "Epoch 88, step 0, training loss 0.591433, test_loss 0.836793, accuracy = 0.719199/0.807140, f1 = 0.810562\n",
      "Epoch 88, step 25, training loss 0.581148, test_loss 0.830116, accuracy = 0.723117/0.808881, f1 = 0.812400\n",
      "Epoch 88, step 50, training loss 0.638576, test_loss 0.802262, accuracy = 0.739660/0.811058, f1 = 0.813996\n",
      "Epoch 88, step 75, training loss 0.631019, test_loss 0.808407, accuracy = 0.733565/0.808010, f1 = 0.811588\n",
      "Epoch 88, step 100, training loss 0.568093, test_loss 0.821566, accuracy = 0.734001/0.812364, f1 = 0.815858\n",
      "Epoch 88, step 125, training loss 0.687161, test_loss 0.823522, accuracy = 0.730953/0.811493, f1 = 0.814944\n",
      "Epoch 88, step 150, training loss 0.545279, test_loss 0.841784, accuracy = 0.714410/0.811058, f1 = 0.814941\n",
      "Epoch 88, step 175, training loss 0.626358, test_loss 0.818060, accuracy = 0.723552/0.812799, f1 = 0.815748\n",
      "Epoch 88, step 200, training loss 0.581308, test_loss 0.822509, accuracy = 0.721376/0.809752, f1 = 0.812985\n",
      "End of epoch 88, training loss 0.617156, test_loss 0.829060, accuracy = 0.724423/0.809317, f1 = 0.812514\n",
      "Confusion matrix:\n",
      "[[838  50  16  33]\n",
      " [ 35 468  52  45]\n",
      " [ 19  69 418  47]\n",
      " [ 14  22  36 135]]\n",
      "Epoch 89, step 0, training loss 0.633900, test_loss 0.820773, accuracy = 0.726600/0.809752, f1 = 0.812955\n",
      "Epoch 89, step 25, training loss 0.593991, test_loss 0.812781, accuracy = 0.725729/0.811058, f1 = 0.814337\n",
      "Epoch 89, step 50, training loss 0.616781, test_loss 0.816661, accuracy = 0.733130/0.811929, f1 = 0.815314\n",
      "Epoch 89, step 75, training loss 0.575744, test_loss 0.812260, accuracy = 0.733566/0.809317, f1 = 0.813508\n",
      "Epoch 89, step 100, training loss 0.558310, test_loss 0.804628, accuracy = 0.737484/0.811058, f1 = 0.814233\n",
      "Epoch 89, step 125, training loss 0.649651, test_loss 0.820089, accuracy = 0.721376/0.812364, f1 = 0.815494\n",
      "Epoch 89, step 150, training loss 0.536322, test_loss 0.821111, accuracy = 0.728777/0.812799, f1 = 0.815994\n",
      "Epoch 89, step 175, training loss 0.635389, test_loss 0.814145, accuracy = 0.729647/0.808881, f1 = 0.811680\n",
      "Epoch 89, step 200, training loss 0.526890, test_loss 0.818806, accuracy = 0.730083/0.804528, f1 = 0.809477\n",
      "End of epoch 89, training loss 0.622873, test_loss 0.813394, accuracy = 0.728777/0.804092, f1 = 0.808682\n",
      "Confusion matrix:\n",
      "[[832  44  19  42]\n",
      " [ 33 444  68  55]\n",
      " [ 16  58 433  46]\n",
      " [ 11  20  38 138]]\n",
      "Epoch 90, step 0, training loss 0.617563, test_loss 0.825234, accuracy = 0.724423/0.804528, f1 = 0.808942\n",
      "Epoch 90, step 25, training loss 0.610579, test_loss 0.821719, accuracy = 0.720070/0.808446, f1 = 0.811971\n",
      "Epoch 90, step 50, training loss 0.610792, test_loss 0.802509, accuracy = 0.733566/0.809752, f1 = 0.812530\n",
      "Epoch 90, step 75, training loss 0.612877, test_loss 0.820325, accuracy = 0.726165/0.809317, f1 = 0.812896\n",
      "Epoch 90, step 100, training loss 0.524535, test_loss 0.822839, accuracy = 0.726165/0.811493, f1 = 0.814011\n",
      "Epoch 90, step 125, training loss 0.607438, test_loss 0.825907, accuracy = 0.723988/0.811493, f1 = 0.814023\n",
      "Epoch 90, step 150, training loss 0.565729, test_loss 0.821890, accuracy = 0.728341/0.812799, f1 = 0.814844\n",
      "Epoch 90, step 175, training loss 0.627960, test_loss 0.831327, accuracy = 0.719199/0.811929, f1 = 0.814510\n",
      "Epoch 90, step 200, training loss 0.570180, test_loss 0.810612, accuracy = 0.736613/0.813670, f1 = 0.815780\n",
      "End of epoch 90, training loss 0.610128, test_loss 0.814376, accuracy = 0.725729/0.813235, f1 = 0.815304\n",
      "Confusion matrix:\n",
      "[[840  52  18  27]\n",
      " [ 35 469  58  38]\n",
      " [ 17  67 430  39]\n",
      " [ 12  25  41 129]]\n",
      "Epoch 91, step 0, training loss 0.605296, test_loss 0.823310, accuracy = 0.735307/0.813235, f1 = 0.815253\n",
      "Epoch 91, step 25, training loss 0.605407, test_loss 0.825715, accuracy = 0.726165/0.811493, f1 = 0.813941\n",
      "Epoch 91, step 50, training loss 0.646305, test_loss 0.811842, accuracy = 0.733130/0.812364, f1 = 0.814883\n",
      "Epoch 91, step 75, training loss 0.663179, test_loss 0.819439, accuracy = 0.720505/0.814541, f1 = 0.816920\n",
      "Epoch 91, step 100, training loss 0.548069, test_loss 0.825961, accuracy = 0.725294/0.814105, f1 = 0.815741\n",
      "Epoch 91, step 125, training loss 0.640275, test_loss 0.822349, accuracy = 0.728777/0.814976, f1 = 0.817046\n",
      "Epoch 91, step 150, training loss 0.583264, test_loss 0.809461, accuracy = 0.733566/0.816282, f1 = 0.818744\n",
      "Epoch 91, step 175, training loss 0.677906, test_loss 0.820913, accuracy = 0.727906/0.817588, f1 = 0.819252\n",
      "Epoch 91, step 200, training loss 0.578264, test_loss 0.820064, accuracy = 0.723552/0.813235, f1 = 0.815836\n",
      "End of epoch 91, training loss 0.627061, test_loss 0.829519, accuracy = 0.730953/0.814541, f1 = 0.817193\n",
      "Confusion matrix:\n",
      "[[842  48  20  27]\n",
      " [ 34 461  63  42]\n",
      " [ 14  60 436  43]\n",
      " [ 10  23  42 132]]\n",
      "Epoch 92, step 0, training loss 0.623562, test_loss 0.808184, accuracy = 0.728341/0.814541, f1 = 0.817193\n",
      "Epoch 92, step 25, training loss 0.533466, test_loss 0.816094, accuracy = 0.730953/0.813670, f1 = 0.815717\n",
      "Epoch 92, step 50, training loss 0.642439, test_loss 0.813189, accuracy = 0.726165/0.813670, f1 = 0.815966\n",
      "Epoch 92, step 75, training loss 0.645438, test_loss 0.802754, accuracy = 0.735742/0.813235, f1 = 0.816215\n",
      "Epoch 92, step 100, training loss 0.525412, test_loss 0.819491, accuracy = 0.717458/0.814976, f1 = 0.817575\n",
      "Epoch 92, step 125, training loss 0.594829, test_loss 0.816941, accuracy = 0.723117/0.812799, f1 = 0.815309\n",
      "Epoch 92, step 150, training loss 0.515504, test_loss 0.821636, accuracy = 0.732695/0.814105, f1 = 0.817266\n",
      "Epoch 92, step 175, training loss 0.601936, test_loss 0.837884, accuracy = 0.721376/0.813235, f1 = 0.815822\n",
      "Epoch 92, step 200, training loss 0.539972, test_loss 0.818184, accuracy = 0.721811/0.811058, f1 = 0.814100\n",
      "End of epoch 92, training loss 0.587489, test_loss 0.821613, accuracy = 0.723117/0.811058, f1 = 0.814053\n",
      "Confusion matrix:\n",
      "[[836  52  18  31]\n",
      " [ 39 455  61  45]\n",
      " [ 15  61 434  43]\n",
      " [ 11  19  39 138]]\n",
      "Epoch 93, step 0, training loss 0.613041, test_loss 0.828591, accuracy = 0.717893/0.811493, f1 = 0.814433\n",
      "Epoch 93, step 25, training loss 0.586178, test_loss 0.821603, accuracy = 0.723552/0.810187, f1 = 0.812748\n",
      "Epoch 93, step 50, training loss 0.697019, test_loss 0.809345, accuracy = 0.735307/0.811493, f1 = 0.813986\n",
      "Epoch 93, step 75, training loss 0.591761, test_loss 0.802917, accuracy = 0.732695/0.811929, f1 = 0.815164\n",
      "Epoch 93, step 100, training loss 0.514239, test_loss 0.813087, accuracy = 0.729212/0.813670, f1 = 0.816293\n",
      "Epoch 93, step 125, training loss 0.661651, test_loss 0.816538, accuracy = 0.730518/0.809317, f1 = 0.812259\n",
      "Epoch 93, step 150, training loss 0.530197, test_loss 0.811545, accuracy = 0.732260/0.812364, f1 = 0.815357\n",
      "Epoch 93, step 175, training loss 0.611415, test_loss 0.821189, accuracy = 0.723988/0.811929, f1 = 0.814681\n",
      "Epoch 93, step 200, training loss 0.530062, test_loss 0.824898, accuracy = 0.720070/0.811058, f1 = 0.814068\n",
      "End of epoch 93, training loss 0.639633, test_loss 0.827199, accuracy = 0.718328/0.811929, f1 = 0.815200\n",
      "Confusion matrix:\n",
      "[[835  51  19  32]\n",
      " [ 31 467  56  46]\n",
      " [ 14  67 431  41]\n",
      " [ 12  23  40 132]]\n",
      "Epoch 94, step 0, training loss 0.598912, test_loss 0.815809, accuracy = 0.720070/0.811929, f1 = 0.815166\n",
      "Epoch 94, step 25, training loss 0.551216, test_loss 0.807613, accuracy = 0.730953/0.811493, f1 = 0.814579\n",
      "Epoch 94, step 50, training loss 0.661339, test_loss 0.805086, accuracy = 0.732695/0.813670, f1 = 0.816492\n",
      "Epoch 94, step 75, training loss 0.583089, test_loss 0.822188, accuracy = 0.737048/0.814105, f1 = 0.816961\n",
      "Epoch 94, step 100, training loss 0.571108, test_loss 0.822465, accuracy = 0.725729/0.811493, f1 = 0.814814\n",
      "Epoch 94, step 125, training loss 0.700886, test_loss 0.821832, accuracy = 0.729647/0.811058, f1 = 0.814160\n",
      "Epoch 94, step 150, training loss 0.557685, test_loss 0.824243, accuracy = 0.712669/0.813235, f1 = 0.816291\n",
      "Epoch 94, step 175, training loss 0.611261, test_loss 0.830386, accuracy = 0.727906/0.815411, f1 = 0.818106\n",
      "Epoch 94, step 200, training loss 0.580535, test_loss 0.829538, accuracy = 0.719634/0.812799, f1 = 0.816106\n",
      "End of epoch 94, training loss 0.644114, test_loss 0.820277, accuracy = 0.722246/0.812364, f1 = 0.815301\n",
      "Confusion matrix:\n",
      "[[839  50  18  30]\n",
      " [ 32 463  61  44]\n",
      " [ 17  63 430  43]\n",
      " [ 12  21  40 134]]\n",
      "Epoch 95, step 0, training loss 0.578339, test_loss 0.816988, accuracy = 0.728341/0.812364, f1 = 0.815301\n",
      "Epoch 95, step 25, training loss 0.558321, test_loss 0.828669, accuracy = 0.726600/0.813235, f1 = 0.815821\n",
      "Epoch 95, step 50, training loss 0.627351, test_loss 0.799942, accuracy = 0.735307/0.812799, f1 = 0.815537\n",
      "Epoch 95, step 75, training loss 0.611677, test_loss 0.820061, accuracy = 0.721376/0.811493, f1 = 0.814787\n",
      "Epoch 95, step 100, training loss 0.504868, test_loss 0.801122, accuracy = 0.731824/0.812364, f1 = 0.814928\n",
      "Epoch 95, step 125, training loss 0.656678, test_loss 0.824712, accuracy = 0.730518/0.812799, f1 = 0.815163\n",
      "Epoch 95, step 150, training loss 0.529275, test_loss 0.821203, accuracy = 0.728341/0.817153, f1 = 0.818798\n",
      "Epoch 95, step 175, training loss 0.660600, test_loss 0.820235, accuracy = 0.730083/0.813235, f1 = 0.814220\n",
      "Epoch 95, step 200, training loss 0.606488, test_loss 0.805403, accuracy = 0.727035/0.810623, f1 = 0.812833\n",
      "End of epoch 95, training loss 0.595655, test_loss 0.816178, accuracy = 0.724423/0.809752, f1 = 0.812310\n",
      "Confusion matrix:\n",
      "[[842  46  19  30]\n",
      " [ 41 455  61  43]\n",
      " [ 18  64 427  44]\n",
      " [ 11  21  39 136]]\n",
      "Epoch 96, step 0, training loss 0.633269, test_loss 0.823024, accuracy = 0.727035/0.809752, f1 = 0.812310\n",
      "Epoch 96, step 25, training loss 0.574875, test_loss 0.815927, accuracy = 0.725294/0.811058, f1 = 0.813431\n",
      "Epoch 96, step 50, training loss 0.643027, test_loss 0.808860, accuracy = 0.727035/0.810187, f1 = 0.812239\n",
      "Epoch 96, step 75, training loss 0.549493, test_loss 0.816003, accuracy = 0.730083/0.810187, f1 = 0.812562\n",
      "Epoch 96, step 100, training loss 0.544142, test_loss 0.821681, accuracy = 0.722682/0.815411, f1 = 0.817165\n",
      "Epoch 96, step 125, training loss 0.592941, test_loss 0.834564, accuracy = 0.717458/0.813235, f1 = 0.814909\n",
      "Epoch 96, step 150, training loss 0.537483, test_loss 0.814641, accuracy = 0.727906/0.814105, f1 = 0.816244\n",
      "Epoch 96, step 175, training loss 0.578428, test_loss 0.833358, accuracy = 0.714410/0.814541, f1 = 0.815585\n",
      "Epoch 96, step 200, training loss 0.605029, test_loss 0.812872, accuracy = 0.735742/0.809752, f1 = 0.812030\n",
      "End of epoch 96, training loss 0.567644, test_loss 0.818699, accuracy = 0.716587/0.809752, f1 = 0.811949\n",
      "Confusion matrix:\n",
      "[[841  52  17  27]\n",
      " [ 37 465  60  38]\n",
      " [ 17  69 423  44]\n",
      " [ 14  23  39 131]]\n",
      "Epoch 97, step 0, training loss 0.620232, test_loss 0.810598, accuracy = 0.724423/0.809317, f1 = 0.811619\n",
      "Epoch 97, step 25, training loss 0.562065, test_loss 0.825940, accuracy = 0.731824/0.810187, f1 = 0.812833\n",
      "Epoch 97, step 50, training loss 0.641356, test_loss 0.813628, accuracy = 0.723117/0.813235, f1 = 0.815414\n",
      "Epoch 97, step 75, training loss 0.526786, test_loss 0.827197, accuracy = 0.733566/0.813670, f1 = 0.816497\n",
      "Epoch 97, step 100, training loss 0.509014, test_loss 0.824194, accuracy = 0.734001/0.812364, f1 = 0.815137\n",
      "Epoch 97, step 125, training loss 0.633590, test_loss 0.812454, accuracy = 0.725294/0.814976, f1 = 0.817302\n",
      "Epoch 97, step 150, training loss 0.590893, test_loss 0.819036, accuracy = 0.723988/0.817153, f1 = 0.819583\n",
      "Epoch 97, step 175, training loss 0.668368, test_loss 0.831805, accuracy = 0.713539/0.814976, f1 = 0.817002\n",
      "Epoch 97, step 200, training loss 0.561334, test_loss 0.833710, accuracy = 0.720070/0.808446, f1 = 0.811085\n",
      "End of epoch 97, training loss 0.585678, test_loss 0.824005, accuracy = 0.720505/0.808446, f1 = 0.811080\n",
      "Confusion matrix:\n",
      "[[842  49  16  30]\n",
      " [ 39 460  54  47]\n",
      " [ 21  67 421  44]\n",
      " [ 15  21  37 134]]\n",
      "Epoch 98, step 0, training loss 0.633328, test_loss 0.816138, accuracy = 0.721811/0.808446, f1 = 0.811140\n",
      "Epoch 98, step 25, training loss 0.553328, test_loss 0.827451, accuracy = 0.721811/0.808446, f1 = 0.810698\n",
      "Epoch 98, step 50, training loss 0.715352, test_loss 0.798749, accuracy = 0.732695/0.810187, f1 = 0.812629\n",
      "Epoch 98, step 75, training loss 0.542373, test_loss 0.804539, accuracy = 0.736613/0.809317, f1 = 0.812164\n",
      "Epoch 98, step 100, training loss 0.524230, test_loss 0.824282, accuracy = 0.715716/0.808881, f1 = 0.811780\n",
      "Epoch 98, step 125, training loss 0.638319, test_loss 0.811942, accuracy = 0.731389/0.807575, f1 = 0.811051\n",
      "Epoch 98, step 150, training loss 0.550002, test_loss 0.814547, accuracy = 0.731389/0.813670, f1 = 0.816593\n",
      "Epoch 98, step 175, training loss 0.617179, test_loss 0.827168, accuracy = 0.720940/0.809317, f1 = 0.811924\n",
      "Epoch 98, step 200, training loss 0.586675, test_loss 0.826884, accuracy = 0.725729/0.811058, f1 = 0.814869\n",
      "End of epoch 98, training loss 0.590271, test_loss 0.832351, accuracy = 0.714410/0.811493, f1 = 0.815125\n",
      "Confusion matrix:\n",
      "[[840  45  16  36]\n",
      " [ 33 458  59  50]\n",
      " [ 16  63 431  43]\n",
      " [ 11  21  40 135]]\n",
      "Epoch 99, step 0, training loss 0.646528, test_loss 0.824344, accuracy = 0.731824/0.811058, f1 = 0.814767\n",
      "Epoch 99, step 25, training loss 0.629163, test_loss 0.830278, accuracy = 0.717458/0.806704, f1 = 0.811170\n",
      "Epoch 99, step 50, training loss 0.580530, test_loss 0.818100, accuracy = 0.726165/0.811929, f1 = 0.815374\n",
      "Epoch 99, step 75, training loss 0.571464, test_loss 0.835491, accuracy = 0.722246/0.810623, f1 = 0.813814\n",
      "Epoch 99, step 100, training loss 0.572175, test_loss 0.810651, accuracy = 0.730083/0.811493, f1 = 0.814985\n",
      "Epoch 99, step 125, training loss 0.601582, test_loss 0.812367, accuracy = 0.733566/0.812364, f1 = 0.815438\n",
      "Epoch 99, step 150, training loss 0.512074, test_loss 0.816640, accuracy = 0.722682/0.811929, f1 = 0.815670\n",
      "Epoch 99, step 175, training loss 0.704735, test_loss 0.845530, accuracy = 0.717893/0.813235, f1 = 0.816159\n",
      "Epoch 99, step 200, training loss 0.582866, test_loss 0.835289, accuracy = 0.717893/0.807575, f1 = 0.811509\n",
      "End of epoch 99, training loss 0.581120, test_loss 0.834678, accuracy = 0.725729/0.808446, f1 = 0.812158\n",
      "Confusion matrix:\n",
      "[[836  50  16  35]\n",
      " [ 32 462  58  48]\n",
      " [ 14  69 424  46]\n",
      " [ 15  20  37 135]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "tr_loss, tst_loss = context_model.train_loop(\n",
    "    sess,\n",
    "    balanced_train_vanilla['probabilities'],\n",
    "    balanced_train_vanilla['weight_neighbourhoods'],\n",
    "    balanced_train_vanilla['labels'],\n",
    "    validation['probabilities'],\n",
    "    validation['weight_neighbourhoods'],\n",
    "    validation['labels'],\n",
    "    num_epochs,\n",
    "    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815308\n",
      "[[843  80  20  31]\n",
      " [ 36 428  51  32]\n",
      " [  6  59 461  43]\n",
      " [ 11  38  26 131]]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"context_models/neighbourhood_models/tmp/model.ckpt\")\n",
    "\n",
    "# Evaluate f1\n",
    "print sess.run(context_model.f1, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })\n",
    "\n",
    "# Show confusion matrix\n",
    "print sess.run(context_model.confusion, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f34feaf7e50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niLkn5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34fee68d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_loss2 = []\n",
    "tst_loss2 = []\n",
    "tr_loss_overall = tr_loss + tr_loss2\n",
    "tst_loss_overall = tst_loss + tst_loss2\n",
    "x = range(len(tr_loss_overall))\n",
    "plt.plot(x, tr_loss_overall, label='train loss')\n",
    "plt.plot(x, tst_loss_overall, label='test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Saved to: context_models/neighbourhood_models/v6/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "saver = tf.train.Saver(write_version=1)\n",
    "save_path = saver.save(sess, \"context_models/neighbourhood_models/v6/model.ckpt\",)\n",
    "print \"Saved to:\", save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore the model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"context_models/neighbourhood_models/v5/model.ckpt\") # v5 is actually slightly better than v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816414\n",
      "[[846  79  18  31]\n",
      " [ 35 432  49  31]\n",
      " [  7  62 453  47]\n",
      " [ 11  37  24 134]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate f1\n",
    "print sess.run(context_model.f1, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })\n",
    "\n",
    "# Show confusion matrix\n",
    "print sess.run(context_model.confusion, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def show_results(patch, probabilities, neighbourhood, label, context_model):\n",
    "    colours = { 0 : [255, 0, 0],\n",
    "                1 : [0, 255, 0],\n",
    "                2 : [0, 0, 255],\n",
    "                3 : [255, 255, 0]}\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(patch)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    pos = np.arange(4)+0.5\n",
    "    barlist = plt.barh(pos, probabilities, align='center')\n",
    "    barlist[0].set_color(np.array(colours[0]) / 255.0)\n",
    "    barlist[1].set_color(np.array(colours[1]) / 255.0)\n",
    "    barlist[2].set_color(np.array(colours[2]) / 255.0)\n",
    "    barlist[3].set_color(np.array(colours[3]) / 255.0)\n",
    "    plt.yticks(pos, categories)\n",
    "    #plt.xlabel('Probability')\n",
    "    plt.title('NEP Prediction')\n",
    "    \n",
    "    n = np.argmax(neighbourhood, axis=2)\n",
    "    nrgb = np.zeros((5, 5, 3), dtype='uint8')\n",
    "    for i in xrange(5):\n",
    "        for j in xrange(5):\n",
    "            nrgb[i][j] = colours[n[i][j]]\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(nrgb)\n",
    "    \n",
    "    probabilities2 = sess.run(context_model.inference_predictions, feed_dict={\n",
    "        context_model.probability_tensor:[probabilities],\n",
    "        context_model.neighbourhood_tensor:[neighbourhood],\n",
    "    })[0]\n",
    "    plt.subplot(2, 2, 4)\n",
    "    pos = np.arange(4)+0.5\n",
    "    barlist = plt.barh(pos, probabilities2, align='center')\n",
    "    barlist[0].set_color(np.array(colours[0]) / 255.0)\n",
    "    barlist[1].set_color(np.array(colours[1]) / 255.0)\n",
    "    barlist[2].set_color(np.array(colours[2]) / 255.0)\n",
    "    barlist[3].set_color(np.array(colours[3]) / 255.0)\n",
    "    plt.yticks(pos, categories)\n",
    "    #plt.xlabel('Probability')\n",
    "    plt.title('Context Prediction')\n",
    "    \n",
    "    print \"Correct answer:\", categories[np.argmax(label)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "18\n",
      "48\n",
      "55\n",
      "61\n",
      "81\n",
      "91\n",
      "132\n",
      "139\n",
      "180\n",
      "186\n",
      "200\n",
      "217\n",
      "306\n",
      "309\n",
      "313\n",
      "316\n",
      "351\n",
      "354\n",
      "384\n",
      "424\n",
      "460\n",
      "462\n",
      "468\n",
      "471\n",
      "495\n",
      "510\n",
      "528\n",
      "550\n",
      "551\n",
      "577\n",
      "601\n",
      "603\n",
      "634\n",
      "637\n",
      "660\n",
      "662\n",
      "670\n",
      "683\n",
      "688\n",
      "707\n",
      "737\n",
      "748\n",
      "760\n",
      "769\n",
      "772\n",
      "783\n",
      "808\n",
      "823\n",
      "834\n",
      "845\n",
      "848\n",
      "850\n",
      "885\n",
      "889\n",
      "893\n",
      "896\n",
      "905\n",
      "949\n",
      "967\n",
      "968\n",
      "979\n",
      "981\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(1000):\n",
    "    p1 = np.argmax(test['probabilities'][i])\n",
    "    p2 = sess.run(context_model.inference_predictions, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'][i:i+1],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'][i:i+1],\n",
    "    })[0]\n",
    "    p2 = np.argmax(p2)\n",
    "    correct = np.argmax(test['labels'][i])\n",
    "    if correct == p2 and correct != p1:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer: epithelial\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxkAAAKoCAYAAAAbAjKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzsvXvUb91VFvbM9TtoAgHsIKVYHKEMbokFrIlDwUFlIJWL\niohVa2oEREG0CoRhEYZtMSpVRI21FeuNWoyEgVSh1gsIYsUKgkTl0hAUJFAv3AnXaM5vzf6x5uWZ\na+/3PedLzuVNMp9v7HfvvfZt3X7feZ4151xLVBWNRqPRaDQajUaj8agwnnYGGo1Go9FoNBqNxlsW\nWmQ0Go1Go9FoNBqNR4oWGY1Go9FoNBqNRuORokVGo9FoNBqNRqPReKRokdFoNBqNRqPRaDQeKVpk\nNBqNRqPRaDQajUeKFhmNRqPRaDQajUbjkaJFRqPRaDQajUaj0XikaJHRaDQajUaj0Wg0HilaZDQa\njUaj0Wg8BYjIFJH/gc4/3tKe94je/272vo99FO9rNJ4JWmQ0Go1Go9F4LBCRjzOS+1Mi8rNPrv89\nEfnmLe277Zmz7W/SfZ+9XfsJEfk2EfkDIvL2D8jXu23P3heR14rIXxWRn/foauAZQ217RhCRF4vI\np97yzkbjiePe085Ao9FoNBqNt3j8TACfCWAnwmcEWAH8EwB/FIBs1/71yb2fDOAnATwHwIcB+L0A\nPgTABz1Evr4IwN8EcAHwAgC/A8BHiMgHqOo33/rk48EXAnilqv77Z/jcfw3gPwXwP3Giqr5WRJ4N\n4A2PKH+NxkOjRUaj0Wg0Go3HjX8K4BNF5A+p6r99iPv/laq+8iHf/X+o6g/b8Z8VkS8F8DEi8otU\n9R894NlXqeoX+YmI/EMA/yeA327bASJyATBU9ZETd1VVAM9UYDzonY/0fY3Gw6LdpRqNRqPRaDxO\nKID/EWtg8zOfwPf+ru3f/U19ltyqPl1EPlVE/gWA12NZPSAiP0NEXiYi/1xEXi8i3yMinysiP4Nf\nave9XES+X0R+TES+TETedf/4TTEZIvKRIvJ/27OvE5FvEJHfYNe+BsCvAMAuYN+15f9jt/f9UhH5\nWnMx+xHLz/O3e36fPfseIvIX7b4fFZEvEJFnvRF123grQ1syGo1Go9FoPG78SyxXoE8UkT/8ENaM\ntxGRdzpJ/0lVff0Dnn1P2//QM83kLc9+ApbL158B8O8A/LCICIC/DuAXW/q3A3g/AC8F8F4Afg09\n/xewXJr+MoCvA/BLAfwNHN3FDjEZIvLx9vy3Yom1HwXw8wF8BIAvBvAHAbwjgHcF8GlYLmY/cVMB\nReS/wHIR+04Anw3g2QA+BcA/EJEXqur3UF4A4EsAfBeWQHwhgN8K4PsAfNZN32g0gBYZjUaj0Wg0\nngw+B8DHAvg9WET8Nnw4gB/Y0hSL2P6RLf2djPA/x577ZAD/FsDXPkSe3tbEjMdkvNy+8yXbfe8K\n4D3ILQsi8hIssfBLVPXrKP3bAPxpi+v4ehF5fwC/EcD/oqqfYrf9aRF5BZYouREi8g5YcRZfD+BD\nzlyfVPWrReRfAfhZD+li9nlYIuoDVPV19p0vx4qDeRmA37zd/02q+kmUp+cC+C1okdF4AFpkNBqN\nRqPReOxQ1X8pIn8JwCeZNeP7brn967ECuPfA73++nQuA1/BnsEb8P+4hLB7AItW/n579cQCfoapf\nvt33pSwwDL8WwKsBfMdmdfkay9eHWDl+hb37f96e/xNY1o3b8MuwxNMffhSxFSLyLgB+nr3vdZ6u\nqt8iIn8HwC/fHlEsKw3jawH8ahF5jqreaDFpNFpkNBqNRqPReFL4gwB+E5brzW3WjB9U1a95iPcp\nllvSj2PNoPT/qeq/fAb5+bMA/gqAieWG9G03BHR/90naewF4Po4WF8/XO9vx8+z937nd8xo8GO9h\n+297iHsfBu9m++84ufZqAB8mIs9W1Z+m9O/Z7vsR2/8HuMUtq9FokdFoNBqNRuOJwKwZr8CyZnzu\nI3rt155YGR4W/1xV/+6Db8NPn6QNAN+CJZZ2iwsAfK/tz649LN6UZx/V+66P8F2NtyK0yGg0Go1G\no/Ek8QcBvAQrNuPNGd8J4P0fwuLy3ViC5D1Q3b2ef3p3xb/AIvPvixV8fRMedsG977b9+5xcez6W\nBelMUDUazxg9hW2j0Wg0Go0nBlX9LgCvAPDbALzLU87Om4IvAfBzROQT9wsi8iwReVs7/VtYQuFT\ntts+DQ8WB1+J5Qr2WSLyM2+57yexZpi6FTar1z8F8HEWVO75fV+shQz/xoPe0Wg8LNqS0Wg0Go1G\n43HizK3mc7BiM94HK1B7x7uKyG88Sf+Jk6Dsp4W/BODXY80U9SEA/h/kLFW/Dou0v0pV/5mIvBLA\n7xCRnwXgHwL4UCzLxq0uR6r64yLyUgB/DsA3isgXYcVE/DwAz1ZVnwnqmwD8ehH5YwC+Eaue/q8b\nXvvfYk1h+/Ui8hcAvC2A32nvfdkbUQ+NxilaZDQajUaj0XicOIzWq+p32kxTH3d2HcB/hrWuxo7X\nAnhUIuOwJsUzuU9VVUQ+Gism42MB/GoAP4Xl1vRy1ODq3wzg+7Gmsv1oAF+NNevU9z4oD6r6BSLy\nfVjB8v8dVoD7t9s3HJ+PJTw+HstC8loALjLK+23K24/AEhQvs/f9PQCfqaqvvS0vjcYzgawV7BuN\nRqPRaDQajUbj0aBjMhqNRqPRaDQajcYjRYuMRqPRaDQajUaj8UjRIqPRaDQajUaj0Wg8UrTIaDQa\njUaj0Wg0Go8UT312KRF5JwAfjrVAzOufbm4ajcZbKJ4F4D8B8BWq+kNPOS+NG9D/HjQajcZTwyP/\nd/KxiQwR+W8A/G6shXb+GYDfparfeHLrhwP4y48rH41Go0H4jQC+6GlnonEj+t+DRqPReLp4ZP9O\nPhaRISL/FYA/BuCTAHwD1hzSXyEi762qP7jd/t0A8Fmf8Dl43ru8eyR+/l/5o/hdv+EzMC4XXC5j\n7cfAsONxGRjjgsu9sVayEUAk94I8jzSJ00Ma9j0QM0srHZfZshXQ9Qdq6erH/Lxd++w/9Xvx33/S\ny3CdCp0T1znX/jqhU3G9XqFTsaYVFstrZmztBP5fZNOeUctA5mWlqWa62sV4RlcG+b4xBsYYuFwu\nGCKrvofV95C1vwx8zl96GX7vx/4+KzToHVRFt0yRLHJcg0h11c1Uxbxe135OTK8ruqb+HfWyKJUZ\nVF77lqy9UKfI9IH/9a+/HL/9oz7dOo7vtk4S9e75UqhaW1pe1dKn5XXvK7D81Q6yPjhkYAzfD8gQ\nXGRAhqWPYfWW5UW0IUo/+HN/60/iEz/yU3AZF4yLtVu07Xonn3svE/vx+O8DlpbXSovtLViOVh5n\n9rGS73VNqT6iXqxOvP0UwMu/5I/h037dS1e7TivvtLae695p13Z8z/e/Fn/oi18G2P9vGncW3w0A\nr3jFK/CCF7zgKWflbuGlL30pXv7ylz/4xrdCdN2co+vlHF0v53j1q1+Nl7zkJcAj/HfycVkyXgrg\nz6jqFwKAiHwy1qIznwDgj2z3vh4Anvcu7473fl7+o/KcZz8H7/1uPxeXexdcLpeyH9t5iIVdUJyc\nswA5iAw+Bw4iwdO0HN8gMug+P3+Ht3sHvO97vT+u14l5nbjO69r7+XWdH0UGyYrbRIZW4rmnFXJ3\n8gyLjMvF6tfFxnZ+uVzw9m/7Dnjfd38/Ehb126vsz1xkuKi4Xq9rb+fzeo3jq4uMkzJMElRVZEiK\nDD+O9IG3e9Zz8F4/5/nRcVhkFMGx5bPkMfKaadFXdpFhwgCUx0HEP8SeH1/W8S4y4l0ksqCKt3vW\nc/Ce//H7WHtZu408Xu/L8yokXGR4Pb0xIsPzNHN/lhbtxGKD+89Kf86zn4PnP+/5UIWJuxQZc64+\nPSntBrQLzt3G6wHgBS94AV74whc+7bzcKbzjO75j18kN6Lo5R9fLObpeHohH9u/kIw/8FpG3AfAi\nrNUsAaxVMQF8FYAPfNTfazxpHIVB4y0P3cqNRqPRaDTeFDwOS8ZzAVwAfN+W/n0A3ufGp3KQ2MZC\nc9RZ2CQRI8zPFOT7JJLjrYqjixS9v4yIkhtQjELnmw9juus2snTs+QkLCZtK1r0iKyMKQFQBARQC\n8ZFeG1mOkevD228eyr0ZOYIcGTmUazuLe7ReksOtBQ/VhlJ2ZsXxw/0D2aYS+aSPnFgx3HQlJ5S6\npihUrd+txqEr3CdyO47v3+AqdYLTKzfW1wMq+vDidKtK69NNFqeHfTfdI9v5/rxZXR782vVtEVjd\np7VHVVf7qUJtLwBUxH4rcqsFrdFoNBqNxuPHk5xd6lbGcu/ePdx7m7eJ8zEE9+7dC7eOjAtYri3h\n6mIoBNNdU/aPat5wnhmpDyi5XZAbVLq7HF2i0nWlPuP3TXMRmeHas+IxpsVpzOnuI+ISw/hlkmEX\nXc55ndUWF5PC45wgW95LmS1z7Nt/uk3oFKgRuDln3Bt1Re/0zz20IGShF5pSIEMgKhiWpkMw7AY1\nkeVlH1b2cCECtZ99wEXGwR3K8jqGv5vqB+SeFFVW22zFX+SmFpux4hG86llIkui1fEoQ9Co6D1Ul\n/iopdR11SG3vv5HVxBNzCoBrlE11QMfEnP6bsnoH4jxcp1z4h9Kj3Z7mAwbuDuUClly6vJ1qP91U\nv4s7qLmTXSBidS+ATMUUO1bFFJgIqf1cRs/W3Wg0Go3Gk8TjEBk/iMVi/qMt/Z1xtG4E/tQX/xE8\n523fPl/yo9+Pr/7Gv4WP/KCPtiDv5ZMu4ygwAARTWWRLiYDTxQ1J0W64rxB3EAlHSdvjMvyaEl9U\nBT7qg3+1kU/3H58UQ0DCY6rlTMq+Cg4rwTZiWy0vPvrL6amiYhQbTM5v2KZCRYOoigh+xQf+qm3E\nuI5QO4mPW1hIRH0f5Z7wJoAMl1guMAa8gZXeX9qKBIaWN4MsIsSMBfjQF34EZEjJjouD1J1pCeCA\ndDXBobvg8JiMmpFoEOX0Qze9TXCQwPBiqaVYPX/w+/0X+R5d8QrQCUxXAANzKsZQjDFNLJwLjRo4\njzi2R7JOvY3tuTIhQQiN+Ckdyy3cMlkWQPERv+gjMS4DOpeFY1qflIklNKYCAvydb/zb+KpXfWWp\nrZ/46R8/qcPG3cWrn3YG7gieC+B5AIAXv/jFTzcrdxhdN+foejlH18uTgzwOtwIR+XoA/0hVP9XO\nBcD3APiTqvp5270vBPBNr/hDX47nv/v78pVltbAZdnymHRmjHgf5ge2TWLvYiGvmfpHEKUdc9+Dw\nFAdkFTgIihzZPlgtyHrh92aAtwUx33A8px5IsBSRgO36Ted0RlYTDeuJjTLbLEhOkvcgbw4QXjNL\nrWORccP3HhbHvufWnbASaM7UpOoEXreA6v0dJ1+wof7DvVvuWUSspqYgcnu5KsqsV7mdpB1cg84y\ntyAycgY1nvkp0nx2KKH+twfbUxC/Ybir2JA8tm1ZBmnDUVCkRWNPo/t2IRLmjSoyvMH8WPmHIm5p\nilM6zvTpkxZMswxOxbTZpZZ4X9cYr/neb8dv/aMvAYAXqeqr0LiT8H8PvumbgI7LBNa09a+BC41G\no9F4XHjVq16FF73oRcAj/HfycblL/XEA/7uIfBNyCtu3BfAXb8zIvXt4G3KXArCEhPvNuwVjVEJU\nYETQR1B5zH67sX6npISfx0FMxHHZHy0Y/NwuUOoMSNWCUY8pn7qJh3Luo8lk9aAhZXeyWv7qgkOs\nRiHPTLAnVAVTFWIjxlMV4vmcgjFm5EGZGBJLzPMTQXHWHLJG5EUQcSciijFkWVDGwNCJ45wFe284\n2kysmHkeZDeaiobYra5IRYbwmFrEz0FkKFsy9NhPtzySxEF2mIeHWF7dYuV9wH8D680KmBFDRMMK\n4VYptk6czjKFXURIERf5u6zXo+6ofN7fuNTpupb597QQMF5eMVEhau5SnlYtG1yPyw2u0Xhzw+ux\nnANaZDQajTc/PBaRoapfIiLPBfD7sdym/imAD1fVH7jpmcu9C+69DWeHSU6wnCQ65lCz6CDIp93I\nlRMueVCg7U6Dk4WWEeIYcKVA2V1MBJM9WjU8X+4aFZYEd53yNRemxztQ/o5+PzEyz6PKPNobV73e\nXIABOMgvGvkufvMkNjImg851ZBUqUsxgNcbiiFJqmJsiCLBwvWsRGsASm5hLaKw6dWHlb+E+gTj3\nFBYU7B4GOg6rxQSm5VRchGxuY3XtDo3Yi4xdIRcqnVbvR5KbAsDORahVjv31YIch7Zb9XSLvXoEK\nRFn8t1HyQG5PTPBTaKQFA7LiY4Rio8YQyCRLCQmOhGeUBcdWGBYam4hJsSNLuFFcBlxckPjAtlbG\n6JiMRqPRaDSeKB5b4Leqfj6Az3/ojJxYMgAQ06znymn+TftztGDse9mfOuJUZFQrRggM3x1EBXJw\n2p+nBdxcdHhshtKIeGRtExi6FUWwucHAIhcOA/vrus/Gc6g3IIn0ybasGGbdmHO9a84kqCCB4ZQ6\nNY693wUIfVfDZpDvoWejtUxgDAVUB0Tm+o6x4IwPMEIK32c1clB4rikBsh4JJiZkYokye9jJuZKr\nlouLsGDoicuUPeMlTFHk9ZVtWFuCKucGeLmWFUnTHOAWPBOW6y1KTb6EVBXUqVSivciCsR+7kPBJ\nGJZbo2DoCIuZu2GVDLuqi3JnX/BbiiVkc+Vi18ipKTSKuLDYjEPg96UtGY1Go9FoPEk8ydmlbsVR\nZFCwLaVs/DhGosMzw8hFTPu6s/LDMcpIfIwXHwSFbscsOhD8CTecLzebWUi7E1efXYrdpvi9lh1W\nA1EPQwZEBXDCJwCGWy18hP+GGkj2favASCvGItNiloxpYdhgy4UKkcgkjTmCnm5IhWi71QApSvxF\nw7Mqkd1lRWFhFaPdbNVJoht+/GoLtvnxdBcwtdW5M69O0rPOFSW4m1b1Zpep1X4z3KqKhcW7W4iA\nVa+nQuP0nF5lhN0Dvl3g+UxLISitsVlcQTXEkwup1V7UZ4oFI489RspjpoYKxhzQodAhEB1QExqe\nV580qmSfyrDSqA2jP6fYiJm/zFKxRAUs4DvFxQoC5/+DrN9Jo9FoNBqNJ4c7JjIyOy4eck8kCQiS\nlCRck8zACUwKjJNoBAMxYh49PhEZu7jQWQncmQWDzytpJ4K6p02l73MxNlGjgI61Qjd0YIwJHcNc\no5i8VpLrFWw1GPVZBMfU5Rpl4iLcpiw9YzLMkoDjJ4JUxwi+C8B16scKOhAqMJHdUBmSt4gMGu3O\nWcfqcYqMCBJ2a4SPhls6rIwrsNo/zoScgs/JWpGubmadIuuGTjUrBhWYKkmIaGvE2twgLDakxS6M\nGFk/5CKXzTtJbLk7V1rVwIIC5CplHwivRRMYg4LUx1BczIVuqGJJQ4nMeTl3C9tu7UihkTFYY7hb\n1tqzu5SLipjKdq46Vql1OC4tMhqNRqPReJK4MyLjsq2TAdQRfydHcb5uqdJBkf79mokpMIKSle8E\nyqj6mbAwkj/z2K/H9+l4P59E6Or0sORyoxmTwSIH9K0qfsb61gB8zF/MP30n+ZscoHxqKe+tFg0P\nBqeYDB+ZLzVLbi+AmPuKkIXJn9PUF95Ogi2XWQ5V1xopKHLtFB/5HuWaKooYGFMxh5PVaQR1AnPA\n3aaCUAMkMM5njwprVJkJK92r0mkrWbt4X1VELIaUXnqTKGaRsqwXsSCd7XlROnC7mpWlrO9B4jbc\npLgNiquUW6aGzTQ2MHTNfqWXAdWBiwsywOrR2l52QWHHXj/00TLz1RhF1Pj7jkIDITR8zxXYloxG\no9FoNJ4s7ozIuHfvUiwZAMpIsZirDtwFxaasrKjiIuhasWoAuIG+LQjczaoKCSdqlYyfiYlzFyeE\nSNoFRRlZnjzCjGJJKQJjZr4y6xKuP/ltsmTsQoDq7BCrcLI5KU/rBpFizTUbhB2EhCwZLDDEnwNZ\nMfb3eG4VGdAs8MD1RToH7WU7X5sqQhRcTWjIlCUwxL4/AcDXAOFKygZOS8a1uEZNEhhM5L1tV2GF\nPcmyHYqBQ2p7chudwUUK30ECo/w+uO9NnyrZ6uR6jXuFu8pBcCDI/5w2pbEO6LgscXGpUh6gBf6G\ntR/3DfuQp0f+ySI1oh3NciJjCQmzQLmbVFgvZu5LVbUlo9FoNBqNJ4o7IzKcTDgW8RgQCzKWASOG\nPpStB1J248hvYftJcteI/0pzMhyDrQeBsVk2JomM8nE5pilTy7hrsyz40Pkqm49+qw13y40OXzyq\nnW+OUWjkCHIe50w9Pkwd7jH+Nrd+bPWDs/ucSAY5PKapS4MQE3s5lEgxCydaPdwFh9dI+OsDYyQB\n9v0YEvl2ejuoXjOgOEfa3VVqqECHhPuPXhQXFxsXL9fEXMtOr76JuUbQzcwmAhNm6bZ1iCHBVncU\nxJ/rW1TXoSWcNKwW5Tfg6eukxor48XVuomtGMH+2PcJy4fn2a6qj6FcuwxSbFMB/K6Skst/UTlX7\njqdx+6alSoZAbAZjmavdJ9aEABOCEf2odrCx+2k1Go1Go9F4rLgzIoMJDYAYoQ1ySyReZI1o0wS2\n9JwTDK2k3IbNVbaRcjtfZEmD63NArMdeLLcZhOjwvQAkJGhU1qdaLcVMEg5IIVcRuC3uLCPAWKPu\nWsoqCN/+G8hZElgSFTuBC4J4JHo3pR1JPC/whsOz0a5Kda6wGZGsnW5qs9o94sBrQkKXETmW3IcF\nRFfblnaQfbN+FeUc0MvKzaXkSYBxxbwKpg4j6MMI/DCLhpjFQDCGRv0j2gPUNin8xpAVyE+B1cMW\nnPRR/BQZc8UfaNbYbnkKkXGtYuJ0EUHVcGUT6mqRb/9B+k+ptPV6dm1pFTs2oGS77ULCt0Mf5P7k\nbWe/fNIqq/7SjdInC4jP9zoZjUaj0Wg8UdwdkbGhigsngDhoijWy6uyH3XcsyUefye3FxYXfEesP\nUBpcRNh7D+LCv6E+xp5k3jma5TxJMaWV0WwauVYjXZgxXg8dGueV/TkproHO6917Grb9bYTuGW5j\n25+IjqzW3b/HWkm3EegzTkhElftIfofFBw2dS25HcQFrg9W/xlj9SSGA0ormdu8YgnEVzLEvxscC\nI8UHWwiK2PCMSZ4VYUHTw3K6Tx07pw3lA2kBcoK/uWyt7XqzyPC1PTJLUf/ihc+dHQtE5uqzZv3h\naYH9F8dx7vGuXbhGH84+uyrb762iJIS8vXeMFSeECbNEqbnzcX7bXarRaDQajSeJOyMyeKQSSLea\ng9gIYn10l8qHU2iciYw49pvLttJ24laO/dQFC4uGmJM1yfANrJiI07AkEg1DV+xDsVxQlmlUV9yi\ncZtw8DwxWduFQCHsKRTYesH7knYiLIpFI2wU3GbHdoi7tgAG4umUliPcQiIiqhpZdeuyHu5ngcFl\nWi27i4xF7kWYoI/lfqSTxEW1ZnCmWVx4ih960Hrsi7BIK8ayeE1MEYr5sIBr1RANKTJIYFzJekEu\nVGvNEwAqUW9ZdqVj28/V5nOsQGsZutzK9lilWlSEIN8E6ihigwXr8XcTrxow1zSzXLjYUCsH/WR6\nxe9Go9FoNJ4s7qzIACqvLsSQBMc+LJ781UlXHvM+CK1OOia3HXpPiortIz7oHgR/JLmNjDuN9BFY\nGljfRnNVBsag/LIFI5hfWjHWt49Tt7LggAuP7Xs3WRz4fNzqvsLXUciijOP7ch0HpAi0k/jP618y\nhsPrN+sSRXwWcUTX8v4Vb0FNkNe294joKgcEIxisTZsqgjmWiBi2DxeksYuLgeucK56IRcamh4ku\nRzl3ywUHPLs71RgDvsSfqEC0rv3h665cr7dYL2YKEb9/ZSXdB2sfLpmGzFUnMs21bOpaJ8OtUtay\n+Sv1voijwI5ZpHxGqdv7aVam0CIqa1uLNUqNl0KLjEaj0Wg0njTujMjYwSPTxKltHLSOrO7GjBjM\nJBcn1RQVTmZX2rR7PG2JjrSGVEFRjlWLwBgysRi2560SmxAbQm4fZ2QqRmjJgjHEZsyRWAOgWC6w\n7aVec7FTBMdtzxyEx83WjJsJoYsAazOvU0FttAhWXm2QLjZEKCVH2DNvKS74+CA6dLvH006ExnAR\nN4C1crrF8QyBTA2BMXVglFiHTVxcTZiYm45WZXXoU6qI+AsJMWH9ihe+o8DvcCvyl1k/r4sDPkhk\npMtU/sao6ulYKNMyl+gSs5aMMTB1WTPY+qfbq1xopCXtbBvHNBYp2xszd2nVWbOQEUa7SzUajUaj\n8SRxZ0RG4UsAzQAFI41rpJldXIJQyDZdpxO6LRC2bCEuaApZ26dFAzcSQxp/NjcPADIgY9ooeJ2a\nU2w5C3HLRpCnJPPDZzMSGxWeuvzdbUE3FcEkq8Zy1/J3kRXDj0k8ZB0Kzgneuajwa2cuUqfnp3EZ\nll8TG+nhk8LCBZ3HbOTIOY33n1ofnLDSuZNNm6VrWTI0GG8KjdWPvG+NAQvWlmUdsIBmHWozGbk7\n0ljuRmNizIkrzdYkU1ZQuAiuc82OZoXznfXv2r+WyGC3qNuOPQZCCt0OK8JDCIyjyMg+L2zxyW5O\nnV9MVE2Lh0iBsTSG5m+4vKOqwOwzvqjiibjY+q93Dv79eduKx4VIBvs7WmM0Go1Go/FkcXdEBqrI\nAHIQ/2RQlY6ZEUm4SOW6DyjiIhZPK+KCzu3anjcmXVIpDjDWrFBzAGOORUpNYpz5pDv5DRcdGsFd\nvvZ+v4/O8nM1/ZSUnVgm1mN87UR0YH/fbcJjFxgep3t+3xp5P1qdAodYGXKZcsFwyBMJhuhEeR5p\nbLVQixPg+4LAaizep0xa4QIj+9VUDXEhI2MdZE5MmWHRmFcJK0YIKRYaRsqXZh4xhS2v/XEmNnzN\nEv7RqKKsaM7iR6fHjZykWZC419dx/RlvEhchNbh9TP8dDfrdnfqGIYTvoY+S29Sh7+7nJN/pJ6L2\nx4Us/9+iF+NrNBqNRuPJ4s6IjB0xaBkEsx6fDbeyAWKdV+uFrxqex0m0Ym/HkY+yl0OaE3iIzdEf\nFghfdVvrG0JgsLgwgilzucTAfeRz5NiZ1ICstRgyAzi3XJCbySYgECTvTBSgpN9kweApbKsVY7c2\n5MbB/Bp+suXvAAAgAElEQVTD+hmTkULDi+01vR6ULPKWzyoYwBv08O1YbbtYM6hlc3AcPnNZuPjb\n3kfxr1fBmIKrrNF9jlWY15UeLnvk0pSufCalzCKXrlEUnxHiY5DgsIUDLcPlfadB33oQGilI7Lfg\nVZ2/IFSksM0ZtfgdbClMy0qxO7AQtD6TQd9nFoxqzVhWjGyn8vMKC9nqE+0u1Wg0Go3G08PdERlS\nBmWLq4WU2xab8BFuJxWVcVAohY1KzwmoESwtROtKs/G44LjStygfUqWGE3dVrGF8Tx8KtqRUTmQM\nthB/J11pyRiCNVvOVF9pLMSGZIaWwDixXBzSPP8PIHIPtlycCZOHidGQJPirZahVU2wciS1CECXJ\nPBEYLDTA95DrnWLFV2yCxEVf9EMzdZDcyWNdbai6LAVuxYj9nLjKFWLCQ6agjO6rlnMWHOJku6yJ\n4YJjoM4wtZFvJKnnmIzr1fu7Hvs+3Xe2gN2xpZLRL5GTv6e0YrhgZKtVCmAXuNF3ZRzdpQ6uU97X\n7R1Vt6zfILxvaVlA3tFx341Go9FoPFncHZGxEUwe8YRUwhD33PQmI0zHWAyEFSNIF68loGvk1y0Z\nISaEjuFiw2aKkhUc7IuZ8UjuWYaDHMf5en4MW/PApstRKKbHAcwVfDxttqkx0tJxJi5SsMVw/rHO\naOSeSTnA5F0O5zduJ0LnxgaK2tnbh9zUTBQA5t6kZ+/bqSSfu5qRqM+dREu8O8tqBbbrm8xNdbes\nCCIQs1bIVXD1fAPLgmF1kmtXHPsinw8j3GOwpchnlZJjvMtW9t09MEXFfny07J2JjKMYRNTlLiZM\nJxVrT30PV3z2j1OhS6IyBMnecPbi0BxmnfL+v3+0tG+j0Wg0Go3HjjskMip41LeSlrORbiJENnzK\nnKm4kmieJ0GKoWBAPWh0pYu/XCrhZAHCNo+wsJS73QiRAmCMtGqsGYzE4jp0+bjHOgYrAFltPQIV\nNf95xYTGOgo2Hh/lcNI+FcB1ldBdZ3TfIj6FxZmLtWNtV8FB9X/wt6GWIbca3qprz/q+iCxRMUZa\nIMbE0EW0VQRDBR5of3T3qucAqqscE+vdRWvvWNySJNw8+Lp8d6x86Vj5HwJbNkXWbFW6rG7VgpHn\nKShGkGLJJo0+7JaHJPoZ51HqP/LrkyMsi80a+V/HXgalXszFLVVguFwGxuWCy7hgXAa5dOW+igcv\nSIrezK6VXSUX0BOzTipWH1/aGsN/z/koUI71VOQAsMD2RqPRaDQaTwp3R2QEybVT8EiqlhTGPmjJ\nPHdpCSeSJDzCRz4f0vIJqS+M4VJmW8/AvFIUh4Qr1HLtWMHhKgodWAJjLFI8jHiLiQ2RJSyWwJgQ\naPjqH91mYLNSrUXbAGwzCqkF/VbSrXpW13u9P6AeNOjeOlWE1Ujjm7wgXIoOqNo6GwBAAgIuLsaa\nqUsAkWkxFb5ZXMuZyNgtCKe2DSqbJCHOUXChPiDh2jPU8iY2g5ZkG4sHIkPCaqIkNlIQusgYxWLB\nlZrWnlHaK0tSBUZatTzwnoSGpgDwWaqEi+7PlipZB5cxcLlcMC6XoxsX5z3KIOU9tZ9E6eK3AF2/\nBzdMeZfMe7NfHYQF9b0qQupkDo1Go9FoNB4v7ozISNoXCSkGztngg16YVg0g3hNE0y4wp47POL/Z\nR7IDbLcgK0axaiRPrdaMePEalfdvO7kaSJeuq7lSyVzTqUIhsGMRTJnVTYnKbvICmE703D2sLtCm\n7ptP1ozbXGicjFYSLPFhDSYtdm4aTav1QicLjXRbg+bMW6rDYkAQ61qERUOS5LvAwEFgLNEBpFWm\n9oEb+pcwKXay7Y0pdJsLi9WWoi46QGJjExdI0h9WDCwRK9YnqmsUtal4OXJGtLDIId9f28skzkFo\nIPbFaiLkEhjFpfsEuJgV4zIGxrhscSI8lfKxzhgsFjxeBtFfECMI/tuY/ltyIbEJiyo2ak20yGg0\nGo1G48nizogMAIUh1bHmVAE3ag1iWIokHWy9KBYMIpcsLmITIOaf1Ty8UXQchmqPxCr8xQVrJNnz\nS8dOPOdVMWXa3kaffWQfc62XcRA0TPbX0VQNcTP1GpaMIi7Y/UaTkEdlcolCSLHQonuNIApJxmXJ\n0HDLqhaMKjSW6wzMmjEB3WIR3B0pzs2l6gaB4cRYo65JbFCHimJGU5qADJKdilFELF7GCDtZM0KA\nudgYiIXhpORjnbjAcDHmJD3WXuHKVa5Tj41AWOsOv47g+CQ0dsEBFhnp2sRCMgXGOl5uUr4toSFn\nAekuTqg+SY+WdmChdbaGyPFcS5uy2GBrhqPdpW6HiHwNgH+iqp/+tPPSaDQajbcM3BmRsVsy0vLA\n3P8GMlVfdNjKmhnwNJSR0Eiz01h12kelAVIaLDR4pDsJVbieBDGlcxhpU3oPH0+stRauRpSvLjKW\nwFhfmZHxgz0hyJpLEatfml0o9+eWi4jPOFRwjvLvwbSr3ux5ATWTxxJw0PEsAcgZnLzchlwzqSxf\nfHehCqtGnO/i4ug2Bc4K6iC3lotFMlWBEdYNt6DAXLWQblIDR7FBVgJ3VcrRedm+b8+gPp9VSaKI\nXKXOW8ml4Ip18JgHd0mKfLn6AbY6xPnCikOWFeNyMSsGWzI8HmPE/UdLxi6+NYS163oW9ynMtrJH\nUooKLefbV1pkAABE5IMBfA2An6WqP/a089NoNBqNt1zcHZFxOoLOSqBiuQ6p0/z9bXSUFo0gIORi\nkoJjvWmNMNPot5PLA5VP8lhycINrSNwlgNiK4Omv7iTWSjOxFnOTtZjbFUaao7R+vK9OnkO+SvWX\nLkJVZJR1QjZ3qfIOfy25ETmB3YWI3nBwm7jgOJElMma4HokTeHeRcncicplCIcLHuIzb2iRzSO0a\nbZHCJoSkvXNgiU8OAE+xkQHgg/qS9xUXgcWKol7F3if2bGef3WerQrQZvyi3g8CwzKQrmwvhrY7P\n1kgZw2IybBsjg7/9ub1dvETiOZTDWEAIqVDIK3EqMMA3pMhIqxSdk+BgzHaXclDtPuYPidxT1fuP\n+zuNRqPRuJu4OytU7daHGJm0ize48Pg/lWf/YjrpKO8jIuLuU/HKA19nS8N2HuLiOEobd4mAuBWN\ngucUpWumHidtF9y7XHDvnu0vF1zu3cO9e2vkmLdhZC9GkGnE2MuZ6yVcaePg75kB0eTOlPWyEdco\npVDRk5BnUyUBnhNFVBShwUHoxXXKjmnF6tiua+2H68zt+I6btzqVLA5kFFmsSpaxj+rXLdYPGRIr\nn7vLkwhyWlrJto8+MIiwSxJ1thqtqnUXqa2t6OreF7O7pjUmXZnIYgIJS0ROpbtcoTzIu/a/Gvgt\nZSOhFuan3U4E+r1zEHv2X579i/t06V82kQC7/7lonmV767FkiMjPEJE/KSLfJyI/LSJfKyK/QETe\nDcDftdt+RESuIvIF9OgQkc8VkR8SkX8jIp+9vfcdReTPi8j3i8jrROSrROT96fpni8g/EZHfIiLf\nBeD1lv5rReSbReSnROQHReQrReTZj7seGo1Go/F0cXcsGTtJIjNDDoqTCrjlTaxJWFh4Om9BqLdn\nhEZOAbBS2BNCWtzmFZJcS4iADgjSvWTY8XITmbjKhFwnruT8wuVIQj+hE5VwEhHlPeYxbbdiRCzM\nWXWHqEtXHNYiu0+8i5Vc/I2sGLqJi6t557N7jrVFukflFLdpuUCxXrCYEyK76Y7jRHu9PFzjtmIK\nl/TEMnKcxtanrbVv67pn1UOq4SJFlb+Y50XjhTVJQhwfp+E9tpXnSa18ogol9y3Plx9Hv4y1Oqxf\n0todbskYl3GYwnZIjclId7pdjFO54NPn2pn/CMVik5BT1+ZTXu48Vj2ml/qYb1WWjM8D8DEAfhOA\n7wHwewD8bQDvBeC/BPCldvzjAH6anvs4AH8cwC8E8IsB/EUR+Qeq+tV2/UsB/ASADwfwYwB+G4Cv\nEpH3VtUftXveE8Cvse9fReRdAHwRgN8N4MsAvD2A/xxPwJLSaDQajaeLOyMyqstHJOW1Gx47/EtF\n1g8eja9WDKTgoOP4plsteBj55N9EHxFmc0WMgjOVpGssMMraAuJE7WIiZ0LkGgLDy4aLvcl1wFyT\n2UKovCwYyqrMCug0Mkbn2+jw7u9/sGMQgRQnvqX+My88Kl2ERlgzNEai53SRsQmKzT1KBGvdiU1c\nHLbdpcrqKcmvkVuhMfbVSLHRYXEnsrUQw5VIdXedQswwlX2FP7L1Kc02VuSq1VWwuZg4tlExyZwI\nXCiVU11sbXUR/VKyT154tfE8dgscX8t4jG2GKbJ6ceZWF16xRhmT4ZlFiNip1CxFWKSbFIutdPlL\nzAcOTrxlQETeFsAnA/hYVf1KS/tEAN8N4BMA/GO79QdOYjK+WVX/gB1/p4j8TgAfCuCrReSDAPwC\nAO+sqm+wez5DRD4GwK8F8Oct7W0A/CZV/WH79s/H+r/WX1PV77V7vu2RFbjRaDQadxZ3R2RsSJLK\n7D+u7nefvCD3SXRppH27Xl+zk8DjvvA4Yeq0jdryNSet7jYjPgpss/PIcj+BCq5ytfdc830RNwLo\nZeV7Yq2tMWnUOkWWuwld05IR7id5DHa/uYWM7ePRYqPNfjVsIPanuLmwy1QRFtXVqVoydpKvaaXQ\nG4QFWzDC0kHPlbYpNoW4TtLxJC8mIgCKyUC5zrNOiXJ/YUGaIi3qz+pKuA3XLgg5dLmgVUGY1/cu\nXCwZsHYxsu7lz/x7/aW71IUFBosKOg7Lh1DsRggsqtEbjBkapkPvPJ5B2MxcSqaOrexsydjSGG9F\nMRnvgfX/9X/oCap6X0S+AcALkCLjDN+8nf8bAO9sx++PZYX44SqY8Sz7puO1LjAM/wzAVwP4VhH5\nCgBfCeBLyfLRaDQajbdQ3BmRMY0QO5w4LHJqi6lNX1QN5lu/EY6T2ZJ8ZDNfvNiKxHA4MIa9SwQy\nB9RHx8Ej2LxHXh9OZM3VaedSReQQKQIfr6laFRM6V/4iRmJu5TlxgUqXo+uKWZhXzOuV0q4mKpy2\nambsbCT8jRn19ZHkw8aWDBYYa4Q629LvhXFxH76GzYbk9a9bGmDVnttkYTKj3Q7PRRoLmxHvG14u\nB42yc9Dxsc6MIO/16GYEZsxlXyr0uNdqnSuiRwS6lpGHqw65Z4s6CrlXycBQxRzZx7z/n4qJsVsz\n+DxFRVYoZUGXVUqtOV1LpBCNn2Mt/jJpUDldzNpvI34//JjmD89vPdT9WwW4Fvb0B/2w37CdKzJu\n7zkA/jWAD8axNlkw/GR5wVqg5MNE5AMBfBiA3wXgD4rIL1LV196UkZe+FHjHd6xpL37x2hqNRqPx\npuGVr3wlXvnKV5a0173udY/8O3dHZFwnrtdrSWNR4SJjBXeiCBAP+NzJrZPe9TIE+eBxZSdmaqso\nY6xnXGCABUXyqCI6dl/0uAlO4Ylsw0bwBcAQmL5YsxCtSaegKiEYPFg7jj0YmvYpKq64XvO5q6WF\nyIiK2Aiw+DS4aZU4Q5LHTTg9cEMVS3Pbl/f5l/Y8sMVkuzpRRMm+PVhYSN4zJsZcymUOQOZc1iXv\nkBhRV275qYKD0zPffnhTqWoaieMwU1TRIdaP3XICrXM4iAiuU9YK8pqWJBd5IwTsWEHRCpuQYHeN\nqmlyYXcqsvBsJcs+v7I8ZcVWTLU96Hx1ekTB+NhEncfQ6PadpUeSV4ur/IO+e6tRGf8CSyx8EIAv\nBgARuYfl6vTHAfx7u+/yDN/7KgDvAuCqqt/zTDOlql8H4OtE5A8AeC1WzMafuOn+l78ceOELn+lX\nGo1Go/EwePGLX4wXb6M2r3rVq/CiF73okX7n7oiMgyUDhYBWQZEj4FNxMmvQUWhokGujIubgLc7+\ngpQoiRHaw2IFsF2TEzcRdizyPADL6mA5GLAVrpn4qlogteB6va5ZlGI2JRIY26rdLtDm9RqC43p1\nwXEf1+s1RpUz30ghpTXtAFYWZAlRlXKpCI+tPdJ6odSGbOlwPu3D2159Tislz11llE3WwncluU5x\nHI+pVmFB7lQDgikjxcYYmC40jBlb6aNsKWaPgqN+WXfuSyXjKvb+mN/K99Ce+h9cCHkfnANjmy64\nWJTISuZCPgSFuZxxrAWLDnZJg/d36u7QdPlyUYEsUmiIVVaaPCDEgSB9xuhYtgggFhOCnKr3RGhs\nLj5vsVDVnxKRPw3g80TkRwB8L4DPAPBsAF8A4O2wauajRORvAvhpVf3JG1+Y7/0qEfk6AF8mIr8H\nwHcAeFcAvxzAX1XVV509JyK/ECuu4ysBfD+ADwDwXAD/75tW0kaj0WjcddwdkXFVzCuJDBoJTYGx\niYwgpzPIkpPZKjQAZiZJpoVEhF/NA6a6zFHEhqQ9yYnXYCsJ3e8j2joVkAmVNbKblpKVvWGj7lCk\nsHCrRUzbei1Tu0banCEsriYsJh2rpttQ5JXOrWbcg+yB476qi5wz2U6rRYqNaI+5tU1xd2MrBnND\ntlmofdMrXlM0+Db3hEVQ2ZKxzl0GLqHkblhqLnQiEwPLkjFsoQYXD6ITKqNYK0IKeBoLMRK3qxjH\nYXbWt1B+imtiFxrZjnMMDExABmSqpetKPxUZE6ojrRoWcL8mInDB7ALDp97layYwhruheUfm/qFB\n9P03qHwugK96HmthkGDIwBE/XuJwt7n5N11+1JgbOrw7k3U/CXwmVum/ECuO4h8D+DBVfR2A18ma\nmvYPY4mOL8QKCH8Y/HIAn2PP/YcA/i2Avw/g+2555scA/BIAnwrgHbCsGJ+uFpTeaDQajbdc3B2R\nMdcofMAFRnGnSTLKQiOChn3bLRrI59PNxEh1uELlnq0XONnLfn4DaV93aDzu5HOqLTgX3EyN5Gq8\nO4TFidioVoxquXBRcb2/9vev93G9fx+qmoulDUTQsow1ep953uXFRogVRLAlRvHPLBiH0fMgvCRC\nZrapv3+RzCowcrX1FBtef8VVasQTliRRp6oaz7m71BKQKTQmlmicEyY0JoamNUOpM7H1olgw/DhU\nwzYD1w7lwxTGUdel/1grhcIVDAUUYw34i2KoQgcwtzapVo15EH5Clgq2WMTCfG7lMGFR3Akl+07I\nPxMaXB6AXKZEw8oxRTBImITQgFmaFCEOa12maPM+fBAbqL/Jt3So6r8D8Gm2nV3/HCyxwGkfcnLf\nx2znP/mA974MwMu2tG8H8JHPIPuNRqPReAvBHRIZuyWDR7mPIqMKjfNpWJOdsSnjOBvRODkH+3cU\npxXd3pfENQZ17TtREJtedkIhusTF0AHIis1I0WNiQ2GWiVnEBlsv9kXmriQ07t+/v8TGfRYZM33s\nVcy9Zq3NoWONKq+wkByRPsiNqI88TnGwiw0WEmfC49ie5zEZRtKtflhsJDxOQ0vQN1s13JrhFpjl\nLmV7SpMlMzDGivMZc0AxgTEyfyQyjkLD+4pm16lD9FYstmhY7uPdtXT8ruiDcJG8npUhIaZhwnp4\nnbLFgiwZc5ogCZGxCQtyi+J0t755kQ4EXkkI0M8oLRZS8ullmzChQVW2rHxSX84Qt2JQvZwJirci\nkdFoNBqNxl3AHRIZJ5YM7AKDyChdC0sGE78gr+QyBeOnISZGuoYILz7mAsHJIpFHOg6Gjc2dahuA\nr2IFgJq4UA6aVazF+VbBXVSwoDiKCw2B4daM+yE0ljXj/v034Hp1S8Za3wDqw8vD8jtQLQdHMIlj\nIVDcpKK+KfaCA45viJvZxYaU7+1iwyinHxdXKDms3OZvENcnErovyLILuxWTMTCxxO4SYBNT14xM\nS8yO5bZzIjScWqc1I9tcw3foxsq1wyTeqjfcBCqHW6H2V+v6JosMn01qznFi2dBqwQgLhQuNPI8m\nEfoYaeqSGf4NKJZLGv0mPSA8xwMkOsByx8tG5Gl36/c9+QZ1jLcuS0aj0Wg0GncBd0hkVEsGQKKC\nj52MHtKOQiNdTZisiBEzmkVHaHpO21YGZoiMHLGeCLGxEUl7CAC5VPloLRTQ5Te/SO6Eh4hHnqAQ\nm+VqXjUsGWzR2DeP0QhLxn2zZJjAuH//Pu6bJeNyuQA6gIuLCx/dd3ceTVexczPGZsHwtEq499mj\nfHXvcp3cp3axUXxmXBHk4g7rWyHOMh+rycSsEtWi4Y+H9QJszVgFFosBGCssf0kNqQIjXfBIgG7i\n1ntc3BM+Q4dukofRXbRydN1up+fYxS3Jf1UA8fvYFz28QWQUcUFuUSk4ON+7oNvOrSzVgrH6GAeE\nx6re5FqVMRsIgaHULbikWWSByJbmp2NLaDQajUaj8VhxZ0SGL8wW5/bnVGhgd6M6GyGvBHYnZ+4O\nMuSCcRm4jIuN9F9wGYPExb5S9kCsko0ZrIhJdx2+BVlDADVxsWTIMPecnJFK7F3nLlJ6tGaY0LiG\ny1TGYtw3wXH//huIAA/47JVOHsfISl5UjDzaDyPv1aUpBYLWYx49jw3mRrVI5ixtmNv+PRcdCllW\nBBHTG2oCogoLDHZFglkpWGi4uFIiph6jYX3QxcVc7ezB3gcXqaDWlkYptQzcr9ltaq9X6vuU/yOE\nxJHP8ER7U1fPTGQgRQXcLeooNrycvlBelh9VVHshFGHBCHHh5drERbV6WEn52P+ymBAX634DiQ3w\nc41Go9FoNJ4U7ozIcJLMYHER58q+53adR8rJ5x/KBH+xGechIjn//2Vclri4XOIYSIGx9pPObURW\nJdLc5WZlFDEtZ478V6K5eO1M0kRCQyco1mLGzFspOjaxcT3GZLi4eMP9N+D+G+4jGD7uOS/DnLk6\nteqDp99hslssGppuQjUuw9tlrimKlWYAu0EMsoBhISMZUAG2ZPg0texk5WuPsDXDNckisUSo7V2A\nE+ixbjTBuz63ZmJS8XxO7pBVfBwUkxbBwDo0dnu9+v00lW95B1IgxgKClvdjGo6rrHvbbCIjrVhJ\n0stECCTIVDWnngW3W17PHyitDE9C8syaMdU0IhCWjKPY0IjDKNaMk3zH5bZkNBqNRqPxRHFnRIaT\nnpJmf6olQ+M4OIxu/v6H4OKdBBmpd39zcpO6XIa5FS0xsRb5M3ETogJrFquIaWDiaQQ3RnT9expE\n1489/xLHdkYiQ2M17yVyeCatPfj7aOHIRfxUFTJlrZ3Abj9UJXtAfI5cU5tQPd4kMHbXqFmsGefC\nwts2v5HY9EXEIJR+svWcGgxMwsRPceaFZStUT0AxoGJ9UnS155wWzjIsnywsvF23/7iCg5CfZ151\nJ8J00aw33KdqW3k80YhjEeqfsiYdmCKQqZiyhPGc0/YkvCy7Xvd72hFeMAkR59YJgddLWiHU38s4\ne/cN95B3VAoL7q8n/fb4wUaj0Wg0Go8Td0ZknIJIaF287ex4d9s5nod7j80glARx+dsvwqxY80A5\nNTrbIoNx5O4lkSwDgFs4NImxwIZjyd+jEGchSlanPg1SzwIh8pwIS00E7Q6IrMDv5Ro2MNh6c7ng\nnu/v3cMYF9qYtFr2rV7X8SYgfNQ83HI4TmaeiMCiAqOunJCm0ElCDWxuPMCBZHJzlC7lNa8w4k3S\nUwS1/7hQyvgMzOwHc7qFxja3CBTh4d0kJc9NbN1FlMcgQPbVzetIfdnGcZa0jD3ByfIc3m+sjGk+\nCdPP2qW1RzjfaWjK9EhbboAKoYX9pE6DW9K2+4SuuXCKa9nWpxaX2B/rttFoNBqNxpPD3RUZxNVi\nrYxwvwHNlkOCg913mMSCSLG9WHUCPqIfkkKJtO+iYj9e2IkhkzHiYWCqWKbkjNl0JB/wg5MB77pP\ni0jeK+5LA55BC4oS2H65kOVmXDBIcLgAcYHhM3AV9mYk3Ufrb9pmERy76PC2QFhDGFlvR/J8cOPJ\nWyvpZaRRA8JVHPW+CdOpUKGA7zlrL2CBtZcn+iNZMpDfuU1ohEUAgMSUvQjyH/VBM6OdWaBy1qmU\nNuv1aqEn2fPD0oOsH7cHrdymYOG63Pu4Z1E1hS2LBl5BvK7BcdPaHCyWfe/VQYIyxKf9OVRvq4xG\no9FoNJ4k7qzIKETO3W60+pfXKVHz/rqHCYftfZouLSE6sKwP9tDJRjmL1YjJgCESrjd203IO4ak4\nNQlZUOogv8Esa0WoZ8vzum2UrySYSTSHrDiDYRYM3zgG5XK5F1udaStdcc4WGTxaj3irVozdpQ3c\nDqY0ovpC05wIDCOuISywjVQfOGYVL9Ev/HlNsszlmTqBaX3CVtR2yxeAsGTcJrLy85vYuEVoZP7J\n2kUXBLVNbt7WM+tY04Dm+TnLK1LLuJXHg733CkuB4Rk2le3tIZuo2M930SECGTgRFVKuw/PEbV9E\npydSlbYpo9FoNBqNJ4o7JDIEJdA1RpVhgdApLHJbQawxWks6IGRFJK/h2QxyJmtGsHiPs7hBWJxY\nMjzrwC4wkBaKars4cV2x0WN7yAle1sRO6rGRw6MFwH3yhwjmWOtvrCB3smKQwLh3ueDevbX59L5u\nxYiRcrbGkKg7dzHSGk+yTWu7u7RtzVdIdnUJGiE0orZ2/njgk1tlCp14OdyyYfmZqrmYnU9f625T\n1kdiil49KV+0l1sRzsRFmAwOmZfKoClNjuLr1NJD4kBQywzu3d67pkviFF2CLddmzSi5FZSOzwJJ\nQGIiXZ7OjnchwQJDBMUdjMsTAsM/uesy0H2NRqPRaDSeGO6MyND92BaM24krL0I3r2uWpf0lWlnb\n9qHNtQVLaMCtGif7c8EB8ASegBOZynKECZiR2BrA6+4olKb8nkyLXDkpDz+jmisw8RwDY04bVb6E\nNeNyWS5S7CblgoMFipAlI1yRNPN9k8DYZ5HKWaaquEiBoalcmFhL7ktw83AxyDR4q7AbrqQZwx8n\nsREzh7mblK+ObSuBW7wOgLRiHGJPvG/Re7e8FpcuauoirtIXiNKzbXEQFkbISXQof6IIDetNmyUj\ndLEfx9+0W6g3UWSa7pF8comMESKDBUccX8iKQe5Q58fCXYMEhZyk1SZvkdFoNBqNxpPFIxcZIvLZ\nACL6vZYAACAASURBVD57S/52Vf25D3r2jCbGyDJbMGjmpCIy9rzsR8NHlo1AIoVGsW7AV8BmEbFb\nDHR7O7mJbOn7GLaPIAtgLlI7IT4xc/jeCf7u8kXf2ke2xxiAwAK+BwmNEWKDXaZ2wspktuTzVGC4\nC5Ftk0j42YrfLJq2dgtqHW5f5irlCyYWVzGu2YNsO223VY9bzZsAgsLWyFjTAKzPrdWyfS0NFk3H\naXm93bhUKTTOjhgR7O6WC/C5t8e4WXBAgnvH9VrSFNMuMsTtFce2WE+ErWNvKBIYnr6+HyLjwuJi\nhBXDz8N6wZYMsmKE2JD9O7m/SWDUi41Go9FoNJ4EHpcl41sBfCjyn/v7D3xCAXaXilFgdmGJKVlz\nJezrvAZP49HhGIUVJDGiqVtjpDpG0Nn1qHyY/NV3q4bBR9vBxNizkudralR/jyB9pIRGvXOUWyGh\nK3JfrQBszYgPESEbMqBjCZqMyXCXqUtdI8RcpiLXUS4p9avAmnFoa59CtiN2xqffvWUtExr934f1\n95H6QZuKO/Bk+RW5SNyhfxUxx21KxJvzBV88bkLnWHOSjYlp/bTEnhyCv8kVjEf6iwCqxNeNAIcB\nerJMpSVjVGFRxAcJze2d6yBF6/rPV7bf8uJ3Rv73l6G4K7mVIb7pLlCXKirGGJDLdl6EhJU5rBi3\nC4xD2U70REuMRqPRaDSeLB6XyLivqj/wJr2ByWv492ssULcWnqMF/IxQuctSEBWFkVFAlGYKYhGx\nCYxY86KIikpad5oYI8ZwghdHeTyMeE77ppG3FAgKKE9hu1cICw0mw1EF9P10PxmaFg1f1XyfwpYD\nv2+GcFYOI/e7pSJnADsTGNVNxzWGVF8ya0sauSdLxmo3Exq8MJyPuStlllo0E8gSspST5RUYE5hj\nYuhYMUFjYkzBhGDY+ii3BX2XPmPiSaHRRzwXeyvvoiLEQ5yTuAhhMXAQGvEeTXJOH1POm4vuA2PX\n1CTeV/2apMBIcUHHlh7uUG5B28TFuIyIt+DnZGznQt/cumMex2jDAR343Wg0Go3Gk8XjEhnvJSL/\nCsDrAXwdgM9S1e99pi+JEXwln34KJnahgSBSLjSSmKzF1ta1RTpZaFigt7tQ+doZZZT7BiuHbzTa\nDP82jSLH6LPImlEJObLt0d3VY4qoJ2VDbWTdTRpB8j3NkOV34jaAoUVkRAB4rJthQuOer3Zunw03\nLTcEsH3gnFxzTIa7Sbkl48wKs5NyXpCuCDQXTJIxGcKWh636VD2a4KxXUdl2oUFiDorl/jUEYw7M\nAchcfcjfoWf1sKU52YcJn4zTOVpu3F6Urj9sreBZvuT2Y+uYty3wp/yf6kFHHJ9wEe35pj6+CQLf\nFxepC/XB7fjMguGiorwfiFW/93zenG+u0Eaj0Wg0Gk8Cj0NkfD2AjwfwGgA/G8DvA/D3ReR9VfUn\nH/YlCjFyTcS1CIxZLBlJbmQjO64CNMQFmUmSFC5GiZjGFk4/eUT65vwGueeRd9S9DiuHTx0lYuRO\ng3MWAnWslBAbhbSXjKRthS0Aw2ZmirgMj8UYdUG+e/fuFTesEDLwwX4l8YfNPagKjcO0tTcKDbZk\nbJVayiGxmNsY1JYyayW4VWKrypAVZPHwm3S7sRhByJKBIZhT6PkTYbGLHzXbSvRDuZnzhsXh2I/3\n/rXuGUVcHAWH2ju4bqtQTrGKJOlqmRETFUUPkWVks1xwkPagGaSKRcPdpy4pemXslhCQ4Mjj7Bbi\nLVDrLrK/zYLVGqPRaDQajSeKRy4yVPUr6PRbReQbALwWwK8H8L/d/OSwbcHdPMTWeBCZp0QrXJQ2\ncTHGkaQ56QkiNASDRkuFSI0675fMz241OAURsQMpNBHhI8ZOhMob9fCiWz/j48kK5LeGYK25PKJG\nM8B2rAX6xAlqHR23nFtWmHg7oWaBMGlq4blNLezX2JLhAsnfdyg0lc9JshNET0GM7qf4O8nvoWbP\nvrFbkWrd7tBbrsUVQU4/LGrCieqW2G49PvuavTAsSHosFiY2to81W5q/JSR0fCe3/F3oLuYEFgtx\nJt5dVO/H9Z68kMdH4UTPev2RFaPUbTk8tm24x0XJ6Y4H/W4bjUaj0Wg8Ujz2KWxV9XUi8h0A3vO2\n+z73L7wMb/9278AP4iM+6KPwyz7wV661HmRgiGKIYg7FUMUY6dOfI93YVkDO0VUfAb8MEhyevo32\nmibgNfcCderaSj0l/vMEYlxGQNkjRbe0vOL7uiVhXV9RImkwUTNkwAbdMQcwoLHy9/C4BqmkEpHr\nLF21WKyNV+6e7A41fb0ISzeLU6yT4RYDr08nzuz1wvmRlDxejc9sOPpmUpk8fcmzWKXdXYYA+n42\nx/51F3frhelu5DFAfF8w6HIeZ/XtbtHaTTGYWKuBC8TibBR8PGyCqBVfIfDpeE0g8rtCSKznB8aB\n/BdRMKgNiqZhobCJDt9bfVRx49fzmIVFrXv6jYXlKeuGf4sK4Mu+6q/hy7/qr5W2+rGf+DE0Go1G\no9F4cnjsIkNEngPgPQB84W33fdZvfRl+7nu+X5yrKq7XifvXK2QqZCjEhMWwkfQxkrSKoM63bwRq\nFOvGINcNWtG6rC5cuWwRFwfBcS4NklDGeHxaMkAk95RIohJveiUTsCBlSuJDzIIhNvvSEGAKdFxM\nSA2qE5/+9PityMPumkUCQ0NIuCvb3KwYs6StNt2KuKmMKKOT/iCtRMM3Av9MwPUulB+TGvHxiGkI\n1mvnJPDiBSYSIR5vsdLr6u8SeefaJt2BvIs6mVge/Z3q/cjy6OJCBIKxJjawvIuJkRrzsl4cZN8m\nBdCx7F4hPMKSINsxynF2861jkiWiWDS28pYfzGk619FuR6oCI1zXAHz0h340ftWHfjT4d/Utr/kW\n/MpP/Ag0Go1Go9F4Mngc62R8HoC/juUi9a4AXoY1he0rH/AgRAYlrFiFsELMgSlLbAwjvGMQURTB\n2ObaD4uGiYecujUXAEuLRh1lpWzkoRzT3NxBzjxw0nST1SH2EZzM9PJMuOR741yS+CodA2bJsOUc\nxgB0ai6CJtWKEQR6G0kHQHEZ65hniPLF9kJMkBWDxYVbNFDKcZOdgQm91x/KcYgrq7fbLBa3QyBi\nDmuaLVDa3oXPDTnV7Wy1qfcfJsVy+Lt/aO9yS1ccrWVqeVVvwxAUSHGk2SdKzJG7W5GAcNc6xch6\n5vo2gcD7Yo246Tz6I7Z0ut+ro1TJiRgpNbM5RHmMkP8NS8feL9pdqtFoNBqNJ4nHYcn4OQC+CMA7\nAfgBAP8AwAeo6g/d9hDHV2TacpHScJEaawRddLkBaRKxEoPBFgw/JnepYsWw7+4uUzHIfiYsHgCn\nylaIsDK4W1QS1KOaScIv25tIaBBZC5//CPZYUyANrBFqnVjrZLj1YovDEGZ/kChnTi1rRC4Ehi1A\nN6ubFAfln21RaqG6KSPYOYruJFW8X3DFbvV8Y9PoTReO8gDC0wYbcQ9rxvHbuzxQySlzXbjwQu/7\nU7K94ZBvYE3J60kaEsP+uoCQbFeLzYg0K8tqvlkqhIXBGKvPqKznQxeXYxIfnmVWX/RMipgzMSHb\nM5LJ9Pxm8DlBBqqHwOCAe67IqMMWGY1Go9FoPEk8jsDvF78xzx1FhqQlw8TGsmSM5TZlAuMgMiKY\nm45ZaFx8+kya+YZdppwk7QKDuOlZsDDluhw72VsuOfwaXz9Z4+7blAxzulpHoTTyDgvGECjUVjlP\ndzFyl/KR8MhnRU7EtQV8W4A3u0mFFcNcqeZm1Vgj/XIY4A8JxcQ2CG4Z4kZYOIo4Oak5tj5tVXqU\nGCzutFRjZjITebDdVZ63Y5TP7qk6Y6/fG85d3ZI/nYJJsufTfy8DihmuU2w9U165Pn3D4J5hYwBz\nilkERy0u1XEl/SwMdmtGaoldgByeoWv54Vt0xX6BXPm8fLrtGWlNazQajUaj8STw2GMyHhYuJhI8\n+q5k1Vgj80rkF0C4Sg2PqygWDDsfklO4FmuGEaCRZClyYe5Qi8irkUoOjQbOCGO4i7AlQ0yg+Mh3\n3OtUkpUM6N1JdMuMVX49MrxGtBXD6miG2BAP+rZt8Hskv7TYsQ8RcwC4hsuUu03NYtXYBUbdFh8n\nIen5p3lrD0IDWbSax5P+w1VWcEyVcreQ1SAJepLiQyq9RWNBxVhlXEhORkAF5/I896fOPW5NomK4\nKE1RgbRGQcLK4TEa6zXRiutL1MHd5VBVTrMqN6QV0cB1tZ/D87e9h64JnVcBelZlethumkK4PNWG\njEaj0Wg0nijujsjAubuUkPVCdM2eM7SKDQARV3EQFrKlX3wROppdqgSMmxgAbMQ3fZyYqNxIaoU2\nMGeqS5j5ehhpzbA3qtSXnH1E6v4m9xsxsQHdYjK4vNi+Z9jFRQR+88xRLDDm7S5Te6xL1J9suTeG\nenDbob0T0DeJN5a85NtC2BxNGvSclNO1UjZH1ghrp4JiRbmhP7ErUO61nKcVyiWt/aeulmdkwKcO\n5o8JH6hA0idrqx/dzrErr6oAz849vyE8pFyLHrwLjJNa8zP1cu0Co4gMfq4tGY03RzwLwHOfdiYa\njUbjjcKdERkx4p8JITCGAlqsGCQ2zPiR09EihMNBaJB7VHEdGmkBgSRH8iAKd48yPnZgt3F7If2V\nAoLFi1M8ORMYevr+GPXd/uOb1tNrMcE1yr5m5FLVCIIfxaJh+dreFSPn4S5FhI4sGmWBRIrTiPUy\ndBcZstoz6ovJOgsfL09aa874794Uec5/TyD1bstM1PFp7Z9qjpAYcRxnNwgM2TLMVorIEQsLFwje\nBqkyiOwLbeY+Ra26e2CJdTURRND4Xh+l7qgsyy3s7NMnFo0iLLIqo239t8Z1e2joo8AIP74w7+wi\nY55YMtqU8eaFVwB4wdPOxB3AcwE872lnotFoNN4o3BmR4W48CRcYNh3oqMLCie9YD2PIA4SGHcdq\nw7768DbNbawHQEYF2Qka5fHIPKX8TSJv5C/IsxNSoffc5NpzwnCJ++6Bxk7onFepZND7HvR9Gvgd\nrjnIwG9aubvGY8wMCN/XxiDrhseEYE7o8m2z0XPOtPcFF2YI8u9/dvKelqDbcH49pIvoIZ1JsGQG\n9hdQuvIbsfeNMBRInq9TLW11IM5wcZcir+SxHOe5dxA9zTeJSuFcutuWP6X0PIXGh4jY9M1u4QDK\neXw1rvNvZcsLCwyvs1I/LHqpvnQWy4ZjxQU13nzwAgAvfNqZaDQajcabgDsjMnZSsBJRSNLiJU4A\nbS0IsUXEfJpadpc6Od7dok4+GCEJ7pOR02NWl4wgOljT7S4iae4aYsduAdnu3y0DTuLnSdq+sZXh\nYPVIM4wR2JX7mFmLZ5ciYrq/J2eV2iwYtACfL8zHa2IE0dO0cvBMVct6gyIwchScrFlMSql9uJ9k\nfWg9LvlnawVxV6kU+oBNWGx0+KTvsNioN2RRdTvHioUAov/wO1JgJJn247QI+cxdLtAnHXM2yN2s\nnNdysWXNLS/F2hbij15ehAQLkU00iKZojM7LItu/tZKEq5Rn24LmfXGm8fRxbRBsx41Go9FoNB43\n7ozImPOK6/Ua50xS97UYCtHnYXdzP1ruIGKuQus4CTPWtK4wL+0wAdjIr/qWMQjzluMgrLqCaOEj\n32YJGQLosJXKp2JerSzXGcfX68S8KqVfcb1OXK9XzOvEdV4x76/99Xq1Z9Y1Jk9J6FxgrDINICwJ\nOb1vEvqga0VIuMVimz3qNPZiF0L81hQSnh8XiaB8yL6GB5FOhdU5FJN86z3Q3IXNZIFDxy5urGpW\nG4XQSCFThEOUwd2JdlvGLioy/YS7IySNNctZYHLVjnYUnXYjz+o0W0jAZBnZ2gAIld8Lk9Yipv0h\n5KwkJZ9eJ5sFo9wQyoLb/yhYszwTU9fkBFSEqIGoShKG2c9mFcNnqrvRaDQajcZTwZ0RGdfrFdfr\nfQDpOhKEltdh0HXOw/g89rp8zI9CwwmTTbgETI3Vsdc3FapmHQkxQhYGJ7NOuO3YSegowmJZMsYA\nVNbigTCRcb2mwLjOax4fRMcMQeGio6TNK65zhgUAQBn9jzgQuMDINUJ8tW/2Q3ECmJaKJO5R75ME\nUhEYLDTyfQCC5LK44LVJimVpuEvXSd6w2l2mFMI9XUhMOt6EBucjRIYcXczCrlFmm0K57wgn6uWR\n3RASZYFbLEz45gWQoGDivIkOkNAQIKN6SER5tiTFXfSTEBcSrnt+PawAITQ03APDehR9K5q1xlYc\nikxT/Npe1+It1r9kxVxRHVULhr+F3smClqwYVWO02Gg0Go1G42niDomMifv3r5TiwcNsQZiVYBxc\nIpLpH4SGX0Lu5wTEGOTifLZyskqOkG/7uZ3DV3geZLkI0bHcqCAKHbqsFWyhCHGxnbP4YFLvYoPS\nnDyWOAbbM4lfsSeXbXYprzOvFC4br9pN8Rfl+AZLxkbwmPgy+V1T6dbt1JVNdTkF2YRJKtfVRicW\ni7RoUH9BHdlfZFttVezMZEwke2a6CMK72TOknvAtR5cq0xWiW2zPdg9IPm/9Pfq9qM0kZcpWkGrI\nT4n8l6mPdyuS3bTiGYrxBOUnJnmcmiILmUdKN+dDqhrZhU6oDkCXRYqFnLL4Y4Hn1gxvb9Q+x0Ks\n0Wg0Go3G08WdERnLXep+nLNrBccpMKEF2MPCXDCcLG5CA0rTxU7FFMFafwNmwVhETGWR2fg+E+gT\n4RGj42qCJYidhpuUWzOuVz26Qt1n0XEtFg3eX3crgu091gJwrimVxG8rnS+3pCSWIlzfSJJuFptc\n0fu4XU1oHGNHNnKKFEE+co6TAPQlfkYRP+qq0E6UiHztHzcIjbBk8LfWlL5HDcAWodK5UDsb0+tq\nQeA1IVhkhLiAWWL8ZRSLUSwWRbBthFpt1jBfXXz7JbDVYhcTufbMMV1VyBqkWLM0ATO4e5J3L2ex\nYoj/Bkz82A9DrXNG3AmJBagAU2wwgOp7mR8PQwhedywycvSgJUaj0Wg0GncFd0ZkXK/XzZKBSlpB\nx0GCgBzz9QBmrQuk2ZBxCIzyASPm5t7k7iPuM5/i4mbBAUgKCRnkLuVT76Z1gwWGiwu3ZPD59Xpd\n5H5zS/JzpfNlMsESGrGgWnU/yul6XWAkyeTK4LLO2NKCURbau1I+SmwEgoyuvzmSzRaX22Iy4rHI\nV7YVE10WFmdCw9NX/Wxixqtu5MfYTSeMGbvQ4FPh58gVy60JIUiSAUcfdGUal5IsayanqxKN1vt/\n4mpu9/uKfKzPDC43CwwWnLIsGaKD6nIsIQtgmjJYsgYkpv1bJxVVQL8+K+oEMHS7nsYYfnQTHJsA\n83oNBbPLjJYejUaj0Wg8adwpkcGWDABEHohsbekrAfBZlNZIsREi883Y5YWa1SEtEEnIYPsgzPso\nvQsOt6YobFSeBQVZMGjPIiKO71+r6LifLlFJ6rUEXivtTRatUe1tpDnckMZagNDdpg4L8WnWqSrS\nOkHbjZYME1x1BBxFDLjo8cr1b48D2XWRoRuhBGCj6pzGYuIgNEKU2qrXSEI9jCHPIRhzAMOkgEZ2\nKdDYj93kg8KA3XYg1oGSgO/uaBV74Le/O+WZ9y+tQoM3cbmReSkb5cNd5KL9vc5Hig5Vm+rVBYbO\nFbekWK5ZM+0mKaiOH0/BUcuY9esqTjCniZ+tXm8UHMg6SmtmirD6cKPRaDQajaeFOyQy9pgMRx0B\nLWKh3Cd0d7pMIcZeN+LjVgy/gwfQhUjdJip8pD7dpVJcuJuUFItGCg2fHYoFxf0QGXbuMRpE7sNN\nLARGig7gApG5SKDXRFhkFom8jEsRF7zwIFemimKqWzLmjW5SJSZjt+wUK1PmZ+3P4gKc5GasCLyO\nwYJyt2hpPS5WjCp6IGt9FdjsWphjLc7IIlZWQ4aBYRcam7oIZysJ2k1uSl5WKjzyW6A3HalwCmm4\nhCChkeK2/hJKjZPKOAgMX4wx9iP6xpyr/2IuKxHmEmIy3TpDcStpNDsXHFRf3gb+C4UK5VbNXSof\nKaLOa0RZ57G4qOXXkxptNBqNRqPx5HFnRMac9w+WjAUpu9ORYREiXSYbhFhL+Fuk24SPtjOVyU+k\nlSLEhDLJQyF6QbLcTQow3/RhaTaFbVgwXFBcw02MBcdyi0riHgLDrQYUExLrhQyyrBiR51iMNWsT\njWxL2DGs9Mas43sKdg+b6lMKV6uGlnrhPJy1Y47uH2aZipXIkZPUepuGleIoKuZJWtl8HYlBUmAA\nYw4ogDl0iY2IGTgXGrsFo3bJrNM4JuuG16+Yqs2BdqooFzxRbBK0PFK/WzeKuNDyc8n2lhQaJ250\nbs2AwGdDgE63clnhbVY2mVQVYa2h75ffa0p+z3OFyzeeSJh+m1u988KAvqdfcxEdjUaj0Wg0ni7u\njMi4f79aMoK8hN97JKQbirjNgqwXjhOe4SPj67595LMSlByV30bStR57fKvHZPCxmlVjmFvLEhAm\nLK5XXO/fLwLDj6/XK05jQU5muBJ3+9ERnNxH1IUExuUySj0yOVSAFl1L0cCCoq7oTW5cm4tUWhu8\nKrP9zgQGzzK1grEFghmkO0RdLFZIq4wfXKVSWJQgaQGAJSqGRRhgAFBbUd7XRaHg5LCoCNXRoUcx\nNZY4r9Yau0oCg2c7yzagfuf1B7JgeF0gj/m+kiu2Ytg2BGnJKFtOCBD3T+DqJZqAjCUCZFZrBv0k\n6XivqZQBUWTNFDXpoFY/stV5qWNVerUe/uJw3Gg0Go1G42nhzoiMfXYpgEeGhchx+mYIeBQ06AqC\nzmg9d4NHjAg7IfFRYjuGk7i4F3lOo/XuE84zUw13l4JaDMCyqmRMxirnLjRSZNzH9eqB1GQl2K0p\nHqA9J3SOdf1ipShWgoFxucQMVMViQ4RsjbS7EHM3rVksGKpHocFxMkGV+bi2aBUXB4uGCSEK2AdY\n9FQXrmLBCEFSrS+qM+INRvSE1T4ex7La0117TDTCZyM74c2nZdosB2TV8H6bAkNinxa4BMvf0tfY\nWkRCY29L6wKH+q0WjIFxGeWcLSEu3IFl1ajlqdbFIjbgFZYXoi7VfqE5j20+yHKhiDwTUsJyY6sz\nOUlrvFnj1a9e++c+F3je855uXhqNRqPxxuHOiAwfWU2YkCBCigOBIzcVOLEC3E++uHLA9YO7nURq\nkjXlc8TIvN1GlEhyIidUYnlOnnM/t/QZfvL1Oozz+erkOmz15Wl1YyuYsfsLT1krwrNKrbqtfJaI\nngsFGxmvK35rWQ/jEJexcbugiprUsRBvHvvntiWLB5h/2iGP4FfLxeYidRAb+Ya0tFQU3ixhiyDS\nLKWPVbFUbRhsPvC+6ZYRjzUIoQFfiVztPrX7NO5b9aHZ/ynTaR0C7bPDHv6L+lpS8zyGZUIx6akZ\n78qWONoqnOfzVLRpRWLx5lYdjWOFu0ZFZVLDZJ2nxYS+zhXine4EMm640LiTeMlL1v5ZzwJe85oW\nGo1Go/HmiDsjMhYpvmxp6XKyE/mDhSP+VJ7BJCeHxtmaAeLZRkTzprhe3DboQDzvkZ+cKWlPU3JR\nuQxd62j48WWtpXFRW/PCLRmi1aohy4rho9plZNqngaVgXhF3hRlUfrb61LphV6m0HmiZ0SrW6dC5\nV8ixXbdrKQorUSyCMPlsCEM/PsRc0Ch/WKd02yAkLrYRf88UNiHBwhZkFYDUvBZR4e5eKTDWpvZ+\nje8sUp6WAZEltOc0Qmz7MRHB1/A9WGCQdSHyxX24WkDSEjbh824tyTHWIpAhHn3TrF/uP4ISr5IL\nG6Y1y0VFrJEBhJXKf7XFYmR/S3FISJXjaLxshnPxsTD2EYfGmwVe/3rgB3+wRUaj0Wi8OeLOiIxx\nWe4bDh5BPgqMfXTcsQ9T6+Eai4sgsEiLRaYlCj2x743wJpEbRQWnDRkryNi2JTAmxhh2rCY8RriH\nRCwGH2/CI11epAiN9LVPSwrXimiOTXO5FXqI/fC1MDgWw12XnGXKzv6EBIa4bYAsFvH3BtYYeWO3\nIRJbk0fns+kPQoSE5alHDVm9brNGRXn2azjeK17eXQjTfgDLamXlLmIDghnfW/ulOwSuFQd966Tq\nsi3dCkFWDF9cb6hi2qrbQm261j252UJU5ZoLJq0zRPn1GwSGIi02ZAupPYEsFyFOqbxyuHlPo/eN\ngUaj0Wg0Gk8Od0dkiOCyEYFC0sZO5OjaZn1IISHk+uTpOXLPMyEFibV7geQpOUpLHIeIZ7pEVVEh\n2/ESFHO5Lm0WjdxfcgCarRi7RcOEUbVkSHGdioBqXuQuqqNacdjnP1b81rpGh09ZG+5SRjjTJWjV\n0M4bnZwnCczjIjkOg80uIFJo3Eh8y3kYP8hYpfzazJd9OOwVYdVAtG9aNW4QGiE2NrFCAmSN7N8g\nNjaRUcTGwAq4tr3bo44uekedARJcEF/7QjFCbJilxN6X4mIi1xwx96kQFyTaBCkusFs2UKwZZwLD\nXcaq4EiEBKM6TQtH7Ufn4sP7vLYlo9FoNBqNJ4y7IzJsRB5AktMbRAUHsrovu4sIn/HJSanzXRcP\nZVaeW84L8Y3R2SSHYWkBaN2Bc6Hh6arLUpGWDNtfVr4vNFKsarER5h7FrlJ8fHCXCqsGrYtgKz37\nus1RoLDYuGXHSXq6SMVaGIeYjGXdcPLtTK/MzgTfB4WPOqNhapRG5xwpH58IjW10/ewaqYy0epwh\nrAJOZquwYFcpvx4Fdw11qwXE9mdigy0Vnodl6rD+JUsImBtVPEtZyOqrFgwB8vdhQT6+0F6KF4UM\niUUVY20WdpcioeFVSJ+EFS2rk9I8zvthBIZsZTpYiMKacbTihJBmoRFt2yKj0Wg0Go0nibsjMkQ2\nd6kqJORAOPL64pIW0Dor2XGCiiCfSDFBpLPOGgVIDMv6yLwEEY2RY8rHLijq2g+2loWOIi48FuOi\n69zTPH/iouIGi8bESUzGyBgMtmQsf38f2c1pf13QOAFPcfH/s/f2Qd9uV1nYte7fgwVDA1bqZzds\nCAAAIABJREFU2A7EkY+RtB2kCbTla0DoCKJSKNrhzIAgU0YETSaBWrVIAIsgESIqUBASwgCn2kAJ\n1pBYJEaGFmgTPlINJED4jEAgkA8+z/vbq3/svda61tr79zzvOZz3Pc852evwe+/73vfX/rgfcl3r\nWmvvsTbGJYIxQmtEjuJFJ/BnJe5qzuQMdb9YqFNcx6rmrEkG39fB7ppdhNqA/J0VYuFANY39IBfB\nMhwlM8kwgN+v41Wzg2QYCTGykcKpRi6GhVElUpP6kgeCyLPYN9UABMHgHBBpQosr8urtLfcx9aP1\nLZBVDCccOojEklAQ0bVj5wihzEjq2pm4pX3u0/JRHTtcatu2bdu2bbuvdntIxnHqoUJmK1KxCJk6\nhpLRFB0cH90D2z2+pFCAPOJEJlKsP58Pfzuya3T2VtvMUHJcUDEG2ehKhni4lJ4EhwqUwqb0NKD1\nAPmej8EqBkwt0EQsPB9DcvhU1PXonmwRn9UnSNZ4diIX6ov/tapuDEB6SBsI8OhzxMKphHucHXSn\nsytyYeAzLEKfgiRer2SwatXvkxLpM72y1BMwsFpVDd4ifwfluzAmIAyEgZQgvSIZfO0ynGrES7F3\nP1SYjPR7mFTvxLFBX867V6o16WtgtLG+y+jLSjRAs01555bB0xhwWJiUUTt7t3VzKhNe54bHJfp7\n+v8Bdt7GycUNVjfy8zbJ2LZt27Zt2+6v3SKSUZUMLElFLeveWIW0DoWaNhyte3zVPKmAg0yPoCGv\neITSBPkwb3FMVbsmF5ZrkVQMXl15qBrHIX09C1IyVJXIxYFTIOru+S7qRVsQjp7XMSd8H4PYWFmv\nc/NZgZLak/qDiYQRjEIuOCdDjsEvdGBPCa99+hfkXibQPMpZCQlXOFfS6hokiNULa0dVNQbNIJJJ\n7zEiUciBA1cmEEKkwgnEAgT7MaLtRhw0PO0xs5T6NSkHY3z/aEPhOIDWjHTY3wb3Ze2uMYOTApDW\n+0BH/ZqB9bEvMYVuTGNblKH4w1mGRfkASOyCvjUZaoXNJaWcEF4ZS4gU3ne1j334rP0i8zE/ctVJ\n27Zt27Zt27Z7ZreIZBw58ZtBHs2QtFY0OgAHGtBsrYmx+B69oxKJScmgYwA+538lGh3IWDK3EYo8\nk9ORyIZdq1A9EsnQQ3E6jTpVJaOoF7YqdyOP/hQm5eoFHReipuIQznomtT+BTW0lXIpX+27oYf2d\nPFkYVk/yNQA6e+djgEH1yCAwKRakWjAZYvXC9xHX9DHHQLozQPa3EgeqxCLUjQDzTDScqBixMIBM\n/c1EggmXfVM9NCrgtudgdOYxkY4jPZ8a4qwCg6gOVWOl4LQuN6j9PblahEX/0hjQ850LJqJB/amg\nUCkqQ//7zDfRQNDgBOGDE3fvO1ZywNdWUos9u9S2bdu2bdt2n+1WkQxWMnpZgHlhdaAAZ7X1Gsjb\nnYBgAUcc289hUzwz0QEXFcbiYQwouU45/yL2Q9XwKWT1GOrFAT0FyehbDLLBSsZaxZCGQUD6bFSr\ntTKOEbrl62aYskOeYDNuv6sX028mGp3kZG+3yphpisEmKQFAgMDka+b68GDCCMdMglYkgwmTlfXQ\nMHtkgG5WTzKRuO64qhgs0MyErocDiffHimTkPkHOwUCsn3HgQDuaKyJMNCpttIHN/MIGJVakEAi0\nISkZ/VYibIDvJ8ZygVwwARE71N66eY0M+y7jxlAqgjwwoc95GTYGfI9MnbFnl9q2bdu2bdvur90a\nkmFTr7IxqEgkoxCN1g4cotDhkY2YeHuSqRfhi80qBnnybT2KscK2QsYJyUAKAdJgwAYI8EOe7wCn\nfsEAT9kj7d7aowO/ZrExh+Bw9YLVAsVxEqQZpUhB8T7y2pI5IfPuKURLL/9arKGBEYykoj2pt/QR\n91ZWLoqDXXmj62uKEqErD729Tew8gfcJgJJXHPHdsGKRj/s9fLt/Bf4N1J+BYQoNUl2QjD7YloNx\nHEDTA0draOjqV9OGYxDV8OAzyLZfer33XNIUtJQbuSBiwdvObMqAyF3se/utu6P/g3RSX/qfblYr\nEkG180wsFuWlEtu2bdu2bdu2+2i3h2R4aIkdF2+tgwchVOK+2H5TRa2DTQRozuSihknFgndjHxiJ\n5B0Yio7wpQHVGhQ4tK81IBhx8wCkjbZ0BaFJD36pMzTZWhS+8Jkda/OmJAeshbWITdsrIx+DyMVh\n/Ub9MLbuyCeP/0Sypr5a/MrYsdJwYXSTkuDXLUlMfld9zqQS6JiFy2L8F8cx41a9n7zhjwSFksfe\nKuv97mRr8VxXLYKRHQdgU8s6kVDtoX/avwvRUBtCYUEQFhr37O03wlSA/UUbdMTeLYvekdhK3knn\nEwGgv/FVec5tYgJIz9Z4vhGk/qceIWm+v23btm3btm17zOzWkAxLjmabQOHCV1yxBAPTEtyR0OsU\nftMK0OX49MakAgP0DdUDDU0OJxidVBjhaIADK+khRq3FQncaCdS+0jLVgSsvBPT6QmcGTo+xWnoB\nzwnzddDtoJ7b5u9ag3wH+9dsqZYLcpCVC3WiYXXpZa3/M4aJXxJPcTAqMlZGH3k3TigwwpOGqjI8\n9Baytgq1Y4Ep2yWQyhCWlRvxTywD4ghBml8xufydYDiZ8PEysqEeZmTgu9Y/chLsXFUMLjVRUznn\nVLiM4WSF6s8b++cRkIwIiSqEMNWwEAgFTTTQvx1TbOp127Zt27Zt27b7Z7eGZIAAyCiY1YzhtU0h\nISsz8Dvc7kEc2Bt/jRe9KfQAtI1pXg8mHLGkHcaaFgdan/lHetL5cRyJcFizphWzjdi0UDOMaPRX\nLLzO7N1V4HQ6Qs3g/I+4PWLfTYNxNce6qqo80Xf2cxWEuti7eiIbC8VDy7lK8jTAODRUF28GKQ/8\nPQTB6FsnVK5qDGKR1g8J4peVseujaoI/UOhTPhENjIqnokQMyDwnQpiA0XdnxElNR+ObL1TYgT7S\njlC9ogFxi1Miyp+YHnuByMzEhtQWU4yYcEx/49mpUMcnWSF0ipgW2MjHtm3btm3btu2xsVtDMjqw\noClsiyc0AxUDeGu3rPLPve4rUmGKBAFeB/6YyEUnHOUYQ7kwQnEAaC3CPYYHvYHCpbSV9SZMwQiy\nERDWQmHMQy3pXCIYHi7FxEQdgDHp6meYXFV1BzPYxaxuGD7VoWIkU8lwOKrghGdFMjxXZhpd8e/k\nkOGrHtN/qYRyIXbOFASJpHxLyJf0LfHXw/17veW2ZWIh3vUzIXCFYIBkIxj9nATRGM+17yyFucHG\ncKrJ/M7owBvCpNKldLH6GT7nXMX3C4lxAmHXLFQNJhkof+fT+NDf+CCQnXwRa2Oywd2w+ca2bdu2\nbdt2X+3WkIxVuBTcc40AKUCAmYtPIy88Q65wlK896RwyhRvIxTh2xeLo9fH8DOkzQEVsubiCoa2E\nR9lsTfR+AWLqXANbxcMrECIYHGKCEmYSUNR6Yw6VqkSDCEElFaRuOJGzN1UFo9wmzjQkSMdEMuoz\nJANPGcqEDo1GInm5E7HxrAFCbXrhS1P6xve0kBgufF75Oipw0mV6QGgDrhOIzLkORDAs3IdJipMO\nIhk+qnwdbKpjqgy9I9hGrn0qmvpA8m1GpHjLRIO/24lkII1l/I0T4fB7jViXahUFA2Ltpv4rjLce\nb9u2bdu2bdvurd0aklETv3sZcAnM1ETWZMWDOXnL6Xdp9iQ9gNY05rIdK4jX4+MYE0D13O5BMEbC\nrkgQECISiWy0keitFio1lAw5kpLB5IG98TZlrcWzr8KlACMJtc2YCAbonBMIvo67l5WM2ucFdMeB\nUPePnANKaO7PsnEq3wh9JwckSJjNuOUEY4RQ9bd5P+W4f/quSl9dNCXiV9qUj+OBVVVwbCz5yxVI\nzi0ItsJ0Iv4lhclIlRMMER+QCVrf1E46L9wxiWRcJhhTeSq7mWT0x2RFRGr32qdV1AydyOa2bdu2\nbdu27bGyW0MyDHiUIkwkA+TdXLleyZOccGr10Lt3fkEwTKE4blAymtoMsyP3Qj0vQ8Yxh4nwatmh\nXvQ8DSWCYWExAoEc6uCNVxK3BNmD1uw4CNRFVxJ4tz4hBpEVjDlkKvUbyResdFgSenUWT4rGuEfE\n6mKzZI33Nu1eac3e+TH6noQso8Pd4z+AKpRCqOwc5j6b8nxCI7t7U/uHQ8JmwjGrIwagi35gbfA7\nZ887vydIBqtvRKLFNmsPvpcKH5FqIFwvhNpDf4ucxO3KA0KRyGUXSIbfT+2fVJN4v/VNDZEykchv\nnD6+ZTds27Zt27Zt2+6R3RqScRyYw6UAZE8m7RdQxqb8TwrFWSkX47IGAtjjOZYAXsnFICE8fW0Q\nDDjBOI6xcnPTQTJiETtTLZqqr6htYVQwcGirQPsz4aFRtuBezi/oyknMmhToKxEFZMLBxIOJBpTv\n8+4s5I2npyWiUQmHBk7sCoblHgxyoIIGdXyYQLaDTgEwVsg+DsDApl09SAj4X0WESvEaIh3tkve9\nvO4azhEagWlN+XgC7ZV7EBjny3Jbj6mMa8DfcNNGhKN1oY3HQbIKYo+sZV7N+jfmpHUmEjnMiYiF\nkQww4bieZKzsprHw9pmqoUPNKEnfK9K2bdu2bdu2bbt3dmtIhodM1PK7KCOn/bRV2oZn/kKYFKkZ\nEAxCIYlsNAqTsnKzHjHVQc6BTirCY64xXW1aK6MoGW1AbMnuWA71OQ5L+D4I3B3DH5+JWFgwhAiH\n0tEvyqdvVDTS40o/A73P6pD4MYFBC3OyMbHr+Z29GcVNLRgQPBK+GegHwRgAmBPjpfwGcbHnrvBs\n5giz178SjGi/N8A97zE2st73JpbKGMgf+0xWRSVC7dqB5ov6qdM2o0NZHarjY30ZysIqHGoV6rSa\nKepGkkFkZe7xSn8W3a0Yi0BKNEZI6di2bdu2bdu2PWZ2e0jGIlzKym++OXaVdioAnpKLCUiDQqXS\nNZafoQI0IhcA2qFA66qF5V8YXrWk7zgnMZtUWitDx4xSQTbs5Qa1WMVIRON0BEgmwJwVnqxiBKkw\nIK+pb1ZEg/sLcQvMRZ65XcB9VjdE8rYDbx1rfgTJSApUGtA1CWACwlDaLlbYOBTVp4SWuYf+WquS\nRJSpxn7/ZOnaScnIIYAM0KOp0dh1voIMgjFyhxRjlfgG6QlF1DdBLgRzUjR1Zt51QmD1ySTjErmo\nKkUKnXLyIXO7MRQH+yisJB3HdXW8vExj3Ldt27Zt27Ztj43dGpLB4L6W32Tn8xntfMa5ndHOHcSf\nCdDP61IoYrXttZrR3z3WyRgLoa3KmNR0YgEEeDSc1sOoWmtev0Z17YvyUfvV6UA00kFm/tGpqMhU\nSgCeFAMPh3LyQUqFERaJbV//o6+gfdITVBXH6eSqyul04DhOfWvrd5z68QRCjwpI7T1BRiqUFBj+\n7OTNGpVXc9CyF4nf8yxc/O7S0akX1udS94rS+QyMPTkZnQhJsCwYATDwb8B4AtETUcGYRarvxMJ5\nQjNXlfoS+HbSoZmA+HeVSNhMCh4u0UhkxRWSmdgxnfD+KkTJ6uptiq7s3w5sn7SQu/j/I9u2bdu2\nbdu2R89uDcmwMKJsiuuwgZ1r5zPO5zZ+5046GMSfmydZp6lqy5ZDiWS8QEW8TAnAqVJYjIdtGMBp\nAYyJHHh4lCV8J1XDvPelwe4V146kDFw7SIu+6rcWFWNczLMRRaJw8I7o59rhBhgP9DwTherJPfeJ\nVJxOTi58fxCPKcyGw2fA+wbKC6QPhgFbfK/3ieQ+KAQjCJK1gbf27uxNd0977c5w76ceynUdBJRI\nh09JPACzhcI5sTCiIeLXQoJ09G2MYxpu6xreSgDzUaNpelzPZXGywo2M9jvBSLksd0807FofJ+73\n8Tqr07o1c5mpFcTp6HKNNUjqIN1gIvJyAD+kqs+++WpARP4YgG8E8P4AXgPgEwC8HsD7q+qP3s0z\ntm3btm3btieq3RqSocO7320AoAIMIiSFj5HIxbm1IBytk480q5MRholggPIAzLNfFAxbWVotREYJ\n22iBuF7LwEK2NkZTIjy0XoZXwp5q5CKeNpzMrpLYO5xxmLfaruYwJE50sA5UnQ47gK8g8hgEI6s9\nTCZOQ7Uw4sHnwnudwSXMc27nkcNeLnnvRerJ0WojKnQz57Pwlj31/gru1wvhNhf0DO9Db4eakkEE\nQ7NnPlSOIBN+jeQygEOANG+vIS4ZkIeKwqS5Kz4ov1AwloQCtYyUDyIZiWCkHqR+pxbFPtOPTJym\n0Sht1DJ2d6ljfAKAh+7uUgDAFwJ4G4D3AfAbAJ5896+6nSYiDcDHq+p3PtZ12bZt27Ztj2+7NSSj\nhwxlJSOihyqxyAQkKRhnCkU6r8OlXLFo5NVvICUjQKBaGErfgYVKWcKpEtiLejJ4j/2Y/Ud9H01z\nOQwgZ4swFi4czzdAboSEEqrZmx2qBSkZSr+J2FWCYdu4IohEJRZ0fBwZrwtBzUV7jGDwLKUONyXA\nerTfruBnkW9eAKG1RDhMqhKM2Zy1gLvfLyVw6+FOOgC8wL8lpxJCgVNKBMOVDCSlxkkHrWjuw33B\nQgkqz9dYW6Q/RmlNjdE6Jws3/5xUYFG2IhlGKpednWlGJRe6uCb1/fjHv6m1h+JaU9Vfv/GibO8F\n4P9Q1Z8HABF5MujTeHs2EblS1TuPdT22bdu2bdtjZ8fNl9wfm/MnKHeh5VAo3r9z55wIhp9f5GNE\nmJIOwsGAn39wr3+A8iA7fGxbn4J2hGd1RaXX7875jDt37uDOnTtU10GEeOXvqjRMZl5rBaSHDZnn\nXVJ8SNnnttm59CpnGWTivyAaXaXw7ek0ci7y7+p0havTCafTVT++uhr7/fh09JAqqfkRGIDVFY5Z\nTYm6jLUvJKbzjbwLSWV+/Wq1b+T91Hzf9eApLC9IXW49HKTTe52+LSN1fod/X0bi8r7S+cQOU22M\nKKyVCOtTwAhr7LM6JlR4HcnwRSGnfq3jmgkJEwzu18QZ+Yx/G/xd1n6Pw0ScrZvuQl8QkZeLyFeM\n/deLyN8QkW8QkbeIyM+IyGfQtQ3A0wA8R0TOIvL5i+cdIvL1IvJTIvKbIvJjIvKMcs0LROR/H+/6\nRRH5NRH5PBE5iciXicivisjPicin0T1/RESaiPx5EfnX49k/KCLvIyIfKCL/j4i8VUReIiJ/kO77\nABH5FyLyRhH5dRH5VyLyn9P514+e+o7x/J+ic39ZRH5CRH5HRF4jIp9c2tFE5DNF5MUi8lYAnyci\nrxORZ5fr3n9c+0dvHpFt27Zt2/Z4tlujZFiOgh8XFcPBPyrgxwD1RjIaEY6Sj9Fa3Fu2DP4s9MnD\nVihUykJRzFvtYLKoFEBWLDSBwro/tqNtnTDET5gRSIS1uGOXHbyubFj/0Elvo+VnBKnSOO1Vy6Ev\nh7/3OAKsno5T/7l6QftXsa/UTgfcsGNNVXQ1o1iATF3LDlMIVRxGOyp5WbyFwHZWWyRtwuK9rESY\nkjGpMJAIubOvyBUGISWDnxXjKVPCgbXRqpPraSpGSBjiSgaEvxEiFva8R6BoYOpbWW0WHZk+ZMwq\nxqgz9XreufDYR27PBvC3AHwxgD8P4GtE5BWq+loAfxjAvwTwXQD+HnrY1H9Y7j8A/ByAPwfgVwF8\nMICvE5E3qOqL6LqPHNd9GIAPAfD8sX0FgP8CwCcB+FoR+Req+ga67wsAPHPc+wIA3wrgLQD+KoDf\nAvC/AfgiAJ89rv/30XNI/gp6L30OgJeIyHur6m8A+EAAvwzgUwG8DMAZAETkEwD8fQDPGG3+swBe\nICI/p6qvoPo8B8BfH3W6A+B3APxFAF9B1/xFAK9Q1dfXzt62bdu2bU8se9hKhoh8mIh8p4j8wvBI\nfdzimi8SkTcMD9v/KSLvfdNz8/oRVcWw3ApWMVpSMWrI1JmfcSY1Q3kxPB3Txs5KRgfc6tsA6AMW\nF8JjM0RZ3c/nhvOds/9YxbDcEW+nT1+7cLlK/kk9Re5fnnFp1A5GYpxYgDy8oMunV7OSYaFGdRap\nS78rnK6uYv90hauhYvhsVKcDddXyGmoz/Q5JC+u5F91+MtSR8TumX51dqpIPOFhO3TANyGzOE+mA\nlQz+fuBjQWpFIdGzkqHpuVrfWao49x+8j11McCUHvjUVwxSIOh6hDi3Ui9U6JEXRkEsfs1d9Jh5S\njv27XI7EWsm4i2iplf1zVf1fVPWnVPXvAvgVAB/R36G/jA6k36aqv6yqvznXQ++o6heq6qtU9WdU\n9UF0kP/flUt/FcAzVfV1qvqNAH4cwDup6peq6k8C+BIAvwvgQ8t9z1XV71bVHwfwlejKyhep6ver\n6o8A+AYAf4Lq83JV/VZVfe245zMB/H4AHz7O/8q49M2jTb86jj8HwPNV9WtV9SdU9XkAvh3A55b6\nfIuqvlBVf3qEkL0AwB8TkQ8AABG5AvDAqNe2bdu2bXuC2yNRMp4E4IfRvW3fVk+KyP+I7in7VPSZ\nVv5nAC8Tkaeq6u9eeuhaySDQn7a5jGeQOvOMUgzmz50E9GeH6z5CVRBAEMMpDpuVaWyle6DTNLZW\nR1/Nu/nWk7rHgnvmhRXCVwHsxjEQSasrFGX4zN3sJGWQR1rtmBSDCW0R2cgqRnjTTbGI6WvJmy5Y\nEIwDp6vTCJcyNeMUKk9SUCIR3+tD/ZIa7cdazi/6qnIE6y8Hzbwv803TO2vx6gSpGeOfpGQMAmgz\nOYmpYNbXQ93w42kc4GMqpki4lx/+CUi/cFqkrs8iZZXiYxc3Rr9KJhrXKhhr9SLCo7ifFgrEBWP9\nwktGm7VcWZ8Wn/cjYxXFXl2OfxHAH3o4DxCRz0b33j8FwDsB+H0Afqhc9m+UE8+AX+J3q2oTkV9d\nvPvV5R4A+P9Kmd8jIn8IXZX58FF+GnV6yg3NeCqAry1l34eubLC9kg9U9RdF5CUAPh3A/wvg49Db\n/yLcaM8C8C5971nAu7wL8MADD+CBBx64+dZt27Zt23atPfjgg3jwwQdT2Zvf/OZH/T0Pm2So6ksB\nvBQAJKMIs2cC+Nuq+s/GNX8B/X/sPh7AP7303DqF7ZpQrI7L+hMrskE5Gf3hBEYo7IrdwwohoBah\nUinUxe71HI+sxiipMa018pZHOEoAM8CAbYRH0W/kYPSrNBy6uoJa3os9GCepM9R3YNBf7zUP9zGe\n3gbBOPz+7tk2dYJzMk4pXOrq6oSmh8+o1YhctD6AVFsKplkQB1nJObZZEo2YkYmBdD2evmR/oI9M\nIocT7xkkgCO2lPhf3/RvyUG0kVQrMRJrdSykQ2DfYh2r6JsIy5r7U0elJHFSutb7Za0oHSXXAv4d\nM8nIJMXezKvA16526kDtilrVFtZSib/h+Ym57Q/f6kxTioeh/orIJwF4Ljpi/n4AbwXw19BDoG56\nz928+6FyflXG93wTgD+AHk71s+jhTN+PDvxvstqFq/+38xuL+74ewDeJyLMAfBqAf6Kqv33z656H\nLswAz3se8LSn3UUNt23btm3bXdnKafOqV70KT3/60x/V9zyqORkjmc9ilQEAqvoWEfkBAB+E60jG\nQslYhTG1afG8usidToTDk74tJIk857bVcmzAiBWL9exSUc/+TiMaI9SrxYxXIujJsofEvthK4QIc\nDGkvdbI6EfEZhxzlEqrFALVENIJJUTvJ87sOLclkw7zzqjpWHb8QMmVqxlAyDm1ocoxVqmWMB4DW\n0I5YoVoNBAMOYq1LmEiIEMZh5WIiGhEOVM8Hycj3GJmI3wVVg82JBpxU+FCYUkHfkBMGKzcyOJQA\nI3E2LiJETFzVsBdzH9F3ID764Km6/LR953af9atEm6dwtUnNWBCN0alGMlgp6cczdZhpgZ2x7g02\nna6f2MT6SY+OsPGw7YMBfJ+qugogIu/1KD37kbTogwH8ZVV92ajLewB4t3LNQ+gKB9tr0EO1vrk8\n6zV38c6XoJOPzwLwMZhDvrZt27Zt2xPUHu3E7z+M/j9+v1TKf2mcu2xGAHJheOHVwEn/cVnkThCA\n0fyY8Yr1q/n6dF9HRxYqZcCvh0cBepgKojFrlbYpPyOUDAEOxdE6YOsea8AVjIX3eAZ07Lov/YcA\npaa8QIE+U67Gz+saoV5aZtua+yt7+1OMvuQcCOGyMctTa4AcDUcTNMjox9G2Aa6hpT98NwDyTDRK\nXxS1Ieqbu2upwQFBOPled/tTuSbc7mUO5P1Bo+8M7rOSgQiRYsWFvzNrp4VdsZJxAU4nH7NRGIvT\nklJ/VwfGO2/6Bi0fw+qFRYgUk4wgS0jt4eNevUtEg9qR/lAlfaCVbz1aUsbv0V4H4FNE5E+ih45+\nCnpy9U9de9fd2eoLvokKW31eiR6L9GUAai7JTwP4KBH5vwD8jvZpfZ8L4J+IyA+hO5A+Dn1NkY+6\nqZIj1OuF6Hklr1PVH7zpnm3btm3b9sSw+zW71EpaT/YVL/xSvPOT3jld/tEf8mfw0R/8pyMPQhVN\nDRBF2FRPAu6ecBFBQ4OjdgiANp6qAUY4Hh1ADUMRv3+YE5kG4EB3wvfntmaJ2zyLlHpLIkxqALij\nJ8keBtJt2tUx9erJVs0+RpL0caRQlV5x8dckwtXGfhsEQ8XDubK604nGubXpx+pG2luwtMzJdIDr\nUJqaKo5JkTIik8O47BUiw+M/vO2cX0A4PuAm4c5EEkhRSIBWSlP4oVQW75Hy0ljkTueLFyTngpLh\nqL9XoIdbidc3k44A0rzPVINBOpfyt+hdJaUXK6E4xJU2mRLmWe0oJMOfFe9J5IKUhqRIyAWikXwG\ndI4HsOx+x3d/B178Pd+RHvPWt70Fd2HRWev/f3U31IXLvhZ9NfD/dZQ/COCrAPypu6jH7/XdK/t0\nAF8H4FXo4VJ/E31mLLbPAfDlAD4DwC8AeE9VfbGIPBM90fsr0QnTp6nq997lu79hvGsnfG/btm3b\n25HJrB48jJvL6rAjXOonAby/qv4oXfevAPyQqj5r8YynAXjlg8/9Djz1vf7TOGGgGQT2ngkvAAAg\nAElEQVSgF1toAOgpD+NcgbUBYMQWiBAqP7dWFY7q6YWBwMi7sGTv1s6ezN5Dg84QOXA6JM12dDrF\nrEfHEef7DEwxE9PpiIXtouw0CEUlGLFtY781RbtDq6GfG871+Kw438kLIvZBWu5CPFzqSKFRyyls\nlRLjPTm+lhEgNi+7xIsjhGddt35f+Z7reYBYCd9n2zXITt/AIeme+WH5+awQ5BAkBEi3GC1khcZA\nez7uhzr92/fSfiIipFINhqRMQlx5ElKmBLFGisTaJq425W2MmdOoURW9sE819k09zgfKV1WideH/\nn736ta/Gx/6ljwGAp6vqq5YXbbsnJiIfBuC7Aby7qr7xhmufBuCVPYe8J2K88pU7J2Pbtm3b7rVR\nTsaj9r+Tj6qSoaqvF5FfRJfRfxQApK+C+1+ie/AumkjPUfBnuWfTCIWE19484E4Imnv4838GmEnR\nUCMVpIRQ+MpFh1wBRj03otc35YlYJUvbbIag8Awz2TgSmfDjg8KR5PBWsZKRideoC6kZTjLOa9Ui\nhXSdKS/GvNLcDg+9MZwb/RXjFP3Ax/OUwaDrrMss/yD59qkeozS6nlzzasNEFdY0nPPoEhznZ45T\nSje5IjLOdQ89XRw8IL9kFHhIFEkeKR8jmufKhak58GN4svaKYjC5mEuDvJl6x7kY/Zz4dMBOsJx0\njH05nERkclGIhl3i/Sie1F40jHJkHV3+Divh0OWJbbfIROT3oc9i9Rz0hO9rCca2bdu2bXti2cMm\nGSLyJADvjfARv6eI/HEAb1LVn0NftOnzROQn0ON7/zaAnwfw4uuea2DbzMCcKRkO8p1oxHk5SyYZ\nQmB8kI2eLy0RqmNAtynBvfCRCsOvgUDDSzquMK+w2kJ/MU1rMCBkZYTDpE6x7oQtaOdEQyykitd3\nOBAhYFG3TChGSNkgG422iUzYLFz2O8d+YEjxMBYH/uxKTxZ9VwlHJN3nlc09ZyQBRUPa8GlW+6xL\nmHMg+N2VXESVqG4oTOMyMnVwbN8N3SdMBMqjPEE5lWcy4fkY9mEgvrlaY5utSq3ztas1Wa/IbZmP\nM4D3KXP9ur4XxKISDftmB9lwgjE6lEkG7HFDyRAlrjf+ygbDuUQ0JjKo1KIFp9A6nqth3STksTBb\nE+NV6Pko27Zt27bt7cgeiZLxAQBejoH/0eN3AeCFAD5dVb9MRH4/ejzyuwL4XgB/Sq9ZIwMIAO7H\nQGBHBRRHOY6tEQtWMoJgyPD8diWDwa+M5G1LfnYjz7UXWVy884xIVmbwrCYjOGAiLzcRDaGwqLpi\ndlcvKtijMBV7shEu/w0Vw6bUNeLRFGfLv0g5GedFnobltqCDe+4EA48Lt7+9H6xmjH7tq6UvfrB7\n4MfR1y5nZHPCRx8JD1wqonPpg0oPTI82nqvGSIwE0TfRq3C3SkbAaCcO6cNi8kYNDq7lJNUkCA/z\nK42Z8hkM0C8shi8qHiGB9O2lxQ/7+axyZeYn/EwYQVMniZlcDMJzDQHQaXivIRLXlW+776aqL0T/\n34Vt27Zt2/Z2aI9knYxX4Ia54lX1CwB8wcN5bgcw5bEEspTAVy9jP+yaZIiTCwLmFtrUWp8diiOq\n4oF+kKA0eVQ7JhzHnPBtIUB+ZW3jUCdMoRjqxUHTv1qSrQM+U2eMpHjHELkYr++zRykle4/fWUm9\nOEe4VCEYQTI6ABwvRQqsKckI6uDP1KYgXE1HmEwKlSI1iXrLyErnFxRMZGrGPDxcC+ro2c9/Wb0o\nQN37tb/NFRTtpCvEB10+xt9s2N15zfiWLO4pSuAJ4YNIyOJbdFK1IEkzkaihfXSKVIZaHqFSOck7\nVIwjlAy2i8kpGPzL59YKokELDgYht2l6F4+JTySNLbdz84tt27Zt27bt9tj9ml3qRrPZlbIJOS+l\nlMW1Z/TZpYBzUjGSV1gBQYNigF2IEw1tCj3GYn0O8AqqUyYOSsC6k4zhjoeHSpELNpKYWcWQkXeR\nF7I7XfVjg5+cRBszAvW2uWDiKoY6iUpT1fLsUqxenGt+Rl/Tw+uJAwJilIRMV7DSw9qSitGgrc/4\nFQQDRDSo/sQHhLvfVYjhNXclpXry7bpcsvL548JxkAxSDYzkJjUrKzlJyfBHKqkUwRZstiqmyVM/\nTkRD4zVSWsDhRGZMhKISRBTHxj+plYIhU9L7IUepbqF+tWttIUGxaXgnSkF75bn8QYx28lXXKSA3\ncMlt27Zt27Zt2z2220MyJOdkmIWWIEQsMtgWNJwdRIWiERakQ9GS2qBN0Y4GtF6HJs3xbCgVTDSM\nQNh+r2UiGf6DYzATBMIzXBK+fbXsK++HOfTE+gEWOROhUrwWRqsEo0W41FK9OPvsXOfWuoKCsUjg\nIWg4+r4tSijUMCddsVUQ0VBa4TuVI13DI25kIqsZxDGQcS4rIQzuvSxtiYxM1xSS4Y+jkB+Vu1My\nRhfFZxT9xirYWgXQ3Eh75OgTfoXv1jrZI1iV41mqbAyN7DDJsIRvU9OO/JsIFrMeyWdYtVgRjRXl\nWDKCaRgvsIhNJrZt27Zt27ZbYbeGZMgFJaMSilWZiADnDozPOMMJiWJsbR897Ka1oWkADYqjoZOL\nQQIYya4IRiR3txQqFJ7pQETsxPaQJ55dygjGccLp6srJhnttGVxNjt0cJuVKRiUYZ1sJ/VzUi6xq\nGOHAmMkKB3C0AzgaVA9Y0u4ULuP1GdVc5WZQvyWiAaSy3k+DXig6uK/IlZ3ma6zvexOB8b11edOx\ntrmRDJsVyfbBYT75/swXgqQ4oC9ko9QUERCWHoFLiey1CkE4MmkSrpgrKIMsURjeMa3offiMUofQ\nLGdS3ldMx4svqhbCYWj9uHDy8rBoixXWaza32LZt27Zt226X3R6SIQUMGXlYkIwoL8dMLE6g+2Bo\nbcx0BEAUTYBDGpp0T32zqXCHV1gz3iPgnGdJmtys437hsgHqwjsc09f6DFOnE66uupIRoUcIwgHz\nCAfQ9bAkIhtGOGw9ita0JHzHz9QLD6NqDSoYgVLoREOP/p4K+CW3HoOEQWMWrynxG3nfmQZZHx4N\n1G6AFKZtpEGxnhllCi71c5MHfKV2jHeNfu3KhQYYVr2sZKASmtFFjpp19JckohQ5GKuQISYXdG6h\naCw4z1xuh0QsjFjHit6zcsE/dwQI6gzB49U2I5at9j2GxHasLxEkZBkutSQXi3Zv27Zt27Zt226l\n3RqSMRuD/JyoqgV0WeiNAcca65/w5w0YZQ7bsICd+T7HTTbbjoG3UdfhKPb9q6seDnV1ddUXr7Of\nr+odYC/3RPHwaj5j+QLePg1lw9SMqm4Y+eiEqQ1y0suPA1A9xrm+oN9kB3A0cZLRoMjzAcQ5p0hE\nMmBkYwxMlFtbL4TNcL/4B8JEIwZ7HrWMvleTpop7+O1onHcFIO6/Ge0q5Vf4k/wb6fuR2I+4DJmJ\nWB2UjlakZPTBJDTVZ5XSsWN/O+IxePFbhrZpBv0xMUIps0O63se93utlWvYziQtSOTUrnx/WdPUR\nb9u2bdu2bdvuld0ektERzlx+TWiM32rrMFi4kAPYHPt/GXDyy7STBfekZ59rh7+jXE2BoVAo2j9K\nmeVc8MrYx1jZm6cJNWibHN65hlOnONwmbMizOUW+RvOQqiAeY52PQTp84e12ADDS0UOJfDauBamI\nMwrFQWclyp1gjJJCNC6OSdn3f9OHUYnFzeOdc0witCnIRkwlEFO3srp2iWhkMG63RC+JM9CJWHp9\ntJRdZxGOlCA2s/ML1fRZrVg9gvN0Jx4+9bPVzMcuk4S8HXUzApxIBh0vSUZ5nq6/kGj9dd1zEyHc\ntm3btm3btj2admtIRqUAceJmcBAhQ0qeUwK09CiehraaCCIGP+I8AJSpbKf7IkH2EKSFzHqce589\ny5WL0xXtnyhsqsfBB5jNzV+qGZRzEgTDCBfAs0sZGWuuXEToVy/r5UfruoQeQNPDpYwDg3cogFaB\nK8Pn2lvH2GOgSGASMWb+LI7FuYjlC5lIpGsmGlOOdVEYXL2wUCJX0Hj/Bryf2lHe62QjlJEgMvTg\ni12bKSd3S3ypg2poJRr5KsBlOK6Yc/1ELCSmErbxM/JxN0TByjCeDd4vBCT//SLex+96BJbWwdm2\nbdu2bdu23XO7NSTDEXItvoQw2VFcwjkc5ExhHuwVrQ9ce8wd1hEYk3IzT/t58IreXOYzSZUpaz1U\nipQMiYXeGKCuYdIIS1JanK+VPknJ4C0IR1IyokwPcdWiE4sRS2PHqWI2GAeM0h1LhYPJnpayhwEg\n13FjtL8qs/fORIPxu4UtuV5RyIUHOckF3jONkbVOYkreRGrsfaBcoFwpXsyRbhzA3mpB5GHkOxh5\n8EdeYEZBL4JYYCTec+iUMti3txrwNxXK9ieyQWOeyEgv4GuuDZW68I0kgnbBNsXYtm3btm3b7q/d\nGpKh5tHOhcNK/HnZtbCgutib8xYlD+0SBmJgtArqKD9DA7CxH5lDoxKZGAvt2b6HRo11MXqy92kc\nH74An/3nYWIz7yk2lIxRMW636lAxNE9ryzkYWcmwcweO1ly1ONqBRgyjEo8EnK9TMUqvM8Gwa1xA\nuiu7RCjmfZ/hibpNaCcEBnHwz/cJX+ftZHA/D48TxRW7CSoT4VKFZISKonzbZF4LBWSwGVVdXZrq\nFgnslqQ91AyN0CmlYx3J3HZ/Uh60EoOsRCTFYzxgVjmKArJSMbiT/bO/yMDd2jKxaNu2bdu2bdt2\nr+zWkAx3yKai8H6CT5djDpW6NG1qZhvjvhUwkQGeCURG4vcI40FxLruSwete9P3TKX7HcfL1QI5B\nNOKYiIYcUde1wDJ1mYszBPhi5e+R6G0kgtQLn1GqWQJ461P6HoeHTbWR5N2AwTAUYmrFoSOGyjSV\nWcW4LpI+H0WDO+fjsJ9LHbEgFLYv+UwODOpXer61z7RExMJzJrg1pHRMLRhvSmR2gHh6r/CeYEky\ncoQUV0D9GTz1q7EGA/Ap2m9pcZI5kJGNRC5gQH8OPcyzhgFZPcS9IxkT90qDtGjuXTPXbdu2bdu2\nbdujYLeHZKAoGQPoB9EQOHRjksEhQQuCEV5VdSC+4DNLk0EqGORKqZeBUpua1gnG6YQrX2TviNwL\nOfr0tVL2PfH7CKJTnOXrbhshPKBwKe1J2n07iIZtG5GPpF4Q8TiMaPR6SANwCMaahcAhvcz6ZXAi\nSXkanXD0fy/FKM2HDz/mXgsgpyeMj0WGSkUxS0ktctXCVIxEPsYZnibM3nWhqkp79s0lmkFkxtPK\nheqRGGzeWr3rdLn+jvGaJcGgzyrfOO4mgpGUC4nQqSAZEcZ0KVwxJ20vSMZ4/+q6TFCsHzPx5twf\nNfKv0cepmZtkbNu2bdu2bffVbhXJqN5GZUCfiAWfXwMdexwLGPEO2rIlHBrv5UXSTM1w7Gee6INX\n8R4E4+qEq9MJV1eR4N1DomyRs1jwzJPHGcwSoNKLoFaiKSkvQ/2XFY0gFZyrwWFTR5OuXujhU9q2\nsShfJxo9wb1Zp1lNliFUnWb4NUmQcM0hn1u09VIYlVPPdE/QQgPcc/K1nTdgT/kYaVpZSaA/c4zF\nRLLMk3Uuy08a7xpkI8hOeRGo/heVCSIWqQ81k5ZU1Vh1xAkGhUbVrRGOqla4crYg+/Zsr99C2bBr\n7kbF4L9JH3cEuZjIBvfNtm3btm3btu2+2a0hGU4IcikRibL1fxAApwIfUzEGqTCv8gz6VuEvHal5\nWApf6dgoAKrlZESIlBGMq74+xlUPlYKTDAOyB4HaIzzbCprhKrDlTDaGikF9aH3g09ZqIRhOLnII\nlYdM4cChDa31WbH6Fmitqxbi21QzCI5et6MTi/5vRuimBPV9JdC8cLsH/VgNGl2q6bSH/qB3igz2\nEgvpxTsEQTBcYYgqUvI3kw5mLLlqRkXjWzZSm9sniHdlgkMkI5Gh0kVTl1BdhA+vYSV0+VQ2QH7d\n2kd2HbHwUD0mF94n4QDIf99rklFVDCNGoSQaUdXxTWWyYbbXydi2bdu2bdvur90aktEtAwPVAIe2\nzcClbw3QxMrXpmYQuXBvv2/SKx2XWSiGAdNxjYF/pRscKArGishHDpcaBOMd3qEvwMeANW1NvbAy\nlYjuQSYWS7g9prGdicasVjjBcIDI6kbfP46G1o7YSkNDALqaFG01E2DkbJBHnpUOQShBg0RRBFNc\nx228gV9UBaMqHv14EMYl3g70zknftu8tYMC/eHcirw6WFVwct9mzs2riRCdXK/qZziXQrH5REIG4\npVjtcB1KDyV/G7Eo4VIA0noZNUyxJbIxZiwbr5xCpRYkw65bkYx0LREMr5cYMR/qTO30PYXttm3b\ntm3bdl/t1pAMDq/ox4ATDO3+ywAiFiLUgXVrinaOVazTPnvonXzAwVGQkPDQRn0WFRU4EYDoUDFG\n+BNNV3uM2aRiPYyRbwHA8iiEkaQ905BhkixsX6Y+0jFl6RQy5nkXAf6YYPgChqT4jKcOjz9tYcnv\nxRtPDKF7u3ul+roKpW+pHb15gw2Mtvb3GXCMZ9t+BPbU78bwtZbj+K7yCuor330a3muP091FSfA2\ng0nwoixc+TdYbnMmO9mDv/xeNPEPr3yEPcUzjYjxWHXCCaA1NDlGiFwjEtsSsUgkY3x7XI8gDkE6\nvI+8r+q1dA/1WSUYOr4lGX8PsmaU27Zt27Zt27b7ZLeGZHRykIGXgxlgkA3y1I8yHYShtTbIBc2m\ndFYiG31rRMK9pQZsSP2wc0ALkGPeU0h4S3G4imEL6fFaF9NvPMETu1NjY8eJVQ0ZGaAtQN7YNng/\nMMDjpO/mpCL61KwDzfDiW1uMMInPgCW+3xPWRy6KHLEAoZXTrz+epYCqcRTja5J3P/IX8s0dIDPZ\nqN+RePiMrUFSrxNSPcYwGeAdmD0AOY8Vj5N9m0YsCukTGh9RiDZok7E/14frmNZOAb2H36t8S6hu\nheNRpxA5hACHojX7FNpQB+wbb0N56jfxQo4+sUAhGN6X/L2p9RuPD7UjLopxgXZOz4NejplUbH6x\nbdu2bdu2PfZ2a0iG5QikMl39ZCpLROIcJIOTndu5e/CZRDDByEQDGDTGf9mjHCD3OEjJ8OTtArQR\nWwe5TDSWBMP6gOtLxIvaMMXDu2c5pqf1lb/93tHBBPgF8DofI/xLyjS7nuAuPOVuJxux8nmUg4gG\njGiReHORaghfNgjEkmREG2K/duzo17Gfw7wC0KpGOROMGrbmOR8G7EFjYapQJRnaYOF+l4iHzdKF\nEarXQ8qsTkxyo+qJXGipFwP5VR9zu6AQJxjx00E2RIk0lu9sRS6SMumbfOxtmCpE503piqFJ52bi\nsbpw27Zt27Zt23a/7daQjNa6msFmHvqWPPeLcp+atU1b9fCpPnOSgWsG7nBgGIQjwKi6JxUIgBue\ndUle/PDgzx59gcCTj7VSlwCsqzpdKjPSEcQiCIaVt2aL7rVQQwLyJRWD22DT7PI6HmlNj+OCYlPa\njNRn1I/+/vo1ECkZYDf2OfE69R40hQxFf8blmWzkl7NqEPxrIhusZFhfMrA2FaPuL4hF06xmHG3d\nFyMAaFCNXokgmnCgrlGl8ZvmviotLaBe8k+lK0CcMyIjFK4me68Ih2YGsbabzlu90u787ch8cPEZ\n27Zt27Zt27Z7b7eGZBhAjgIjEhYOpJ1UrPaJZOiKZLQA3YlM9BcvCEcPNgmA2897ri4C/HqYFC2k\ndzj4PiawzQSjRq/wjoHFnBA7h0qt1IxVDkZr9brc/646AK5gCOeY8M8XFiRyUghAJhuwjsPYexig\nb/Rb9GCAXe8rHX1r7VqRDbsm9u1D43ucYMAIhgTZMCVjXG6gPrz2ZTxWJGOlYgyVY+YYQnVVV7+s\nCcaHvXkL0gHaJsVs0dM61BMZ5AKuwo1j2PjO4VHLNir383pk5wIp59dkdMrQuY6zbnvc2ju+I/Bu\n7/ZY12Lbtm3btj0Suz0kYyQq+7F56MeMUcttQwBoTvTWtiQeHGbU36EEyjL56GC7bw+wNxwJPPfQ\nIlvnwrz767wMQ6YOGzMWDuDopGfU0+tm5UAlDL4ehkb7g2D0maMYDPqLk7dePGTq8PZQiNQgF6cj\n8jKMQFhfOJCnZ00AkFFgPg21/gb3Mfz5NdeD7zSVyAmkPzFeGsA3yi1fo/erkSRTMyJsqYZNGcmL\nMKVrVA0bF5U0Q1Nr2smRzRM8asbrtRglVcRaFkFK4+eTAFD53BNEYq3frCcGgVAj12BygdTn14Xp\nzWGHMQRMHBIFcQKl+Y/N71urFGtCIfOJpfq17bbaN38z8NSndoLxlKc81rXZtm3btm2PxG4NyaiJ\n3z0kg0lET0pNK1cTuPbwICYWmtWM8PzbSwyQaQCysS997TlABHoADrTMsz0AcCIYtJ3yMQYATxBX\nGe4SGCNwWPNFQsGYPemqSECvth/pGQQ0JfuFPfRr5JuwinFiJeMwbQEOiB3LSZRfAojXupyFdohp\nXCIZqiAlI5dzxxqQBvJMSnZOdaVmYMxaBCdl43ED1FeV6Tolg3IzhpphRANNTbiBS15cP/p+rG3T\nWCbS0e9l3cK+u1wWxMNea4qP9Vcfy1DfLikX0fZ+TXwOTLArkaD2Wf+S+iVlu+2Jb099KvC0pz3W\ntdi2bdu2bb8XuzUkw9QGP/ayxY+JRkMiGB4uRdfwVJuGssKZXwjG2HReITgOoC7iZsTBkr59dqWS\nzzB53jXa1p9D1IIB46hEJRixfw3IKwqOjlwUbS0UkRRMQ+3yUKfDFZr8O/V1QI4TjtMJIplgYN5c\nBoUXeMdUKKxqzCRDCa9mBaMaE4sgFf4t8JVGMET8+aoaqo+9DxdUpUoyLDSqbgshPKaAKdMvolN6\nfhCv8p7rXcQVb4sR2XwM/yb6w/t5ywHp/+edASMblWRAmWhRHxg5cbVIXMGr66NE+fokk/t5aK8b\n93j+tm3btm3btu3+2a0hGaZYuClKEnf/nSfSEapF2lbiQYDInp8AlpEP35e+qnXyFB+zR/2QmMZ1\nSTD6Kt7JC8vv8mMyU1uIVKR9957PCkcGrrHAXl6zQEsdComiqWtlysnoBOM0wqVmuwbwJaR3EzCk\nXBYx537u++gupXtGu9LjFZYUHsQiFA1bE6SfN+KSVQ0ZKJjDphKiLwj/xpwMIoVOPA6rUekH8Ncy\njhev7gfOgBJp9h5X+3q4n+K7T8qaxPt8vMbLmUhUkgUqcyVExAlSCj8jZUnGO3lNFMvFCfVQoiH2\nbyIeF76rzTK2bdu2bdu2+2q3h2S0SjKYVNjUtIozk44z52HMMytN5GPl4vXd4uId8KbJ0b2rdC48\n60coGXR8aaYlx/acRcw2gKH6tpCKcZGma+CAj2eYqkSsTg+c3m0oTo1DkVJDyd6nlPx9wnEcRT0I\n3/VEpOo7M+OaLVDmIBo5uTx7tONZagSRSBgAxOJ+QSw4ZMrIhOVkeD7MeJ6NQySDL0gegWsbPwbc\n/k1KA1oQmSCF1wk/knuKybEidWN8E3mtjCAZQTQV8Y2tR6OUOMnQpGiEmkFlTup6f/epcI1o9I8t\nkyqhf2HJOZnUi7WJr+XGy8WWbNu2bdu2bdvun90akoEp8TsTiTMttHc+27ZNSgUTCyYcjTzM8ZKy\nk3DJUCEcPBl4kQA+tJaE2GJ1aVrXPI3tgLXuxp2mXC2eZfY2r0jFpF6k5G/78dS11rK8k49JganT\n154OnE6xinmELHlNBwgfHmkDzRqKSd+sxqD0PUYfU5hMDZuKB1R1Ym2uSCRlA2CVI6sXtOJ4Oc7e\ndALY9N9EMMqvtb4GhakZHi01CUQEqGWlIIRwofHhePfYORurOI46B0Gbem3Rjxpj7oQjSLzvo/dV\nz7VgogH66KiVq1Coxfl8nY3lqKtEb10fPrdt27Zt27Ztu5d2a0gGAxNgBtJGEPJ0mZiAWwqJAsAA\nTaEjfCmdqrsAMMA0/Y7Yv/Jywel0wtXpwNXpNJKhTxFqlEJ6rFHRLpQ2oLTZSYPNpFUUCm1wlSLW\nwqj9EX1pwH3GeAbexpGrBnWUZLozHOoBMH2LQuomMleVjhgn759xfRtLUXeO0Mlc5Npwuy1Mrvmx\ntc2T75XbFqrGbLXcapvJjKRj78Q4X1UtVKJUXjVxME3njOwkwlkJDZHT3odBLoLMIl07vZzuq/2i\nPjbqY764G7n/5n0nk1L+GAWYSKWpWqXTSgRVPIaeecgqtG/btm3btm3bdq/s9pCMyg3IK5sJhwHw\nTDrI9Q8Gge7VBHtCA6xwWXjQkUjFTC5WpOOE04k9/zGjlKG7iTAl8nSZTDX7JZIBWhMkT99byQYD\nwDmnNrc/+m/1y+MlI3TGx8u37NG2N6e74zVTOYWVNUU7AGmKQwQtxfVbqFGQCZ7Cl7c2zu5Jn9hT\nzknxaqipGJJyM5YeciH4K0CfkqzPGpVWRieicTk4aqIs0Sd+QAyC1IpUnBSHIPK8z+fixZVYaNlk\nAhnjPlXUW5FCogrLl3ypkwvma/MECvlDFgDq+R2zbY6xbdu2bdu23V+7NSQjkwQmGAa8MYB6JRgr\nEhL3Y8TPywCvwjHeCPCSPad3QTIq2fBthBqNVxEArOrLTDpUMS9uZmoG73O+CnnzG19rzzbgt1Qm\nbEME7JqolSCDEaay8mozwUignAkOe8+Fxp0/hNYHrckIvRmLOBjYz6RivY8xzn3KXXp/UZrscO4q\nKln1Y//EOvmhawzyrmYb86i7+rAyVATjE3WuKkYlHX4bjUUiH17WL0qEgfcm0hHEJF+dyWxSe5jA\ne4dd6EciIdFXnI8Tz5uUi9yN5eQ1H/W2bdu2bdu27VG3W0MyqpIxhYM4uUCQDQbkCMAe5ujPcUny\nJh/Zu8z5E0wiVuSCy44BYE+eKM3hMISeiWjMCkYlIEQqlBK4WdE414UII/+kEgyFdYVOwLaqOiCy\ndWG0fOtj5kQDFwGsDYc/pRIOQugZtPY622xEUS/uqxoqRiu8e9ssof3wIenn6P+rAaAAACAASURB\nVHu52GR1XNuJTnSDJWX7+g+JdOi8hgos10QCMEfTUy9bDo91m8D6l1WJxd8Kl+FSeTzD+jn+fjT/\ny9fkjlnsLfpTppJREHJFJRh2uib+rx5fC0uafF+dftu2bdu2bdt23+zWkIyqZBjoTk7aRC7KMYHp\nSjR6KEWHbEYuYnVu8cXnDjp3XZjU1VUOlzKSIQLfPzh8puPESbVAAXpzSBgtqGfH07S+Nk3tKh8j\nQOhlVz3FpKCAOAtbuWHg+B0rgqHjfbGy+Hg6IWcbN1MoDMNncmT3spKxajcTjP6S4xC0dox1TxqA\nw7ukroNSmkfkwt6/gNOjXgp1EmJwt5JZVtKqlmGv6Jxm0AzjNBodVpWM9O2g/m2siIVO10YN6JuJ\nUU7nL3bWJbUsOmkOkrK+8LEVdwgEuSBl426sXLeebnnbtm3btm3bdq/s1pAMA0J87ASj5f3q5Xcy\nkh5IrmawN9QIxhGL6Y1Zog4qu0QyrkbuhZU7oRhA6BieVxMxDELm8Cjab1xewGFVMrSQixQuZYoG\ngW5maKhAuZAJsPe4xrLMwE5zZ3v/KyHa2A3SwGqG2vuI9ATwp+cOdlJ5EZMKJPCcCYe1pxOMA60B\nx2F9fF3id+0zOGG0NnAIkF922JlBcIjQer4BmGjY9UwCB8HQUC8s4Tu3FamfJ7XiIgnh65lkMJmZ\nCUdXlfI48P66K9dEwzJT+DoXNkBEzQlaJcHrV9Qijddu27Zt27Zt2+6T3RqSMVny+K9CiDLpiNtm\n8KwEXGJq1tWK1vG7WpKMk+/btif1qkPEyFfVADaO2ZgUrRSM3EZe98ITmz1kiklGi1XOFyoGKwKL\nCJZ0FAB4vmI5TEpQlMkF2ENuITlSyIaGSkDvSjkcJVQn+daTWqLlfaFo9DYd6HPEwtf3UOUVwGvD\nuHgAfvu6EmoNxuHwmVQMAJOSEXkvQr/yXo3XRB2ZCFQSwXwyBn5JKi4QDxs7H1EFvVPjGicU3tAA\n9NYdCyIbu0LNNhUjvoC1khH7yapiUV9rPbxZxuPKXoPXPNZV2LZt27YnhL0b3g1PwVMek3ffGpJB\nDvd8rMgAyslFUTLizgXwCADN4VI23azPCnU6cBplK/ViqWgcBv6M3ti+RIXBhInBHqayAIeaZ5gq\nuReVZOT+yKTFUeTkZs6z+Lh/2cBf2fLY5MEjMIvyXicDXTEwvCy8evYA0h0IRn/1R1uHxFHuU0vu\nvkQ0FKHQHNM1phZM31A6kk6IOHQJDGglgdu0T4A5TWE7efHjoUqfsNdfQ0MQGwSrtNKx1jGIMZt+\ndJ0pIPYADo9isqHQslK3ESHxot5HRMLcVtIHorFC/eV/s6WM1Z+ycx2P2CTj8WWfjE9+rKuwbdu2\nbU8Ie0e8I34cP/6YEI1bQzJQgV4lGB4ytVA1/CZh7FNQh3lCOVzKCMbJlYrTqa9mfVm9yMfHIV7J\nCE9qUQnyLBuo87ZOCsbcPiYQfSrbNpEMtVAqzWQD/K7smk8Ws2pVQlGu13rotIIGiw7BWFh9TDzH\nQjGmo82vcsBLfRohPQF6V4RitW/tskXPbdG9TDYCVHfVYsHJbChdhSHQ7yDYjin0J+VihFee8w3q\n8PD7jZhBY6HAGN6qSGRVY9Uv0zfm/Ryjeh3ZWKoVNsFCFSyuUzRoX9K/mZj5/hFkIXMGmf7U68Dt\nnIxt27Zt2/b2aL+N38av4Fc2yWAQy0DJQXxbA6iOdyQBMrFnJg/oCJdKoVEnJxen0wmnqzieSUVW\nNPoCfH1ROIxcCGjzugFWZuTiMqlYEigHgZTcbYSD8zI8lEoXIVPq/ekmFYIhn0T1/IZGE+MzVnKu\nnnH+j+sg6CDUQao4WLepX3Nd2cNOidyan23XxfX5XkATeepqSkOESpW+WX2XwhxgNLQwgwSMeweu\nvfDDcx9KhiCNhhMKjFyUfuC5Pa6+xLcf31EQ2fx3kgkf/xr/nRmlsH4htujUYxCd3CfWPsU8dxmp\nEVEy70v+8XS1ebppe6akRwg/p5IOG65t27Zt27Zt232z20MyzGuZisy7PvIeSqgJ/4sE7iSembyi\nK3IxCMYgF1dXufxqsV7GMWaZsqRvhfhCYB2f8X6Qh0ZJ3kaY1sRj9QtlY1rl26fxNRCOwQhk0ZfU\ne7L+1cXj+BnX2SWS5GE7BZguPgI4QYCRASIXdrwkGbh43PdHpxARiWtusIuVjm/OgC5/gwyucxgQ\nkR5q+XXv7URNQm1wglEIK8qxlm9jGhdn8rlfjFKW7mFlIhOlKKG/SjCJktIv837NW6FjnhZ6IhVB\n8vxoIhmbZWzbtm3btm33024NybApYc2687tDifPyjgoOw0tsALp6kEUOnK6GCnFFxOHq1FUKIxhX\nJ6+PzzjlK3jH21W1pxJX8Obgv27HPT5DVt5edDeHTHDxVK+UwTsOz4l6rwiEHHl9EFmtTr0ggL0P\nCuC/oMY0bWMkh2deMMKlLMdBEbM8AdO0tFivgeG1cHCcvwkLLcpO9AzrU6sukYmk/BTlYQm0+dp5\n6/8y0bgEgrkB1mahc4kooHyLlXgEoci/8Vjrf69VvNuPjbSjKDVVubmRTJRzYwrpWLSwrC1Cixmu\nSMZELGp3bo6xbdu2bdu23Ve7PSRjhB+ZqeoFckEW0RwLUjEfyyGZYFT1gsjGcfSk7oOA+XiUv9xD\nTJhMrAhGIhmmZJQwl8wlLnKN0TlZIZjxNQADggeOo6sovEggk40oP5x0mOJTSUcCa/ReIxyVaPiU\nuoNUiIyAHxVfGLDj6B5qgwKKs5qRlYxJpQBvRx846ew90svSBVOvxb9ry556xBERGPLfZ9WClSEi\nGnasqxd3xj1aJ67GVKUiyGpRLewZ1mfpYwJ6PgWTjdqu3DdMIvr1a4IBKr+JaPjfGS9oeaxIcOgn\nM5GQqapxarOMbdu2bdu27X7a7SEZI3zJzGLPqyVQftKAlBIgjr34vagfH4dQKNRpIhyuZlyd8qJ6\nFK5hyKoDZwSo5pmdWmxby8clQqVvWyELhJfj+uyhBpeD+oFJFf2OA7Cpeyei4e0MkmHkggFef3om\nGhO5IILQEkEAPGZfQQRjrP8AjBmcrK1MKK5TMmz4FywrPg1kT7csvqx0B9bKBHECmZ/ScfVaKWE9\ngMFwegt17dQaV6xIseD/qnpRPrQ+BFq+l/zBVfKVCAbVjcmE3ZdJOBOI6xQM+9tCfHtGLljFINJx\nCCVwL/nhpZHdJGPbtm3btm27n3ZrSMZxEpyucrgUIy3z7hMPcde/KRnhPR1A2wE3BsngEKkjyMbV\nSO6+CrLBK3gLEAvueW04cZhIhRYFIykbRBra7FienM0UI5XVjgCRyYk/LDzooVAApGTY6uZENPq5\nI3uOjxKiUrzBDlUn9SGTrR4uBdhUsJzo3QlGhE5hes4iL8OVjNFeKY75KYQme92jkxaqReK2rDQY\ns+D9Tg7qUyrRyO+ReSsolcDor7mvrYpaPpyL+TBpfMbdak/Mb+A2VcLg7fIuWZTz9dcqGHNZhCQe\nQXKrijFIxzxouFzmY3L53LZt27Zt27bt0bdbRDKKklE81aPQdvr/kZKRgPAgGEnRkL4ImxGJHiZF\nZGMoGFfj+BigybzTjgPFajCmYB2e9iAXmmaA8hwNIhkdH8ocvaIgDKhxDnaOvdWscNh9AYov5VWY\nN5gVi2NVvvixg58JRt3WfAxtWmaSUti6CkEwNFYCn5SMqmbYIns0IAggqToTohUduBvcOakY4G6g\n/i5XM9EwUJ7qUu67qGBUKuBEIffzRaLB5AL8d2UfXd93YmBVJSUivifM5MKvD+VjVjPG/rQoYVzj\nBOMg5ULyvn2Xj0Ss2OFS27Zt27Zt2/21h00yROTDAPwPAJ4O4D8C8PGq+p10/gUAPrXc9lJV/dhr\nK3IcTjLMyw2AokM0VAxV6Ak4OVASAkVMLCSVRbhUVjKuTMEg8iEDDFt9oECfR4rqMLYpJIoJh9aF\n8hDYTnvoUJAMSQTDlJtKLjwsycElB7yM2pK3vXt/ewM8BMUXI6zk4ihA0AhW/JeQHI2NbVeqRtO2\nTPJ2oiGsZGBJKFJeBqI/JC1mEQC4f4u2Ld7vlXRwg2U+UyjFJaJBe+7952cu7pNJs7BNlEfAUyYX\nS1WDVB8FPYfJhtdSE1lfKRBO5FH61/dHW4ykX1IvFmQ2vkc69usjtO+SLfNZtm3btm3btm2PiT0S\nJeNJAH4YwPMBfNuFa74LwKchcNbv3PTQY5H43Xfs2E8MgmH7HWQagKnEIpOMWGCvqxdHJxakYNgx\nkwlx9A+SHarXfl7HwhSMNrbhPA4Voz9HiLTQOVIq1F/NSoamazsRCm80gzdVCS+x1P0VyQDcgw17\nYIbmSv2yVDCUyBfmJG8D1KFkSH+qA+RLZMOUjKxiWN9mosGAONSMXnjNBzmZlPuLBrEiGolUVKKx\nVgFUo19GJwNEBFaEzmnHqq/GQ0zNmAhM2mdycJkQoNTZ24G53FSyi+FSrFKwqpbC+CRdWy3UzOlU\n2FYytm3btm3btvtqD5tkqOpLAbwUAORyDMLvqOobH85zjQDQe8aWjzUpCHpSnMYFclxPMCz/4OQL\n6cUK3ytFw19OHnR2LGuzcy2DOiIVrnCMMiwIBoXI53MaIN6VDycVHDalCTo6zSAgFyRsJhUcnsIk\no49vf144p41lxLBX1YKPeRFBkTnJ21b79iRwD+m5rGToSGZxT35SMQgsc49YH9Cp+cNdKRAXSlwI\nKUSDjpiM3Eg0RlkG/vkw1AeN76WoGL3vW1YzEq2oFCO/j/gDAf8M8I+xcnaQCmpH5l9LJWRWMDCe\nTWFR5Z2cQ1T/Xw5/AZDaPm5cLdi2bdu2bdu23Uu7VzkZHyEivwTg1wB8D4DPU9U3XXfDicKlgOyx\nNe82FF3FUACnUTbyMlJIR/GcgryjPfcib6/8OJQMJxgjlwJNBq4rQSsGqI1MOMBmwqERLtUbBUc9\nTjLEz9l7VANcBsdaKxkFLjoh6KCsA0MjFBY2FQSjkgwAFXTfBUibCEf5dYKhF1f7FilKxkWyEUrG\ncXANCtgNNjAUA74q3TE79iXOBclKvTsTjYmLBCmb3rkiGhBA6DvxyiCIlSsSRLYnokH9VJ+DGlak\n0T/2zRgpPUCgP2Z/MtK66szU9eO6Y6Vk8CxnhcQkMkLqxopkpHaIeCvrVTsnY9u2bdu2bbu/di9I\nxnehh1G9HsB7AfgSAC8RkQ9SzfCJ7TjNi/FNW/fudzB1MnBFHtPuwc+5BYlkkIJxRUqGKxsjhMpU\nCRX0LaRPNSuhHqQwKW2FWMzHFs6TQa0go0o6rqQCpF6wkuHKSAfpBhhVM7jKSgavSZBJxnVm/vZc\njyCBWJQzMRvsAphyNGoo0GWC4aQTuesyuYgyUzKCHgixjuvauzq3ViisZCZo9fqsXmTVY35TKBjw\n798JhROPa0gZsyd7TUHiXkNRCmUignHIFMZ0sYv4FCsZFIZXp4VORKYQjBxSdVwYrs4KFfwNsENg\n27Zt27Zt23a/7VEnGar6T+nw34jIqwH8JICPAPDyS/d94df+T3jyk54czwHwZz70v8HHfvDHOYjn\n0KRA1qQKODgKsAT3yMYvVIgGVUFrZ5wbgAbgTign6ipEW/w0yEPJvfDjc87R8IZxK5WArhMqnpmK\ntquyCdAHyPegmO7kHW0eYUs6gD7fN8JNroPdyzAUx+0FDB7l0uQtR3jzbfg8pApQPcb42D4Ti1BG\nLsf8m9e7UoFLrRrPBHIYl/JxJUUZ1M4dQ+1OigYTDe+SuW8XdQxWFRKWIsa6e/Rt5rMktsQBHTMv\nizC6CKGLxRklKRlxo+bD1HQjE/z3x3+Ii3FaqCxpJjLk1Pi4yg4UL3rZt+HbX/bt6Zq3vO3N627d\ntm3btm3btt0Tu+dT2Krq60XkVwC8N64hGZ/3338h/rP3ej++D+fzGec7DdrOvt5EB1nDm+1eex3x\n5JLIRIR8YKweTKBreHl7vgDQlxcPrzBs6lVtF8gGqRQ3XGPkKOJU1uRiNLyvzaexWnYb9WiDWKTt\nUjnISgOGAmIJ1oogF1ktCXAaNnutZ+d1/0+N3I1VmQ+1+P38jCo4cKiRgfe+f6R2gUiSj3kiFfU4\nlzEhYkIHU5ZcaNFMLOi4V0yLSkREN7SSqYwJBasf3nCKe3MozZzCzNWrQi6SaqH+DCN06VWj7r4v\niFnGPOk6TwhgitdyEMc7k10ck/g7BT+GVQh7nDkFyqPV/pVaBnziR38iPvGjPzFd/yM/9iP4qE/5\nSGzbtm3btm3b7o/dc5IhIu8O4A8C+HfXXdfODefzOQpU0c4NTc+eQFyTrANkGXoa++5ZB4EcBNAc\nBKWNZG5pSOWHz4wURAMTiVgQENW4TjPJQAsv/JpcwNvSX6dJ0cjE4m5/QTbs3WKkwjzDhWQEmOM+\n9e6Jqham0WehMpWiA9KcVxOPXXu9o6BPb2tqRSUZpDrwuFodJmBbX1aR7Ogj7w/OF0E6hkgBvxeM\ncPgyXKr2waIrDESn/zT2+Qr+kMTL6JkhHPjfgEQFU0iT5+VwiJSHSi3yInw3K4re5kFiKrlI43Oh\nL/ufhN5wPvfY6k8r+mnbtm3btm3bdr/skayT8SR0VcL+p/89ReSPA3jT+D0HPSfjF8d1fxfAawG8\n7LrnNj2jtSAZ5slPIUgeh26xTQNgDSTlTllhcGXhGuw9NaDaw3HOLUjHoSMvoYZL0TG4Pk4uNEiG\nHzeahcpIkVwkF3auKWJ2qlWoFKkZThCwUjTifFcIRqiPhiLggHoiGaP/JmIhTji0ADuBAAdwUHiT\nhUB1/eTSR8UHXN9+komFh4GNi0zB8rEGUrkBfcrGuGCdafCaHWKMosdJRXswO+1zWwhsEwmaiUZR\nM1hiKVWL/SDXOn1IWi/OxMLJBpNuImW88J3nQ8yzPk0xYt5mLWVBJoxwzKoSEY9lo+PvZUkUKqm4\niQBu27Zt27Zt2+6LPRIl4wPQw54M0Xz5KH8hgM8C8H4A/gKAdwXwBnRy8fmq+tB1D23nhnZek4wI\nF+KQqQBUHasMZDqmQ81hU4NoHEKgpCPz1hrkEGjr4LJpgzRx9UEXygTSscsFTi6CVIzpRO2aawgG\ng/uZUHDYFJ2rZAKhXFS1x8J71EOnjFh0YM1hU9apHjpl5GLUty56FiE/c7mKEQNvcG7+AjhGbkYQ\nlaxixH1idXNiGaFJdpxYJ9eXKmJqRuRiGLEA0sKBRDT6sy6h2qJjrJz/xHou0ItcQeqxOS8prhWo\n59fYw6t6IEQYVsnWaUYpKx/7E8mwNy+KmVT0v0sihDZWhZRxd/I3Ik446Rr6XstNE3ndtm3btm3b\ntt0/eyTrZLwCU0pvso95JBVpesa5lXApnxbWpoYt4VIJYPWU0PBq59+RQjM0eeK1DagjArQBcj1M\nSmeSwaoGE4xA+fQDXWNts38kIzPz2LZFmBSRinSO3u8hNYQ/7fVj7DyROYVOWVV8X+ImAWALxBkW\n1OJ2LuVMLhIwpEYOaoWKFnUsyNer0EOngohFB1qCOBimMteZcCurBbk63hzVyL2gvItKNLhvdKYs\n6b2g95qKAKoP56Osjdknf/dRNqkYgyz5Psrfw7QORVUvRtiUnws1w/JtKl+eeoKYVAqZgu3baZnH\nMX0dZeyX5ELWCsb82W3btm3btm3b7pPd85yMu7VJyQCBaw5bgiJCpfqVnVSoA5asYJiKYfhOPf7e\nHcSubpC5WkAhT63sk3Jh9xiql4zuqbqXyYUh3kj8plCtQjY8XMo8/IVoIJEOA+0DxKv1gTj58aTw\nQYA6UUAiGO7dh63OHTYnd8/kQqmdScVQC6ZSB59BMMLHf0kRARhf6gw2DdgvPPAOZMvaHSMaK5SL\nQTRi6l2q/nU8QTLBYQKU6i4jjI3bW1Cy91lSMWp3VNIRKo8RDJ+Ra0UgFsccKiWW+O31zm+emk8q\nUlKdfEwQ26kTg2C4upWYpL1U+TO5gbRt27Zt27Zt2+6H3R6Soa0oGb0se/FjNeMKpIAAPVXF4MTW\nDlTgYUNBNgLEdQzXPM+iE4vmIUog8B+Eot8rhP1EAwRaqBG7gL0ISGwnEr8pTKomfXO4FK4nGQ7w\nk4IRoN33h1c/4oZcyMhlMk8jagPA3uwZ1AeJYcDcF+RTVzE6EGXXtJb7uawe0z3J+b1AnsRhci5G\nb3gNkUrXIQDyohtgH6Ira+m8zH2Vq5M/70LKFHls06+A7Uy+KVSqJnTXRfAodKqGU626MfWwcBm1\n1QlFIX0XyR+TPF10Er2UP5fFWK8I0LZt27Zt27bt3tntIRnnc1IyACxDhFK+wYAOYihe1D22TDYO\nYSUD03MayrGB9Cmpe0E4Bmh3X7XGlss6VrysXjAyi0X85tColBDOPwPsDj7D2e14zBQMFSdWoXAY\n2bLKkcfYvfqgfIk1majhP3bOyc6omLp6oE4wsnKxRI/IcLGQjgTIJV0r1Jzh10eyQTj7WA3lwuuF\nIENGNBBqx1TFQmtcqajnpFyZq5zb5eMT7TS6MREN+3sYxJXJt4UNxqKMsZ3DpCSRDFuXpCp/lQpy\nWahI1HZqfP5eeL+rOkY0IHC1Lb1YEc8JZrLgGbePZojI1wH4RAB/AMCvA/hGVX32OPd6AM9T1X9w\nD977cgA/ZO+6cM09e/+2bdu2bXv7sFtDMvrK2Zz4XclAHLNn24BpkIsBMVnJOOAJq6ZcdIDacz2a\nUnK5JVp7WNTYqpaZo3SESmUwKSoOYQ1ASsU8BhJprQyOLJqSulv8WM3oC/wxyaBHJxUjyIQBtVAz\nMLz2TDJk9G0JVVlszap3evJWg5UjJkWc5O1Po46i+P3cgaPf1D8YHeFMYuSDVQgbkfqw0WdBQFHC\nomifiMaleWydSsiilHMRiFhM/MRJhPccbQtzVL6y1oUJt8TfgoVKDRXjOFE+RiEVcRznmRNxTVdk\nw9tfiITQvp9ZjLP/dQ9yVwkGK0zpfevhuTUmIh+DPkHGhwN4PXoM6G89ppW6RyYiH44+Wci7qupb\nHuv6bNu2bdu2+2O3hmSc75xx586dVJY87AZS3Usfx54cbGDe5QR6mBEORSgXg2hYrsXZksxbmXp2\nSThIyQATCynbqECPubfGFXewNRjhuDbQb+DSCZKTAXdwex+B37Ew99ZLOH2hQb5YyahEgm0mGoHq\nYn2KAKlMJGL9idF/RoD8Ohq09M4ZznKOiTV81N6fGffTs9KD6y4VeEfh+u0NFnUaIViIsCuSukjx\noW+tqlakXvm3obFf2+UiQgH0KZTwWoKRc52QxnzZo9nsW+CX+64sri0FtYyHZ/lmnWa6uv6v4jGx\n9wbw71T1Bx6tB4rIlareufnK+24P4y9l27Zt27Y9Uey6WaLuqz105w4eeij/7ty5gzt3zrhzvtNX\n/z6fp2ltDZAl0MUI3czAGnmDc4gUr9zdhqpR9m0a3VZmufIfaBu/pGr4fwvwN1Acl3OYCdJuvMAu\nqd5yBpHx7ABtQVAG2fJ2xmrjXMZtbrRvhI86u9Q1wGkFtBb/n1aZ5vNH/CwJOf/g7YqpUmtfTXzT\nd8gx7/3k3n/kvkwe+botTZ/6wz9L7jPr865Q9fC4+L6bK200jfGy7y0MrZBS+hRLhSa7eHbqrJpJ\nQl+z9X8w7j5GiHGy/s3rZSyIThpf/km5/pqxuKUmIi8A8A8APEVEmoj8lIi8XES+olz6ZBH5VhF5\nm4j8vIh8VnlOE5HPFJEXi8jbAPzNUf7hIvIDIvLbIvIGEfkSEan/v/5KRP6hiPy6iLxRRL7ohjo/\nS0R+dNTlZ0Xkq6SvmWTnnyIi3ykibxrXvFpEPkZE/giA7xmX/ZqInEXk+Y+g27Zt27Zt2+PMbpeS\n8dA1TrgKtvnU5NYHgaoocye9KyRzWFLkQfTVwFmxYDXD7o0IjuGscxC2cNyRt93QkSgBNKuuATC+\nlJ9WETM5+K0+nAvhoUtTFyp3D7QBIuoAzrzt/XbKT7jUNjoomBA6lJzsBR+gdCgps4JxGRib+mHX\nKTAvHEiqzMob7pqTAVarLwjAel/ScZUFbjAdlTMFyb9B/2RsHIhAtJi2OQgGL0ip1HI+0njnXcgt\n6mfV6OriO4v+Y0K70jHWz2Dyx8+q41LeM9XjQtlibG+5PQPATwL4DPR1hxqAFy2u+1wAXwzg89Gn\nBv9KEflxVf2XdM1zAPx1AM8EcEdE/mMA/xzA8wF8CoD3BfD16KFYTCQ+bZR/4KjDPxaRn1HVb7hQ\n5zOAvwrgpwH8UQBfjb7Q6l8Z578a/X9PPhTAbwL4TwC8DcDPouedvAjA+wB4K56gYWHbtm3bti3b\nrSEZd+7cwUMP0Xp9CRjLtO2bANI8s5JOBIOOLSRFkciFT1frSkUOV+lkA6RaxHOiygILV8phINeg\nnoSnh5fWhIDsZr/xMTpYxkiXLaSg1il7uA1oAkYIzNOsdNzP9mOEdxkG8C8hxJ4nASMuC4IiAJRj\nnuhBIrVsTT6yeKDLKwPz2rNHeVF67OuL3JJS2drMm0yRcwpSVYMixHowpK4lJaNRSFW0mkOlcmjQ\nTDBYaJvasCpIBEPSpTksKVZ19xqw8lH+fvsuPeBSZW4iGfbGCwMSPXM7TFXfKiJvBXBW1TcC89/m\nsO9T1eeO/X8kIh8C4FkAmGR8i6q+0A5E5IsB/KyqPmMUvVZEngPgS5FJxs9S4vfrROT9xrOXJKMk\ngP+MiPwtAF+DIBnvAeBFqvpvx/FPU53eNHbfuHMytm3btu3tx24PyTif8VDJyQgPcwmNIU+//08z\nJyfACAQBLh2QalzDoU4pFKgkfoOIhdbjplTXXhzEJ2EpOCK3+A7NmRwcF6LC6sOKXBigMjYSWgor\nExbi42CSnqMGwgsS93pXciFGQwpFUAObTnPoReJN83Uw6O78asF62tr5yrVp2gA8zS49lzoiQqCI\ntDrRmEOlQLXn/pwhfP4GNNUt2mGzJtnJORStjfyhqmQ0fordnb8J5B67emI2oAAAIABJREFUllis\nrHwwiRwseIF/gUueSSGAoL6msvp9Ti+4UEedLryF2ReP3P7vxfEzS9kry/H7Lu77PgDvLCLvrqo/\nP8q+f/HsZ4uIaHhp3ETkv0ZXTN4XwJPR/7fj3xORd1LV30IP//oaEfloAN8N4NtU9dU3tnDbtm3b\ntj1h7faQjDtnPFTCpXi+/tiPWH6IAMcRKgZCZegWhANeYvkDTDAsVIrzMIJQ+H4hHvm5sXViUKJV\nJs5Rb7ZTGd2m3bXDMz+XgT4rB1K8vQqM8CpTeIwsGZFzxuFP8ZmVnCwdrohUL7XXRYSpTn/zRBKD\niEQHXYKL9ZwCnETNDbxwt4Nb71cKlxKDvUZAJN133RCEImREI76M/BVavelIFYqW1AybAS0RjfS1\n+avS98j94LVZ9sdMPdKRs6qZpPFDp8/ZL5HUcd6TUs7Vh9D7a3Gmn4VUXBqcu2JWjwuro/gb5Xj1\nh7Ni7ndtI6/inwH4KvS8jzcB+DD0cKt3APBbqvoNIvJSAH8awJ8E8DdE5Nmq+lWP5J14FoB3KWUP\njN+2bdu2bfs92YMPPogHH3wwlb35zW9+1N9zi0jGnUQyBPBFwo7WoDanv/YVidtx9Kx1D1/q+wMu\nw136FIrimIiSlSNMKkKmWsrDmN8BpdApMDAfr5UpMv16jJM85TFrU2Cz1d0FaKaHaQZ5fl3BH5Yw\nLNRPnsNh5GLsGQNJmbagaV37+QqyK+lhglHrK3x87X631qJdabrZ4s3PvUdgdyIYoS55U639Uh50\nDS6ON8cVpDeMfk8lFO4XCd46CEUlGqGALDCjlS+Ge11HoT3uLSaLmWBQ+tCyI1YEJZMLfmY+t25P\nLeIRzo1cB8k9bu2/Whz/2A33/FsA/20p+xAAb1XVX7jm2R8E4HUrFQPA0wEcqvq5ViAin1QvGs//\nOgBfJyJ/Bz3n5KsA/O645HRD3cOeB+Bpd331tm3btm17GPbAAw/ggQey1+ZVr3oVnv70pz+q77k1\nJON85w7ucE4GbA7/A8dx4FDFoceYD0twAJ14sIrhSkaAtm5KuCPnbuSZfiw/IysZrozQszOBCeBj\n07MCRjYqMs2/KYlYELkYydtL2Jy206yu04EBUhng1kAYgVxqnwIp+VvctT97ug9YX3Si0Z+u8Glf\nF9VZh3/1OuXEb1OcLhMNDwdTINa20OBMFW+WPmJiETNLSSJZQsTK/qu0abLCbKyPNe1nwpG/yU4u\n8ixSjRaNbKlNUrtnBfgvVHPWMehg4g+S+KGkNl544YU8qrl8UcEL3wllHVmtRr8u6nPh+HFiHyIi\nnwvgxejqwJ8D8LE33PPVAJ4pIv8QwD9CD2/6AgBfXq57DxH5e+ik4OnouRXPuvDMn0CfjeoZ6IrG\nhwL4S3yBiDwPwHcBeC2A/wDAn0AnPADwM+hD8GdF5CXoykdVYLZt27Zt2xPMbg3JqOFSIn0605Mq\n9FDoycCwwmbeFRFSHDgHg0mBgY/wGNeQp1jsbkwfajkZ/gzk56Tj7j21Be4w9uf0ZoJqS+RH5EMC\nPGXAV2/UNYqsoN6uHt5+5xQEfsO7Pvv+Xc3wn6kHPVRNvE8l3W7QfAKntY6pIBBzTvgOLlTvs1yO\nIBgOO1MrhOshiIEY++R4r7xqAuE5nwbXm38yg2YokQqjG5aPQUQijnlWKUv8LuYEQ5JYpMtff1b9\nQueRL31Uy1J/lLqkfYkxTsQ5ly/btChkqpFDxKghjz9b8aIvR5/56QsAvBnAs1T1u6+5B6r6BhH5\nWADPBfDD6KFN/xh9liq+75sAvBOAHwRwB311769fPVtVf1REng3grwH4OwD+NXp+xjfR9Sd0UvPu\nAN6CTjieTXV6Dnry+fPHfZ9+bW9s27Zt27bHvd1ikgGcTieoHn1LnkoZwLJ7fCUAXFIaQmXI/3ab\nE79pNe1VuJQ9oJINmDaC4c0nbFRVhoSlMmxnnK0+s1P0RXLy4yL+KmAvPO6uYVBTEvj10JysYrhn\n/8j19T4U8sQHZM6cSVJ1Lnqwg2wYIWTXfCgd1objAFob9VNb1G/c44+ZoXNKuTclw/ZZxaDruC1z\n3y9Go34IK4Ix7bf4Bgu5aCjT1yYiQaF1I5RKga6o3USA7tokE7Pa7Poe+mCFSVxSNCrpuPSMbIlg\nWIwiJD6M+IRuranqVwL4Sjr+yHL+Pe/iGcvwI1X9XszhUHye3/XZF655z3Kc6jvsW+j8M3CNqeoX\nIxOdbdu2bdv2BLdbQzLO57zidweMCtUTVIGrAZK7h/n/Z+/dg71rqvLAZ/XvRYkw6MRPxdQMjpEQ\nQQkq0cggYkRF0YiooxKNaMZcShOnnIoXnDI4mWQszQTvpJI4RcVIcBwvDCYo4n1Q8IYjKIiloqiI\nqFDcL+HsNX90r7We1d37d855v/c95/d+9PPV7+y9e/fu3bf9vc/Ta3W3tDnfEtYKZCtG/KURbRIV\nYHLnI8ebWzNGy8XOub9BEDeN6PKweTf6TeUMNHJLO5anUf5jhDEJkRAX8ai0agoCzgQXTGBn2DBs\n3ZjqL0u4MXudqAgrRMpyFGYiKrh4Vhbf00MEUGmuXv0zndCYkOUQVPAfdTgXHBeBv83qGKRPW11t\n3O+Q++GGXK8uNtpzff0240VYMrwGJ8sFz+0VUS975yYGEG05xNtLgwWGi4odN6q9tDz3TWC0cvj+\nHsr9+px8LSwsLCwsLNx2nIzIECko5UDX1V2qlEN3jN9sB+gg9ACzO3MPcY7WeVm4x70IipRKYtLu\naYCRmjHvxEzpl0nrRUiUDpdJJlHmjZjW9yOTK+Nb3YjumE4IEbVRZcVQp/s/iksEtCehs6JXithc\nt4aR5ygbnyvl2wn5NjtGYuGOY20SMq+fd5LK05UzCQ5qVx6x78vnNgbrgyY4QnHALEkhKvq6oOQ1\nBJZZutxKQH0shRUqh++aXjzcC2FtyALMyr4nco+JEmqAowLDwyZlnrwz5l+YNdNfU61YtunhTnIL\nCwsLCwsLV4OTERmHwwGHQxYZh0Np4XOREWIjiK7QiKvDSZ5dtHcgBIAti6tS6hyQ6v8EH/l15kJh\nbl2ZkO9ktdghaTsIq0C2lpjvPqmneo8Hp20+wkDcIxUuf+w6HZlLZSl92WZCYxQXHk7vTuWn6syk\nMIsKnq/g1qdW6DRXQXVcgamVkoWFE+pjgqkvW/qPa29mm6ICtlCvdRK8Lh5Vk4WDj1kNSxIaYX1B\nFhldeGliXfg7aWIDXVldRIEbL9KMhu2KekRg8DMhYihdFhjHvo/Ud0hgsML2T1NG89fCwsLCwsLC\nleJkREYpJYkMQEhIZIEhvRWDCBSQSVCQNiBMA5reA/QEszSLhY+3IxiMJdxepZmCskUkiBto2DvR\n3TnIzQYuLOK15CEWLjEaMaYCw5k8yYymMioXtALNyPb8RwoD3eUuiDJbQbusjvMVoBzGu7GPQiRc\nt7oK6PPXXQ/laQ/5yHsvprwpjytHFozcpsr55/JSJXVysJ5Js48MomIUHINILNmCkZ7r0gyxEa01\nlJWvd4SG5xFjumF56dPty9+/1uqx1ks1OFZh4frieLMsLCwsLCws3GackMg4oJTIjgiaJWMiNKQX\nHEycJok3MicwUhqovMeEQYEURbGN3dowuygzl+YD7jEkNgpMBBxB+Kaiwmn2mNnuYCP3vRXDR/wt\nsuQk0qvI/SjdEi6JhV1EZKAr795vKHjLe1deL4lm4t1ZK5KlgsuvcYz0tRMGo0jadY9C16e4PHD5\nEfWbymjitGk7VW+6ONdUDp8C1Fmb2HjWKHVNOYk7ynfp2sj2mvHvpAx1AD43gWydA1R+P0gu7+w8\nxWOBgSQwuE4TdoK9Ttg1KgkMwfKXWlhYWFhYuH6clMjI7lIIUXHIosLFRekJPtDRPwBNYKg2MgL/\nmbNLWB7aTuKl1CVsbe+Fnph7uiPZ5jxY+kGqKF9TEsSWkywq/CyR846MDmk6M835lxw5RpLr+y8r\nMFhL9L+BKvJcC64IEgy8QaLvFbHRSkvKy7juEcqxzXouvCs0gHlZAe8riTRP6HAVGM2qNJSYz8LG\n4S5hnP+etFsbYZK/EmFo12VHWOxZpXpB5aKCa+6YqOCDizW/yKJCunt78NvWV0aBUasmBIZIt7zt\nwsLCwsLCwpXiZESGzb8ICA6HtldGqbt857kYdYK2lBJCwwhgex5AIyBBOIiue6zgPEbINkhpo6KI\n3bt7t6n8XIgKtmYM4oKJGDNQS3uwYPD9sGC4u9SMSFnROwJuPLBVSc4OjTiz6LqYwOjJalSsnSbi\nzESa58q0kf7NV/pq5xsJji3um0xEZN0vmLcycU5E24P3yhP3PCEvVybUw3kHdvtKrl29RYME4CiT\nmh3D8oWZwBjPSxG3aPiR6gNU7hADdE2iIGdpXgdJl5CIyN9EtMugY6zOhhB73ygwpG3EaIMHCo12\nA9L5wsLCwsLCwu3HyYiM+epS0tylaOdvc/+QIEtpUiuIFxlvVxv9bdaBwZ2oWTHUHi7NKcrIXhC8\nIMgkNkjgpJFkZDIFIL9bMGFS7NbE8xKQwk1sgHKUk5gQ1fY+kbyfh5M/Pt8TGUAqZy8unKTzO7vM\n1ezReH74ErlL1GabI9qywlqXFmbhkcmxiYNcTh9Nt6z0ZYOVI+JHWJDudA9RX72gsTo3y5m5S3GL\naCtzzMmIOqD56nArTSL5GqQ8Mj4KDD627yNZNbq5GUlASZTR35vEAN+jrGF2rxdoLDiifWYiY7aS\nW63bfYHh711GjIWFhYWFhWvFyYiMw+EGDoc8JyOsFxLnYqvl0Mo5iSg5nQQQnhRB7uyGvUcgqkS0\nBUXCVpHFRnsGmcP0I/9GatFft1HobMEgGE+aWCdirkIXmsTH4EA10VOWexpV7oi1i6ThRwQdcXRx\nwUTUzrsKGxyGbAS/iYxNw13KhEUVF+P1VOhQ3UeZkchzRM1EW7o4VgYWKy6mundYMcdWo7MkKDgs\nBGMbis/ion/LrgjMAqL01o1+/lKZtLWrTSovXaI7Sn9zJj46sceCxstjfSOVeawA3xfDvlAWGK0f\na3z0x5JaWFhYWFhYuI04GZExri4Ft2AcXGRIEh798qpBZnoQGSdC51yujThDgIKCrWyVvGh1y8AW\nYsOe5JkaRrhB5Jvz4gTYXDlYpSQCXjNhhohxGVMrCwuObpqwBpHPf5kECtiWkQRG6Uj2nsiY/Fph\now26Qe1ODxG5zhO7WUxs2xmd57BC+z2UlvdiOwb6u4uXMTgzl2dSJipHFhwRNozgd/2ONYJSu/i5\nryiFLDJ2BEZ6j4mpXmDQ91AKhfHcJYqD1HZeGX7uWoDe6aKDBMJQfu8LCEGR+lTUpwvdociDfa7V\njSDNuyBrj9j8qdTZFhYWFhYWFq4DJyUysrsUOmHRWTOEiJMRFSKQALmtNIIz9ZTy9wXFKTB3qeac\nUhSyGZfpJoK7Ww6N7huBcsFBhdLJeUK4SQGgud+j2GDXIyDTMp6PUYkXLXWbhqV3iHYi2/siI5FE\nHrEeSKh6GXiScxYYtILUICw2bGdnOCORoW0lMCkFKIKyVYFYpNQVwZwXx2h5L/6GduNyg58dyzQX\ntNRCrha91OO55vBIdzIUL6B3k0gotOdFIeteIWvGzpyNUBKhMcKiQaID6Mo9Exg5LE5JrbhgyW0z\nQuaiowkIEUnCrBcY6f7CwsLCwsLCleOERMZsdakgSkVCaNTRWfgILZwIAh218WsnHDr+bEnRESQp\nGulUaCM0xNWdkMbrnZ9FUkHwh1eZpJmhCoTZbaE0XQC5laa5kYDrJUjjaAEarRYRL8hnnxGRfNy7\n17t59dYLXzlqq/MxfPI3x5lYdaydkzXGiDQL0pIXCUibOPoIe2SYeX46P1Jet0N1lggXf7pzjnye\nBeAolsDlnPzQnUP22nh8bjdubwHhbO6Jjl50dgKvF00T20WqE//+kF2i3GWq1asJDB444POFhYWF\nhYWF24+TERmHQ8GNG+QuJQgXGKmiwq8LMuGZjKRKZnmN6YL84uMHP+9X+0GwY3NPssFTI1ZqI7VO\ndYmMUxj6aaw9EzXLBS1hC01k1jlgqQJs26y8TQxpkF9PXeGWnBlhnO/o3dIUKifl4Tzsxenrd/Nl\nadtE7yYs6jnPVWhigvJYpiuOxe/Qr0TG11I6S1j0Fs+7WLvulaUrJ4k9AO5+Z/fmg+qhOI1kJ+sQ\nE3MK22s3cFlcDExEBCZCwtMr41yOLrwXFdJXXic+/JXpme48PXgBC0SrOnaZCgvmRM0vjbGwsLCw\nsHClOCGRccCBREblV+KTU01oGAkuEsQZGMkwUkog16GG2TKiPuGY/Kp6C0hKVz0/AiJb9NokErok\nyJuG8jbz6dqxOBQBDeA2HdXy1XxLVMJGMhDTgahGPY51y7nu65lJnezEsagmMFhobDuCIypCxIh9\nFQyq20RQHHxflUFk8AaOIm051zKUv5OnY/apZEMpKUDzH3CjjhS6tZnbnFhodFYA/g5s3gULDRO8\npAWY9M8sF7t9onSiw99HjYKcvoWz7k9hMwGSaiGfjRD4ZnveKVo4rTaVVd7SGAsLCwsLC1eNExIZ\nBTcO2ZIRxLc/5rBdzIwFbrGwc5DAiNWN/HkAMiH+Qn99ZNhGjf2/FDlGXz3pkUilcOZwqdzNoqPi\nGsipPYmLemaT1qkOd6wXTFSdP7rQmAkLLtwM4bISG82xi1QIjBAbvSsVC40QPaomMA6+vDELi7r0\n8SGJDDGx0URGobpIDLgnzUO5Q0nwQmGpn0h+go+zvtSaLYRFK6hwWOHzY5ao1vtMdLA1g95z9Meb\nXdoSuE1kZAEt8/rq73n8vbg9jgiN1gRi9a8CEbNf8H42nNySGQsLCwsLC1eJkxEZpbNkACQkgCw6\n+LqdA5gaAXKAuUC1K7dgZKHhIgOZ6kjm/jAXEJcUkxHdi46hpkFvkI9+GpwOK84mNqpsk78rvYJM\nRttVqP6yoEij+ElgsNDIx5Tvzvf9aBk7t7Rt02HVKF/etV9rGNH+2kjlgXaDr+cHFxomMg4lxIW7\nWs3IuclG5+FZRh4tVGgOCs9xfN4Pe/BIWJ7SqHtriySkaTfv2apq/mEMfZC7IT8TotXfVbolcCcC\nw0UZ+ndlq8RMRAyGwDG0kxY7QqMJC1MZIq1+3bIhw8DAkhgLCwsLCwtXi5MRGTcOB9y4MWZnILrt\nTz9Qqv31bNhYw3/b52NsOgiMTbfmbUHEb6ApYmPExO86CwbFvQi0ZXxvAmxYItCsGJK9RdLb7J6G\nUIEQqRxFBxPbeOdF6dmEKE/jjBO+eVnavCJQdpey0pkIKofDICj8nMLKRFDM3MT4HT1JzsXp2kdz\n3P7GvEQZLpZd6En0LRITMhEbY3t6g1PqJiTh7Tx7TlhMuMAgobYrMpAbfWh/3t2i1YSLrPNqZlLf\n0h/NhtGO2rfhkhkLCwsLCwtXiZMRGeXQ75PR3H06biDDSbvUTOh4T4sIZ4GRz3uhEa5HlYS5M4aN\n2lrarnayCjIriwsQMdem5C/lwiKXOq48DRqt7glylFmaSLF8c02MwgIdkTXSOYxKD+3Qs7zZvfmz\nsS9GCAxzmTo7O/PnQ1yycJF0DBcpExgmOqrIcFcqIt7SxJbXI7Wp1+IxPjorcro/cYTrzVT2Ou0v\nRtHTC4BBaHRiIfoIi0rTLqMlC93RXfHauQsMEhy9wh8tGEzw+Tt0E6KLC5ncH2VFF8IWC9W6s3oT\nFtWy1ywZfRILCwsLCwsLV4YTEhm9u5ROTmejneojmXV5WbJqaCbx/SB5FhfkMmXuUmlg1hLM5CpZ\nMqYjyOdBOw5qJpacB+ePRSBKpBNIk79tRJeTzK5Ancgw0gkWGVTuSRFq2OCUdc5gsZLA4OVq88/c\nr5w0g+oVmXTzJO/Dwc5DYNSwQ13mmIWLiQy7ovYaBuMv0IQTWdHd1d5TakR6sfWjXlRIZ71g0Ymp\n2PDykjBOZ7LzK7GRn00ut2WAPauDoKBLsdI3IdDVSJUN7Uyjp17UomE6I7pg+z7tfRfpyAsLCwsL\nCwu3DScjMm70S9g25j2KhGDU1fWpkgtzG+Ix9kgoQvrla/235TkCYiYCI+2CJDBgxM2JlnAoEa1M\nwqpFw3LHuVQuWkKM6mexUVDzaJOPg/LX8gon5AIjSHsipjS6PwfbhfZwvsvUuFTwOCfDVjSKNCLf\nNjcgLUt7sPkYTWAc6p4rdu3lTZWa89Vn9SICY1dckGDUfNm9Qb1bQeFl3Cf/MWfC24pFBllj/BgK\nOERkb70ok5/EPBara2n13QuJUZnFMQh/r7JqX6ntneTDvE5n9Wt9Q7V9mrZ/hrV1TnVhYWFhYWHh\n6nAyImPqLqVBvt29qY0Kp/FQn/xpRxIWSkff+4J/VWVM98gQpoLjYHOMhNNYMSmCNh4df3nQdoKa\nndGK4e9mdxYjb6RhrFr8nRLOKjWNTlxYPqciY5A6Q1jlc1lY5NL04X09Z4FxdrYBUJSC6lOP4m3q\n9Uyk99BWlzqUsGb0AuNwOIzCicRqCICOkE5481jEeWMOc2p225x7Rw7uJ3a7ZSGFR1xQG3JYTS/a\nPAuMXqhkIePzMlxgyHxOBujb6ASH9+dZlfjIQN+3mvvTtL40GsiXVgsRE66NexlcWFhYWFhYuAqc\njshoJJFhK/LYkrPaBIFN8LT5B0HeidjOhIaNb7oFY3STcncpS6blxZyQXDgwMYMF2KAxjyRfZBR1\ntGyYtMnkUOOdRVDaO3wzMmCabweLib2jW1pmYqMng328Y+chDvN+GJqERqDgcFB/Pqw4pbNgNJco\nFxej4LD2iF3fo/+IhUuMqh9vo32hOKPFemQiP4CoUhIHI/Hv3KWKjIICdD7l1iw0+D1HLCZCGxba\nDupuyeiEBtdbf+6dcaKyFbFb97RictwUQ7jv52WbAWrvhYWFhYWFhSvHyYgMI58AQhvwqPfWXTcX\np/Dzx7nHSmiR09Ce97iMCEvFMOIsyEzqAhgHa1u6RMgFEAWqxikQbBAUFGwtTgGwtSMQ5phhmqu/\nK72yG20WPieFkq0ZXM7ROlGjVitSbYsN21bzafMrVBVnZ2dtBamzJihi8rfl0khjuEV1O3Uf+gne\ntDcGkWF0RHvWH5KVzEbadU8OyM7lpJLzW+O8iY3zRIdNW7b+LxrnUMS1ELkG7UeC2NTPsuZ3VNoC\nCfWZWIkpvole1G+qKMkCtfnz4VJIX4x15dSFIm9DzbKvlFcnWyKijlN97oUvYbGwsLCwsHASOBmR\nkcgXWzA2+AZ5/SpQW5uwHeTQSGOcOwVpZIQ34otfkO74xV+7l87IUBI358Kjj+IkUogQNoGhaBJC\nABR+OwuMdpQNaTc47PLdDDZ5II9251SOCYzxOvjdhm2rz4sIuUNVl6jNN+LTgRSKWy1MYEi3RG24\nQflmfLSzd5rIDhMQZEmxfjYTGdF5usrS4TKHXp7YHhMbvPdIcnczIWda3EQZ4mjPdDNQSIqKi5f4\nFiSLjFZXm2p1y9sUKq1NpeSUm67QNjeKhWv0syYiSXBEvnpRROWh5ogv/HxxEe2J6f2FhYWFhYV3\nFdwb98ZduOta3n1aIkM3CoiR1Lp3RbgyeZhZMlhM0PMDDWzP8RyMGCmVRkbZcsHXE9HhPPuSVo32\niKiMc8kb6SvYgK0ApRMWjeGKaNUYQ0Wmw9H3X+zmKDiak1qy7/AmetJZR0TgS9Ru2xmUVpJq0o/i\nI7kF8Q7ePt+CREbpLRk8X6FmqGmMEBRhzZhYOLp6SHMDpgLjAvV6pDEGodH6lNdJs1yYKLU4LCxm\nQqO35JA9g+KCrhB/rc5ggqNap0pp30/R5vpE9dTPzaEPRbxMJDgm1hb1wms8mIRGO1Jb7YmLUcAt\nkXEn4XvwPXgwHnzd2VhYWFi443EX7sID8IBreffpiAx0o9pmqWiiws/52MJ3neSHl4R1xPQF6wzG\n6CJ1nJdfSGaI9Kvg+sOVT0lzW1dszV2qaC8wNshWsJHb1LHSnyu8zn2yd8XKI89JjuhI/AB1kZGX\nqg1rRryqybm2T4PtOM1igsWGiws6xkpL9d15CVXNeXQrxp7IIBxTFoMms0n1XbzZ8yZ8MFofkrCw\n54nLHxMa7EJlD9sbPI4iyu5WErb2tW9MUC0aahtVWvnyjhTxxTQRSkY/dDGPunVZGl3RU/sB/t1P\nxUVv6Vgi447Cg/FgfAQ+4rqzsbCwsLBwN3A6IqORzggIS8a2bbTEbPz0rPr29xgn7wa5srkdQa7i\nfRFT/D/QNdOoC2EW0d1L4tzDtTm0eGDBphuKCQxsgJYgTD0BBXapVFAzcf6W9tMYRoBnQqIbrQYm\nRM/c07Lg8JWkdKuWDCOzxpyb0Br2wbCVpA5ZYNy4cWOcnGxWjETyyV3OLCd2flGRsScw3FpC/aJ7\n502Dq5rFhYljpu4ysWRMkzLR1cpvfbFZD1TtyCKjWtS0VIFRtAzlMouV9QRe+cpebuI6xAbnl3qj\nViuddyeq+/SpDi6S1s845sLCwsLCwsJ14VIiQ0SeDOAJAD4YwFsB/DyAr1bV36I47w7gqQA+F8C7\nA3gugC9V1dccTdxJoF2b1cEsF1VQbGe8n0W9jgyyl0ZcsHOIdiTKCZwloEHJWkhnzZBJ6DmYROWJ\n1hxoAkRKs1NsBVvZ2jyNAmxbI18FshlJnxPLHGB1UOuZyWXwuFlanNIoMMIVqZF3J+3ZJS1299Y8\nH4PJYqvW5C4lbMVorlI3bNWoFhcxj8PqMBF0zARGkzcsOC9NTk1cqGk3QLv3o4nbcVh+hGJcaakT\nF3aeVlPS45O/PRkTDk724d9B9X5SFyDVK6odJQRGPdI3wEICGBW+ZItLnzsX1V5szZ+gt4u1GQkQ\n5HabW9KwG7awsLCwsLBw+3BZS8ajAHw7gF9uz34DgB8TkQer6ltbnG8B8CkAPgvAGwB8J4AfaM/u\nordk2MTTTTe3Zmyb4swExpkJDnsm3DNEnEK3ybHGfUJgqJFMBI+3Sh8qAAAgAElEQVQRGjrtLRkA\nOto2DxnKNYvFqzt1EsYsGlDFhiYuzHqhdbWprS1BpW3id6ZPe4IjRnxVQ2yoLSvaEb0Ll1GBDVaX\nG03Q32jCPs2/YAtGNy/G2qu6SpUmMATlIL5c7eFwwI3DwTduNGIbFqFMr8lRKsSE2lwD5JH7SU0O\nWzjQe1ygtT81L0329T5xNNq+X5WxshSTdztm17IQF0bkTaTMrBlcuvopEJnXEBtp/oodNwUKSGjU\nx0ovMCL1tlwuQjRbsVq9jELI2klyZkn+2riA15Z2R0QEdqFCem5hYWFhYWHhKnApkaGqj+NrEfki\nAK8B8HAAzxeR+wH4uwA+T1V/psX5YgAvE5GPUtVfPJJ2Gm1UBbSNfLvAODPrxYazsxAblJ9YWagd\nxVxJfNKskVwQc+lzky0V9Wq0XvjV3JgwQtKBxIYPAztprfO9CxRbjNy62FAINmxa0GNPcPAor1kc\nRJ1Pwmnf4Me1h853niwXyS3KrBfOZJkAaiaDEhaJYeK3739x8N9O9VJNKJ2aEGKxg64/nM9Ea/tI\nxHWBoSE2piQ6au0y8wPMrQkKX+5VadmlFAakd4ZLVZ8mBbZ0oy4An3DdOscm4SbFQie6itC5mloM\nYQEg2zGQMwAZzkLzjdvyhTVj7FPp2D+zsLCwsLCwcGW4u3My3guVCry2XT+8pfkTFkFVXy4irwTw\nCAD7IgNKlgzJhNVco5qoqGKjCo2zsy1EAJNUExgWpvDhVBs895HRRmbgbw9hMRLFTJHSelP2jhSj\nBwkKFxYhiuz2hrqIj6IARNJVtjo1Q0rdUOMINOWBLDgmNIwsd3w8RNCYYq4Hda6tjbhXy1NdsnY7\ni4ne9ZFZfjXJtzwnI3b2LiWvLHXjxiGsD0wqnWhy/nYsF8mqEkKsK+IugjyzwKiWIpvAn/aBoCo8\n16rRxAVbKFxYmCXKwoQsJ+2aRY5V0zBXyeKSkLF6AZDmYGwgd6lNqgC270h5E0NWL6VOuk9Zi00t\nVdTnIUV9ahZtXZ1lEUF2qr4v9NW7NMbCwsLCwsKV4qZFhlSfpG8B8HxVfWkLvj+Ad6jqG7rof9Lu\n7SJbMrS5S8UKREZWzV3qrFkzzt65ufUiCCrtjF21RwgNJuw0EuoEDnCfdZYSbMvYc0c5Wj57lgQG\nCyNY/hsJK6W5HKGKDRcdWlr9aCW05744xobDVSxEnKKmnSqBkInpWG625tQ5NM2CcWZ7Y8RO3lx2\ne7hamVx3NSsGwmXKrBm0u7dZMnjyNu/xABUi5erx2NridUL3WWTYPIJphbgVo50PAmMYk59i7x67\nTfG8C+C4sOA09yaAB8PX/KwLDkn32HLh7lIAbPkBqyf1d1rmvCKj6pr2Y8ExlNvbrld4muIlAblz\nnJR+YWFhYWFh4YpwdywZTwPwEAAfc4G454wJA099xjfivu/xX1GI4hM/8lPwCR/5KejJhnMI9/M3\nBWFR8xCo2R6MnHhydOQM9rMxWG4MMIfzFMYPtLdTHJ/0LcgCQ/gJC69npRo0sG10rqNxYKhk54w0\nqt3FSlU3KR5zxv5tTNfH0D5VnqCNTgjWN1QBccOtFuVwqHMx0lK2VXj43ipds9qQfJp8biKICOpw\nzywPVgYve5Q+Ru07dm8l7CrKXfVouD7m/mC4Z894XH77XjtIPt2XwNTQ7mYFF02ilB+LyvNAtC5F\nXOt+g2ptAyuPhjyKzPC3de7/Bca8ateLjk3gNs33rB/5QTzrOT+U7r3hjf24x8LCwsLCwsLtxE2J\nDBH5DgCPA/AoVX0V3Xo1gHcTkft11oz3RbVm7OIr/86T8eAP/BC/Vq1WirMzrcvONmKtG6CyQYtA\ntrxkqa8yhEy0bGST17SZcRVpsZwZeWiGslO7ET8XG5l48tN7rlfHIB1rFVrN1nYGN9GVxs8H8REE\nGzbqT9YM7WL3l2N1aSxDyy+TaIciAi0FAs1LzfrO3LYXRlwfDgU3btyIn+2Jccib7qV80iEsNuOv\nlsPKDifX2aKw334REMP0yTpjc2woj7NVxOyttd9k5eBic7ZqVjongRavhs24tvBsaop3ucXD2L/k\nOgmRsQHNPYrDTGB4/9FhzSgqqT1HSaum8GyJohbpOx4plt5yZJ/gZ37qZ+EzP/WzUr988UtfjE/+\nnE/EwsLCwsLCwtXg0iKjCYzHA3i0qr6yu/0rAN4J4DEAfqjFfxCABwB4wfF062pCBoVWYbFVQbFt\nRFA3JlmVZQuzKrYIKGBbDrPf/t6QqhCJmWmAbLjwoWCorWqUuZylSgfhkKPnNOzt16YxquiSNOLu\npNlddzqaRyP+vahgcs7hQ/n5r44peSFIRKBtklfakrQ2oXsME5RS51u4wLhxwKEcqiVD+s32uDwm\nnnqhYcvlIsirx4s6y+XoLRRu0phqzxAF3A/JYmPuR0Am+gpIb+VoJ7yIgacD6vPtvX7fr4/1JyuN\nNverbt5Dcv+qD0f1mNiQTmBo64dWl33d5eqNORWgtgK58vE8i5kIZJDAmLyVBXop5wv6hYWFhYWF\nhVuHy+6T8TQATwTw6QDeLCLv1269XlXfpqpvEJH/E8BTReR1AN4I4NsA/NyxlaUAuAuMwUlHs2CU\nZMmofMfmXrTM0YjuPsmZjdJTCdEUy9zthJlMs2ZoIzlCRDGnt/NXZuf8WMuLchzKgBFB54Q2mqsx\nbYCEh40Sh92iUXMf5Xc7QFc3oxyxe1mYBMF0IlzqaHzZBGXi7pSuDwUi3YZ7NP/C4kkRZJXhmfH8\nhJVm8x3hM7k1kcTPttKpiZgdstw3kVC7DmKghnnXcMFryfOqTC2ORH9wId3S5j1B2NJhz7EAYqsZ\n95twCWuuTVYXPNeEdNfw2ZgQ2BQq1PZa02PvKkbfb1wcdvNjPH3tnuPzpP+4/vfb7GbmUS0sLCws\nLCzcPC5ryfiHqNzgp7vwLwbw3e38KwCcAfh+1M34fhTAl52XsG26ZmCR4fMQNsXWrBllE2xS2khm\nhSTCR4kr2v4BFFBfMuSjtySM1ER9NJoHqMlsMk1xKi4m70sj5LVQXboK86cX1KxUYh3xeLWg+kQn\nHlrRufgmETAhdxxxJjLosUR6gSomNiDcndoytL5q1MHCxk336opSFu8Q7lIQMCemDCXhw5YMzqRb\nf+KxaV/oTQK9FSOuSRi4CICLVauULDY4pPWlzt1qdJeauE9B4j0kOrgtUh21jlstb1UYAJpF8jGR\nsdUlbYUXDyA3p2PIos6sS/BnY85MjTezYAxFmoj6GXq3w4UTx8tedt05WFhYWADuugt4wAOuOxd3\nLC67T8a4McMY5+0A/nH7XRhSepGB6qFRqsDYNm0uVcCWVo8aaHo6RoJOwefvT2e0JCdx+96NRNLI\nqRG2GdUx+tndlTFWykV7n7gbi3genGQPxTGXIExujpYHHv0HkzyltIKJE+kMy0gi7S33XDeDuKCl\naGfXvbWDJ30P7lKRw46sbokEU9SW/T1CfNyC0Xcw1xOhMkarQ3S+plHDtY77FASduAirCBACw97F\nVg94vZw3Zk8dGGbRoHJNxIa5V9l/RW3it3h9RxfInTILOHPhy+5ryZrmbZaS6TI2tse5EmKJjDsL\nX/AF152DhYWFBeDe9wZe/vIlNG4Sd3efjFuGIr27FKBFUbZqhSilQItiK4Ky1V2viwi2CXnIITpc\nSRe+Z3vYFSxO1Jh275C7giCfFkey4HCCSu+rC2YJxiFmiTNpW2Uo6g7gXX595JjFRNDxznIR1yE0\nssiYhbOrVSZ8jQC328lKcSO7QrGL1KG5TZU2GTzN2RCBtHkZuTmySPI9VmgJ5GDSnYg4Ovg+ExyS\nysc/dm9qWoPaOqfrblLWkC0f/VwMF9KcPltIJPhzEqlDGPd8393DS9RP3o/O0UrDAs1cpdzawMex\n5oYvcCIwkkWEfx4+NAMdSGx5+XOtrzkZCwsLCwuXxtveBvzZny2RcZM4GZExtWQUrW5SRVE2xSYF\nRZrLVG/JOOKqkdya0EjWDufYndPRpyc2C+J88kIaYwifxeWLSgaBYT5GQ9naPhdEspww2sg5MBET\nRMoxWjJi9H8vrKbWWwSqQMozAqSJRN9Iz+Zc3KjL1dZjnexdrRUdoW7XJV2nwfYoGwuNTbFt9bwX\nlrt1PhMiMrafWy9mregZNLeuEFx98tG28Z6h7C1NnusRJFoibzQPZCxXvK2e5aVnTdhGNXV1UDfH\ngFsjkrsUmhjA7nfIq5i5lEgCw7VH/LDTYv4ZsLhgC1dv7brYd7qwsLCwsLBw63AyIuNQCg7l4Neq\n2kSGYisFpQmOrSikVNK6FYVsNgeBR6d52JUPNC9jMkg9s1ykKPvDs5PIHMRktHObmoxC87W/csct\nbCuANAIozZohIk6s3RJBo81JXPh1b8lQt4T4vIuJ8AjBYRkLWcTE1TfSu1FcUPgqUnRuQrOfXxNE\nO1UllYyZKZPXzYN363iXlI8IQg+3ImRR0Akhya3A4ssC3KrRyu3uUpiljSwmLB8TqTSFfxvS2ib6\nCS90NXmQVpfiuhWyNFg/GUvrNyZqwlyoPIz6Jb8+l48EBll2rM56rDkZCwsLCwsLV4uTERkymfhd\niqKI0jwMbTtBS7Jm0BC+JTaSXyWiNzD4HUvDjJcYMYQNSmt7XgZe1Y90p/F9GcNGdcN323skzyqR\njees1NWC1F5LJgylZNLov0YMnsBrI82j2FAikSnllHlx8luvbW7FoTR3KRMY96oi415NbHAfGNPW\nXBA+aoiNcfnaINZ2COofKyzBBcHseDE499+ZMxRuUjp5Te6MITgk0gX1eRYaiLreRSpK1O3UU2rn\nQd1QrXg0fyL6ztDbhtRYFIbQRQhDs5RM06L8dwLDJ8PbeY8lMhYWFhYWFq4UJyQyekJW3WykmNhg\ncVFXlbKJqJUZVWtGct+hkfd6UOeRvl1BZ52Y+bf7ze40xuvRVq8ahcZYznnqKbSLk54h4l5vbCEw\nJISGCCZiQ88brqbi9UQxj1JbPXOTcT7t3O7bClE+H4M23LvXjXvhXvdikcETg5WOtnu2JmLMuXbi\n2/n6cyVbFYhdHGuPifUkxZH8Y1NH2pCv2zxl4Psmyo5YRPo5GmNGIp1JVkd02isEc9Knw0PVelE3\n5GPxGVaIyTPJ2tS5SSWB0X+zuxmhtukERnLXs6hLZCwsLCwsLFwlTkZk9GTQyEca4Yy79dAImPMS\nGycldwxto988Ci9ONGUQHXZfkfmnOQFhwu+OFwz5AUt4onJ8DwN/uWE2MtsOTkDbsQAF0pblMiGg\n7kJVBYnunHM77Fswop0aVae8xFFSmLlE1d27D7FiVJvUzaQ6iCXJnWapGMWDtbPH9Jf2wjVcbGR+\nLfmY3HDIupDTzj8WBhZPW3tGf5JsMXCtQ+3I58jl4D7ggnO4R6KD4vfP7126eKf+ZeduQWGQNhgm\nc2udHxMT8mnODH3fbo2yfgb6blvi2urU29ysd105elmyv5rYwsLCwsLCwu3AyYiMcL3wSyKUaJzT\nRqkBJqH9YP0wmk3k1EhjJSud6Ei8f4fUsThJ+UeoEieT4yi5hSjaCj9q+TCCbdYWVjPtKRpNF79j\nFoy2gs6GOoellVkELiZCVACbksCg89gILdqDRUUfxmTarnsrhghwONygFaQOtG/Gzsh8qrHchrMJ\nw0wrbUQ7lrvdERUtc37X4locFhn9ccfiMIWg7ivh/UtDCLU2tH1c6maDJi6yUOK5Grmw/buPqge/\n1p2oMjm3+tlrKtP11iBJbOwKjK1rx9y37C+LjhahLi5A4qJ+Mq5QJxlcImNhYWFhYeEqcTIiw4hH\nuu7EAsUGlMmOq4v4TxXQbUynET7jI8mS0cRF1QtGZOAvMkLIogA5V4MuSOfJTNJfq4ubepvpU07Q\n30Ej2ZaX5m3UkhRsavnNQkJ8x2Yra5BAU2w2usxEz9rGBR67BIHJdj6/0VylYqO9tu+FbbAn8/rs\nhePMipHGrSX/jlsycI7I6I/ZspF/QwAJCQl3uh5SbWS1K5jAoHPLl4wCo+sNUV4vP/UdFhZRTPRJ\nRDrwMoS4CEUzF1VuS2ztJclasbng2CLMBAhZMnJqrA866wUdzxMRy5KxsLCwsLBwtTgtkZEsGXkE\n1F0nNFHKPhUbQgW6zdh026r1oPn1yyAwKutyS4LbR5prS/sTAmO0UkwMF5PA8dre4uJCQQInq5XR\nlaf+KW1ndKC6S2lpYkLFCZ1bMbbOirGp7xwuXn9w4pfFBefZssJWC3YtCpFxOJTqLlXImlHqPhji\n1gyJavf32H8hI/1MWVBGjUqrT0FmwiEY/CqJDMv/vsjgcnVqJih4tgC0TiZtZ0W2gnFRk1hjEt+L\noiRVepkhY2hLz6wWvGxA/x31FqVUstAXo7gBmqiI42xeTBIYZMnYLG6XH93La2fJiC91//8NY+oL\nCwsLCwsLtxMnJDLyaGM/MRRORILoAkwsYiSUic2mm5Ob6i4VJE8bWayuUiw8xpHnEBpBnLVlPPvL\nB/2eWjbcaiFkPWkVIGbckO7pEDucH5g4apkqBYj9C6TVBSoZa/UYrlEhKlSirllkODXrrEhs1ej3\nbdi7rtaLbmfvQ5uT0Y/SD2yRxGNvzaC8xqPmQhZ03//uiowW5kJiLi76OMlVipUBtz2ioXsNGjG1\nkfgQBy4yTHgMz/E1qwPhbJiBzO+pt122bNjBH6ULE23TidUsCsnqBB4k2BMY2+aDCJzgMUmQXKUu\nYMUALhRlYWFhYWFh4RbihETGvruUWTGCy2TSG2cx8p5da7ZqyWjuSealZDtqOwlrrGtvpSgjpZYF\nCcWxUyiMbHDINwmSFt8sLnsrH8UIdxNKPJbbylXrS9zy4yLC3aSa4GjljWvNpHGo88zW9gQGj/aL\n2OpS4SZlLlOxk3cIAE3vIfGIrk2tT/QktVVM3TBRMmkmu4ALNa/jUUiw0PAjlcv7Tf+enoyz6xK9\nz8VFx/KlP0d3DuS0U168NC2S+gMKyz/1e3CrSqQH+pFoibrskL49Ow9xy2KDBcamm2dAZ+lyOYEk\nMNyaId3Kcn3WlspYWFhYWFi4UpyUyNiYCPBItTpTHgWGkSgefe/FxbY5oXF3HoW7JLllorlKOcFP\nLjEZsse0WC3MrmHWCsuDkriw4pj4CSeq3prR8UkY6VVLS0O8mNCYWjGaq5QJjOx6NIo5/2tCLblH\nscjIgsPnYIj4hO+Yl+HOTV42M9C0FvWKC8FEVo2+behPAdXrLRIZITBMSMS8CRMWWVyElSWLAL6m\nXejpmMNMkFDe+j7A50lUNPHawmo+o+5YTAiHkHWm34WcZVP/icYCAWRJJGuGC4xta999/xF0pRL4\nN+5luow1Y4mMhYWFhYWFK8VJiYy5uxT53ucnZomMBJRHUdsOxU5+3UXJ3GsAHLEgDG4i9N6jFg3O\nch9N8ytrUr3A4OdGN65EXKXFcIJOWeytFltcs0uVK5Mh82Nh5qJivLZVpPwo2YoRo/CdJcX1ResB\nXZ9A/+N2sAF8s0wlkYFJWLjSmXiIKELxWWDA8+7Em4f903tY7ERWUxuKDvG8MWeChCSBh4gM7zCL\nV7NvURhZD4TTCMHRn7P4MPniQp++PQDQDeN3uHWuUm1XdvFOy/Vle6Nwu5BlgqwZx7AsGQsLCwsL\nC1eL0xEZW+cu1bk8JfJChMHoXIxx1l+Ql/qrhGZD7EMRcyKEmFi1LEjbb4LQkRmeh8HaYWK4mIqL\n0CU6PKfaBAaTSiOq/QBzGv+vxwgOEm0CopI9pNWl2IqhW+RpRA6/qMAIa4Z0YVlgyPCG9k61Ng2x\nwXN2vNm7mmCmfjGRQe1qBJqOfD8dOY5E/fP8ikgiLAGYHLk3w/uHhNBIBeSyxjwM6e7a8rh2Qylb\nbCebpT+ekxCboLWUfyt5TgatJkWuUltbsSBWbAurnU85amVk60WNmgXGntvU+TJkYWFhYWFh4Vbi\ndEQG8mhjFhgTb4eBM3Skhn/b1iaAb0GANchtuFHRXIhNoCVkRggMc0vqJ3z32elH1TWzOo7CniJZ\nbbSXG1Ge+pLAXY3SCLp018iCopXB52WYAJH2nknRsqwC5mLCLBajyHCCTQQ9iaXWLipbal9zw8Eg\nMEygZdGZSKgT1mMiI0JnIoPDQ+yNIiQR/lRnnbBgIUL1YKVVK8XQBtQHuV2SlmHxA3ppzF0AtAmN\nEC8c3X8pf+QWBs6adWazlinq4gMtv+lbjNWkzGXKF2YAwHNoBjSBEQMCEze5HYHRoi8sLCwsLCxc\nIU5GZGBmydjIhQfqRwBE0EBEkdEIaOdmM0Py0jF+JzFHg9WBLV0bpDNriZwFJnaN6Eg9sWSHLPGw\nsqW7O0rf8m3kmQVKcGWPXEeY23Va7SjES0nmm+6dfpFH/sPtaSY4Imw+cm9vD3LtgmLmEsV9gKvM\nBUpbQayl1wvB5GpG9zxcQkgIVeJUcOxYNajih84xuLolaD5SWbW7561nu0i65YsE6vDuZCMYBEhW\nF+2C0/AicbqK8PerAsOsYgLpRAbcIplL3Xf4jL6e97Amfi8sLCwsLJwOTkZkbFpHNR02uk7LYFo4\nQCOsCEILxOhriqxMMpgU2chnvRYiZ6OlYvTbFyZjHmtEfneNNNokTBSRMNhaPovAqLOfbeRmVNfi\n9Ticl0StOB845kLCRDzi9+Ublp7dIYlcdhcDMGHR56+bc2HkdMiFxsg1WxH8drM4tfceExvpekdc\nhCgKq8wgSDrxxEI0akGToUoEoSWE22XWViQ+SmvdTcKvT60k6su8DhmgMirU+5Dl16ws1rWH8502\nZiuciwmgc28cxaF9v6m+2gu97rt2OCoXLjA/Y2FhYWFhYeH242RExmwJ223TGPnsBrCdcA+kqCdB\n9JDSiG275XtSzEaDeynghJrJGJ3zG8/372okc48SmeuIQDZAiuWF8yWe8kiy4yjCtgD1416+clkt\nwUyg0d2bPc85UwqyOQLK1czlZoHhTwdhzvOAM4WvvSKyJSp9E07znMIn4sF7Vj+q3scFxcVenSF5\nz2VBMbNcjEJDNkALvB7TUYzwz8tp9WPWJauiZIFCnEdfk7Espi40JminlZ+sJKqpnS2f1aDCAi3e\nKZ5HFhldh9FcW2jiagmNhYWFhYWF68XpiIxNfQKoh5GbRSJYQGykZ0fQKL5kfhW0mqwVxlYBZ2Xu\nC9/t6J3IdhrhlXTOb3RyveumoTlmGskGlabFGKwaSmXe+3W+T16FRyiYpAMXu4/CFUGvpciugzKV\ndpEwCIzWShq7tcc8jC6bM23T1NQguMYS2cvGaLviop13x/raTnC0vIQoiRWd0PqyCT/Lr1lcppaL\nJAtbeBG3YlRSLV6vvv9LUtRxKn0AUNPpXN24/7Mn2LxG7eUxL8KEz/6ECKtH+x7jW4b0IiNb7qy+\n1Nz+NGpoYWFhYWFh4fpxOiKjmzNhczFiVBvjSCiC/KRfSrj+wt2qupI4sbHh30bc95awDeqeR3nZ\n3cMf8aQ13GFyaburIGU5jr2VrRrNjavUJ+qKPAJFgQxPbRAprqncmjElfjG0flRgENO8uKtU/yZr\ni/mdaHcm37MHMoGWFHRcVHiUQWgIpWUhxwVHPNYLjDELLiKaoIgsHBEU7TwJjw2Q0tKhczfMpZWa\ncj6zKDQin0UG/HsydUGCw6+oY3nfV39PcpsaysOfCwkI+56mIqP/uOOd9tkumbGwsLCwsHAaOBmR\nwUtZAmhECeHTzaOjLco44XbKQPyJ8N9vYgLMylrqsz0yZOfHeaC/7WWNaHVM1vM0nmex0YmLxOSk\nrn4lChGzVmztfgE9jhAPWe0MZKwXGEk3EfHu7gcZ7BPkUslgQQmSmss+rB7lz/VqoK9xoTxIF82I\n8ETcdCJwLi5YXHXvSeIin8fVTh9Io++9yAhRPAoN1GZW68e1fGKfiXVjU+GWrkjXhiw2eO4DvNdZ\n7of+7afaN230JYn2ZHcpylGqs+SiRaJnT2TU+S22FDVZIj3CzvnCwsLCwsLCbcdkLaHrgW7wvTJi\nsveWRrWNQIiToCBDPkDbEylLP0waA3EzluRjxZ2wMeT3da4lHcu2QdxxSd0tl292vsVOyLHXRz2v\ny3+2pT9tD5AuTtrAkMrSGzBita7OkuI8WZyIJl4tdI8emOm8UdYEiWZBYcuaeh2kePMRahMEs6V0\nSxFIKShSUOhapNRj6eImVyEMaQJxj89NiPi51RFm/VCpY4yCKrXdpr6XhE76gfUXtHlL/X4yLkio\nwXuBUb+ZVgdcfiL0vWWjNxVOqfvOAEHferws7mhFkWneipSUx8hO10/fhUSFiDxJRF57gXibiHz6\n3XzXT4nIU+n6FSLy5Zd4/kki8rq7k4eFhYWFhTsDJ2PJGJewhRNjI2asDcJVRUdx4WQjCwn10Wzx\nsBj2bc83a0dPjnkkN1yz4p0jpckhqn3Y7DyklEAqgRQBis8m8b8WS7FBwNaM4kcBms96fo2OQYEk\nMCiIw9u1j/qP6sTzNy2f5us0os+Tvpk4z7LpI+9BmDEcIw+56XesC4g0+T2crtfEpNyDtJj4y1nf\nRl9mErxhtcgWjTTvoHhUt1zUaBJhQ1tQvk00uZBCclXyY9TKaNHQfGKXVrs+QODuirl66udHQo3y\nM5uAntqAPmFr33cdaZHwvQD+s12IyFMAfIaqfvgVvPuvA3jzJZ95F22mhYWFhXctnIzI2NAtYQsE\naWrnBqfYPKrcWMpAgqBE8BXuJuUsuZ27L7lE3An8nTQCa3TfSU9/jhA4WfzwOZEwypdC23K1c8Hh\npFYFKgXiQmNScQBxvXGcnUo5ERhC5zSCT4/QYYJMNvNEZ2ojExw0RycEZ+4ELjDMckBEmVcosvqp\nzayuK7Mnm1W8pDJbev7aXaGRS8/x+BVsXYgys9Uh+t5umPVjLXHLxUYWNbXbUXv6N2N1aKIiIjjR\nn5aRMPRV+wvzFoRdZAkCbwOA9zbhXj1aC7No7PKRe8e7FAuz//kAACAASURBVFT17QDe3gdf0bv/\n/Cres7CwsLBw5+GE3KV0/LErSSJcQULClSJ4YYzZeurhuuQ0zdx1aLS1ExfapSNM1Dph049gOyW0\n9Du3oHB72neL2QYXqA2budHQMVyrRteb5D6TtM1ESCUiymFzgWH3pa/4dqlDXUbdG7Hu3cm2zkVO\nJ/mU7t3h3iODG1QpBYXco0pp7jaDixS5Qx11m0KO65Vk8Xoh0tWnV7+1yd5vG7+BbaO279yrmqUv\nu6GNTZzbVKis3c/vRdvOJHyS0uYG1pXN43UDBZZiar/dX3N169pKuP8dFc6nC6l4soj8roi8RUR+\nVUQ+q917dHNzepyI/JqIvFVEXiAiH0LPuwuSiDwJwFMAPKw9dyYiX0ivex8R+UERebOI/JaI/K0u\nLx8qIs8RkTeKyKtF5LtF5L2P5D25S4nIV4jIi0XkTSLyShH5ThG5zy2qqoWFhYWFOwgnJTK2bet+\nRJITWdLEJxovdMK58wY6ktWgnc+eSpyZCSZZMYTuZZ4dI/VOlHX+C1LYi40jR2yof7cglum8+y9Z\nDZKNBV3lzmtvEB478SYhLuHSyD2mQsPdpGjEf5ZudqdBCI4dAVGk7AoLkIgI8dCf7wmNILsXIrpU\nEF6il93DfM8Yro8t6sd/w/fRfyvRtpyz+F6OkXrr12EpYqExloutLxjaMzRGVEAS656vueAZ7+VS\n+SDDnYmvBfAFAP4+gIcA+GYA/0FEHkVxvgnAV6C6J/0pgGeLyIHuW8X+XwD+FYDfAPB+AN6/hRn+\nKap71UMBPAfAM0TkvQBARN4TwE8A+BUAHwHgsQDeF8D3XaIsZwD+MYAPAfCFAP4mgG+8xPMLCwsL\nC/cQnIy7FIAJQz3fBUIsnnPS7F7C8XqiUqbnNc7hcPBRcBv99lFwHtU17xRBW+mmsimR5uqkNZKt\nbBU+Jt01TRiI0fQ8kg6+JtLnZTsisYLieY0R8Yu9DaIOxa9FOG4eqXeCLQLz6KrP8Ug/5aHTiwLU\n3am9Hvqmo/pKR27YnpCG8MgvijybO0/sQH68pymVbXad83oOSNyiO438WsdywwMpPe1EVvSJsT+X\niYWgCi6UJsjapPh4d/3j5SNrhmUtrBtcDB2/gSRoJ9UwBFIdShdX2w4xZqXpEovaOl80nwpE5N0A\nPBnAY1T1F1rw7zWB8Q8A/LsW9vWq+pPtmScB+EMATwDw/Zyeqr5NRN4E4J2q+qeTVz5dVb+vpfO1\nqILgowD8GIB/BOBFqvp1lL8vAfBKEXmgqv72eeVR1W+jy98Xka8D8K9b2gsLCwsL70I4GZGRXSuO\nIxMbfnaeBg96GhEzEmYrC/FIdxFJAoOFhoi5dTDZCnLFoqIKDUB6gcEzkGfhPCrvw84TwYF87WVM\n5I8EQ63oGPSGtGOQNhsIT1PfQ13UA9WxUF5h5F0EsZN531p03oizeD3EE5pOusYkIdSPdsfgNokN\nkKhIiVyWkLKI0B0htfNYupy882g2jHTH+/fEhfftLqxaeEoICxMbdD8qELnZOpGBdJmVgLZvgcvZ\ntfoFYJ0xeqHXuvSVqZdrwtPDAwG8B4DniaTedC8Av9rOFcAL7Yaqvk5EXg7gwTfxvpdQOm8RkTei\nWisA4GEAPr6FMRTABwE4V2SIyCcA+BoAHwzgfqj/xry7iPwFVX3rRTP5FQDeswt7YvstLCwsLNw9\nPPOZz8Qzn/nMFPb617/+lr/nDhEZIz3sn00Cg/3A20OJlCWBUarvfhMZSWA0YiY84ktCw8m/IjYD\nayPQNoorUsm8MKmdWjSoqPAB+tGCcc51SucIAWbB0QuM3tpAFd1yzCJjYnHpyHgaFe8tTExsLw3J\n5e7FBsVLQk674FnKF8zSaNG4jDWje2c6I1PLkOEj4qK3WEhYKnpLBlsxpEgIu3mm5pXSBzXR2tft\nUNwhqTFtRV6eoAp2gXfaXXe6y4rHa8V92/FxAF7V3Xs7qgjZw80U8r9M0jAz1n0BPBvAV2FskD8+\nL2ER+QAAPwzgO1FdwF4L4FEAvgtVNF1YZHwzqr/WwsLCwsKtxxOf+EQ88Yl52OZFL3oRHv7wh9/S\n99whIiNT1pHBzARGfi74GZPiEpODm6CoAqOKDnaTsv0Wsq94l/hMYGgd1dd+J/FeVyTrBlL6FxEY\noLhD2anmkqhAJyzovH+uT8VyOxMZZsmQUstQJN45HSxPg+Qk3Oi9IrlpG9V2keL11dRZvCfG26f7\nInJlKV9cBM3mMwiNedRhXP9cilgrgkoQatbLvHOU7DI1CIxOhKCUsb/Ivjg4L+vxLY8Ceuhjk3bp\npZp/HUKLAtBvzOL5LnAngpeiiokPUNXn9zdF5IGoRfpoNNcoEfmvATwIwMt20nwHgMPOvWN4EYDP\nBPD7qv1SfxfCwwEUVf0nFiAin3cT6SwsLCws3ANwQiIDOyJDJnSB3UaQJ8RiJHM2qJ+IcBvFdQFx\nCGGR5mGY+CBREoRWnLwaKTYyzAIDtIRoPdKo+sS6YUYSF0RGpiXuJYEhUb6WLa6+eF/WZTQRO66D\nAPa1GKzfWiPVaakEt4T88H0+1DYhFxqNTtaHC5D0BJcYJDL42M4nT5LWTC5Ud3fsOwuNTJGVI82K\nkk9SXjnXQn1GvN5qmXsBPFo1OoHhFjp2A+ScsLTZ+/rGO30R3arhCSdF2Sc4Re0znWjpVcZEbchO\nLk8JqvomEfk/AHyz1Incz0f1FHokgNcDeGWL+k+lbrj3GgD/AnXy9/+zk+zvAfhAEXkY6tyNN6rq\nOy6Qne8E8CUAvldEvgnVEvFXAHwugP9Rz/dn/W0AN6SuNvXDAD4GdV7JwsLCwsK7IE5ndal+dZ1+\ntaFj97r/EtsgBlupb5AwJ2ImNg4F5XCISd+H9iv9LtGRZoyai9MyJryVGJK4ARFz7IQnQdGl54RQ\nKJ0QGFnMTCsazMpCn+WVnnwHbq3LptZlcvvVvyLcllfdNu12IM+rZrVMeB69KqekuIkX4brJ99HV\nj1PLvh7OFTGXUjlcoblq704SXbe1M/G/0X+jv2TrxSAwmkC2Xc/reYljYffAukxs6dOgHwvdXshF\n+Xn5WlavmFz35SWNS995BCn14RH9lA2vs5tu39uPNtH6n6HOZXgpgB9BdZ96hUVp974VwC8BeB8A\nf0tV37mT5A8A+FEAP4UqSsyaMKs00sD6x6jipgB4LoAXA3gqgNfp8PFOn38xgP8Z1d3qJahTKL5m\nv+QLCwsLC/dknIwlw4gJY2bDsPA0PnmBUU2zFPSkKU/uPuDQxMVA2NATLhq5NkuGmGUlLBja3F2y\nu5QizV0YLBphrThu0WikzwiUDRJPB4vJxcREhSa5AeZvFjtZO8y6QaseSQFka/koUvcZ3wRbMQVL\nE6Q1lzESCdLM4eft4JzFnQk6P6NjZ9dKO/GNL9qzqvhKW0cIa1g0+niaDt1TSWgYga/WCzp3sTxb\nXaoTHhOxwS6CYdUIi4a3cFtta27lqSGaZ9KTwog+E59zrWPbfA9WP2zR6qoJoma7iXptlWN9GHuC\n43QNF7tQ1e8A8B19uIg8up0+X1UfuvPsvwfw7+n6HQA+ZxJvcKFS1b/YXf8OgM8+ks+P767/cnf9\nrahiiPGMvbwuLCwsLNxzcToiY8oVZgJjMpRGFo1eaUgjS2xlYIExCI1DweFwIAJnz2Ui19h+UEFb\nYQoxFwNiS24SOd11keLwuaCYX0e95BMAU0Ks+VyDq7nwsJFjn1DfWqMLB4ACGuFuVptSqtDQUjOY\nPV2kPQdvl0yOLf3zR56jzDxOHZaMVCcaknXWhyapXgI5v/PJ4HuX5+ckrAZN3CWBsScsyiQ8C4u6\n2EHEM1JvO3DbMsdDadu8I6j6QgdcdusztqStCxPABZ7XD1edn7cT12WxgAIr4zTIcCcqi4vjdM0w\nCwsLCwsLOzgZkXGRJWwTOaR/dtktI6181D3sI9+DJaMeD4eCQzmk5WpZnLhIsVAi+MaLBTHpG935\nvuWiFxzI72OBgf46BA+6fLXaGWovWy5YaLDI6M/HMEu3iGArgrIJtBRsWkWEHWeTvqNRRgvRcbS6\nUh7njrqJlHcSok7UtMeFrBj+9kFAHIt3pD+fw4m937XISSTbHesb9t9EbLi4MEtTEhp5BTXrF7xv\nCGsIti2EEKSCuAglocrtJU04iFm3SGH0YqNVQuSHb4fKyELjHot7dukWFhYWFu6RuGNExmz0mcaO\nSWhgiGnEzIhKXUxH6De3ZMQ7evI+UliR2HjMnvUR33ZuQkJYaGRmHO8Ry/dxiwaXMRLJudP0l0eC\nbQlbExpKYiPEhc9/2REZLnZKAbYNBc2K0USHk1SzKAg9ym0kktoq1YvVX9cJJi0xlRczQZHuTZ7Z\nA7crhWKo9/MSHSLomPdO1JrLkPcN7AmLJihYXAxCQ3xFtSoyKvn3zfQwWXIhlT1YfpB9V6xJ3kJi\n75hkTuKjPS+0v4x3EgV9QsmNj6qPqu2OWV3qKFT1Z3BzK0UtLCwsLCxcK05IZOCoyND+igdQtzrR\neNu0I8gRx0VDGjUv46+RrvbUhMLOrnTkOjSqa/dthRxNBMuG1W0jP3PpYbHQs3Jy25qIivRMPzps\nYf11F6fzgqFnlH7ijwklUJ3UIqySQ35JHpmeFTMR0A59XY+SaqyPlPUuLKU3cdWqxD5nduyrR6SK\nWdhYsOkW103MuTsXcWsn6tYe0vqR9mVs1oFGwOuz6vtKeLp2Puszmo8uKlsZ7F6/QMDewgwmrG0z\nSkGbo0SuVsmjrxVLLA9m5DBxwVaVXZe+fH8o28LCwsLCwsKV4GRExhRK9J3IOlsrnOzQakfZKtKc\nSxpLqT7o9utddXh+gT0bmFF5Np7EUedHcp+JvYydEcIm20akYFqS/2RzB5VzNI1IJqtGZYW5XWVv\nMRl9JKK9KDAia65d5rbjLl1cYdOKg9eJxIz5NuJdb/bEEZrDXMSQ8GohSCHcdyw9ducZBO4gaYnU\n77FVVi/ShYaoyEJD0z2vY/Gq8C6QpY9gU0VJacmYtopfcxyoQjf1Otct6kJZREyvzfq1QbfzhUZY\n3CSEpn1naH3OrDX+7WnEsfkhfE4fmwkg/v8C/e9hYWFhYWFh4ZpwMiIjjyZHaBqxdMJO5IJ+LDCU\nmEYdOBWUMu4nMPwQRxrSvVj+G/dJ5JjIWiXySIKDLQBh2Wjs0ldlAokJ+KhwWAdm4qIDCYgwSjSi\nl+4zQZ647ySqCyeDSfPsiQpKec/+EO3dckAVO4iPlgvpryn/pOCi3xA5ZSE7t05wDo+ezuNauk78\nt7gGh1fBUbl0doVTsN6MvuHWv4mo6MUHNm1uUNKdw8+15XUUFHxNwoIsh1tasrjej75slqx+LhGH\nh7DQdq3Te5rrldta01VupyU6FhYWFhYWrhQnIzJYUHiIkyUaTSUSFYR0ayKjH0m1lGIy9VGB0QkN\nJyo7XLPluhI5ECEzbTIInqBI1SVEaRVP9b+CGN1P8d0yQWx+MBnMzAfS5dtGiy1eEHQXHZwG8XSh\nhNiSAdARlLVUU00AdKPz2srrBg0n/e05V25syVAvh4sLAbgsfb3aSRYpJmA01VH3VH9j767XUyp3\nT/wtEyw4NASxNNc5nqMSNasp3U1lYtFo5WExwWKGxIh0VhD+zhSKrfv2+JxFfeypkq0bvaWCrRP1\nurWjxUvXYcUQAa16NTaETltDd84XFhYWFhYWbjdOSGRkOB/SEBHT32bkM0honphs5FcuLjLMbcP3\ntqCRUIkLJubGUV1KdGKnuo7oxP1F6Rw+ZG1FGOJngwZMWEReZkd+IBXEz4XO53mT4bEqMog8ElmM\nd2JAiBUuWCO/Lmg6oQEKb/1ChAWFCZAQF9pct0ykcKt5mPeXjqhqOhwPd2ERoUkvsxWD+kY+btlq\nNVNjXKmdsNgUKI3cF1XoVvvuICw2ha3uFCIkhJaqYtsRFdrq360WW5yHwN/CygETDNRP2ILh15qu\nzYphQj9fHxcLu/eXxlhYWFhYWLhSXEpkiMiTATwBwAcDeCuAnwfw1ar6WxTnpwF8LD2mAP6Nqn7p\n0cS1I2YtsBcUQXCy8PAnMrtzV6lsySjdcQwzxqeN5NV0jF3HvAEupJehHTcXSW1UlyiQ80nkdLzc\nTUAM/DKNCIflwqn1MCG4e2EX2Fs08gM5T/29qFPPVqTbiw1PQ9K1783Ql5bJv4sEpXD1svrWcULn\nQB2l5xo2q1ISie11ZMnwcGrjHJave3ES95Tea3kOUdFbN5pXEMySxfUrEJT0nn3XqLD4tbkbLCzS\nMyQ8EJvczQVGFh9b+wZ9PoafdwswdHMywmIhKUyT1YKEx8TKYZChfx3BEhkLCwsLCwtXistaMh4F\n4NsB/HJ79hsA/JiIPFhV39riKIB/C+DrEIzgLZfOWWex2LYtRIYRmjbR2zAuKxrCwu6PAqNMwwCA\nN+k2148sLtqyn1Rw4PhEWMuimnABOpLd0q28EIqI05sIbIq1cphYPsiakQiWuahYnhvxNJcWDw+3\nqW5Hiih/ZxkyoXGc/PVyQgFyDZOpaCRLhpN1z32zWDTSbKkLnSdhoI1Mk2BhS8ZUaJDU4GvN4YO4\ngAmkfQtGugerz7rMco8NdfNDeFqSysDCwSwaSYxs1uns3Cwe8Oc3tfoJsbF1giMLDBMV9drPN+vv\nNA+js1aA+04XhmaFSlYMa2eAhH679D8phPrRWJ8LCwsLCwsLtw+XEhmq+ji+FpEvAvAaAA8H8Hy6\n9RZV/dPLZcXoNF3ZCLb7ebfVo2glqU2DDGcxAQA00n9BN6kgPTlnfmI+7t3QqBFXIzMDSdvU3Xum\nHJyTlErxFbEEaRBzMhtYeY16KTyGztJ2PtkCBP585egsT7LFwWJ6/qPSk5VoXrgJqCK8nKSHstCA\nj/bbtYs+sMUihyUB5qIiiuPp2fuo7UDvSrXAVhANYTLkWyn9JAKOT/wurTK3ok1GahMWFS400vOS\n0knXm/qu3P6ezdzSWOxEf81zMjpxQcIiXKXi2Fs42HLB8zLYWpHD4cvcamfFsDBItO9MWNT+2auK\npTIWFhYWFhauEnd3TsZ7of7r/dou/PNF5O8AeDWAHwbwv5GlYwoaULYQgEdPN83iwn5nZzsCwYTG\nTQgMCbJixLK6cpDAkNh8j0e1g7NVwZFW4TEbgw0o0zvqiHzjRrZyEPLP+RSV0YMgaesE2yWZIrBW\nqE80C0aknYXFEG6mld5lJYkyCW3XBVtdSfobb6tWI1rcl6waXsccpi4t4JOEva0Gewn9jcpVquhk\nyWAh0oUBLCbJysKiwuOP1ot6fxvCBcBWar5lk2rNkBpmO7dEXfTuUqPFIt3fhOZfzMJkEBm7AmMQ\nFmFlzJaMLYkKnr/D1oshvFkxXISYFcPa1ISkf49wC039rkaluyTGwsLCwsLC1eKmRYZUlvAtAJ6v\nqi+lW88A8PsAXgXgrwH4JgAPAvDZl0nfybpqcstgcbFtG87O6oTZUsLdKTbTy9aNUi4mMOwZ1eDP\nRiQFMTLsI+WJaBoRzkdb0tNIeRINqWItHSJQnoFGzNpfz6c9qkSwJoYIEzJwkSPtvAmKlin1t0QC\nOSwom7hbC1k0KKf7rlON2NJgtNWl16eF08g/C5BaniYztFl+JCxATbO4kLC2sBKFJcMVRbZWkJDg\naxMZue07N6whbNx8r7duiKCJCwEKsJkVYzOhUcsaVogjFoy966029BAG7rPHBYYmUcHWiy0GA3QU\nGXBXqV5wIFkwQHGUrRhu9SAhOfQvk53djaUyFhYWFhYWrhR3x5LxNAAPAfBIDlTV76LL3xCRVwP4\ncRH5QFV9xV5iPELN19qRGiWhcbZt2LazRkwKpChKe5Zdnnhyd2k7egv/pqOslg8/c1ccExh5fJwE\nRjtuduzLRmOte2JDfd+CkR+Zy4iXz8ROC7ZXeQ6T2cQmw5OAUklRImc9XVN6idUtiYkwHXVWjDFl\nl0cKXwUqvdnansJUKdwKoGFlypaMuK7P577VWzKyhYTiIZ/zvcinicImXpridFGjE9coI+FJcACl\nNB2wVdcpt2JsYdHYNqBIte4VicndmyjKhnpUs2igxeN5GqA5GeoWqsFdqguzflxdpZqFjiwXMU8q\nXKlgwpMEAQsHuJWCRQW8rm2ehodb30sfUAgLF5rUdn1bLiwsLCwsLNx+3JTIEJHvAPA4AI9S1T8+\nJ/ovoFKCBwLYFRn/+j9/G+5z7/tEgAIf+9CPx8c+5OMSaQn/dc4QgsyYtaIIComKUgrK4ZCvS6mb\n83Viw8UEOpcb7dmNVwjliRg4CQR1UwHFoCR6sWFkTkShjThC1SdGb1sjYDa6bSkbEUuOTkLCQkgj\nNRLY8mmeMzmuWTkagRdNAsXSllYPpjWEhNAwqtxDdS407J5mIh51SoJCbe0uKxCz0U5IHDtvb/fm\n1KjdEBh8r8tzH4dvpvamNJVy6okINiikbZZXRFqxav/c0IQEFILSmlKhKFVoe/0Ud7Wy+q0LG2gj\n8G31KTTXPqsPjELDrEEh0KwwVsejCpBJ60fPFIohQ2yOF3GoP8XGKu2y9oNnPfeH8OznPSu98w1v\nfAMWFhYWFhYWrg6XFhlNYDwewKNV9ZUXeOTDUWnAUTHy9x77pXjgX3pQCtu2s+b7TcvVNnrmlN5c\nMNzFwsSDCYuCUg44TIVGFRjuRlVi+VqbN2qkM1g1iwm7pDDRgWBafgdxMdErCqAgiPXWyJ20keMQ\nG5UUejJCRI9cxNKLiP85YbVHVH1OCAuMGteIfHcPUS2ma4TeRVrnfKgGNXXrw0jik0VgIiikLdVq\nS9maKHKB4udkcQjKn9ouWzLOyz8d3OqhfMvbvg+3C3ODytVirkIarmgisAVtaynV5UX0tRZC3dTm\neFiTFAG2pgqFxERvwbAisSAKMcUCIzp23tEiC4nxOncTvye9uOCYXcei+n/8J30GHv9Jn5Fuv+Q3\nX4JP+6JPxsLCwsLCwsLV4LL7ZDwNwBMBfDqAN4vI+7Vbr1fVt4nIXwbwtwE8B8CfA3gYgKcC+BlV\n/fVjaZt/t0HN9cL9vPOIdiJjArdAFAnBUIVEExgsNprQsDgiJSwgbskIRyEmjoMy8IFyJllw6gcK\noUFqSkLRPdpc5MNqoSYoLGzTSg635vokNok7xoFdYLgfO7274+dZcJBVQDuBYYIDOizek8QGsiVj\nBq6GPtzr260XMZKOCB4ExWDB8InqJFCSSCWxMVgzIkOpFZP4tPuabmYS3srg7+4T6NLy/hT7Ztj8\nExZuLkQPvqgtWTMURUNwuMBoMevk6forolCpa1Ylt6jcBJE/zUcuQNVI4m8xOcHCohcNc2vFaNGQ\nnXCvztbc0RoXVbcLCwsLCwsLtwOXtWT8Q9R/1n+6C/9iAN8N4B0APgHA/wTgPgD+AMD/DeBfnJfw\ndrbh7Owsh22x8d6WrBkZYqOeLjDqJO9wkyo4lIMLjXCVauKi8F4Z4paBoCtMWJh1kovORCy02ESc\njTS2J9Pgr5r3Uk1XabI4rfyzufjII+0mMJi854nsdj/mZMyFh604FBaLJDBIcDi57Pic7Jz32BMa\nQ715WP6vFxQugEDiyYQiu1sl8YJ8jnjpMbHRZSwJBctrSqcrjHbPRTcIMcrEGVZXZJkwyWLCwl2n\n2n1a/qCFbGYgqH+ExIalQKIuXYMFftdIrrRZPbPcFHBLZ4kxs1bEkzERo3O8UuSOp5EVrrO43/9f\nY2FhYWFhYeF24rL7ZJRz7v8hgI+7mYxMLRn+M7ERQ6vE8504pbkYUpI1oxwKDodDmvztblVkAbEZ\nqnVU1nNDOeUReiK6wvyLGPggOjqmSaPtdlcsmF2k2hyMet1mAYuOziTOybLw8nxrxKuuOE30dMLD\nBYaLIhYcZjnZJ27Sl3MHg2D0IXT4b3TjQYz2S1hdIpFeRSEJjDy/oBMbk8yN2TfhkuMa8efntK+G\nXljsiZV2oTm2HxWKDQVFkdykSq46aLN01WM9L6IQ2ehe280bvbiIMvTncAFndZcUc+xj0dkqZsIC\nQ6zO+kFaYhAa8fCkDil4aYyFhYWFhYUrxd3dJ+OWYWbJSH7hZMUYiKmTkbBkCFsy3EXqEPMwpF9l\nqnOX0rxCFey9PVsxPkSqJ5xjiJhRIsGBg0jGm2rMbbP5BDOXKSLLVgNpBScibyye+N31ZgvTEBoA\nTfI2AcLX4vM3ZpsSpiFlLzAyERzQEXOAxuaZ+LNg0FTvPgHcxBB4pSEksTKeI0bpTUAczWoQ/imh\nzX+OCwvMhIjLFTpXimhWCxIFVHeFzrXVjkMqad96S4ZQWprzMbNeaH6BJU6RauPMrRYc+3yLRi88\nxgrMJ3ORsVTGwsLCwsLCVeJ0REZnyQCYSLO/fIRVEiM+cj8uVSvkLtXmZTQXKZuLEXtnhNAI1yNi\nvkaPZEYUjxAgL0z70wkMJ+HdsHh1jYIPHbOw8PBNUUoli9pW2mGZ0S/L2y+4FDpBSGDodAK4CwwT\nJNqe9QK1svjGF+Z+lJTArFLomZ16cyEAItXsHtVtlBjmGCfIyQIyFRuW3779LiI6Wl9x0h0uTyEQ\nOjHBXavVAfftNJeDXJbM2lIwigkWZYXrM2aMA2db6xe2h8UGLVLnPLloAeUDfu3dsa8fsjzVfpNe\nPrFazEVH1PZo0Qi3P1BaJCqGBjqi5BYWFhYWFhZuO05HZEwsGQCPQAbBSkPDYqP1MWpvG/NlgXFo\n7lISczFMcPh8jJiXYToAMDIdrJC8jo6wz54AUuBEYFi5nCZ37j2bAmh7GtiypkGQbRTfKDeQ3aUK\nTQSnORWWlSQ6hIRGTPJOAsMEh5HnTltpC5RWgUf5nWmCoeJ4lL5z4XHC3h5uhUgrSjWXHXfp8Zzp\ncMWuVK4kU2b6sK7ZB8HgtUBlj0h9UDyiIVqo7c1lcFonLATSr71fAJxZY7c+cRYCYxOBbNVdKvJM\nwiiVgwrqgm2sm/FqPgk8YrBI792lcnrWyp42///B9gH+CwAAIABJREFU63fscEtjLCwsLCwsXC1O\nR2RMLBnMwuajzAHpCHUsT2urSh3yZO9OVPRWDECCiLdXO5+ibMhOnmahg9CIgsFYvq0ktDXxAFXI\nptV3vrdktF/RaskwARB5QyqbT4QWxATj4Oj1mXaeJ3mLi57eouHPeylM5jTrym6bjeqiJ7YpqnYX\nqr7b97iiVGfRAJK1QlnEKL17UEy92CCLi2LMY6SSb3pcTffU70l61oWFbXCnvIzzFlYF/skkzDJr\n7nJnsQM3NrNoaNv4z6woVP/+HhI/SF3v2CeJLBKOi4teZ0o6612pJvNwqI5nQmMmPBYWFhYWFo7i\n3vcG7rrrunNxx+J0REZnyXjBbz0fj3jQx4wrF03canguha8WleZjFJr4LYMgGXb7buTV+STxy/Fc\nhkz1dMa42M++5CfwsQ/9eCKa2sWIsNlcDGN4oqjuLTxno6+krkxiLjMacaIMmss2LFuLzrJR8/Wc\nn/tPeNwjP62lx0XQtrmekfhJow31Vd2fxorbsWS095D9Ii2/6zLDBrudGJvY0E5sKJ77Sz+Kx/51\n20vBzDtjnjxIc8txI5hYYGGhFGlXelmbtyWbeZ+YtGcMEPUSVZWun/fLz8NjP/qTgbNof9lMZFSh\nKEWh21ZFrPe9IOVT4deLi6pyhkLFRpajSBjFhc+sSs/w9bOf9yw8/hOfQHXdWrrzPZvOv1ga487C\n93wP8OAHX3cuTgrP/NEfxRM/ee31MsOqmzlWvcxxqXq56y7gAQ+4vRm6B+NkREaPFzaRYXzBiF0/\nWt9D+l9HtJOQoIj8TKRkuABDaZmaCQzDz77kJ/Coh378fhrElYxEez7sPI0oM6sd8zirJq5HuzYf\ner8HtmAgyLsJD1T3tOf83H/Cpz7y08LSwS+h/Bxrr13MiO3R6JRHorfZUjEmxek/95efSyLDwscO\nd9z9S/cvJ+fah0+eHV2n+Ef3PKl69rxf/nF80t94rN8PoRUvznMwJhJIj1T9uZ/FRRr+4p3jh3+c\nRMaF87BwR+LBDwY+4iOuOxcnhWd+/dfjiV/7tdedjZPEqps5Vr3Mserl6nB0Sdo7AzfDYG9fMgvn\n4JLa7TzcMjeY1f4LCwsLCwsLC7cM9wCRsbCwsLCwsLCwsLBwSlgiY2FhYWFhYWFhYWHhluIU5mTc\nGwBe9do/SoFvfftb8Huv+V2/Tqsmda4th7Y87eFwA4cbB9xI1zdw40a9rntj8CpSbTJsO4/dsWki\nrbaJsYgJuTYZuU7OjZWx9GzDmW5tVaAN21Yn624t7M1vexN+51W/1XI9mz3bjoI2aR2+YWApoMns\n0pbeFd/7gzce5HilHOpk+GElp70Lmhzd7uVJwD7rGm98yxvx0t/9jbhrvv9UgezO5AuZ+rx0awOe\nENze0+rQJyFveZK7vUf6WTQSYXwv74th+fVGhqriTW97I37zD17GqXXn42pYnhdOH3Yc68MmOfjU\nba9P0CpSmEz41nS/HGj1tENbivlQ2/pQCuRQ8Ka3vgkvf+XLUUpd9MAWQCjlgHKj4HCofeXQnssl\nszzFPI2Yv0IT8fu6tf8sss13opXbYnEFO6e5U/EAfY+1z7zhTW/Ar7/8xdGeVqVWl5bPyaSZ3/n9\n37bTew83F04J9waAl73sZefFe5fD61//erzoRS+67mycJFbdzLHqZY5VL3PQ/3dv2b+Tct074YrI\n3wbwjGvNxMLCwrsKPl9V/+N1Z2JhjvXvwcLCwsK145b9O3kKIuO9ATwWwO8BeNu1ZmZhYeGeinsD\n+O8APFdV//ya87Kwg/XvwcLCwsK14Zb/O3ntImNhYWFhYWFhYWFh4Z6FNfF7YWFhYWFhYWFhYeGW\nYomMhYWFhYWFhYWFhYVbiiUyFhYWFhYWFhYWFhZuKZbIWFhYWFhYWFhYWFi4pThJkSEiXyYirxCR\nt4rIC0XkI687TzcDEXmKiGzd76XXna/LQEQeJSLPFpE/avn/9EmcfyYirxKRt4jI80TkgdeR14vg\nvPKIyNMnbfac68rvMYjIk0XkF0XkDSLyJyLyQyLyoC7Ou4vId4rIn4nIG0Xk+0Xkfa8rz+fhgmX6\n6a59zkTkadeV54XL4bL/fxeR/0FEXtbi/5qIfMpV5fUqcZl6EZGHtG/5Fe0b+PKrzOtV45J18yUi\n8rMi8tr2e96dyiHOwyXr5Qki8ksi8joReZOI/KqIfMFV5veqcLMcUkQ+r31PP3i783hduGSfeRL9\nG2v/3r7lMu87OZEhIp8L4F8BeAqADwfwawCeKyJ3XWvGbh6/DuD9ANy//T7merNzadwHwP8H4Msw\nbNsHiMhXA/hHAP4BgI8C8GbU9nq3q8zkJXC0PA0/gtxmT7yarF0ajwLw7QD+BoBPAHAvAD8mIn+B\n4nwLgE8F8FkAPhbAXwLwA1ecz8vgImVSAP8W0UbvD+CrrjifCzeBy/7/XUQeAeA/Avh3AD4MwLMA\nPEtEHnI1Ob4a3MS/e+8B4HcAfDWAP76STF4TbqJuHo3aZz4OwEcD+APU/4e8/+3P7dXhJurlzwH8\nc9Q6eSiApwN4uoh84hVk98pwsxxSRD4AwL8E8LO3PZPXhJusm9cjuND9AXzApV7quyifyA/ACwF8\nK10LgD8E8FXXnbebKMtTALzouvNxC8uzAfj0LuxVAL6Cru8H4K0APue683uT5Xk6gB+87rzdZHnu\namX6GGqLtwN4AsX5qy3OR113fm+mTC3spwA89brztn431Z6X+v87gO8F8Owu7AUAnnbdZbnOeume\nfQWAL7/uMpxi3bT4pRGlL7juspxSvbRnfgXA/3rdZbnueml95P8F8MV3Mge41XUD4EkAXnt33nlS\nlgwRuReAhwP4CQvTWtIfB/CI68rX3cRfaa45vyMi3yMi/+11Z+hWQUQ+EFXZcnu9AcAv4M5tLwD4\nuOaq85si8jQR+YvXnaEL4r1QR/lf264fDuAGcvu8HMArcee0T18mw+eLyJ+KyEtE5H/vLB0LJ4ib\n/P/7I9p9xnOPxL/jcA/9d++W4BbVzX1QLaL9/0PuWNyKehGRxwB4EICfuR15vA7cjXp5CoDXqOrT\nb28Orw93o27uKyK/JyKvFJFLW5Fv3FRubx/uAnAA8Cdd+J+gjsDeaXghgC8C8HJUl46vB/CzIvKh\nqvrma8zXrcL9UQngrL3uf/XZuSX4EVR3olcA+CAA3wDgOSLyiPZBniRERFBdo56vqjbv5/4A3tGE\nH+OOaJ+dMgHAMwD8PqoV7a8B+CbUfyw/+8ozuXAZ3Mz/3++/E//k++8lcE/7d+9W4lbUzTcC+COM\nYvVOxk3Vi4jcD7Uu3h3AOwF8qar+5O3K5DXg0vUiIo9EtWA87PZm7dpxM33m5QD+LoAXA3hPAF8J\n4OdF5ENU9Y8u8tJTExl7EOz7z58sVPW5dPnrIvKLqOToc1BNcvdU3JHtBQCq+n10+Rsi8hJU3+eP\nQ3XTOVU8DcBDcLE5P3dK+1iZHsmBqvpddPkbIvJqAD8uIh+oqq+4ygwu3BJctj/eKf337uJdpZw3\ngwvVjYh8Deq/t49W1Xfc9lxdP86rlzeikun7AngMgG8Wkd9V1XvsPISGab2IyH0B/AcAf09VX3fl\nuToN7PYZVX0h6mB5jSjyAgAvA/D3Ua0/5+LURMafAThDndDJeF+M6uuOg6q+XkR+C8DJrr50Sbwa\ntYO+H3L7vC+AX72WHN1iqOorROTPUNvsJEWGiHwHgMcBeJSqvopuvRrAu4nI/Tprxsl/T12ZzpvY\n+guo/fCBqBaohdPEzfz//dWXjH8n4h79797dxE3XjYj8E9QFIR6jqr9xe7J3bbipemnW+N9tly9u\nri9Pxj1nsvNl6+WDUCcy/3CznANtQSQReQeAv3oPGri62/+fUdV3isiv4hIc9qTmZKjqf0GdiPQY\nC2sN/xgAP39d+bpVaKr5g3APWQ2kfXyvRm6v+6GuDHTHtxcAiMh/A+C9caJt1sj44wH8TVV9ZXf7\nV1BN4tw+DwLwANTJsyeJc8o0w4ejjsScZBstVNzk/99fwPEbPhEn3H8vi3v6v3t3BzdbNyLylQD+\nFwCPVdV7xIAX4xb2mYLqOnWPwE3Uy8tQV9r6MFQLz8MAPBvAT7bzP7jNWb4y3Io+IyIFwIfiMv/W\nXvds98ls9s9BXZ3oCwF8MIB/g7r02vtcd95uoiz/EnXZ0A8A8N8DeB6qYnzv687bJcpwH9SP7cP+\nf/buPs6Sq67z+OfXM4EgSFBH1BWDKKhBBcmAgoBZRRHZhRVBZdbIg4iiIpiIgC4an3AFlPgEKPIg\n2cCgsqigCCwQQRREZtCgBOQhAUR5CA9DCAkk3Wf/qKqZ06dP1a3bfW/f7ns/79erXnWrbj2cqjvT\nfb59zqlL85Sfn2qXv6x9/7Ht53Mfmv+sfw68E7jBoss+7fW07z2ZJiTdsv3P92aaH0SnLbrslWt5\nOvBxmse+flE2nV5sczlNd6/DwN8Bf7vosm/3moCvAJ4AnN1+RvcF3gW8ZtFldxr1+Q7+fAcuAn4t\n2/4uwGeB82n6Df8icC1w20Vfy4Lvy2nZz7EP0Iw7uD3wlYu+lj1wbx7b/hu5X/Ez5MaLvpYF35fH\n0zwW/Fbt9j9N8/TBhy76WhZ5Xyr7L/PTpab9N/PzNH/UuRXNH/OO0nxNwdeMPueiL7rnRvw4cEV7\nM94A3HHRZdrmdRyleTzYNTRP9HkBcKtFl2vKaziHpjK+XkzPybb5RZpBuJ+mefLLrRdd7u1cD3A6\n8HKa1plraZqVn8EeDbg917EOPCjb5oY03ztxJU1/3D8Fbr7osm/3moBbAH8DfKT99/YOmsH5N1l0\n2Z1Gf8a9P99p/oL4nGL7+wNvb7e/lOav0wu/jkXeF5qAXfu/spRhe8p7c3nPz5BfWPR1LPi+/Er7\n8/Lq9vfB64EHLPoaFn1fKvsubcjYxr+Zp7b/n66hqeO9FLjdNOeL9kCSJEmSNBN7akyGJEmSpP3P\nkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZkiRJ\nkmbKkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZkiRJkmbKkCFJkiRppgwZ\nkiRJkmbKkCFJkiRppgwZkiRJ+1BE/E1EvCZbvmVEbETEg2Z4jisi4jmzOp5WhyFDkiQNioiviIg/\niIh3R8Q1EXEiIl4fEY+KiNPneN6zIuKCiDhzXufIznUkIh49xfZXtBX6bvpQRLwuIr57nuUspJHr\nBkXEXdr7fNPK2xvbOaZ0cNEFkCRJe1dE3Bv4U+Ba4CLgX4AbAHcDngzcFnjEnE5/W+AC4BLgfXM6\nR+d/Al8L/PbI7RPwFuA3gAD+C/CjwIsj4hEppWfOpZRDBUrpvRFxI+C6KXf9ZuAXgOcCnyze+2qa\noCFNxZAhSZKqIuLLgRcClwPfllL6cPb2MyLi54H/Ns8isLf/iv6BlNLRbiEi/g/wLuA8oDdkRMTp\nKaVr51GglNJnt7FbDBxv2sAiAXaXkiRJ/R4H3Bh4WBEwAEgpvSel9LvdckQciIifj4h3RcS1EXF5\nRPxqRNwg36/tavSSiLhrRPxD2wXr3RHxg9k2Dwb+pF38m7ZL0npEfEu2zXe1XZQ+FRGfjIi/jIjb\nZu9/YUR8OCJeXZz/1hFxdUQcbZcvoQlL3ZiGjYh4z7Q3K6X0IeAy4FaVa71nRPxjRFwL/Ej2/rkR\n8eaI+HREfDQijkbELcpjR8SPtPf10xHxxoi4W2Wb6piMiPjqiPiT9l58OiLeHhG/2r53AU2LFEDX\nBWy966JWG5MREbeKiD9ty3t1RLyhbfHKtzmnPdb3RsT/ioj3t5/zqyLiK6e8tdqHDBmSJKnPfwfe\nk1L6h5HbPxv4JeDNwE8BfwP8HHC02C4Bt6HphvVK4HzgY8BzI+KsdpvXAb/Tvv5V4FzgB2kq8bSB\n5C+Bq4DHAr8MnAX8bVdBTil9hKYr17dGxCPb/QL4I+AE8OPZ8f8JuBL4gfZcPzXymk+KiIPAlwEf\nLa71a4AXtNf6k+25iIj/BTwPeAdN68eFwD2A1+bjIyLiYcDvA/8B/Azwd8BL2nNNKtPtgDcB/xX4\nA+BRwJ/RfLYAL+bU5/NoTt3nj2Tlz493c+ANwHcAv0fz+d4QeGlE/I9KER4P/A/gKcCvAXcGLp5U\nbi2BlJKTk5OTk5OT06YJ+FyavvgvHrn97drtf79Y/2RgHTgnW3d5u+6bs3WHgGuAJ2fr7t9u9y3F\nMW9ME0qeUaz/QuDjlTI8nyaM3Bp4THvM+xTbvJQmUI29P5cDfw18QTvdjqayvg5cWLnWby/2P5Nm\n7MTjivW3BT4LPL5dPgh8kCa4Hcy2e1h7v1+Trbtlu+5B2brXAp8AvnTgWn66LeOZPdf5nGz5wnbb\nuxSfx7uBd2frzmnL8i/AgWz9T7b733bR/8ad5jvZkiFJkmq6v6RfNXL7e9P81fvCYv1v0vT5L8du\nvC2l9PfdQkrpSpq/6H/FiHN9B3AG8MKI+IJuas//D8C3Fts/kqbl4kU0LR4XpZReOuqqhn0nzV/8\nP0LTOnF/msHxjy+2uzyl9Kpi3f1p7sufFtfwYeCd2TXcCbg5TXC6Ptv/eTThoVdEHALuDjw7pfSB\naS+ux3cBb0opvaFbkVK6mmYMypfn3dVaz0kprWfLf0tz3WM+Z+1jDvyWJEk13VOGPnfk9t1f0d+V\nr0wpfSgiPtG+n6s9LerjwOeNONdtaCqql1TeSzSBIi/Dx9vH0/4pTavA6EfVTvBG4H+1rz8NXJZS\nKp/OBE1rQOnWNN3W31V5L9G0ZkDT4pHK7VJK10dE7bi5riL/rxO2m8Ytaa67dFn2/tuy9e8vtvt4\nOx/zOWsfM2RIkqQtUkpXRcR/AF8/cpfuCUVjnwa13rO+90lHmbX2POcCH6q8f31l3b3a+ecBt2Bz\nRXi7rkwp1YJO6ZrKujWaUHYv6o+I/VQ7H7qvk+7VmHs5bzv5nLWPGTIkSVKfvwQeHhHflCYP/r6C\npuJ8G5puT8DJgcI3A967jfP3BZZ301RSP5JSek3PNidFxL1oxjA8iWZg9/Paa8or97v9qNzuGq5I\nKdVaMzpXtNt9Fc34CuDkIPMvpx1EPnAOgK+bUJZprv29NN+dUTore19yTIYkSer1ZJpuQM9qw8Im\nEfGVEfGodvFlNJXh8qlMP01Tif2rbZz/6vaYNyvWv4KmO9fPtZXtslyHstdnAM+i6eLzc8DDgcPt\n6/JcZ2yjjNv1YpoWjAtqb0bE57cv30wz5uMRxbU+lK33ZZN2nMvrgB+KiKEnUV3dzgeP13oZ8I0R\n8U1ZWW9M81jey1NKs2gh0hKwJUOSJFWllN4TEf+T5gv5LouI/Bu/vxn4XppviSaldGlEPA/4kYj4\nPJq/un8T8CCaJ1S9tnaOCf6JprvN4yLiZsBngFenlK6MiB+jGWR9PCJeSFMRP5NmgPnraR7VCs1j\ncD8P+NaUUgJeERHPAp4QES9JKV3abncM+L6I+E3gH4FPpZT+chtlHqW9t08Afi0ibgX8Oc0g+68A\nvpvmcbNPbcdePIHmEbaXRMQf03wPx0M51VIx5FE0g62PR8QzacaH3Aq4d0rpDu02x2jC3K+19/I6\n4CUppVo3r18HjgAvj4jfoXnK10NoxmJ8z5S3QUvMkCFJknqllF7aftfCzwD3pfneic8Al9J8t8Oz\nss0fRlPxfQhNRfmDwBNpnui06bD0d9E5ub4dNP6jwM+25zlA89Sl16WUjkbEB2ie5PQYmu9q+ABN\nhfq5ABHx32nGbZyfUnpndo7zgW8H/igi7tQ+/ejpwO3bsv8UTbefoZAxdA2jtkspPSkiuu/I+IV2\n9fuBl9N8D0a33R9GxBrNZ/Bk4K3AfYBfqRx703Ib/u7cbvsI4PT22v442+bNbZB5BM0Ts9Zogsj7\nyvKnlD4cEXeh6Xr2yPZ4lwL/PaX08qGyjFivJRJNqJckSZKk2XBMhiRJkqSZMmRIkiRJmilDhiRJ\nkqSZMmRIkiRJmilDhiRJkqSZWvgjbCPiC2gel3YFcO1iSyNpSZ1O8824r0gpfXTBZVEPfx9I0sLM\n/PfkwkMGzS+U5y+6EJJWwg8AL1h0IdTL3weStFgz+z25F0LGFQAXA2ft0gl/CnjKQbj+IFx/oJmv\n982L7cZss+33d3KMYjvOg9OeBAevhwPrzfxgOz9w/eb1Y98/sA6nXT95m52ca+wxfmYDLtylfy+L\ncB7LfX2wu9d4Gc23cdH+vNGedQXAxRdfzFln7dZvhPk477zzuPDC/f+/eFmuA5bnWryOvWcZruWy\nyy7j3HPPhRn+ntwLIeNaaALG2bt0wjOAOwRct9ZU2q9rK+bXnTZ5Pmab7c6n3WetnXMacBA2ToON\nbvkMWLsDHLiuqZifNsP5LI818dgBB+PkJXLaBhzcaD7D3fr3sgjLfn2wsGu0C87e1vw+OOsszj57\nf/8POOOMM/b9NcDyXAcsz7V4HXvPMl0LM/w96cBvSZIkSTNlyJAkSZI0U4YMSZIkSTO1F8Zk7LoH\nxqJLMH/xwEWXYL6OLLoAc7bs1wercY3arssWXYAdO3LkzsDxnncPAWfuYmm278iR5fmfuizX4nXs\nPct0LbMUKaXFFiDibODYMXZvEOhG7N7g7EUc+/rTYG0DDs5pkPauDvzumR9c36V/LFoKx4HDzcvD\nKaW+mp8W7OTvg2OwPGMoa04H3sF+CRqSlt/x48c5fPgwzPD3pN2lJEnaVdcCVy66EJI0V6sZMpa8\nu1RqJ0mSJGkRVjNkSJIkSZqb1QwZ/plfkiRJmpvVDBmSJEmS5mY1Q8aSj8mQJEmSFmk1Q4YkSZKk\nuVnNkLHkYzICG2skSZK0OKsZMiRJkiTNzWqGjCX/M7/fkyFJkqRFWs2QYQ1ckiRJmpvVDBmSJEmS\n5mY1Q8aSd5eSJEmSFmk1Q4YkSZKkuZlbyIiIn4iIyyPimoh4Y0TcaV7nmtqSj8nwEbaSJElapLmE\njIj4fuA3gQuAOwD/DLwiIg7N43ySJEmS9o55tWScB/xBSumilNLbgUcAnwZ+aE7nm86S/5nfR9hK\nkiRpkWYeMiLiNOAw8OpuXUopAa8C7jLr80mSJEnaW+bRknEIOAB8qFj/IeCL53C+6flnfkmSJGlu\ndvPpUsEKV+8jLfm06BssSZKkPePgHI55JbAOfFGx/uZsbd046TzgjGLdkXZahGBc5XptY3bTgXVI\nARtr/XOieQ3D87UNOHj98HRgffI0tuwxZpuRgUXaiaPtlDuxiILsIxFxCfCWlNL5iy6LJGk5zDxk\npJSui4hjwD2AlwBERLTLv9O334XA2bMuzJQ2VXRTfX0ZLnYSOg6sbw4QG2vDYaMLERuRhQ7Gh4wy\nQEwKG11ZthM6avdnUtjou9/SNGp/nDhOM1Bs1UXEOcAlwM1SSp9cdHkkSctrHi0ZAE8FnteGjTfR\nNFR8DvBHczrfjgxVctcmhItpWicObMDG+uaAUAYJOBUoyvDQSXGqvJG2LkNz7tOua6Y8UJTLXcio\nhZGD18PBkS0dY0LI2LBR/Txm+5FLq6rrtjr3/1IRcTCldP28zyNJ2pvmMiYjpfQnwE8Dvwy8Bbgd\n8J0ppY/M43w7UQsXm14XAaNWUR4KGJteD1TWt1TuK5X/PCjkr7vl7nU+lduU+9daOzaFjZEtHbVr\n3jT1BLShgLEpbNiqIY0SETeIiN+JiA+1X4b6txFxx4i4JfCadrOPR8R6RDwn23UtIp4UER+NiP+M\niAuK454REc+KiA9HxImIeFVE3C57/4KIeEtEPCwi3gNc265/QERcGhGfjogrI+KVEXGjed8HSdJi\nzaslg5TS04Gnz+v4s1AGjG5evp40JqPr5lSGjq7b0lALR95tqluXYmtrB7QtGtHf0jHUXaoWXia1\nUNSCxJjWivJ1pGbMxphwUbbIlK8lTfQU4H7ADwLvAx4HvBy4DXB/4EXt66uAa7L9HkzTCv2NwDcD\nfxQRr08pdY8jfxHwKeA7gU8CPwq8KiK+KqX0iXabWwPf055/PSK+GHgB8Bjgz4HPBe6OjZOStPTm\nFjL2k7JiOyZY9M3zcJGHiBT9E/SHhrw71Ml5T5mhOV83z7tH5d2ktjOfJpCMGaexJYRUAobhQppO\nRHwOzZefPiil9Mp23cOBK2i+DPXN7aYfqYzJuDSl9Cvt63dHxCNpxtK9OiLuBtwRuHlK6bp2m8dG\nxP2ABwDPatedBvxgSulj7bnvQPNI8z9LKb2/3eZfZ3bBkqQ9y5DR2k7Q6FowynkZMoZaNGotGQfW\nmzKULRlDA727eRdG8paMWnessUGiFiB2GiQmdY8aChwGD2nQV9L8XP/7bkVK6fqIeBNwFqdCRs2l\nxfJ/0jwVEJour58LfKx5jsdJp7fn7Ly3Cxitf6b5YtZ/iYhXAK8EXpS1fEiSltTKh4xpu0x1YWJo\nLEYXFPL5yRaNNUjrW1sy8oHfnTI8lOWtlS9v0Rgz7qJvwPfQ06dm1oUqv68D4zEMFtJo3U+R8n/N\nmO8puq5YTpwat3cT4D+Ac7JzdPLAcPWmA6S0AdwzIu4C3BP4SeBXI+KbUkrv7SvIeefBGcUzzY8c\naSZJ0s4cPXqUo0c3P+z9xInZP+x9ZUNG/luyDBqTWjPKSvKW7lI9ISRFM/h7rdKNqnsNm1s1oP+p\nU51yGeohY+yja4eeHDV6oHclXAy1alAuF59F+TlJqnoXTVi4G/BCgIg4SNPV6anAZ9vtDkx53OPA\nFwPrKaX3TVuolNIbgDdExK8A76UZs/FbfdtfeCGcvehnmkvSkjpy5AhHir/aHD9+nMOHZ/uw95UN\nGeXTiiZ13akFja6FYks3qXU4EFvHZEA9QNTGZ+RlK1syauXsxmLky0OPqJ20vjeMbEwOIpNaNWrh\no+/68nWShqWUPh0RzwCeEhEfB94PPBa4EfD4o8UhAAAgAElEQVQc4MY0LRT3iYiXAdeklK7uPeCp\n474qIt4A/HlEPA74N+BLgXsDL04pHa/tFxHfSDOu45XAh4E7A4eAt+3sSiVJe93qhoxW7REnkwJG\nLXCUoaO2vuw+VRsYDpO/LyNvuegLI0NjMsa2aJQB4sB62xIzIUjUQsVQuKgFi/xzkDSVx9P8aLuI\nZhzFm4F7ppROACfaR9P+Ok3ouIhmQPgY9wae2O73hcAHgdcBHxrY55PAtwCPBm5K04pxfjcoXZK0\nvFY+ZJTddCYFiaGB3fkA79qYjFrLxqSnS3UmDYSudd3a1FqxDgd6WjJ2+nSpMS0Yk8LFpMAhaZyU\n0meAn2qn2vtPpAkL+bpvrWx3v2L56gnH/SXgl4p1bwe+a4riS5KWhCFjhO20bJRPnCqfHDVNyKiN\nuZgUOrpzjvlSvVmEhzEDv6e9j7WuVJIkSdr7DBnsrPLb16JRCxPlQO/y/a4sffOhinfZkhFpuLvU\n2BaLaQaIj33C1JhWjdpnlF+nJEmS9q6VDxl9Fdqx4SIff5GHjL71ebjo1ufLfQGkHHtRlr8WPmpj\nLsZ2fxoclzFlt6hpukqVn4EkSZL2n5UOGWUltqykTxMuum5RfWGir+UCYP3A1paMsozdF/HVWizy\n5fz7JmrffTG0nI/jGBtK+p4sVS7XwsaYQeCGDUmSpP1npUNGp69SuyVgJNgowkbZIlGu7wsX3fpO\nOe6irGyXIWNLuGjn6xsQG1tDxqQwMfb9WsDoCxZ9AWNsd6ktLRs7+5glSZK0SwwZmUmtGGO6T5Uh\noxZCYOuA7zJ05LruUkPf/L1+YGvZp+0aVQsPQ60VYwd7jx0APvQZNDdi2x+tJEmSdtHKhoxapbab\n904bEGv9QWJo6kLEgfXmL/JpfWtwGCpf15KRz/MKfK2SX7ZM5PPthI9pWzaGQsfYsRmSJEnaf1Y2\nZOT6uud081qLRV9rxsZACIGsu1R7njx8lA5UgkjXYpG3XNTK2YWMSaFgTOhY24ADU7Zg9AWLsd2k\nhrpOSZIkaW9b6ZAxFCry15O6SOUhohzwXY61yINDX5nyqQsTXctFfu61jeb9bruygj80SHto/djt\ntjMuoyz/mNaMvteSJEnam1Y6ZJTKyuyYcDFpuRx7UQsjpUnf9J2Hj7JseRgZGyLGLA+t62vJKEPF\npNBWCxcGDEmSpP1n5UNGX8V2zJSHifw1bA0PteBQWy7DQtmSkYeIvCWjq9R33bVqIaMvTJQDuyft\nNzT+Yuzg8J2EDUmSJO1tKx8yOlsquUzfstHNYXL46AsdtTEIZctFvq4MJRvZuklPi5o2ZEz7ZKmd\nhIr8nkuSJGl/MWRkunp/JGBEiBgz33T8StenfN73Xhkm1hKsr51qydg034C17MlT04SM7YSRofnE\nqacbVXlPJEmStL+sdMjY8hfzSiW33GZsF6q1jWa/aULI0Hm7oLGxBusJYm3roO98m7EhY22jfXLU\nrIJDZZB37zTlOA2DhyRJ0v6w0iED6hXXvuBQroPJoWHMIO6yO9Sm7k9rm8NDvj5vweiW821q4aAv\nNEyzflLwmBRIttzfga5TQ5+TJEmS9qaVDBnBqa5Rm9ZXxgaMbcnIQ0cthHSGBoCX58mX87AxKXyM\nCRmzWh4KEWPHY5C23g/HY0iSJO1fKxkyyCq2sP1uUHmYOHnogbEYtfOVy7UwUQsR3XKKZvu8JaPb\nf8z3V8xi/bRPlKotj+kuld8rSZIk7V2rGTIyY7tL1b4Mryb/du5Jx+2267o9lWGjm7ouUeX6Wjep\n8hG2kyr+YwPCgQ2Ikdt3Xzg4trtUrcvUmM9JkiRJe9NKh4yuJWBLpZfNrQzdfGyLR1fRH2tjbfI5\nai0ZW54sdWBzJX6awdqznMa2TuTbMGHb/LOQJEnS3rbSIaNXETS2Exxgc+V4u1MeHvKAUWvJyOfd\nvl0LxNhwMKkVYpbH6Asj+b2TJEnS/mPIaJUV3a6FoxtjMSkIEEARQroK/9DjaidNXTlq3bX6wkc+\n8Huocj9tQBgbHGrbjbnW/L7k94f29kqSJGl/WPmQkVfm8+W+v65vCRe0lfoNWIv6sfu6Q9W6ag21\nWORTNwg9X54UMsp1O13eybqpQ4ctG5IkSfvGyoeM3FDYyNdtChfF8lriZIvGpMfX1sJHua4LErUQ\nki8PhYy+sDA2VEwKDZPO1dctaky4qLVwSJIkaW9b6ZBRhoq8ZaFsZei2yV+vVcJESsDa5vV5gKi9\nzs9VCw21Fov8/drrWsW/FhrGbjfNtkPb1V6P7T5Vvpak/el04NCiCyFJc7XSIaOTV/T7Qke3Lm9Z\n6NaV75XhIz9mLWjUAkdtXX78siWjDCd9IWBMUJjFvn3vjWnF6FsnaVVcDJy16ELM0SHgzEUXQpLm\namVDRhks+kJFPp8UIobmQ6EiDw21QFG2XuTzvvfKbkpj52Pe28m+YwOHpFV2FnD2ogshSdqBlQ0Z\nNXklv1vO57V1tQBSCxlDgaPWTSuf569rLRe1QDJUsZ9U8R/7/k6PPdRiYWuGJEnS/mXI4FTlNQ8Y\ntbCRvy7DxFCgyCv+5eu+INHXWlG+7lvuq9QPLQ+FgWp4SBBT7jNNS0btvkuSJGnvW+mQEWx+Mmot\nYOTry9dwqhWhe10LHOVy2YJRBo8ydOStFbUQUlsuK+3ThI2x67Z7jLFT3z2XJEnS3rbSIaP7Zu/y\nUbNlpTZfzoNEV7Ev19VCxlCAOBkUujEVsTk89LVYlFP+fl/FfVKlv+/9of1mecz8npfrJEmStD+s\ndshoTarIDr1fCxi1ENG1dpQtGJum9lhrAyEiP8bQ1JVtu60Is2iJyI8xbXn6PgODhyRJ0t5nyBhh\n2kptpOHH004KCH1TF2j6gk0ZMsoKfrduP07b+RwkSZK0GCsfMsZWXKcJB/n2tf1gumNtZ7uuDGMq\n7jPZDpruZzM6p4FCkiRp/1r5kFGznZaLoaAxKTTU1k16b9JxuvOPqeDPYv0sj53f15MBRpIkSfvG\nyoaMrkKbV8g7XQvEpP37xmB0x5jH8thtuzLWKvQ7WoZNLRbzPjbZOkmSJO0PKxsycl1A6F7DcNDI\nt8+X86ARQErDIaHvdRkWtrO+K1dekc/XbVqGanDo3X4Br/MySZIkaW9b+ZBRBow8XNSCRm37bttu\nPnbdLLcv3+vKV85r64bem3b7WR6rXCdpNVx22aJL0Dh0CM48c9GlkKT9aeVDRqdsjRjbXapvDj2V\n/4DEcFCYxbwr436bj91W0vI699xFl6Bx+unwjncYNCRpOwwZzDZgQL3CPxQGpnlv7PZ5WfN5bd08\n3pv19pK02669Fq680pAhSdsx85AREXcHfgY4DHwJ8N0ppZfM+jyzMG1XqaFj1PYbGxamfT1m27x8\nO309i2PM6niSJEna++bRknFj4J+A5wD/dw7Hn6kyaEB/wBizbVnRH1qeZttp9y3Lvd3lnew7y2MZ\nNCRJkvaPmYeMlNLLgZcDRMRA1XfvyMNDtwxbAwXQPDWKcdvWwkotDPQFhLHbDgWMk+WEzQXv1s94\nXW39PM4tSZKkvcsxGa3RFdnEpi+Hq4WL6m4jgsCYbabZbpKx3cH24rEkSZK0d61kyOjq6JPqsrOs\nOEuSJEmrYs+EjPOAM4p1R9ppXvZFX65tmmX2mVXLyayPNSuzDIqzOtYevE37xtF2yp1YREEkSVph\neyZkXAicvehCrIihiv5+eW/IUEV/u++N3XfSE77GvpcwaGxX7Y8Tx2kedydJknbHngkZmq+dDCIf\n8ySrRRyrNGbQ+CwHuteeKjbtuJNp95MkSdoP5vE9GTcGbs2pP8R+RUTcHvhYSun9sz6fJhv76Nvt\nbDeLY2z3vJ3y6VVjv29jx9tVzjvmKWN9j0KunVuSJGk/mkdLxh2BS2iqXwn4zXb984AfmsP5NGCm\nX/IXp+rUO/2iwXl/4eAsvxBw8P2BL2LM9y+/9LH2WpIkaVnM43syXguszfq42pmy8j5Usd+yTSVc\nTNxnim23s09nKAhMms9j21rQqH1fyjTbSpIk7TeOyVgh01b6q/M2cOzkGDMpR2tMxX9skJhmngeC\nvnmfoB3YbaiQJElLypCxxMpwsGUdWyv9O31/N/eB/hAxKWRsZ92Y90cFjezRUdOEE0mSpP3CkLEi\n8rrrUIV+O68XtT+cqtyPCQbl62hvzJb1I/fvQkFtHEbNpLEZBgxJkrQsDBlLrhzvUFuuVfonBYGx\n28zzPJPCQd+67Wyz3WMMhYe+bQwckiRpvzNkrIChcNFXqR9av1f2GarwD63fzj619fn9LNfl63N5\nC0a+bmgfSZKk/caQsUKmrciPmba77yzOOU2omDQBrG1s/xhDZSqdXB9AEToMGJIkaRkYMlZNVknP\n5xtr2TxgY5sBYDen7QaKvmljrb5+LQHpVAjJ52NCRa/U3GuDhSRJWjaGjCW3pXLO1oAxbcvCxtp0\nYWCa7afZdigw1ALAdraJBKloKenCSC2UrLXbd0FkkrYxw6AhSZKWiiFjieXdcPJ101Tua+un2XYm\nx16rt6yMCQy19d26MiSU264liGxdd86+YwJs0ASH7th9YeNkF6t2++6zMmxIkqRl4Ddzr4iuYl4u\nn1w/IgRsrG1e1y33TesHmqlc7puuP7j59cmpXM6mcvstx62tK6be8q5tXq5Nffemb6rd//Jz0mJE\nxCUR8dQptv/qiHhDRFwTEccj4pYRsRERt5tnOSVJ2g9syVgBtcpt/jrF1paCrsJcCxrl+nm+7jt/\nrVVh0uuyBaNbLltFymPXlrvXsHVMxqaWjaJFowwR+fG1cPcDrpti+18CPgXcBrgauCmwrz/JiNgA\nvjul9JJFl0WStL8ZMpZcGTDK19N2YxoKAmMDw0626wsZaxvNe3mQKENCvm5t49T6vhCRh4kyQHTH\n6gsR3fvdPvn97tZ1ywaNvSGl9Ikpd/lK4C9TSv8OEBE3he7RCqstIg6mlK5fdDkkSYtjd6kVMRQq\n+sLEpK5Q+XzjQP29Md2j8u5P1522db6dKT9G3pWqnPd1n9pyfZV1Q12phlpjyq5S5VyLkXeXiojL\nI+JnI+LZEfHJiHhvRDw823YDOBu4ICLWI+IXKsdbi4hnRcR7IuLTEfH2iHhUsc1zI+LP2nN9MCI+\nHhFPiIgDEfHkiPhoRLw/Ih6S7dN1y/reiHhde+w3RcRtIuJOEfGPEXFVRLwsIr4g2++OEfHKiPhI\nRHwiIv4mIu6QvX85TUvMn7fHf0/23o9FxLsi4jMRcVlEnFtcx0ZEPCIi/iIirgKeEBHvjIjzi+2+\nod32VtN+PpKk/cWQsaSqFdaeSu2k4DGpVWMofEwKGmOmWkCYJjRsZ6pdy9jgMGmqfQYTPzstwvnA\nPwLfADwdeEZEfFX73hcDbwN+A/iSdl5aA94PPAA4i6Z71RMj4gHFdt/WHuPuwHnALwN/CXwM+Ebg\n94E/iIj/Uuz3i+22dwCuB14A/Drwk8DdgFu373c+F/gj4K7ANwH/BrwsIm7cvn8nmp8SD26v704A\nEXE/4LeApwBfCzwTeG5EnFOU5wLgxcDXA88CngM8tNjmocBrU0qXb7lbkqSlYnepFXCygst0waLv\nr/K1cDFpm5PvrzXjP4b26923WLe2sXW8RbluaJuuS1PZZam7/rzLVG1dJ+9KBVuPTeW+184XJx81\ntQv/KDTGX6WUfr99/aSIOA/4r8C/pZQ+HBHXA59KKX0YIGJzOmy7C/1Stuq9EfHNwPcBL8rWfxR4\ndEopAe+MiMcBN0op/Xp73P8NPJ4mOPxJtt9TUkqvarf5bZqQ8W0ppTe2655NExi68lySly8iHgF8\nP3AO8LKU0pXtNZzorqn108BzUkp/0C5fGBF3Bh4DvDbb7vkppedlx38u8EsRcceU0psj4iBwhCa8\nSZKWnCFjifX9Rbz8i3pfS0Vf6BgMGT0hYszytNvWAkW3Tfm6DBOTwkO+HjaPl+hCRLlcO39+n/Nx\nGGXQOLk+2al/D3lrsfxB4ObTHCAifoLmr/dnAjcCbgC8pdjsX9uA0flQfu6U0kZEfLRy7rcW+wD8\nS7Hu5D4RcXPgiTSh4ubAgbZMZ064jLOAPyjW/R3wqGLdsXwhpfTBiHgZ8EPAm4H70lz/i5joPOCM\nYt2RdpIk7cTRo0c5evTopnUnTpyY+XkMGUsuDxrTdonqq+wPjdsYs+802w1tm7dUDLVelFMtfJTB\noC9slMudPHjkx8yXa+FuS0uG9pLySVOJKbqYRsQDaboYnQe8EbgKeCxNF6hJ5xlz7uuK92vr8n0u\nAj6PpjvV+4DPtOW6wYRLyY/fqbW5XV3Z71nARW0r0EOAP04pXTv5dBfSDHmRJM3akSNHOHJk8x9t\njh8/zuHDh2d6HkPGCsgrt7X103SbqoWQsWFhzPvdNusHJgeUWsg4sL41QNSmvHJfCw1DYSIPELX3\nJrUU1Vo0tJS+Gfi7rJsREfGVMzr2dv7VfDPwYymlV7Rl+TLgULHNdTQtHLnLaLpqXVwc67IR53wZ\nTfj4ceBe7XEkSSvAkLFCpgkT5Tx/fygAzGPKQ0d+7lorRd/6vhaNoRDS3bPavev7Ju/c2HNoab0T\n+MGIuCdwOfCDNIOp3zO41zi1XnWTetp15TlG0xfpycCni22uAO4REX8PfKZ9rO9TgD+OiLcAr6bp\n9nQ/4B6TCtl29Xoe8L+Bd6aU3jRpH0nSchjd9K99Lqssd/OhsFHOa9O8nhpVTkOPta29P+1UK0t3\nffl8qFWlDGQ7mbQwiVMtBLUIWK6btM0f0Dxt6YU03ZI+H3jayHLs9Nw1P0TTXeo48Dzgt4EPF9v8\nNPAdNN2pjgOklP4CeDTNQO9/AR4OPCSl9Lcjz/1smi5Zz55QPknSEonN4w0XUICIs4Fjx7AH7ix1\ng6/zFoC+oLDd93d67Hy77ey7ttF0jxpqrRh6fyf7zuTYCdYq23X7mjdm5zjQ9jQ9nFI6vtDCrJiI\nuDvwKuAWKaWPTNj2bOBYM4Z8b/xGOHYMzt4bRZGkucnGZMzs96TdpVZA/tfxLX81H9l1asy0JRAc\naMJOuX7S8pht0hpEpXtUWbnvujaV2+TdnvLloTEVpVp3p26sRzdmoxz7sWlK/ceW9ruIuAHNU6wu\noBnwPRgwJEnLxZCxxGrholxODFSCo6nMp8q4jFGhoyc4DAWIsYEkBaz1BIVyuQwRUF8ulSFiaHkw\nTFSCytCyYza0JI7QdJE6TjMeRZK0QgwZK2ZSJXhLC0aw6XsvJrVg1F73BYWT6w+cCiRj9ylbKMru\nUxtrp15PCiL5fcm36daX96+Tfwlf3nLRzYdaNMrPQ1o27RfzPW/R5ZAkLYYhY8lN+mv9UNjY8npC\n96mhFolaUKgFiknb1EJGFwxqgeLA+ubrzINFfk+GWjLKFos8OHTLW1oy1k51hxq6z5IkScvIkLEi\nJlV2J4WNk60aU4zNyOdjw8PYbfMwUWu1yOe14FEGjrHzXBcyutdb5msDIaQncBg8JEnSMjBkrKBt\nBYyx4zCmDAvldmP3qYWJbl5rxchfD81hQnBgawvGNOMxhkKEAUOSJC0LQ8YK6OuiM3ZcRrl+S6ho\nx1QMhYex68cGkS5UdGMxutaMrpwnx1asNY+JzVs0hkJHfm/K9X3dp/paNGrhY+jzkCRJWhaGjBU0\nNmzUQkc1iIxo7ciDQq3VogwT1x/cHDbK5S5clIFhy/I6HCiuvbwXnb6nR9WCRB4gpm3R6Lv/kiRJ\ny8KQscR2GibGDvCe1PqQB4RJ6/taLsr1eQtGN+UtGZtaM7JpbWPzvegCSfmN6Lla+CiDR1eWPGzk\nQWioRSP/fCRJkpaBIWNFnKzAjgwdZctFrRvV2BAyTZeooSkPJl0FvnYdJ4NDz33oQsCW76Fomzwm\ndYGqTfng7qFwUeuGZdCQJEnLxpCxAjb95ZzhcJEHjO0O+J4mOJRTFyImzTd1l9rYWu6+oNQFkHI+\nZL0SPiZNXejIw8fY0CFJkrTfGTKWVN/Yg77Bx0NBoy9wTBso8qCwk226857sHrXejAspnyrV19Kx\n3cr9mJaNfDD62HEZfZ+VJEnSfmXIWHK1rji1cQFjgkYZNsZ2mxp6TO12g0nZSlFeK/S3UpRhoWup\nyN/va52Aza0UZZiY1G1qzGciSZK03xkyVkBZqR0KGGMHfw89MWpSYOgLEHmQqL2XL5dl6Vowat2k\nymuFrY+wzfUN9O7CSD7AO3/dtWSUYaOv9cJQIUmSlpUhY0WUldqhSvik8DFNa8ZQ68XYYFJb7s5d\nXmNtedKjacsxF+VyGSS65fyJUmW4mNRdqjlB/XORJEna7wwZS6xWYa3+VX3gSVKTWjZqj5adNjDk\n8zHb5OeqtVzky333otZ1aSh85Ou7ILF+oB48at2nqqGj8rlIkiQtA0PGshsYs9CtG/vEqYlT0UIx\nqWVjTAvGUMgor2soMGy5LT0horZv+aSoMa0V+XgMJtxbw4UkSVo2howl19Wvx3aLGh0oauGhMuC7\n1koxNB+7Ta0lo2zBGNsNaTBkAOsDYWMogHRBYyNgrdJVSpIkaVkZMlbQmKCx0yBSjruYtjVjUthY\nP9DfcpFfZ247LRbrCWKtP1Dkr0eNw+juf+VzkCRJWhaGjBUwWNmtBIdJYWI7oaEvKJStF/lUriv3\n3VjbfB1DLRn5NXeGQkc3Pxk2KuMv8pCR36uxoaM2TsSwIUmSloEhY8WUFdxJrRW1sDGpJaMMIdt9\nmlQ5ELxchlMV/E7f42fzsRl9y90x1zY2h4gyVOTLtTEYY6by8yg/I0mSpP3MkLHkauMSxnaF6ns9\nKUDkr8uQ0NeCsX4Arjtt8+taS0a3vusu1ZWrvK6h+zEURODUN4XXvoxv/cDWEFIGkPxxtn0BoxY2\nJEmSloUhY4n1BYxuPil0lH+prwWN2rq+7lTTdquaNCYjN6nLUy1ErG2cCg15d6judS1U5d2lyhaM\n2gD0Sa0ZBg1p7zr9dDh0aNGlkKT9yZCxAmoBo5tPChhjBnj3zacdzF2OyRia8paM2tSFgL7H1/bN\nh6a8BaMWQjY9UaqYjw0akuDii+GssxZdiiZgnHnmokshSfvTzENGRPwscD/ga4BrgL8HHpdS+rdZ\nn0vjTQoYtb/Cl+vGBI3ttEzUQkbXLSqf10JG7drya67V38eGi7ylIx/8PdTSsekeVlo0ap/B0DVI\nq+iss+DssxddCknSTqzN4Zh3B34X+Cbg24HTgFdGxI3mcC5NMDQmo+/1UDepMa0bY8drTBNIxrR2\nVAeLT+iaVSvbULevvvtRvXd2k5IkSStq5i0ZKaV758sR8RDgw8Bh4PWzPp8mKyu0tdaMchxBWXEe\nasHYSYiYFB7KFox8cPhQK0D+1KnaQG/YOsA7H6tRtmTkX7BXtmTkr/P7NfZpU7XPSZIkaT/bjTEZ\nNwMS8LFdOJd61Cq0tb+ul0GjFj62M+h7KITkwaMWQGohpBv4PfRYWmgq+l1IKMdWdPMuNJRPjerr\nFlVedx4mxoaLoc9GkiRpv5tryIiIAH4LeH1K6W3zPJfGGRro3fdUpEndocpgMaklowwLY1oyyvmY\nloxuPvZL98rw0bVclKGj9j0ak+7f2MAhSZK0DObdkvF04LbAXed8Hs3ImO49WyrJ29hnUoCZ1zTN\nF+bNapIkSVo1cwsZEfF7wL2Bu6eU/nPS9ucBZxTrjrSTZm/M41qHpgPrm7sOrcXw++Uc6i0Rfa0R\n5XxtAw5eD6ddV59PnNabMvZOPdecT5Pu0aR7rPk42k65E4soiCRJK2wuIaMNGP8DOCel9L4x+1wI\n+MTC+apVcIe+D2IodHStAn0BJI0IHd125XrY3NLRLefzSFuDQx4Aaus2BYjK+k3XMRAkavdkUqCY\ndO81O7U/ThynefKEJEnaHfP4noyn0/yOvy9wdUR8UfvWiZTStbM+nyYbEyzyinP3xKS8Ij2pdaMM\nEflyFwzK5aExFSk2t1yUy2VLRjeddt3mkFG+f2AdDvQEk1roqIWQSa0YtXtXjg2pfSaSJEnLYh4t\nGY8AEvA3xfqHAhfN4XwaUAsXfa+HWjQmtV7kLRd5S0YXNvL1ZStF38Do7j0YbskoWy7GBIgyRJSv\nh8JELUD0vR7TmlF7LUmStJ/N43sy1mZ9TO3cmHAxTaiodY8aChGwtSvUpBaMvrLnLRllC0bekpEH\njjKE5PPydRk8ytBRCx+1Vp+xXacMGpIkadnsxvdkaI+Y1HJRho3avOweNWkO/WGjpgsZZfeocl6G\njDFTLWCMafHoCx1DrRy1+VDAMFxIkqRlYshYYkN/KR/TVaprycjn5Xtdt6h8XrZs5HM4FUKGHvla\nm+fhI+8uVQsR5SDwWQSIvrEp03SR6mtRKj8naZVdxmWLLsK+cIhDnMmZiy6GJFUZMlZEbWzGULjo\na8GojcUYEyJgeKD3UJnLinp37to4jG65HABe22ZSd6mhLlOD4WNE6Mivq/x8pFV3Lucuugj7wumc\nzjt4h0FD0p5kyFhytXBRWx4bOoYGfJehoxzs3YWQWvjY8uV1RQsGsbXcB8uxF5WwMNSK0TfYe+yT\npPJ7tClUDASMvs+h7zOTpD7Xci1XcqUhQ9KeZMhYAX3hYihY1MJFGSjydXmYyJehnfcM9C4DxMl1\nNJX1cjkvz1DrxKSuVNM8gaoWPiZ1qaqGj4HgUV67JEnSfmbIWCF9ldtJYaMLDrXvzyjHZJRh4+R8\nHQ4MdJtKbG3d6OZ9Y0uGgsM0A7proWKaaVKIGAoV5f2XJElaBoaMFTZt5bjWgtE339KSMWI+TZm6\ncR+Tnho16dG1eyF8SJIkLRtDxpKbNkiUYzFqAaIvXJQDwLcTMsaaFDK2EyYmjcEYGvC93fssSZK0\njAwZS2yoEjsULrov0ivHZZQhoxYmxrRg5GXL533rysp8V65akBgKG5NaMiaFkklBY9OUmmlSuDB0\nSJKkZWTIWBHBdOMxaqGjHItRCyB5+AiXxf0AAB0KSURBVOgLI53auItaECmXN3WXWoe1gQDR903e\n+WDuMkCM7SJVhotN926D6lOmyvu+5XMyaEiSpCVgyFgVRevAUBepvnBRDujOw0O+fPKUlVDRFxzW\nD5xaV1bYa8tdyNgUJjbgwEDI2M63e499wtRg4BhozbAFQ5IkLSNDxpLrWjC2rJ9ibEbZfapclweQ\nfOobm1ELI3kZ1w/0B5JuKkNGHiTWNraGi7Lloq9lo/Z6UteofN2W+zcQKsqWDUmSpGVhyFh2I1ow\n+lo08vnaRnOcPFB0YaEMDVuK0AaG2uNou/nG2tZyrh/oGe9QackYmvLgMTQvWzCmHRheGz8y9MV8\ntVYNSZKkZWDIWFJD/f1r874nRvXNa9/SPTTQu+sONWneF3rKeRd+akFhFlMZOqYJFpPmtc9g0mcn\nSZK0nxgyVkCtW05f952hLlNDE5xq7ShbOMY8qravjF2LBpyab6xtDRlDQWHMNmV4GDPweyhwjBmD\n4bgMSZK0rAwZS6yvz/9QkChbCroQ0Rc2cgfWT3WL6itLX4tF3l2qG2ze110qDxl9g7W75W5sxtht\na+unGfQ9ND5jzLgMw4YkSVoGhowlN1SJnTQuoxYuyvdha+goWzA6Yx9PWwaRcnlSyKi1WowJGTuZ\nxoy76AsdkiRJy8aQsQKmCRe1oAHjxmB0+r50rwwM+fqu9SI/d9mS0QWL7ulTtVAx6fWkYDL0/rSB\noy+A9H0OkiRJy8KQsULGjBUYEzrGDPTOjf3G7/y9LmDUuk91XbL6AsJQ+KiGkA1YmzJU9N2ffG4r\nhiRJWlWGjBVVCxdrCVI7eHsoSEwKGd287AKVz7vgUM6H3utaMbqwUwaCMYFjJ/O+dbWB39vtQiVJ\nkrQMDBlLrq+lovYe2+hClc9r5x0qU1mGfN1Q2NhYOxUy1jZOtURMGxBq703TJaovYEwKEWPvjSRJ\n0n5lyFgBQ+MAagGiXAebg8RQ96e+13lwKFs1ytaKbps8VORjMsqQUQsJk4LEUMDoa62YFETy4DEU\nOmqfgyRJ0jIxZCyxWrgol4cCB2x+wlS3XAseteW+suTLfZXv/HUeTLrl/OlSY8LGtNtO06JRhotp\nukvVPh+DhyRJ2u/WFl0A7a4xYaNWea5Nfd8l0TcdvP7U91bky7XptOuaKX89Zqrt3zf1lavvUbfb\nCRvThAutloh4ZkR8NCI2IuJjEfHU7L3LI+JRczrvJfm5eraZ2/klSavBlowVUKvEjhk3MNSlKu9a\n1bVs9J07KmXoO37eYlF2pepaMMqWjEjDIWDMNrXtpx2XMSlc1K5bqyki7gU8CDgHuBzYAK5ZaKHm\nJCLOAS4BbpZS+uSiyyNJ2h2GjCUXaes4i0ndpLoK/JD8G7pHTT1BoZy68nbfhdHNNw7ARr68Nr5L\nUx4ytjXfgMiPVyznrT9981rYGJpr6d0a+M+U0j/M6oARcTCldP2sjjdDAaR2LklaEXaXWkHTBI4x\nf9GvjWuY1HWqr8tU3kUqnx+couvUpv2K7lGT5tUnUJVdqCoDw2cZNLTcIuK5wO8AZ7Zdpd7T04Xp\nphHxgoj4VET8e0T8eHGcjYh4RET8RUR8Cvi5dv05EfEPEXFtRPxHRPzviCh/1h+MiN+NiE9ExEci\n4pcnlPm8iLi0Lcv7IuJpEXHj7P0zI+IlbbevT0XEWyPiXhFxS+A17WYfj4j1iHjONm6bJGmfMWSs\ngKHxALX3a0Gjtn5S0KiN35hmGhpPMWmMxaSxFn3jLDYFjQldpPruhV2mNMGjgF8A/h34IuBOPds9\nBngL8A3ArwO/HRH3KLa5AHgx8HXAcyLivwB/BfwDcDvgEcDDgCcU+z0EuK4996OA8yPiYQNlXgd+\nEvhamm5e3wo8KXv/6cANgLu1ZXkc8CngfcD9221uA3wJ8OiB80iSloTdpVZQV7ntulHl67pKM2x+\nrGypfJJUPn6iPF6ty1bXLat8dG03dV2ihpb7xkb0VfznuVwLHZNaisp7p9WQUroqIq4C1lNKHwGI\nqPYk+ruU0lPa178XEXcFzgNenW3z/JTS87qFiHgi8L6UUjdo+98i4gKakJK3VrwvpXR++/qdEXG7\n9tjP7inz72SL742InweeATyyXfdlwItSSm9rl6/IyvSx9uVHHJMhSavDkLHE8gp+uTz01/VueShs\n9D2+ti9s5N/oXZahCxi15Tx85K9rIWMoCIx9b8zroRaNMd3Qys8nX5Yyb6gsl60Ax4rlr6ns93fA\nTSLiFimlf2/XvbFy7PMjIlJKW/4lRsS3A49vj39Tmt8dN4yIG6WUrqHp/vWMiPhO4FXA/00pvXXi\nFUqSlpYhY0WUFfv8dfd+HirKij7Uv5CvDBF9YaI7Xl9oKANEbV6u6wsCtdAxtN2s9x0ai9EXNmqv\npYryX8jVxXJUtun+527rX1c7ruKlwNNoxn18DLg78CzgNOCalNKzI+LlwH8D7gn8bEScn1J62nbO\nyXnAGcW6I+0kSdqRo0ePcvTo0U3rTpw4MfPzGDJWQF7Zr4WLcl4Gj/Ibt2Hrt34HzdOfNq2rhI88\nhNRCT+185Td910LG2Pl29pl232mn/P5LmTtXlt8+YZ+3Ad9TrLsrcFVK6QMDx74L8M5aKwZwGFhL\nKT2mWxERDyw3ao//TOCZEfFrwMNpgsln200OTCj7KRcCZ4/eWpI0hSNHjnDkyOa/2hw/fpzDhw/P\n9DyGjCXVVdz71ufzbn03r1Xwy1CxZZ6Atfrxu0AwNjz0tWSU24yt8E8TDma9/5bgUdzrfJ5/RhJw\n14h4DPAXNK0DDwDuPWGfpwOPjojfBX6PpnvTLwK/WWz3ZRHxGzSh4DDN2Irzeo75LpqnUT2KpkXj\nbsCP5htExIXAXwP/Bnw+zcDwbnzGe2laUe4TES+jafkoW2AkSUvGkLHkyjBRCxh9YQPagLHWfFPY\npNDRtVTkr/vWDQWRvnAyJmT0VvoTxNhtt/H+2LEZXYeVWsAwXKy08tNPNMHgjjQh4QRwXkrpVQP7\nkFL6j4i4N/AU4J9oujb9IfDEYr+LgBsBbwKuBy5MKT2rduyU0qURcT7wWODXgNfRjM+4KNv+AE2o\nuQXwSZrAcX5WpgtoBp8/p93vhwbvhiRp34t66/guFiDibODYMWwdn6VEvWWgtjx2u2m23fTeWtOV\naqbHjHqFfmh5zOuZHTMLNds+5qL/ES2R4zR/rgcOp5SOL7Qw6tX9PsBfCKMd4xhne7Mk7VDWXWpm\nvydtyVgReatFuZz/Bb1rOciXuwp+udy97qbueGWrRkoQRTgow0L3umyxGDrfUMvBpEr92G22e6wo\nlrt7ni/n68rPSZIkaT8zZCyxrvJerhtahs2V+TJcVEPEiPCQT31BYqgFpTaNCQRj39vp+9vdN/8c\nDBiSJGlZGDJWQC1s5O8NKQNArZVjKATU1uffodG376Rj94WM7QSAaY7TXfe0+5b3u+99SZKkZWDI\nWHJdRX4WFdnuGF1g6cLCpDDQFyDGBImyO1Z+zjEV+y4QdK+769jNKT93fh8lSZKWlSFjBU2q5I5p\nYZi0HUwODIPvB6SBbbrz97UM1Cr683x/VueQJElaBoaMFZFXYvNKem272jiOsd2huuNvZ920+w91\nPRpbyd/Julkcs7zPhg1JkrQMDBkrIA8OZdjIl8uAkYeIAFLqr/jny9t9b9rjdGXsq8jny9veFmDe\n5yiChUFDkiTtd4aMJVcGjDJs9I3XqO5XtF7kr7tj9b2e9P52jtGVbagCP+n1LI6x02Pn20uSJC0D\nQ8YSqwWFMZXZfNsyUMDkEDDmvVns35W1nNfW7fS9eR+7fC1JkrSfGTJWQBkapgkck/YfEyTmMc/L\nNo/5PI89dE5JkqRlMPOQERGPAH4M+PJ21b8Cv5xSevmsz6XxxgaMvu2GKvuLWgecHDPRlT2/jtp8\nr68zcEiSpGUwj5aM9wOPA97VLj8E+IuI+IaU0mVzOJ8GDHWZmtSaMWnfzlxfx8kMsWWbvJzL8lqS\nJGkZzDxkpJT+qlj1hIj4MeDOgCFjAcqwAONaM4a2Lyv7814uw0atzDNdhi0nnPk5JixLkiTtV3Md\nkxERa8D3AZ8DvGGe59KwPDh0y51a4Ojdvq3sl9vXWhj61k+z7dD6mlpFfShMjT4GVFPOTI5tuJAk\nSUtmLiEjIr6OJlScDlwF3C+l9PZ5nEvjTVuZrW2foq1wjzRNQJhm22nM4roXcWxJkqT9al4tGW8H\nbg/cDLg/cFFEfItBY2+aZ6Va05tT1pIkSdo1cwkZKaXrgfe0i8cj4huBR9M8darqPOCMYt2RdtL0\nrKhqVR1tp9yJRRREkqQVtlvfk7EG3HBogwuBs3enLJKWWO2PE8eBwwsoiyRJq2oe35PxROCvaR5l\n+7nADwDnAPec9bkkSZIk7T3zaMn4IuAi4EtoeilcCtwzpfSaOZxLkiRJ0h4zj+/J+OFZH1OSJEnS\n/rG26AJIkiRJWi6GDEmSJEkzZciQJGkfOp3TOcShRRdDkqp26xG2kiSNcjEXcxZnLboYe94hDnEm\nZy66GJJUZciQJO0pZ3EWZ/vNSZK0r9ldSpIkSdJMGTIkSZIkzZQhQ5IkSdJMGTIkSZIkzZQhQ5Ik\nSdJMGTIkSZIkzZQhQ5IkSdJMGTIkSZIkzZQhQ5IkSdJMGTIkSZIkzdTBRRdAkqRNLrts0SWQpP3l\n0CE488xFl2ITQ4YkaW8599xFl0CS9pfTT4d3vGNPBQ27S0mSJEn72bXXwpVXLroUmxgyJEmSJM2U\nIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJEmS\nJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBky\nJEmSJM2UIUOSJEnSTBkyJEmSJM2UIUOSJEnSTBkyJGkfi4gHR8THRmy3ERH33eG5LomIp2bLl0fE\no6bY/8ER8fGdlEGStD8YMiRpf3sh8FXdQkRcEBFv2aVz3xF45pT7pHkURJK0txxcdAEkSduXUvoM\n8Jly9S6d+6O7cR5J0v5jS4YkLVA0fjYi3hMRn46It0TE/dv3zmm7Od07Iv45Iq6JiDdExNdm+5/s\nghQRDwYuAG7f7rceEQ/KTveFEfHiiLg6Iv4tIu5TlOXrIuJlEXFVRHwwIi6KiC8YKPum7lIRcV5E\nXBoRn4qI90XE0yLixjO6VZKkfcSQIUmL9XPAucCPALcFLgT+T0TcPdvmycB5NN2TPgK8JCIOZO93\nLRd/DPwm8K/AFwFf0q7r/AJN96qvB14GPD8ibgYQEWcArwaOAWcD3wncHPiTKa5lHfhJ4GuBBwHf\nCjxpiv0lSUvC7lKStCARcQPgZ4F7pJT+oV19RRswfhT4w3bdL6aUXtPu82Dg34H7AS/Kj5dSujYi\nPgVcn1L6SOWUz00p/Ul7nJ+jCQTfCLwSeCRwPKX081n5fhh4X0TcOqX0rknXk1L6nWzxvRHx88Az\n2mNLklaIIUOSFufWwOcA/y8iIlt/GtAN3k7AG7s3Ukofj4h3AGdt43xvzY7z6Yi4iqa1AuD2wLe1\n63IJ+EpgYsiIiG8HHg98DXBTmt8xN4yIG6WUrhlbyPOAM4p1R9pJkrQzR48e5ejRo5vWnThxYubn\nMWRI0uLcpJ3fG/iP4r3P0ISQPtsZ3H1d5Rhdt9mbAC8BHgtEsd1/TjpwRNwSeCnwNJouYB8D7g48\niyY0jQ4ZF9L015Ikzd6RI0c4cmTzn22OHz/O4cOHZ3qeuY/JaAc0buTPVpckAfA2mjBxy5TSe4rp\nA+02Ady52yEiPo/mkbWX9Rzzs8CBnveGHKcZS/HeSlnGBITDwFpK6TEppTe13au+dBvlkCQtgbm2\nZETEnYCHA/88z/NI0n6UUvpURPwGcGE7kPv1ND2F7gqcAN7XbvoL7RfufRh4Is3g77/oOewVwK0i\n4vY0YzeuSil9dkRxngb8MPDCiHgyTUvEbYDvBx6WUprUcvIu4GD7tKmXAnejGVciSVpBc2vJiIib\nABfT/NL6xLzOI0n7WTvQ+pdpxjK8Dfhrmu5Tl3ebtO/9NvCPwBcC90kpXd9zyP8LvBy4hCaUPDA7\nzpbTZ+X4T5pwswa8ArgUeCrw8SxglMfI978UOJ+mu9VbaYZQPL7/yiVJy2yeLRlPA16aUnpN+4QR\nSVJFSun3gN8r10fEOe3L16eUvr5n3+cBz8uWPwt8X2W7LV2oUkqfXyy/G3jAQDm/rVj+imL5t2nC\nUO75fWWVJC2vuYSMiHgg8A00z3SXJG1fOQhbkqQ9b+YhIyJuAfwW8B0ppfJJJr18ZKGkWTjaTrnZ\nP5hvV23nKVKSJC3UPFoyDtP0GT6WPff9APAtEfFI4Ia1AYQ+slDSLNT+OHGc5gfTfpNSei3be1KU\nJEkLNY+Q8Sqg7Dv8RzSPW/z1EU8okSRJkrSPzTxkpJSupnlCykkRcTXw0ZRS33PdJUmSJC2JuX8Z\nX8vWC0mSJGlFzPXL+DrlYw8lSZIkLa/dasmQJEmStCIMGZIkSZJmypAhSZIkaaYMGZIkSZJmypAh\nSZIkaaYMGZIkSZJmypAhSZIkaaYMGZIkSZJmypAhSZIkaaYMGZIkSZJmypAhSZIkaaYMGZIkSZJm\nypAhSZIkaaYMGZIkSZJmypAhSZIkaaYMGZIkSdJ+dvrpcOjQokuxycFFF2ARjgJHFl2IOVv2a/T6\n9r9VuEZt08UXw1lnLboUO3L05S/nyL3utehi7NiyXAcsz7V4HXvPnriWQ4fgzDMXW4ZSSmmhE3A2\nkI5BSrs03WcXz7Woadmv0evb/9NuXuMxSDTT2Yv+mec04vfBsWNpv7vPfe6z6CLMxLJcR0rLcy1e\nx96zDNdy7Nixmf+etLuUJEmSpJkyZEiSJEmaKUOGJEmSpJnaCwO/Twe4bBdPeAI4vovnW4Rlv0av\nb//bzWvMfr6cvkun1PY0vw8u283fCPNx4sQJjh/f//+Ll+U6YHmuxevYe5bhWrKfuzP7PRmpGWy3\nMBHxP4HnL7QQklbFD6SUXrDoQqjO3weStHAz+z25F0LGFwDfCVwBXLvQwkhaVqcDXw68IqX00QWX\nRT38fSBJCzPz35MLDxmSJEmSlosDvyVJkiTNlCFDkiRJ0kwZMiRJkiTNlCFDkiRJ0kytXMiIiJ+I\niMsj4pqIeGNE3GnRZZqViLh7RLwkIj4QERsRcd9Fl2mWIuJnI+JNEfHJiPhQRPxZRHzVoss1KxHx\niIj454g40U5/HxH3WnS55qX9PDci4qmLLot2z7Q/gyPieyPisnb7f46I79qtsg6Z5joi4rYR8aJ2\n+42IeNRulnXIlNfxwxHxuoj4WDv9v730O3TKa7lfRPxjRHw8Ij4VEW+JiHN3s7x9tltPiYgHtv++\nXjzvMo4x5efx4Lbs6+18IyI+vZvlHbKNn1tnRMTTIuI/2n3evhd+n0/5mVySfRb59NKx51upkBER\n3w/8JnABcAfgn4FXRMShhRZsdm4M/BPwE8AyPjbs7sDvAt8EfDtwGvDKiLjRQks1O+8HHgccbqfX\nAH8REWcttFRz0P5gezjN/0GtiGl/BkfEXYAXAH8IfAPw58CfR8Rtd6fEddv4XfI5wLtp/n//564U\ncoRtXMc5NJ/HfwXuTPMz65UR8SXzL+2wbVzLR4FfpbmOrweeCzw3Ir5jF4rba7v1lIi4JfAU4HVz\nL+QI27yOE8AXZ9Mt513OMbbxc+s04FXAmcD3AF9N8/vuA7tS4B7b+Ezux+bP4+uAdeBPRp80pbQy\nE/BG4Lez5QD+HXjsoss2h2vdAO676HLM+RoPtdd5t0WXZY7X+FHgoYsux4yv6SbAO4BvAy4Bnrro\nMjnt2mc/1c9g4IXAS4p1bwCevp+uo9j3cuBRi/4sdnod7fZrNBXDc/f7tbT7HAN+ab9dR/s5/C3w\nUJqw9OL99nkADwY+tuhyz+haHgG8Eziw6LLv9N9Wsf9PAZ8AbjT2nCvTktEmy8PAq7t1qblrrwLu\nsqhyaUduRtNi87FFF2TWImItIh5I8xfQNyy6PDP2NOClKaXXLLog2j3b/Bl8l/b93CsGtp+7Zfld\nMqPruDFNi/JCfwbP4loi4h7AVwGvnUcZR5Zhu9dxAfDhlNJz51vCcXZwHTeJiCsi4n0RsfAWS9j2\ntdyH9o8hEfHBiHhrNN2DF1bnntH/9x8CjqaUrhl73oPTFHKfOwQcAD5UrP8QTVOW9pGICOC3gNen\nlN626PLMSkR8Hc0Pp9OBq4D7pZTevthSzU4bnL4BuOOiy6Jdt52fwV/cs/0Xz7ZoU1mW3yWzuI4n\n0XQBKYPgbtvWtUTETWnKf0PgeuDHF/zHj6mvIyLuStOCcfv5Fm0q2/k83kFTib0UOAP4GeDvI+Jr\nU0qL7Ga0nWv5CpqW+ouB7wJuAzy9Pc6vzqeYE+3o/3tEfCPwtTT/1kZbpZDRJ1jO8QvL7unAbYG7\nLrogM/Z2ml8WNwPuD1wUEd+yDEEjIm5BEwy/I6V03aLLoz1j2p/Be/Vn9l4t17RGXUdEPB74PuCc\nlNJn516q7Zl0LVfR/Ly9CXAP4MKIeE9KaU+Ma8hUryMibgL8H+DhKaWP73qpptf7eaSU3kjTnafZ\nMOINwGXAj9C01Ow1Q/+21mgq7z/Stha8JSK+FHgMiwsZfcb+3HoY8C8ppWPTHHyVQsaVNANWvqhY\nf3O2JjvtYRHxe8C9gbunlPbMIMpZSCldD7ynXTze/vXg0cCPLa5UM3MY+ELgWNsSBc1fVr4lIh75\n/9u7YxAprjCA4/8nmhiushBNOAvRoAThLGwMNomoRQqxEgkIdqYLiYoSBQ2YgBBCGkE7A1EQK9Om\nUERtIhcE0S4gioKFlahH4Fl8z7isos7cu53b3f8PBu6W2Z333ex+s9/MvO+AD0tC1mhqk4MfNlx/\nEEblWNI6jpTSPuAAsDnnfGtuhtdIq1hKvnmZb2+W23MO0d3k6aZxrCImR//Zk1MXAKSUZoA1Oed/\n52isbzPrz0jO+b+U0jSwuvLYmmoTywNgpu94dhtYnlJaWI7zgzabz/tHwE7gcNONjs2cjHLm9AZx\ntgL4/5abzcC1rsalZkqBsR34Iud8t+vxDMAC4lL+KPiL6OKynjh7OAX8TVxSnrLAGG0tc/D13vWL\nLXQ4T2lUjiVt40gp7Qd+ALblnKfnepzvo+I+6TTftojjNq/n1ItEZ8IpovvXwNXYH2X+wjo67sbW\nMparvF4crQEedFRgzHaf7AQ+AP5os+GxWYhLu0+B3cBa4BTRvWdp12OrFN8EkVjWE12Xvi2/r+h6\nbJXiOwk8JlrZLutZFnc9tkrxHQc2EWem1gE/E/cJf9n12OYwZrtLjdHyrhwM/A781LP+RmAG+I44\nSB8FngGfDVkci3py831iLsMUsGrI4jhQ/v47+nLwxBC+tw4SrdBXlvW/B57TcTe/pnG84fnzpbtU\n0/1xhDiBsJJor3oOeAKsHcJYJomua78R8zG+Iq7KHhymOHqedwU422ab43S7FDnn86Uf8I9EYvyH\nOBvzqNuRVbOB+NKWy/JLefwMMaFq2O0l4rrU9/ge4sMx7JYRcXxMJKibwNY82l2YvHoxRt4jB08S\nhfXL9a+nlHYRBfhxoi3k9txxs4emcQCfANO8er/vK8tlYoJoJ1rE8Q1RMF3oe6lj5TU60yKWCaLT\n3STxxesO8HXOuT+2gWoRx7zUIo4lwGmiqcNj4qz7xjwP5iO2yFv3UkpbgV+J/0Vxv/x8YqAD79Pm\nvZVS+hT4nCgAG0ulSpEkSZKkKsZmToYkSZKkwbDIkCRJklSVRYYkSZKkqiwyJEmSJFVlkSFJkiSp\nKosMSZIkSVVZZEiSJEmqyiJDkiRJUlUWGZIkSZKqssiQJEmSVJVFhiRJkqSqLDIkSZIkVfUCege0\nH/7iHHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b9af9e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 984\n",
    "show_results(test['patches'][target],\n",
    "             test['probabilities'][target],\n",
    "             test['weight_neighbourhoods'][target],\n",
    "             test['labels'][target],\n",
    "             context_model)\n",
    "#print categories[np.argmax(test['labels'][target])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
