{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy.io import loadmat\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import classifier_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import context_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1559 patches because too close to image border\n",
      "Dropped 523 patches because too close to image border\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'epithelial',\n",
    "    'fibroblast',\n",
    "    'inflammatory',\n",
    "    'others',\n",
    "]\n",
    "\n",
    "train, test = utils.get_augmented_dataset_divided_per_image(categories)\n",
    "\n",
    "# Carve out a validation set from our test set\n",
    "# Split it 50/50\n",
    "# Need to shuffle the test set before splitting\n",
    "np.random.seed(8080) # repeatability\n",
    "N = len(test['patches'])\n",
    "new_N = N/2\n",
    "perm = np.random.permutation(N)\n",
    "validation = {}\n",
    "for k in list(test.iterkeys()):\n",
    "    values = test[k]\n",
    "    test[k], validation[k] = np.split(values[perm], [new_N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train hsv_factors (60000, 3)\n",
      "train deltas (60000, 2)\n",
      "train patches (60000, 27, 27, 3)\n",
      "train rots (60000,)\n",
      "train labels (60000, 4)\n",
      "train flips (60000,)\n",
      "train centres (60000, 2)\n",
      "train img_ids (60000,)\n",
      "test img_ids (2296,)\n",
      "test labels (2296, 4)\n",
      "test patches (2296, 27, 27, 3)\n",
      "test centres (2296, 2)\n",
      "validation img_ids (2297,)\n",
      "validation labels (2297, 4)\n",
      "validation patches (2297, 27, 27, 3)\n",
      "validation centres (2297, 2)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in train.iteritems():\n",
    "    print \"train\", k, v.shape\n",
    "for (k, v) in test.iteritems():\n",
    "    print \"test\", k, v.shape\n",
    "for (k, v) in validation.iteritems():\n",
    "    print \"validation\", k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99]\n",
      "Test: [9, 12, 21, 25, 36, 37, 39, 44, 46, 47, 58, 64, 65, 67, 70, 81, 83, 87, 88, 96]\n",
      "Intersection: []\n"
     ]
    }
   ],
   "source": [
    "# Sanity-check that the test and train data come from different images\n",
    "test_img_ids = set(test['img_ids'])\n",
    "train_img_ids = set(train['img_ids'])\n",
    "print \"Train:\", sorted(train_img_ids)\n",
    "print \"Test:\", sorted(test_img_ids)\n",
    "print \"Intersection:\", sorted(train_img_ids.intersection(test_img_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DELETE ME\n",
    "# Temp for spot check\n",
    "(all_imgs, _, _) = utils.get_dataset(100, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff020120e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFeCAYAAABU066vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJptssskJZYPwJptssskJ5f8DMf+mDQnYqpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff018853f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFeCAYAAABU066vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJptssskJZYPwJptssskJ5f8DMf+mDQnYqpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff01886c690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DELETE ME\n",
    "# Spot check\n",
    "i = 420\n",
    "plt.figure()\n",
    "plt.imshow(test['patches'][i])\n",
    "(x, y) = test['centres'][i]\n",
    "img_id = test['img_ids'][i]\n",
    "img = all_imgs[img_id]\n",
    "plt.figure()\n",
    "plt.imshow(img[y-13:y+14,x-13:x+14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Softmax CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass # sess doesn't exist yet!\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "patch_model = cnn_classifier.SoftmaxCNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From cnn_classifier.py:86 in train_loop.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0, step 0, training loss 1.386460, test_loss 1.387063, accuracy = 0.207272/0.250163, f1 = nan\n",
      "Epoch 0, step 25, training loss 1.386188, test_loss 1.387260, accuracy = 0.230786/0.259525, f1 = nan\n",
      "Epoch 0, step 50, training loss 1.384773, test_loss 1.387609, accuracy = 0.238189/0.249946, f1 = nan\n",
      "Epoch 0, step 75, training loss 1.386149, test_loss 1.388587, accuracy = 0.238842/0.251034, f1 = nan\n",
      "Epoch 0, step 100, training loss 1.385368, test_loss 1.388743, accuracy = 0.241890/0.266057, f1 = nan\n",
      "Epoch 0, step 125, training loss 1.384659, test_loss 1.388955, accuracy = 0.204224/0.246897, f1 = nan\n",
      "Epoch 0, step 150, training loss 1.385288, test_loss 1.390291, accuracy = 0.209885/0.249075, f1 = nan\n",
      "Epoch 0, step 175, training loss 1.384866, test_loss 1.389790, accuracy = 0.223166/0.249728, f1 = nan\n",
      "Epoch 0, step 200, training loss 1.382402, test_loss 1.388770, accuracy = 0.224907/0.250163, f1 = nan\n",
      "Epoch 0, step 225, training loss 1.382191, test_loss 1.389419, accuracy = 0.248204/0.249728, f1 = nan\n",
      "Epoch 0, step 250, training loss 1.381043, test_loss 1.388842, accuracy = 0.253211/0.249728, f1 = nan\n",
      "Epoch 0, step 275, training loss 1.379149, test_loss 1.389566, accuracy = 0.246680/0.250599, f1 = nan\n",
      "Epoch 0, step 300, training loss 1.380347, test_loss 1.392835, accuracy = 0.238624/0.253865, f1 = nan\n",
      "Epoch 0, step 325, training loss 1.381823, test_loss 1.390499, accuracy = 0.146092/0.094927, f1 = nan\n",
      "Epoch 0, step 350, training loss 1.380241, test_loss 1.393183, accuracy = 0.166558/0.124537, f1 = nan\n",
      "Epoch 0, step 375, training loss 1.384148, test_loss 1.388877, accuracy = 0.175702/0.132593, f1 = 0.084149\n",
      "Epoch 0, step 400, training loss 1.386673, test_loss 1.390580, accuracy = 0.216416/0.255824, f1 = 0.132885\n",
      "Epoch 0, step 425, training loss 1.379036, test_loss 1.394514, accuracy = 0.212280/0.253865, f1 = 0.118529\n",
      "Epoch 0, step 450, training loss 1.373980, test_loss 1.378196, accuracy = 0.325495/0.376878, f1 = 0.402153\n",
      "Epoch 0, step 475, training loss 1.363669, test_loss 1.380568, accuracy = 0.279338/0.332898, f1 = 0.275373\n",
      "Epoch 0, step 500, training loss 1.350486, test_loss 1.374401, accuracy = 0.287829/0.261703, f1 = 0.290430\n",
      "Epoch 0, step 525, training loss 1.336582, test_loss 1.349814, accuracy = 0.409536/0.443719, f1 = 0.469767\n",
      "Epoch 0, step 550, training loss 1.336406, test_loss 1.297770, accuracy = 0.531461/0.550620, f1 = 0.477718\n",
      "Epoch 0, step 575, training loss 1.303578, test_loss 1.513431, accuracy = 0.263009/0.279991, f1 = nan\n",
      "End of epoch 0, training loss 1.246720, test_loss 1.248178, accuracy = 0.461572/0.468321, f1 = 0.481906\n",
      "Confusion matrix:\n",
      "[[1009  145  757    0]\n",
      " [  53  633  453    8]\n",
      " [  81  552  474   15]\n",
      " [   9  298   71   35]]\n",
      "Epoch 1, step 0, training loss 1.276942, test_loss 1.212122, accuracy = 0.482038/0.502504, f1 = 0.506036\n",
      "Epoch 1, step 25, training loss 1.226034, test_loss 1.186796, accuracy = 0.482038/0.518398, f1 = 0.515885\n",
      "Epoch 1, step 50, training loss 1.259481, test_loss 1.337368, accuracy = 0.349663/0.342478, f1 = 0.370396\n",
      "Epoch 1, step 75, training loss 1.320439, test_loss 1.245132, accuracy = 0.433268/0.438493, f1 = 0.458351\n",
      "Epoch 1, step 100, training loss 1.264940, test_loss 1.163975, accuracy = 0.524929/0.541476, f1 = 0.550156\n",
      "Epoch 1, step 125, training loss 1.300692, test_loss 1.242020, accuracy = 0.388853/0.381450, f1 = 0.385592\n",
      "Epoch 1, step 150, training loss 1.231230, test_loss 1.230110, accuracy = 0.461572/0.487045, f1 = 0.498851\n",
      "Epoch 1, step 175, training loss 1.413474, test_loss 1.296912, accuracy = 0.415632/0.436969, f1 = 0.457942\n",
      "Epoch 1, step 200, training loss 1.289042, test_loss 1.235997, accuracy = 0.473547/0.484433, f1 = 0.504073\n",
      "Epoch 1, step 225, training loss 1.181049, test_loss 1.135432, accuracy = 0.545831/0.567385, f1 = 0.568751\n",
      "Epoch 1, step 250, training loss 1.354496, test_loss 1.115469, accuracy = 0.554757/0.570869, f1 = 0.566425\n",
      "Epoch 1, step 275, training loss 1.190600, test_loss 1.276713, accuracy = 0.367080/0.366645, f1 = 0.373561\n",
      "Epoch 1, step 300, training loss 1.259583, test_loss 1.182765, accuracy = 0.426954/0.428043, f1 = 0.431610\n",
      "Epoch 1, step 325, training loss 1.270161, test_loss 1.021815, accuracy = 0.587851/0.596125, f1 = 0.545862\n",
      "Epoch 1, step 350, training loss 1.210265, test_loss 1.081088, accuracy = 0.607011/0.627477, f1 = 0.631164\n",
      "Epoch 1, step 375, training loss 1.137500, test_loss 1.002884, accuracy = 0.621380/0.630742, f1 = 0.624739\n",
      "Epoch 1, step 400, training loss 1.170973, test_loss 1.030918, accuracy = 0.603092/0.629218, f1 = 0.631931\n",
      "Epoch 1, step 425, training loss 1.226030, test_loss 1.007832, accuracy = 0.642935/0.652515, f1 = 0.651236\n",
      "Epoch 1, step 450, training loss 1.267530, test_loss 1.017716, accuracy = 0.642282/0.663401, f1 = 0.657708\n",
      "Epoch 1, step 475, training loss 1.108221, test_loss 0.945388, accuracy = 0.658829/0.662094, f1 = 0.636456\n",
      "Epoch 1, step 500, training loss 1.090078, test_loss 1.004292, accuracy = 0.621163/0.636839, f1 = 0.641807\n",
      "Epoch 1, step 525, training loss 1.057306, test_loss 1.021885, accuracy = 0.601568/0.613107, f1 = 0.611092\n",
      "Epoch 1, step 550, training loss 1.105320, test_loss 0.972471, accuracy = 0.650773/0.661441, f1 = 0.667233\n",
      "Epoch 1, step 575, training loss 1.205214, test_loss 1.311538, accuracy = 0.462007/0.466144, f1 = 0.450006\n",
      "End of epoch 1, training loss 1.086401, test_loss 1.112216, accuracy = 0.554757/0.566514, f1 = 0.578757\n",
      "Confusion matrix:\n",
      "[[925 697 260  29]\n",
      " [ 17 553 270 307]\n",
      " [  9  57 878 178]\n",
      " [  5  44 118 246]]\n",
      "Epoch 2, step 0, training loss 1.161716, test_loss 1.063974, accuracy = 0.586762/0.597866, f1 = 0.607000\n",
      "Epoch 2, step 25, training loss 1.064130, test_loss 0.879105, accuracy = 0.686915/0.689963, f1 = 0.688352\n",
      "Epoch 2, step 50, training loss 1.025201, test_loss 1.054811, accuracy = 0.606140/0.610712, f1 = 0.607149\n",
      "Epoch 2, step 75, training loss 1.126813, test_loss 1.037734, accuracy = 0.601132/0.602439, f1 = 0.593923\n",
      "Epoch 2, step 100, training loss 1.018319, test_loss 0.925388, accuracy = 0.652950/0.661224, f1 = 0.658926\n",
      "Epoch 2, step 125, training loss 1.126041, test_loss 0.949307, accuracy = 0.639234/0.646418, f1 = 0.645926\n",
      "Epoch 2, step 150, training loss 1.160683, test_loss 0.868390, accuracy = 0.678641/0.687350, f1 = 0.666748\n",
      "Epoch 2, step 175, training loss 1.097866, test_loss 0.827946, accuracy = 0.698019/0.711300, f1 = 0.695766\n",
      "Epoch 2, step 200, training loss 1.104402, test_loss 0.874465, accuracy = 0.682560/0.689092, f1 = 0.694139\n",
      "Epoch 2, step 225, training loss 1.001872, test_loss 0.983025, accuracy = 0.595471/0.612889, f1 = 0.632719\n",
      "Epoch 2, step 250, training loss 1.213957, test_loss 0.991587, accuracy = 0.613542/0.622469, f1 = 0.631502\n",
      "Epoch 2, step 275, training loss 1.131680, test_loss 0.868000, accuracy = 0.669497/0.677553, f1 = 0.681932\n",
      "Epoch 2, step 300, training loss 1.176559, test_loss 1.220179, accuracy = 0.453299/0.459612, f1 = 0.490218\n",
      "Epoch 2, step 325, training loss 1.087659, test_loss 0.823498, accuracy = 0.698672/0.702373, f1 = 0.683376\n",
      "Epoch 2, step 350, training loss 1.080558, test_loss 0.898444, accuracy = 0.656869/0.657087, f1 = 0.666546\n",
      "Epoch 2, step 375, training loss 1.051497, test_loss 0.891011, accuracy = 0.656869/0.660353, f1 = 0.674857\n",
      "Epoch 2, step 400, training loss 0.982699, test_loss 0.840466, accuracy = 0.690834/0.697583, f1 = 0.693169\n",
      "Epoch 2, step 425, training loss 1.041759, test_loss 0.843968, accuracy = 0.687350/0.690616, f1 = 0.692371\n",
      "Epoch 2, step 450, training loss 1.046906, test_loss 1.062970, accuracy = 0.593294/0.595036, f1 = 0.590833\n",
      "Epoch 2, step 475, training loss 1.099475, test_loss 0.803631, accuracy = 0.703462/0.706292, f1 = 0.694720\n",
      "Epoch 2, step 500, training loss 0.961690, test_loss 0.954990, accuracy = 0.626170/0.628783, f1 = 0.632848\n",
      "Epoch 2, step 525, training loss 0.901901, test_loss 0.916335, accuracy = 0.657087/0.658393, f1 = 0.659718\n",
      "Epoch 2, step 550, training loss 0.992557, test_loss 0.859488, accuracy = 0.677770/0.681690, f1 = 0.686534\n",
      "Epoch 2, step 575, training loss 1.164375, test_loss 1.264543, accuracy = 0.486392/0.484433, f1 = 0.474389\n",
      "End of epoch 2, training loss 0.986793, test_loss 0.991141, accuracy = 0.606575/0.616373, f1 = 0.623616\n",
      "Confusion matrix:\n",
      "[[1028  632  231   20]\n",
      " [  28  666  263  190]\n",
      " [   8   51  954  109]\n",
      " [   8   71  151  183]]\n",
      "Epoch 3, step 0, training loss 1.038434, test_loss 1.044958, accuracy = 0.579360/0.587198, f1 = 0.594246\n",
      "Epoch 3, step 25, training loss 0.984690, test_loss 0.838698, accuracy = 0.682560/0.688439, f1 = 0.694297\n",
      "Epoch 3, step 50, training loss 0.931356, test_loss 0.965236, accuracy = 0.650120/0.649467, f1 = 0.649629\n",
      "Epoch 3, step 75, training loss 1.104674, test_loss 1.061080, accuracy = 0.589593/0.595471, f1 = 0.589267\n",
      "Epoch 3, step 100, training loss 0.968934, test_loss 0.820547, accuracy = 0.703680/0.705204, f1 = 0.696364\n",
      "Epoch 3, step 125, training loss 1.067223, test_loss 0.884964, accuracy = 0.673416/0.681254, f1 = 0.681339\n",
      "Epoch 3, step 150, training loss 1.040252, test_loss 0.812841, accuracy = 0.688221/0.695188, f1 = 0.661830\n",
      "Epoch 3, step 175, training loss 1.062288, test_loss 0.767783, accuracy = 0.721315/0.724799, f1 = 0.710670\n",
      "Epoch 3, step 200, training loss 1.109430, test_loss 0.865219, accuracy = 0.684520/0.689528, f1 = 0.688945\n",
      "Epoch 3, step 225, training loss 0.952108, test_loss 0.902500, accuracy = 0.658611/0.663183, f1 = 0.666359\n",
      "Epoch 3, step 250, training loss 1.177659, test_loss 0.821641, accuracy = 0.708687/0.712388, f1 = 0.705628\n",
      "Epoch 3, step 275, training loss 1.047324, test_loss 0.991831, accuracy = 0.603963/0.610712, f1 = 0.623538\n",
      "Epoch 3, step 300, training loss 1.118716, test_loss 0.934046, accuracy = 0.600261/0.610059, f1 = 0.636517\n",
      "Epoch 3, step 325, training loss 1.015528, test_loss 0.777722, accuracy = 0.716743/0.721968, f1 = 0.704505\n",
      "Epoch 3, step 350, training loss 1.063661, test_loss 0.886616, accuracy = 0.664054/0.670150, f1 = 0.674672\n",
      "Epoch 3, step 375, training loss 0.955661, test_loss 0.813337, accuracy = 0.701285/0.705639, f1 = 0.711063\n",
      "Epoch 3, step 400, training loss 0.949900, test_loss 0.804644, accuracy = 0.705857/0.709123, f1 = 0.707383\n",
      "Epoch 3, step 425, training loss 1.021734, test_loss 0.800582, accuracy = 0.703244/0.711953, f1 = 0.712466\n",
      "Epoch 3, step 450, training loss 1.012461, test_loss 1.057983, accuracy = 0.603963/0.606575, f1 = 0.604404\n",
      "Epoch 3, step 475, training loss 0.937369, test_loss 0.764448, accuracy = 0.723928/0.726105, f1 = 0.700321\n",
      "Epoch 3, step 500, training loss 0.916922, test_loss 0.826260, accuracy = 0.682343/0.686262, f1 = 0.677817\n",
      "Epoch 3, step 525, training loss 0.840589, test_loss 0.844544, accuracy = 0.694971/0.696059, f1 = 0.692484\n",
      "Epoch 3, step 550, training loss 0.982263, test_loss 0.804963, accuracy = 0.701720/0.713695, f1 = 0.713348\n",
      "Epoch 3, step 575, training loss 1.026965, test_loss 1.079101, accuracy = 0.581755/0.584585, f1 = 0.583161\n",
      "End of epoch 3, training loss 0.949053, test_loss 0.888281, accuracy = 0.655345/0.655998, f1 = 0.658424\n",
      "Confusion matrix:\n",
      "[[1149  542  208   12]\n",
      " [  42  724  268  113]\n",
      " [   8   69  996   49]\n",
      " [  12   79  178  144]]\n",
      "Epoch 4, step 0, training loss 0.978497, test_loss 0.941274, accuracy = 0.630525/0.633791, f1 = 0.638494\n",
      "Epoch 4, step 25, training loss 0.989974, test_loss 0.818546, accuracy = 0.693447/0.702591, f1 = 0.704734\n",
      "Epoch 4, step 50, training loss 0.893400, test_loss 0.879902, accuracy = 0.676900/0.687786, f1 = 0.690869\n",
      "Epoch 4, step 75, training loss 1.001814, test_loss 1.173802, accuracy = 0.536251/0.539952, f1 = 0.552008\n",
      "Epoch 4, step 100, training loss 0.985017, test_loss 0.755120, accuracy = 0.726540/0.732637, f1 = 0.720620\n",
      "Epoch 4, step 125, training loss 1.026837, test_loss 1.013479, accuracy = 0.599173/0.609188, f1 = 0.614529\n",
      "Epoch 4, step 150, training loss 0.936472, test_loss 0.781433, accuracy = 0.718920/0.719356, f1 = 0.704468\n",
      "Epoch 4, step 175, training loss 0.994031, test_loss 0.737841, accuracy = 0.732637/0.731983, f1 = 0.715209\n",
      "Epoch 4, step 200, training loss 1.040558, test_loss 0.830360, accuracy = 0.691269/0.695841, f1 = 0.696866\n",
      "Epoch 4, step 225, training loss 0.942309, test_loss 0.871080, accuracy = 0.656216/0.659264, f1 = 0.650268\n",
      "Epoch 4, step 250, training loss 1.093742, test_loss 0.860699, accuracy = 0.686044/0.689092, f1 = 0.690960\n",
      "Epoch 4, step 275, training loss 1.076470, test_loss 0.868112, accuracy = 0.661659/0.663183, f1 = 0.666685\n",
      "Epoch 4, step 300, training loss 1.134863, test_loss 1.036948, accuracy = 0.532767/0.542347, f1 = 0.580815\n",
      "Epoch 4, step 325, training loss 0.966918, test_loss 0.772376, accuracy = 0.713259/0.718485, f1 = 0.700202\n",
      "Epoch 4, step 350, training loss 1.033444, test_loss 0.804770, accuracy = 0.685173/0.689963, f1 = 0.682782\n",
      "Epoch 4, step 375, training loss 0.976491, test_loss 0.798088, accuracy = 0.699543/0.705204, f1 = 0.710695\n",
      "Epoch 4, step 400, training loss 0.898920, test_loss 0.753793, accuracy = 0.719791/0.723275, f1 = 0.717110\n",
      "Epoch 4, step 425, training loss 0.975887, test_loss 0.776713, accuracy = 0.713042/0.717178, f1 = 0.714916\n",
      "Epoch 4, step 450, training loss 1.026528, test_loss 0.833154, accuracy = 0.696277/0.704333, f1 = 0.695813\n",
      "Epoch 4, step 475, training loss 0.935244, test_loss 0.813812, accuracy = 0.691269/0.689745, f1 = 0.674858\n",
      "Epoch 4, step 500, training loss 0.975116, test_loss 0.892133, accuracy = 0.648596/0.650337, f1 = 0.643414\n",
      "Epoch 4, step 525, training loss 0.757423, test_loss 0.805280, accuracy = 0.706945/0.709340, f1 = 0.705735\n",
      "Epoch 4, step 550, training loss 0.934346, test_loss 0.774710, accuracy = 0.711953/0.715219, f1 = 0.713686\n",
      "Epoch 4, step 575, training loss 0.978011, test_loss 0.930491, accuracy = 0.643806/0.642935, f1 = 0.639646\n",
      "End of epoch 4, training loss 0.905207, test_loss 0.824080, accuracy = 0.680165/0.684302, f1 = 0.690548\n",
      "Confusion matrix:\n",
      "[[1279  439  173   20]\n",
      " [  60  747  214  126]\n",
      " [  12   85  935   90]\n",
      " [  15   76  140  182]]\n",
      "Epoch 5, step 0, training loss 0.944948, test_loss 0.840883, accuracy = 0.670586/0.673416, f1 = 0.681862\n",
      "Epoch 5, step 25, training loss 0.956249, test_loss 0.810839, accuracy = 0.692576/0.692576, f1 = 0.690879\n",
      "Epoch 5, step 50, training loss 0.813188, test_loss 0.830427, accuracy = 0.669715/0.679730, f1 = 0.693829\n",
      "Epoch 5, step 75, training loss 0.940649, test_loss 1.059493, accuracy = 0.578489/0.590899, f1 = 0.602545\n",
      "Epoch 5, step 100, training loss 0.949476, test_loss 0.729976, accuracy = 0.733290/0.733072, f1 = 0.719013\n",
      "Epoch 5, step 125, training loss 1.042769, test_loss 1.093048, accuracy = 0.554540/0.555628, f1 = 0.554070\n",
      "Epoch 5, step 150, training loss 0.899796, test_loss 0.728585, accuracy = 0.725452/0.730895, f1 = 0.703823\n",
      "Epoch 5, step 175, training loss 0.996689, test_loss 0.753739, accuracy = 0.713695/0.718702, f1 = 0.719615\n",
      "Epoch 5, step 200, training loss 0.965776, test_loss 0.809482, accuracy = 0.683867/0.681254, f1 = 0.678220\n",
      "Epoch 5, step 225, training loss 0.895121, test_loss 0.776692, accuracy = 0.697366/0.697366, f1 = 0.687581\n",
      "Epoch 5, step 250, training loss 1.133028, test_loss 0.861127, accuracy = 0.644459/0.650991, f1 = 0.670210\n",
      "Epoch 5, step 275, training loss 1.108709, test_loss 0.752674, accuracy = 0.721533/0.725234, f1 = 0.720015\n",
      "Epoch 5, step 300, training loss 1.036071, test_loss 0.873969, accuracy = 0.649902/0.654256, f1 = 0.663956\n",
      "Epoch 5, step 325, training loss 0.911400, test_loss 0.781131, accuracy = 0.708687/0.710864, f1 = 0.698649\n",
      "Epoch 5, step 350, training loss 0.993043, test_loss 0.843673, accuracy = 0.667973/0.668844, f1 = 0.670041\n",
      "Epoch 5, step 375, training loss 0.948576, test_loss 0.768976, accuracy = 0.705204/0.708905, f1 = 0.708155\n",
      "Epoch 5, step 400, training loss 0.892026, test_loss 0.730075, accuracy = 0.726323/0.728064, f1 = 0.724061\n",
      "Epoch 5, step 425, training loss 0.914888, test_loss 0.837066, accuracy = 0.660788/0.668844, f1 = 0.681990\n",
      "Epoch 5, step 450, training loss 0.966774, test_loss 0.824897, accuracy = 0.686044/0.690398, f1 = 0.675896\n",
      "Epoch 5, step 475, training loss 0.914432, test_loss 0.790463, accuracy = 0.696495/0.708252, f1 = 0.714480\n",
      "Epoch 5, step 500, training loss 0.972725, test_loss 0.791378, accuracy = 0.690616/0.698890, f1 = 0.686787\n",
      "Epoch 5, step 525, training loss 0.750023, test_loss 0.755438, accuracy = 0.715654/0.720662, f1 = 0.717988\n",
      "Epoch 5, step 550, training loss 0.917785, test_loss 0.747216, accuracy = 0.721750/0.726976, f1 = 0.726155\n",
      "Epoch 5, step 575, training loss 0.941226, test_loss 0.878272, accuracy = 0.662965/0.667102, f1 = 0.667360\n",
      "End of epoch 5, training loss 0.863565, test_loss 0.797403, accuracy = 0.679295/0.687133, f1 = 0.692232\n",
      "Confusion matrix:\n",
      "[[1313  403  173   22]\n",
      " [  73  732  219  123]\n",
      " [  12   78  943   89]\n",
      " [  17   74  154  168]]\n",
      "Epoch 6, step 0, training loss 0.918551, test_loss 0.811921, accuracy = 0.679948/0.680819, f1 = 0.687644\n",
      "Epoch 6, step 25, training loss 0.929511, test_loss 0.793280, accuracy = 0.692140/0.691052, f1 = 0.687059\n",
      "Epoch 6, step 50, training loss 0.803847, test_loss 0.822086, accuracy = 0.659264/0.672110, f1 = 0.690855\n",
      "Epoch 6, step 75, training loss 0.912044, test_loss 0.973725, accuracy = 0.615502/0.620074, f1 = 0.627352\n",
      "Epoch 6, step 100, training loss 0.904900, test_loss 0.719691, accuracy = 0.726758/0.728064, f1 = 0.715245\n",
      "Epoch 6, step 125, training loss 1.014714, test_loss 0.947171, accuracy = 0.620074/0.617679, f1 = 0.615102\n",
      "Epoch 6, step 150, training loss 0.876003, test_loss 0.722333, accuracy = 0.725887/0.724799, f1 = 0.703122\n",
      "Epoch 6, step 175, training loss 0.944514, test_loss 0.726561, accuracy = 0.713695/0.718485, f1 = 0.721015\n",
      "Epoch 6, step 200, training loss 0.950351, test_loss 0.751361, accuracy = 0.714130/0.718702, f1 = 0.713357\n",
      "Epoch 6, step 225, training loss 0.919596, test_loss 0.733392, accuracy = 0.721315/0.723057, f1 = 0.710085\n",
      "Epoch 6, step 250, training loss 1.152854, test_loss 0.851982, accuracy = 0.647725/0.661877, f1 = 0.678846\n",
      "Epoch 6, step 275, training loss 1.092989, test_loss 0.741659, accuracy = 0.709993/0.726323, f1 = 0.727642\n",
      "Epoch 6, step 300, training loss 1.016798, test_loss 0.845784, accuracy = 0.662312/0.666449, f1 = 0.672265\n",
      "Epoch 6, step 325, training loss 0.862365, test_loss 0.747748, accuracy = 0.716743/0.725016, f1 = 0.711375\n",
      "Epoch 6, step 350, training loss 0.981681, test_loss 0.843792, accuracy = 0.670368/0.667320, f1 = 0.668121\n",
      "Epoch 6, step 375, training loss 0.925027, test_loss 0.758817, accuracy = 0.706074/0.707599, f1 = 0.707928\n",
      "Epoch 6, step 400, training loss 0.847126, test_loss 0.731681, accuracy = 0.714130/0.721533, f1 = 0.718850\n",
      "Epoch 6, step 425, training loss 0.927066, test_loss 0.848149, accuracy = 0.648160/0.654692, f1 = 0.669903\n",
      "Epoch 6, step 450, training loss 0.917124, test_loss 0.794279, accuracy = 0.700631/0.704550, f1 = 0.693826\n",
      "Epoch 6, step 475, training loss 0.907476, test_loss 0.785883, accuracy = 0.692140/0.702155, f1 = 0.712475\n",
      "Epoch 6, step 500, training loss 0.971839, test_loss 0.762586, accuracy = 0.707163/0.712171, f1 = 0.702405\n",
      "Epoch 6, step 525, training loss 0.693054, test_loss 0.737444, accuracy = 0.721968/0.720880, f1 = 0.716936\n",
      "Epoch 6, step 550, training loss 0.932627, test_loss 0.715825, accuracy = 0.726976/0.734378, f1 = 0.731604\n",
      "Epoch 6, step 575, training loss 0.899616, test_loss 0.859389, accuracy = 0.674722/0.674722, f1 = 0.673182\n",
      "End of epoch 6, training loss 0.806413, test_loss 0.767326, accuracy = 0.699325/0.701285, f1 = 0.705687\n",
      "Confusion matrix:\n",
      "[[1389  333  168   21]\n",
      " [  81  729  212  125]\n",
      " [  18   74  936   94]\n",
      " [  21   69  156  167]]\n",
      "Epoch 7, step 0, training loss 0.872226, test_loss 0.805154, accuracy = 0.681472/0.681254, f1 = 0.688802\n",
      "Epoch 7, step 25, training loss 0.905056, test_loss 0.793224, accuracy = 0.688003/0.690616, f1 = 0.685179\n",
      "Epoch 7, step 50, training loss 0.771536, test_loss 0.801582, accuracy = 0.667973/0.681690, f1 = 0.698980\n",
      "Epoch 7, step 75, training loss 0.907132, test_loss 0.969717, accuracy = 0.618550/0.619856, f1 = 0.618845\n",
      "Epoch 7, step 100, training loss 0.867614, test_loss 0.712818, accuracy = 0.728500/0.733072, f1 = 0.720259\n",
      "Epoch 7, step 125, training loss 0.993304, test_loss 0.912754, accuracy = 0.639016/0.641629, f1 = 0.642398\n",
      "Epoch 7, step 150, training loss 0.861612, test_loss 0.718687, accuracy = 0.729589/0.731983, f1 = 0.714509\n",
      "Epoch 7, step 175, training loss 0.939680, test_loss 0.721983, accuracy = 0.714130/0.720226, f1 = 0.722872\n",
      "Epoch 7, step 200, training loss 0.947914, test_loss 0.757671, accuracy = 0.709558/0.719791, f1 = 0.717946\n",
      "Epoch 7, step 225, training loss 0.893800, test_loss 0.726245, accuracy = 0.720226/0.731113, f1 = 0.718331\n",
      "Epoch 7, step 250, training loss 1.159467, test_loss 0.812383, accuracy = 0.674505/0.682343, f1 = 0.692307\n",
      "Epoch 7, step 275, training loss 1.041926, test_loss 0.731447, accuracy = 0.718920/0.728500, f1 = 0.726566\n",
      "Epoch 7, step 300, training loss 1.014439, test_loss 0.808479, accuracy = 0.676682/0.679295, f1 = 0.684626\n",
      "Epoch 7, step 325, training loss 0.852797, test_loss 0.732331, accuracy = 0.728935/0.728282, f1 = 0.716020\n",
      "Epoch 7, step 350, training loss 0.951834, test_loss 0.814780, accuracy = 0.679512/0.683214, f1 = 0.681068\n",
      "Epoch 7, step 375, training loss 0.894828, test_loss 0.715774, accuracy = 0.730242/0.732201, f1 = 0.728958\n",
      "Epoch 7, step 400, training loss 0.843384, test_loss 0.736646, accuracy = 0.710211/0.717178, f1 = 0.716049\n",
      "Epoch 7, step 425, training loss 0.928834, test_loss 0.879288, accuracy = 0.636839/0.642282, f1 = 0.650676\n",
      "Epoch 7, step 450, training loss 0.899738, test_loss 0.762240, accuracy = 0.711518/0.718920, f1 = 0.712594\n",
      "Epoch 7, step 475, training loss 0.907133, test_loss 0.788366, accuracy = 0.703680/0.711735, f1 = 0.714729\n",
      "Epoch 7, step 500, training loss 0.967796, test_loss 0.751581, accuracy = 0.715437/0.721097, f1 = 0.714666\n",
      "Epoch 7, step 525, training loss 0.702725, test_loss 0.723270, accuracy = 0.726105/0.734161, f1 = 0.730823\n",
      "Epoch 7, step 550, training loss 0.904710, test_loss 0.698675, accuracy = 0.740475/0.745047, f1 = 0.740616\n",
      "Epoch 7, step 575, training loss 0.868813, test_loss 0.817431, accuracy = 0.692576/0.701285, f1 = 0.700732\n",
      "End of epoch 7, training loss 0.808428, test_loss 0.764974, accuracy = 0.693664/0.702373, f1 = 0.706139\n",
      "Confusion matrix:\n",
      "[[1337  392  165   17]\n",
      " [  63  810  183   91]\n",
      " [  17   95  923   87]\n",
      " [  21   82  154  156]]\n",
      "Epoch 8, step 0, training loss 0.852782, test_loss 0.779011, accuracy = 0.689310/0.694971, f1 = 0.701037\n",
      "Epoch 8, step 25, training loss 0.895345, test_loss 0.772344, accuracy = 0.696059/0.697148, f1 = 0.691843\n",
      "Epoch 8, step 50, training loss 0.731605, test_loss 0.801756, accuracy = 0.671674/0.682778, f1 = 0.699811\n",
      "Epoch 8, step 75, training loss 0.918712, test_loss 0.927093, accuracy = 0.634008/0.637710, f1 = 0.636923\n",
      "Epoch 8, step 100, training loss 0.760283, test_loss 0.696897, accuracy = 0.735902/0.740910, f1 = 0.727313\n",
      "Epoch 8, step 125, training loss 0.988567, test_loss 0.872760, accuracy = 0.654256/0.660353, f1 = 0.664102\n",
      "Epoch 8, step 150, training loss 0.836289, test_loss 0.692902, accuracy = 0.747224/0.748966, f1 = 0.732133\n",
      "Epoch 8, step 175, training loss 0.888755, test_loss 0.716238, accuracy = 0.723928/0.726976, f1 = 0.730692\n",
      "Epoch 8, step 200, training loss 0.929885, test_loss 0.724623, accuracy = 0.724581/0.732201, f1 = 0.730080\n",
      "Epoch 8, step 225, training loss 0.836581, test_loss 0.701930, accuracy = 0.736556/0.736120, f1 = 0.724135\n",
      "Epoch 8, step 250, training loss 1.176650, test_loss 0.781690, accuracy = 0.687133/0.696495, f1 = 0.704615\n",
      "Epoch 8, step 275, training loss 0.973710, test_loss 0.696609, accuracy = 0.739168/0.740910, f1 = 0.734143\n",
      "Epoch 8, step 300, training loss 0.976470, test_loss 0.851023, accuracy = 0.654692/0.661441, f1 = 0.673658\n",
      "Epoch 8, step 325, training loss 0.814767, test_loss 0.736407, accuracy = 0.714348/0.720880, f1 = 0.711200\n",
      "Epoch 8, step 350, training loss 0.902738, test_loss 0.835278, accuracy = 0.665143/0.679730, f1 = 0.681401\n",
      "Epoch 8, step 375, training loss 0.915750, test_loss 0.738116, accuracy = 0.716525/0.716090, f1 = 0.718000\n",
      "Epoch 8, step 400, training loss 0.853680, test_loss 0.742867, accuracy = 0.712388/0.721533, f1 = 0.724491\n",
      "Epoch 8, step 425, training loss 0.933038, test_loss 0.817515, accuracy = 0.673198/0.678424, f1 = 0.682043\n",
      "Epoch 8, step 450, training loss 0.848616, test_loss 0.749172, accuracy = 0.720226/0.721968, f1 = 0.717100\n",
      "Epoch 8, step 475, training loss 0.883900, test_loss 0.743219, accuracy = 0.713259/0.723492, f1 = 0.731018\n",
      "Epoch 8, step 500, training loss 0.958404, test_loss 0.710517, accuracy = 0.734814/0.734378, f1 = 0.726338\n",
      "Epoch 8, step 525, training loss 0.713504, test_loss 0.722696, accuracy = 0.730459/0.738080, f1 = 0.737173\n",
      "Epoch 8, step 550, training loss 0.865803, test_loss 0.694388, accuracy = 0.736991/0.745265, f1 = 0.745352\n",
      "Epoch 8, step 575, training loss 0.836594, test_loss 0.848144, accuracy = 0.674287/0.682996, f1 = 0.686022\n",
      "End of epoch 8, training loss 0.810488, test_loss 0.772376, accuracy = 0.696930/0.697366, f1 = 0.701979\n",
      "Confusion matrix:\n",
      "[[1297  434  161   19]\n",
      " [  52  821  178   96]\n",
      " [  16   95  922   89]\n",
      " [  21   82  147  163]]\n",
      "Epoch 9, step 0, training loss 0.798230, test_loss 0.781371, accuracy = 0.692358/0.693229, f1 = 0.699882\n",
      "Epoch 9, step 25, training loss 0.862727, test_loss 0.719224, accuracy = 0.720880/0.722186, f1 = 0.714933\n",
      "Epoch 9, step 50, training loss 0.734803, test_loss 0.786780, accuracy = 0.679730/0.689528, f1 = 0.705019\n",
      "Epoch 9, step 75, training loss 0.918469, test_loss 0.930293, accuracy = 0.632920/0.639451, f1 = 0.637978\n",
      "Epoch 9, step 100, training loss 0.778524, test_loss 0.679813, accuracy = 0.744394/0.748095, f1 = 0.737066\n",
      "Epoch 9, step 125, training loss 0.937718, test_loss 0.821149, accuracy = 0.679512/0.684520, f1 = 0.684473\n",
      "Epoch 9, step 150, training loss 0.778644, test_loss 0.686503, accuracy = 0.742434/0.747877, f1 = 0.738033\n",
      "Epoch 9, step 175, training loss 0.883424, test_loss 0.709108, accuracy = 0.724363/0.732854, f1 = 0.737647\n",
      "Epoch 9, step 200, training loss 0.890442, test_loss 0.707011, accuracy = 0.734378/0.742434, f1 = 0.742927\n",
      "Epoch 9, step 225, training loss 0.875155, test_loss 0.676029, accuracy = 0.747442/0.751143, f1 = 0.739424\n",
      "Epoch 9, step 250, training loss 1.123994, test_loss 0.788595, accuracy = 0.683431/0.692793, f1 = 0.701365\n",
      "Epoch 9, step 275, training loss 0.951375, test_loss 0.690378, accuracy = 0.742216/0.751796, f1 = 0.747831\n",
      "Epoch 9, step 300, training loss 0.975197, test_loss 0.816207, accuracy = 0.678424/0.684520, f1 = 0.694334\n",
      "Epoch 9, step 325, training loss 0.784659, test_loss 0.726410, accuracy = 0.725016/0.728282, f1 = 0.720100\n",
      "Epoch 9, step 350, training loss 0.858533, test_loss 0.845290, accuracy = 0.667538/0.673416, f1 = 0.674598\n",
      "Epoch 9, step 375, training loss 0.858680, test_loss 0.709831, accuracy = 0.730895/0.734161, f1 = 0.733936\n",
      "Epoch 9, step 400, training loss 0.828613, test_loss 0.734541, accuracy = 0.713477/0.723275, f1 = 0.730461\n",
      "Epoch 9, step 425, training loss 0.928358, test_loss 0.799166, accuracy = 0.681254/0.683214, f1 = 0.687693\n",
      "Epoch 9, step 450, training loss 0.848222, test_loss 0.724457, accuracy = 0.724799/0.729806, f1 = 0.726659\n",
      "Epoch 9, step 475, training loss 0.895336, test_loss 0.761546, accuracy = 0.709123/0.719138, f1 = 0.728458\n",
      "Epoch 9, step 500, training loss 0.908407, test_loss 0.708690, accuracy = 0.731330/0.736338, f1 = 0.728806\n",
      "Epoch 9, step 525, training loss 0.688700, test_loss 0.700960, accuracy = 0.739386/0.741781, f1 = 0.741943\n",
      "Epoch 9, step 550, training loss 0.837977, test_loss 0.683498, accuracy = 0.741346/0.745265, f1 = 0.747509\n",
      "Epoch 9, step 575, training loss 0.772382, test_loss 0.818508, accuracy = 0.685826/0.691052, f1 = 0.697261\n",
      "End of epoch 9, training loss 0.758015, test_loss 0.724139, accuracy = 0.722839/0.724581, f1 = 0.726170\n",
      "Confusion matrix:\n",
      "[[1411  327  159   14]\n",
      " [  68  826  182   71]\n",
      " [  22   85  938   77]\n",
      " [  22   84  154  153]]\n",
      "Epoch 10, step 0, training loss 0.769960, test_loss 0.737954, accuracy = 0.715219/0.722621, f1 = 0.726428\n",
      "Epoch 10, step 25, training loss 0.853145, test_loss 0.711845, accuracy = 0.725887/0.729806, f1 = 0.725800\n",
      "Epoch 10, step 50, training loss 0.767527, test_loss 0.790145, accuracy = 0.674505/0.685826, f1 = 0.701788\n",
      "Epoch 10, step 75, training loss 0.855034, test_loss 0.773582, accuracy = 0.699760/0.705639, f1 = 0.703479\n",
      "Epoch 10, step 100, training loss 0.779951, test_loss 0.684335, accuracy = 0.740257/0.747006, f1 = 0.739430\n",
      "Epoch 10, step 125, training loss 0.847376, test_loss 0.925128, accuracy = 0.621598/0.628347, f1 = 0.636008\n",
      "Epoch 10, step 150, training loss 0.767778, test_loss 0.684418, accuracy = 0.741999/0.744176, f1 = 0.731402\n",
      "Epoch 10, step 175, training loss 0.838266, test_loss 0.678792, accuracy = 0.742434/0.749184, f1 = 0.749474\n",
      "Epoch 10, step 200, training loss 0.902700, test_loss 0.677006, accuracy = 0.750490/0.756586, f1 = 0.754414\n",
      "Epoch 10, step 225, training loss 0.874446, test_loss 0.661121, accuracy = 0.755715/0.758763, f1 = 0.750669\n",
      "Epoch 10, step 250, training loss 1.142608, test_loss 0.769078, accuracy = 0.697366/0.703462, f1 = 0.714798\n",
      "Epoch 10, step 275, training loss 0.897460, test_loss 0.695803, accuracy = 0.735032/0.741999, f1 = 0.739347\n",
      "Epoch 10, step 300, training loss 0.921752, test_loss 0.752874, accuracy = 0.703462/0.713042, f1 = 0.721450\n",
      "Epoch 10, step 325, training loss 0.764910, test_loss 0.694662, accuracy = 0.736773/0.738515, f1 = 0.730813\n",
      "Epoch 10, step 350, training loss 0.837231, test_loss 0.799868, accuracy = 0.683649/0.689963, f1 = 0.691219\n",
      "Epoch 10, step 375, training loss 0.798179, test_loss 0.684723, accuracy = 0.745265/0.752449, f1 = 0.751536\n",
      "Epoch 10, step 400, training loss 0.865254, test_loss 0.744795, accuracy = 0.709123/0.721097, f1 = 0.728430\n",
      "Epoch 10, step 425, training loss 0.886991, test_loss 0.810193, accuracy = 0.676464/0.682560, f1 = 0.691698\n",
      "Epoch 10, step 450, training loss 0.811246, test_loss 0.731867, accuracy = 0.723492/0.727411, f1 = 0.722109\n",
      "Epoch 10, step 475, training loss 0.833814, test_loss 0.726264, accuracy = 0.721968/0.726540, f1 = 0.731778\n",
      "Epoch 10, step 500, training loss 0.946483, test_loss 0.681960, accuracy = 0.745265/0.746789, f1 = 0.738139\n",
      "Epoch 10, step 525, training loss 0.684304, test_loss 0.685120, accuracy = 0.737209/0.744829, f1 = 0.742579\n",
      "Epoch 10, step 550, training loss 0.781744, test_loss 0.675668, accuracy = 0.744394/0.752014, f1 = 0.751092\n",
      "Epoch 10, step 575, training loss 0.808802, test_loss 0.823321, accuracy = 0.683649/0.684955, f1 = 0.690089\n",
      "End of epoch 10, training loss 0.776249, test_loss 0.732959, accuracy = 0.719791/0.722621, f1 = 0.724148\n",
      "Confusion matrix:\n",
      "[[1406  325  164   16]\n",
      " [  64  791  203   89]\n",
      " [  19   69  968   66]\n",
      " [  22   82  155  154]]\n",
      "Epoch 11, step 0, training loss 0.731195, test_loss 0.778600, accuracy = 0.697148/0.702809, f1 = 0.709217\n",
      "Epoch 11, step 25, training loss 0.811234, test_loss 0.696997, accuracy = 0.733508/0.738733, f1 = 0.733975\n",
      "Epoch 11, step 50, training loss 0.739516, test_loss 0.780676, accuracy = 0.679948/0.691705, f1 = 0.706804\n",
      "Epoch 11, step 75, training loss 0.904816, test_loss 0.786209, accuracy = 0.690834/0.694753, f1 = 0.696664\n",
      "Epoch 11, step 100, training loss 0.711635, test_loss 0.659516, accuracy = 0.748095/0.760505, f1 = 0.755634\n",
      "Epoch 11, step 125, training loss 0.844696, test_loss 0.859803, accuracy = 0.656434/0.656651, f1 = 0.661615\n",
      "Epoch 11, step 150, training loss 0.762876, test_loss 0.675616, accuracy = 0.743305/0.749837, f1 = 0.741167\n",
      "Epoch 11, step 175, training loss 0.779480, test_loss 0.679962, accuracy = 0.739604/0.749401, f1 = 0.750635\n",
      "Epoch 11, step 200, training loss 0.839952, test_loss 0.702180, accuracy = 0.730677/0.743740, f1 = 0.744744\n",
      "Epoch 11, step 225, training loss 0.851591, test_loss 0.644403, accuracy = 0.757457/0.766384, f1 = 0.756565\n",
      "Epoch 11, step 250, training loss 1.142527, test_loss 0.742970, accuracy = 0.707599/0.722186, f1 = 0.729185\n",
      "Epoch 11, step 275, training loss 0.909098, test_loss 0.659109, accuracy = 0.751143/0.762900, f1 = 0.758034\n",
      "Epoch 11, step 300, training loss 0.908244, test_loss 0.769378, accuracy = 0.696277/0.705857, f1 = 0.714858\n",
      "Epoch 11, step 325, training loss 0.715604, test_loss 0.683952, accuracy = 0.740475/0.742652, f1 = 0.733073\n",
      "Epoch 11, step 350, training loss 0.813984, test_loss 0.768282, accuracy = 0.700631/0.704550, f1 = 0.707356\n",
      "Epoch 11, step 375, training loss 0.768393, test_loss 0.694000, accuracy = 0.735467/0.740475, f1 = 0.739136\n",
      "Epoch 11, step 400, training loss 0.802895, test_loss 0.706283, accuracy = 0.731766/0.739821, f1 = 0.741954\n",
      "Epoch 11, step 425, training loss 0.840330, test_loss 0.804991, accuracy = 0.682343/0.691487, f1 = 0.704868\n",
      "Epoch 11, step 450, training loss 0.843618, test_loss 0.704150, accuracy = 0.726540/0.731766, f1 = 0.724076\n",
      "Epoch 11, step 475, training loss 0.821474, test_loss 0.731667, accuracy = 0.720444/0.728500, f1 = 0.732063\n",
      "Epoch 11, step 500, training loss 0.865289, test_loss 0.688364, accuracy = 0.737862/0.741128, f1 = 0.737639\n",
      "Epoch 11, step 525, training loss 0.678291, test_loss 0.704479, accuracy = 0.731983/0.742216, f1 = 0.745802\n",
      "Epoch 11, step 550, training loss 0.772655, test_loss 0.649199, accuracy = 0.754191/0.764424, f1 = 0.762816\n",
      "Epoch 11, step 575, training loss 0.794354, test_loss 0.810439, accuracy = 0.689092/0.696712, f1 = 0.703288\n",
      "End of epoch 11, training loss 0.737661, test_loss 0.718886, accuracy = 0.718702/0.733725, f1 = 0.734238\n",
      "Confusion matrix:\n",
      "[[1433  314  149   15]\n",
      " [  73  816  188   70]\n",
      " [  23   77  964   58]\n",
      " [  23   88  145  157]]\n",
      "Epoch 12, step 0, training loss 0.682064, test_loss 0.745621, accuracy = 0.711735/0.722621, f1 = 0.726459\n",
      "Epoch 12, step 25, training loss 0.821724, test_loss 0.671131, accuracy = 0.736338/0.749837, f1 = 0.744809\n",
      "Epoch 12, step 50, training loss 0.694213, test_loss 0.744042, accuracy = 0.709558/0.719138, f1 = 0.726343\n",
      "Epoch 12, step 75, training loss 0.839361, test_loss 0.768848, accuracy = 0.699107/0.702155, f1 = 0.704258\n",
      "Epoch 12, step 100, training loss 0.709549, test_loss 0.656695, accuracy = 0.752885/0.754409, f1 = 0.746471\n",
      "Epoch 12, step 125, training loss 0.775944, test_loss 0.860503, accuracy = 0.656434/0.661006, f1 = 0.671490\n",
      "Epoch 12, step 150, training loss 0.759145, test_loss 0.666857, accuracy = 0.751143/0.755280, f1 = 0.746371\n",
      "Epoch 12, step 175, training loss 0.799561, test_loss 0.667705, accuracy = 0.745482/0.755933, f1 = 0.757007\n",
      "Epoch 12, step 200, training loss 0.846902, test_loss 0.673280, accuracy = 0.745047/0.757239, f1 = 0.756260\n",
      "Epoch 12, step 225, training loss 0.823180, test_loss 0.651323, accuracy = 0.759634/0.762465, f1 = 0.753881\n",
      "Epoch 12, step 250, training loss 1.135059, test_loss 0.739419, accuracy = 0.707816/0.719791, f1 = 0.724500\n",
      "Epoch 12, step 275, training loss 0.904996, test_loss 0.649688, accuracy = 0.759417/0.763989, f1 = 0.762026\n",
      "Epoch 12, step 300, training loss 0.843975, test_loss 0.740141, accuracy = 0.717831/0.722186, f1 = 0.729855\n",
      "Epoch 12, step 325, training loss 0.725097, test_loss 0.680749, accuracy = 0.746135/0.746135, f1 = 0.741262\n",
      "Epoch 12, step 350, training loss 0.775481, test_loss 0.787804, accuracy = 0.684955/0.691269, f1 = 0.693130\n",
      "Epoch 12, step 375, training loss 0.752737, test_loss 0.676734, accuracy = 0.747660/0.748313, f1 = 0.749158\n",
      "Epoch 12, step 400, training loss 0.839593, test_loss 0.703722, accuracy = 0.724145/0.735685, f1 = 0.738083\n",
      "Epoch 12, step 425, training loss 0.857330, test_loss 0.801451, accuracy = 0.682343/0.684084, f1 = 0.695288\n",
      "Epoch 12, step 450, training loss 0.813199, test_loss 0.696137, accuracy = 0.727194/0.731330, f1 = 0.723468\n",
      "Epoch 12, step 475, training loss 0.773485, test_loss 0.724731, accuracy = 0.720444/0.724799, f1 = 0.732088\n",
      "Epoch 12, step 500, training loss 0.801775, test_loss 0.679158, accuracy = 0.735685/0.742652, f1 = 0.740948\n",
      "Epoch 12, step 525, training loss 0.606511, test_loss 0.689037, accuracy = 0.733072/0.741128, f1 = 0.742952\n",
      "Epoch 12, step 550, training loss 0.717475, test_loss 0.654716, accuracy = 0.752449/0.758328, f1 = 0.757103\n",
      "Epoch 12, step 575, training loss 0.740353, test_loss 0.775187, accuracy = 0.696712/0.704768, f1 = 0.711110\n",
      "End of epoch 12, training loss 0.701757, test_loss 0.704700, accuracy = 0.727411/0.739821, f1 = 0.743823\n",
      "Confusion matrix:\n",
      "[[1507  250  131   23]\n",
      " [  87  798  168   94]\n",
      " [  27   82  898  115]\n",
      " [  24   79  115  195]]\n",
      "Epoch 13, step 0, training loss 0.675435, test_loss 0.732802, accuracy = 0.714130/0.727194, f1 = 0.735763\n",
      "Epoch 13, step 25, training loss 0.808944, test_loss 0.672075, accuracy = 0.741781/0.755498, f1 = 0.751900\n",
      "Epoch 13, step 50, training loss 0.695307, test_loss 0.760049, accuracy = 0.694753/0.703026, f1 = 0.715703\n",
      "Epoch 13, step 75, training loss 0.830648, test_loss 0.797904, accuracy = 0.687350/0.688657, f1 = 0.696066\n",
      "Epoch 13, step 100, training loss 0.710721, test_loss 0.647667, accuracy = 0.758110/0.759852, f1 = 0.754720\n",
      "Epoch 13, step 125, training loss 0.760072, test_loss 0.779803, accuracy = 0.700196/0.703244, f1 = 0.710587\n",
      "Epoch 13, step 150, training loss 0.765018, test_loss 0.667880, accuracy = 0.749619/0.754627, f1 = 0.749869\n",
      "Epoch 13, step 175, training loss 0.788918, test_loss 0.678828, accuracy = 0.735685/0.749184, f1 = 0.750617\n",
      "Epoch 13, step 200, training loss 0.781215, test_loss 0.663468, accuracy = 0.748095/0.760070, f1 = 0.758576\n",
      "Epoch 13, step 225, training loss 0.795707, test_loss 0.635393, accuracy = 0.765295/0.769214, f1 = 0.761248\n",
      "Epoch 13, step 250, training loss 1.031054, test_loss 0.718139, accuracy = 0.719356/0.727847, f1 = 0.734292\n",
      "Epoch 13, step 275, training loss 0.787079, test_loss 0.646546, accuracy = 0.754844/0.760287, f1 = 0.761340\n",
      "Epoch 13, step 300, training loss 0.837467, test_loss 0.763427, accuracy = 0.702155/0.711518, f1 = 0.723801\n",
      "Epoch 13, step 325, training loss 0.668249, test_loss 0.667085, accuracy = 0.741563/0.753973, f1 = 0.745764\n",
      "Epoch 13, step 350, training loss 0.705899, test_loss 0.735345, accuracy = 0.717396/0.718485, f1 = 0.719094\n",
      "Epoch 13, step 375, training loss 0.683136, test_loss 0.663089, accuracy = 0.750272/0.749619, f1 = 0.750647\n",
      "Epoch 13, step 400, training loss 0.759881, test_loss 0.713140, accuracy = 0.717831/0.729371, f1 = 0.734174\n",
      "Epoch 13, step 425, training loss 0.856979, test_loss 0.754567, accuracy = 0.702155/0.706945, f1 = 0.711381\n",
      "Epoch 13, step 450, training loss 0.795257, test_loss 0.702297, accuracy = 0.724145/0.726540, f1 = 0.718103\n",
      "Epoch 13, step 475, training loss 0.813137, test_loss 0.725436, accuracy = 0.720226/0.728935, f1 = 0.736684\n",
      "Epoch 13, step 500, training loss 0.767143, test_loss 0.694117, accuracy = 0.728718/0.735902, f1 = 0.733281\n",
      "Epoch 13, step 525, training loss 0.605131, test_loss 0.695141, accuracy = 0.737862/0.741346, f1 = 0.745953\n",
      "Epoch 13, step 550, training loss 0.741279, test_loss 0.686983, accuracy = 0.731330/0.745047, f1 = 0.746115\n",
      "Epoch 13, step 575, training loss 0.764609, test_loss 0.808315, accuracy = 0.686915/0.691922, f1 = 0.702652\n",
      "End of epoch 13, training loss 0.686253, test_loss 0.682764, accuracy = 0.737209/0.741999, f1 = 0.745465\n",
      "Confusion matrix:\n",
      "[[1501  256  130   24]\n",
      " [  77  821  171   78]\n",
      " [  27   81  901  113]\n",
      " [  26   85  117  185]]\n",
      "Epoch 14, step 0, training loss 0.690982, test_loss 0.713621, accuracy = 0.722621/0.732201, f1 = 0.737934\n",
      "Epoch 14, step 25, training loss 0.728332, test_loss 0.655824, accuracy = 0.750272/0.762029, f1 = 0.759663\n",
      "Epoch 14, step 50, training loss 0.634787, test_loss 0.741484, accuracy = 0.705639/0.716525, f1 = 0.727018\n",
      "Epoch 14, step 75, training loss 0.830202, test_loss 0.764053, accuracy = 0.701285/0.706728, f1 = 0.713899\n",
      "Epoch 14, step 100, training loss 0.650234, test_loss 0.648048, accuracy = 0.754627/0.765077, f1 = 0.759571\n",
      "Epoch 14, step 125, training loss 0.717983, test_loss 0.795324, accuracy = 0.689963/0.695624, f1 = 0.701763\n",
      "Epoch 14, step 150, training loss 0.697686, test_loss 0.661007, accuracy = 0.751361/0.758110, f1 = 0.753410\n",
      "Epoch 14, step 175, training loss 0.778387, test_loss 0.691566, accuracy = 0.729589/0.738515, f1 = 0.741614\n",
      "Epoch 14, step 200, training loss 0.771025, test_loss 0.659152, accuracy = 0.752014/0.760941, f1 = 0.762480\n",
      "Epoch 14, step 225, training loss 0.783065, test_loss 0.636886, accuracy = 0.757239/0.766166, f1 = 0.761527\n",
      "Epoch 14, step 250, training loss 1.068870, test_loss 0.748626, accuracy = 0.700196/0.706510, f1 = 0.714608\n",
      "Epoch 14, step 275, training loss 0.763004, test_loss 0.641891, accuracy = 0.756586/0.760287, f1 = 0.760383\n",
      "Epoch 14, step 300, training loss 0.766198, test_loss 0.703368, accuracy = 0.726976/0.739386, f1 = 0.745129\n",
      "Epoch 14, step 325, training loss 0.643899, test_loss 0.662973, accuracy = 0.747224/0.753103, f1 = 0.747816\n",
      "Epoch 14, step 350, training loss 0.770193, test_loss 0.756120, accuracy = 0.700196/0.712388, f1 = 0.714221\n",
      "Epoch 14, step 375, training loss 0.657653, test_loss 0.696283, accuracy = 0.733290/0.738080, f1 = 0.742442\n",
      "Epoch 14, step 400, training loss 0.765262, test_loss 0.743858, accuracy = 0.707163/0.713912, f1 = 0.721323\n",
      "Epoch 14, step 425, training loss 0.857885, test_loss 0.747683, accuracy = 0.705857/0.715872, f1 = 0.722688\n",
      "Epoch 14, step 450, training loss 0.744033, test_loss 0.708865, accuracy = 0.723710/0.727629, f1 = 0.723069\n",
      "Epoch 14, step 475, training loss 0.731494, test_loss 0.719789, accuracy = 0.721315/0.728282, f1 = 0.737350\n",
      "Epoch 14, step 500, training loss 0.779896, test_loss 0.667990, accuracy = 0.748966/0.753538, f1 = 0.750865\n",
      "Epoch 14, step 525, training loss 0.588112, test_loss 0.668493, accuracy = 0.738080/0.752014, f1 = 0.753659\n",
      "Epoch 14, step 550, training loss 0.671887, test_loss 0.663506, accuracy = 0.745047/0.748530, f1 = 0.746505\n",
      "Epoch 14, step 575, training loss 0.760165, test_loss 0.778982, accuracy = 0.704550/0.706728, f1 = 0.710598\n",
      "End of epoch 14, training loss 0.695474, test_loss 0.703916, accuracy = 0.724799/0.738297, f1 = 0.744832\n",
      "Confusion matrix:\n",
      "[[1515  240  120   36]\n",
      " [  88  798  163   98]\n",
      " [  26   80  853  163]\n",
      " [  27   76   85  225]]\n",
      "Epoch 15, step 0, training loss 0.647605, test_loss 0.731337, accuracy = 0.714348/0.720880, f1 = 0.730739\n",
      "Epoch 15, step 25, training loss 0.719256, test_loss 0.669683, accuracy = 0.745482/0.752449, f1 = 0.752956\n",
      "Epoch 15, step 50, training loss 0.633281, test_loss 0.746352, accuracy = 0.707816/0.719138, f1 = 0.731314\n",
      "Epoch 15, step 75, training loss 0.780322, test_loss 0.761331, accuracy = 0.699760/0.713259, f1 = 0.722592\n",
      "Epoch 15, step 100, training loss 0.662363, test_loss 0.656762, accuracy = 0.747442/0.760070, f1 = 0.754680\n",
      "Epoch 15, step 125, training loss 0.696858, test_loss 0.779665, accuracy = 0.694535/0.707816, f1 = 0.715269\n",
      "Epoch 15, step 150, training loss 0.731683, test_loss 0.652045, accuracy = 0.752449/0.757892, f1 = 0.750618\n",
      "Epoch 15, step 175, training loss 0.746681, test_loss 0.679891, accuracy = 0.735032/0.748530, f1 = 0.752142\n",
      "Epoch 15, step 200, training loss 0.771962, test_loss 0.685067, accuracy = 0.731330/0.746789, f1 = 0.751391\n",
      "Epoch 15, step 225, training loss 0.731192, test_loss 0.636577, accuracy = 0.759417/0.765730, f1 = 0.763481\n",
      "Epoch 15, step 250, training loss 0.998579, test_loss 0.756137, accuracy = 0.699760/0.709993, f1 = 0.719595\n",
      "Epoch 15, step 275, training loss 0.828852, test_loss 0.637597, accuracy = 0.756804/0.766384, f1 = 0.766030\n",
      "Epoch 15, step 300, training loss 0.741216, test_loss 0.720198, accuracy = 0.721315/0.733943, f1 = 0.740875\n",
      "Epoch 15, step 325, training loss 0.661131, test_loss 0.658743, accuracy = 0.741346/0.752885, f1 = 0.747953\n",
      "Epoch 15, step 350, training loss 0.720898, test_loss 0.746643, accuracy = 0.707599/0.713912, f1 = 0.716804\n",
      "Epoch 15, step 375, training loss 0.639213, test_loss 0.671441, accuracy = 0.741999/0.748095, f1 = 0.750167\n",
      "Epoch 15, step 400, training loss 0.737201, test_loss 0.721397, accuracy = 0.715001/0.721315, f1 = 0.729060\n",
      "Epoch 15, step 425, training loss 0.816677, test_loss 0.697019, accuracy = 0.729806/0.737209, f1 = 0.740671\n",
      "Epoch 15, step 450, training loss 0.785297, test_loss 0.680741, accuracy = 0.733290/0.741781, f1 = 0.738134\n",
      "Epoch 15, step 475, training loss 0.744959, test_loss 0.744889, accuracy = 0.709340/0.718702, f1 = 0.731488\n",
      "Epoch 15, step 500, training loss 0.701622, test_loss 0.672316, accuracy = 0.743740/0.749619, f1 = 0.748136\n",
      "Epoch 15, step 525, training loss 0.657065, test_loss 0.667326, accuracy = 0.733725/0.751796, f1 = 0.754874\n",
      "Epoch 15, step 550, training loss 0.679513, test_loss 0.659898, accuracy = 0.744611/0.755280, f1 = 0.752428\n",
      "Epoch 15, step 575, training loss 0.729164, test_loss 0.778308, accuracy = 0.698890/0.706728, f1 = 0.712577\n",
      "End of epoch 15, training loss 0.716716, test_loss 0.682909, accuracy = 0.740257/0.757892, f1 = 0.759769\n",
      "Confusion matrix:\n",
      "[[1530  244  103   34]\n",
      " [  85  855  150   57]\n",
      " [  26   90  913   93]\n",
      " [  26   93  111  183]]\n",
      "Epoch 16, step 0, training loss 0.630096, test_loss 0.720028, accuracy = 0.727411/0.740039, f1 = 0.747306\n",
      "Epoch 16, step 25, training loss 0.681874, test_loss 0.658954, accuracy = 0.749619/0.760070, f1 = 0.758926\n",
      "Epoch 16, step 50, training loss 0.631069, test_loss 0.801577, accuracy = 0.678206/0.694100, f1 = 0.713092\n",
      "Epoch 16, step 75, training loss 0.693313, test_loss 0.729516, accuracy = 0.715219/0.731766, f1 = 0.740204\n",
      "Epoch 16, step 100, training loss 0.691458, test_loss 0.634509, accuracy = 0.762029/0.768125, f1 = 0.760928\n",
      "Epoch 16, step 125, training loss 0.683907, test_loss 0.767614, accuracy = 0.699107/0.701285, f1 = 0.707182\n",
      "Epoch 16, step 150, training loss 0.691226, test_loss 0.648376, accuracy = 0.748313/0.763553, f1 = 0.758833\n",
      "Epoch 16, step 175, training loss 0.710992, test_loss 0.673063, accuracy = 0.735467/0.745918, f1 = 0.749983\n",
      "Epoch 16, step 200, training loss 0.752417, test_loss 0.686275, accuracy = 0.735032/0.740692, f1 = 0.746858\n",
      "Epoch 16, step 225, training loss 0.667814, test_loss 0.629951, accuracy = 0.759634/0.770738, f1 = 0.767974\n",
      "Epoch 16, step 250, training loss 0.934457, test_loss 0.713607, accuracy = 0.720880/0.728935, f1 = 0.736289\n",
      "Epoch 16, step 275, training loss 0.726540, test_loss 0.619047, accuracy = 0.762247/0.772262, f1 = 0.772019\n",
      "Epoch 16, step 300, training loss 0.720689, test_loss 0.757010, accuracy = 0.706510/0.723928, f1 = 0.737440\n",
      "Epoch 16, step 325, training loss 0.654451, test_loss 0.664949, accuracy = 0.741999/0.750054, f1 = 0.744967\n",
      "Epoch 16, step 350, training loss 0.715163, test_loss 0.775968, accuracy = 0.695406/0.706728, f1 = 0.709056\n",
      "Epoch 16, step 375, training loss 0.589610, test_loss 0.644931, accuracy = 0.751796/0.758328, f1 = 0.759016\n",
      "Epoch 16, step 400, training loss 0.701714, test_loss 0.713607, accuracy = 0.722839/0.728500, f1 = 0.736094\n",
      "Epoch 16, step 425, training loss 0.773796, test_loss 0.708124, accuracy = 0.722404/0.731548, f1 = 0.735325\n",
      "Epoch 16, step 450, training loss 0.698559, test_loss 0.696406, accuracy = 0.730677/0.735032, f1 = 0.729305\n",
      "Epoch 16, step 475, training loss 0.695065, test_loss 0.709039, accuracy = 0.720662/0.730459, f1 = 0.740944\n",
      "Epoch 16, step 500, training loss 0.714402, test_loss 0.665147, accuracy = 0.746135/0.758763, f1 = 0.757699\n",
      "Epoch 16, step 525, training loss 0.609596, test_loss 0.659418, accuracy = 0.750054/0.757892, f1 = 0.759570\n",
      "Epoch 16, step 550, training loss 0.667331, test_loss 0.647234, accuracy = 0.749619/0.760941, f1 = 0.759306\n",
      "Epoch 16, step 575, training loss 0.685176, test_loss 0.781235, accuracy = 0.697801/0.708252, f1 = 0.717034\n",
      "End of epoch 16, training loss 0.631800, test_loss 0.662207, accuracy = 0.751579/0.760723, f1 = 0.762472\n",
      "Confusion matrix:\n",
      "[[1586  207   86   32]\n",
      " [ 109  839  127   72]\n",
      " [  34  112  878   98]\n",
      " [  31   90  101  191]]\n",
      "Epoch 17, step 0, training loss 0.639194, test_loss 0.691081, accuracy = 0.735032/0.743305, f1 = 0.749016\n",
      "Epoch 17, step 25, training loss 0.670348, test_loss 0.653967, accuracy = 0.754409/0.757457, f1 = 0.758056\n",
      "Epoch 17, step 50, training loss 0.612255, test_loss 0.781449, accuracy = 0.690398/0.703680, f1 = 0.721524\n",
      "Epoch 17, step 75, training loss 0.749759, test_loss 0.733271, accuracy = 0.721968/0.729806, f1 = 0.739952\n",
      "Epoch 17, step 100, training loss 0.664313, test_loss 0.617483, accuracy = 0.767255/0.773133, f1 = 0.766482\n",
      "Epoch 17, step 125, training loss 0.639893, test_loss 0.742549, accuracy = 0.708687/0.723492, f1 = 0.726763\n",
      "Epoch 17, step 150, training loss 0.640637, test_loss 0.651489, accuracy = 0.749184/0.762900, f1 = 0.758475\n",
      "Epoch 17, step 175, training loss 0.677807, test_loss 0.676639, accuracy = 0.742434/0.751361, f1 = 0.754325\n",
      "Epoch 17, step 200, training loss 0.788037, test_loss 0.712370, accuracy = 0.720880/0.730459, f1 = 0.737725\n",
      "Epoch 17, step 225, training loss 0.766304, test_loss 0.633143, accuracy = 0.766601/0.769214, f1 = 0.766058\n",
      "Epoch 17, step 250, training loss 1.019687, test_loss 0.745619, accuracy = 0.705857/0.717178, f1 = 0.725660\n",
      "Epoch 17, step 275, training loss 0.719328, test_loss 0.624127, accuracy = 0.768343/0.769214, f1 = 0.766433\n",
      "Epoch 17, step 300, training loss 0.725697, test_loss 0.704175, accuracy = 0.729806/0.740475, f1 = 0.747548\n",
      "Epoch 17, step 325, training loss 0.593559, test_loss 0.658625, accuracy = 0.744611/0.750708, f1 = 0.747395\n",
      "Epoch 17, step 350, training loss 0.731506, test_loss 0.764895, accuracy = 0.702809/0.711518, f1 = 0.716096\n",
      "Epoch 17, step 375, training loss 0.586403, test_loss 0.673614, accuracy = 0.740910/0.749837, f1 = 0.750770\n",
      "Epoch 17, step 400, training loss 0.675790, test_loss 0.730452, accuracy = 0.708905/0.724363, f1 = 0.731331\n",
      "Epoch 17, step 425, training loss 0.805270, test_loss 0.701623, accuracy = 0.721968/0.732201, f1 = 0.736505\n",
      "Epoch 17, step 450, training loss 0.730602, test_loss 0.704466, accuracy = 0.727847/0.732854, f1 = 0.732015\n",
      "Epoch 17, step 475, training loss 0.697717, test_loss 0.741819, accuracy = 0.702373/0.716307, f1 = 0.730335\n",
      "Epoch 17, step 500, training loss 0.650290, test_loss 0.679539, accuracy = 0.743958/0.758110, f1 = 0.757476\n",
      "Epoch 17, step 525, training loss 0.567648, test_loss 0.663982, accuracy = 0.739168/0.754191, f1 = 0.755406\n",
      "Epoch 17, step 550, training loss 0.655434, test_loss 0.640290, accuracy = 0.748748/0.759199, f1 = 0.756040\n",
      "Epoch 17, step 575, training loss 0.721854, test_loss 0.779867, accuracy = 0.698672/0.708469, f1 = 0.718760\n",
      "End of epoch 17, training loss 0.610990, test_loss 0.674073, accuracy = 0.745918/0.753103, f1 = 0.755202\n",
      "Confusion matrix:\n",
      "[[1510  258  110   33]\n",
      " [  90  852  148   57]\n",
      " [  27   97  908   90]\n",
      " [  29   86  109  189]]\n",
      "Epoch 18, step 0, training loss 0.622828, test_loss 0.698936, accuracy = 0.726540/0.741128, f1 = 0.745964\n",
      "Epoch 18, step 25, training loss 0.658388, test_loss 0.660234, accuracy = 0.748313/0.756586, f1 = 0.755095\n",
      "Epoch 18, step 50, training loss 0.581111, test_loss 0.776567, accuracy = 0.690398/0.705204, f1 = 0.722499\n",
      "Epoch 18, step 75, training loss 0.700411, test_loss 0.726050, accuracy = 0.713477/0.731548, f1 = 0.741952\n",
      "Epoch 18, step 100, training loss 0.676710, test_loss 0.629797, accuracy = 0.763118/0.772480, f1 = 0.764139\n",
      "Epoch 18, step 125, training loss 0.719263, test_loss 0.702726, accuracy = 0.734161/0.740692, f1 = 0.740109\n",
      "Epoch 18, step 150, training loss 0.651465, test_loss 0.672316, accuracy = 0.744611/0.759634, f1 = 0.757009\n",
      "Epoch 18, step 175, training loss 0.702824, test_loss 0.692943, accuracy = 0.727411/0.744829, f1 = 0.750593\n",
      "Epoch 18, step 200, training loss 0.761517, test_loss 0.714978, accuracy = 0.715437/0.730024, f1 = 0.738064\n",
      "Epoch 18, step 225, training loss 0.764891, test_loss 0.628997, accuracy = 0.764206/0.773351, f1 = 0.766733\n",
      "Epoch 18, step 250, training loss 0.886161, test_loss 0.742632, accuracy = 0.704115/0.720880, f1 = 0.729070\n",
      "Epoch 18, step 275, training loss 0.735440, test_loss 0.629688, accuracy = 0.757239/0.770738, f1 = 0.768120\n",
      "Epoch 18, step 300, training loss 0.713575, test_loss 0.717538, accuracy = 0.724581/0.736338, f1 = 0.742203\n",
      "Epoch 18, step 325, training loss 0.591692, test_loss 0.661047, accuracy = 0.741999/0.750490, f1 = 0.748812\n",
      "Epoch 18, step 350, training loss 0.716351, test_loss 0.710986, accuracy = 0.727847/0.738515, f1 = 0.741673\n",
      "Epoch 18, step 375, training loss 0.545611, test_loss 0.659529, accuracy = 0.749401/0.755933, f1 = 0.758045\n",
      "Epoch 18, step 400, training loss 0.660280, test_loss 0.751994, accuracy = 0.707816/0.716307, f1 = 0.726868\n",
      "Epoch 18, step 425, training loss 0.704016, test_loss 0.679598, accuracy = 0.740692/0.746571, f1 = 0.749295\n",
      "Epoch 18, step 450, training loss 0.694917, test_loss 0.792748, accuracy = 0.687133/0.698672, f1 = 0.703823\n",
      "Epoch 18, step 475, training loss 0.669648, test_loss 0.735329, accuracy = 0.714783/0.721315, f1 = 0.734313\n",
      "Epoch 18, step 500, training loss 0.621011, test_loss 0.672338, accuracy = 0.747006/0.757022, f1 = 0.756487\n",
      "Epoch 18, step 525, training loss 0.570678, test_loss 0.648165, accuracy = 0.751361/0.760941, f1 = 0.761866\n",
      "Epoch 18, step 550, training loss 0.657930, test_loss 0.665239, accuracy = 0.743087/0.752014, f1 = 0.752115\n",
      "Epoch 18, step 575, training loss 0.656160, test_loss 0.707461, accuracy = 0.731983/0.743087, f1 = 0.747225\n",
      "End of epoch 18, training loss 0.590699, test_loss 0.670183, accuracy = 0.747224/0.757022, f1 = 0.758579\n",
      "Confusion matrix:\n",
      "[[1533  228  113   37]\n",
      " [  99  830  152   66]\n",
      " [  30   82  924   86]\n",
      " [  30   82  111  190]]\n",
      "Epoch 19, step 0, training loss 0.624076, test_loss 0.687994, accuracy = 0.741999/0.748966, f1 = 0.753196\n",
      "Epoch 19, step 25, training loss 0.637699, test_loss 0.683148, accuracy = 0.740910/0.755933, f1 = 0.758815\n",
      "Epoch 19, step 50, training loss 0.522555, test_loss 0.822308, accuracy = 0.672327/0.687568, f1 = 0.709923\n",
      "Epoch 19, step 75, training loss 0.661002, test_loss 0.696586, accuracy = 0.727847/0.742216, f1 = 0.750906\n",
      "Epoch 19, step 100, training loss 0.601344, test_loss 0.638100, accuracy = 0.763989/0.767908, f1 = 0.762443\n",
      "Epoch 19, step 125, training loss 0.620895, test_loss 0.703519, accuracy = 0.731113/0.744394, f1 = 0.743533\n",
      "Epoch 19, step 150, training loss 0.651952, test_loss 0.687114, accuracy = 0.738951/0.750490, f1 = 0.747628\n",
      "Epoch 19, step 175, training loss 0.661939, test_loss 0.712422, accuracy = 0.730024/0.738297, f1 = 0.746362\n",
      "Epoch 19, step 200, training loss 0.821070, test_loss 0.722728, accuracy = 0.712171/0.732419, f1 = 0.738938\n",
      "Epoch 19, step 225, training loss 0.634190, test_loss 0.663985, accuracy = 0.753320/0.750490, f1 = 0.747598\n",
      "Epoch 19, step 250, training loss 0.942224, test_loss 0.785472, accuracy = 0.697583/0.704115, f1 = 0.719067\n",
      "Epoch 19, step 275, training loss 0.680060, test_loss 0.673617, accuracy = 0.736991/0.745265, f1 = 0.746030\n",
      "Epoch 19, step 300, training loss 0.659705, test_loss 0.726089, accuracy = 0.720880/0.727411, f1 = 0.734538\n",
      "Epoch 19, step 325, training loss 0.592237, test_loss 0.672140, accuracy = 0.745482/0.752667, f1 = 0.753243\n",
      "Epoch 19, step 350, training loss 0.662133, test_loss 0.765232, accuracy = 0.711300/0.720226, f1 = 0.725260\n",
      "Epoch 19, step 375, training loss 0.538620, test_loss 0.687905, accuracy = 0.741128/0.747442, f1 = 0.751469\n",
      "Epoch 19, step 400, training loss 0.635384, test_loss 0.750034, accuracy = 0.709340/0.715654, f1 = 0.726903\n",
      "Epoch 19, step 425, training loss 0.745215, test_loss 0.715640, accuracy = 0.717178/0.728500, f1 = 0.734597\n",
      "Epoch 19, step 450, training loss 0.650116, test_loss 0.827763, accuracy = 0.675376/0.685391, f1 = 0.692462\n",
      "Epoch 19, step 475, training loss 0.594753, test_loss 0.727718, accuracy = 0.715001/0.729371, f1 = 0.739847\n",
      "Epoch 19, step 500, training loss 0.623782, test_loss 0.656714, accuracy = 0.751361/0.763336, f1 = 0.761429\n",
      "Epoch 19, step 525, training loss 0.557512, test_loss 0.646433, accuracy = 0.754627/0.763989, f1 = 0.763938\n",
      "Epoch 19, step 550, training loss 0.604525, test_loss 0.683967, accuracy = 0.735685/0.748966, f1 = 0.745262\n",
      "Epoch 19, step 575, training loss 0.667358, test_loss 0.717957, accuracy = 0.727194/0.734378, f1 = 0.737665\n",
      "End of epoch 19, training loss 0.564958, test_loss 0.667312, accuracy = 0.750272/0.758763, f1 = 0.760798\n",
      "Confusion matrix:\n",
      "[[1568  201  108   34]\n",
      " [ 116  809  149   73]\n",
      " [  33   76  904  109]\n",
      " [  32   76  101  204]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "tr_loss, tst_loss = patch_model.train_loop(sess,\n",
    "                                           train['patches']*255,\n",
    "                                           train['labels'],\n",
    "                                           test['patches']*255,\n",
    "                                           test['labels'],\n",
    "                                           num_epochs,\n",
    "                                           batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Saved to: context_models/patch_models/v2/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "saver = tf.train.Saver(write_version=1)\n",
    "save_path = saver.save(sess, \"context_models/patch_models/v2/model.ckpt\")\n",
    "print \"Saved to:\", save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore the model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"context_models/patch_models/v2/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76079822"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we get the expected f1\n",
    "sess.run(patch_model.f1, feed_dict={\n",
    "        patch_model.patch_tensor:np.concatenate([test['patches'], validation['patches']], axis=0)*255,\n",
    "        patch_model.label_tensor:np.concatenate([test['labels'], validation['labels']], axis=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Non-Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1559 patches because too close to image border\n",
      "Dropped 523 patches because too close to image border\n"
     ]
    }
   ],
   "source": [
    "(train_vanilla, _) = utils.get_dataset_divided_per_image(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derp Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_vanilla, test_vanilla) = utils.get_dataset_divided_per_image(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'classifier_utils' from 'classifier_utils.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifier_utils as utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img_ids (15769,)\n",
      "train labels (15769, 4)\n",
      "train patches (15769, 27, 27, 3)\n",
      "train centres (15769, 2)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in train_vanilla.iteritems():\n",
    "    print \"train\", k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1917\n",
      "[1 0 0 0]\n",
      "[1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFeCAYAAABU066vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa9c1ebf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFeCAYAAABU066vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa9dc3bd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 1010\n",
    "i = train['img_ids'][target]\n",
    "c = train['centres'][target]\n",
    "for ii in xrange(len(train_vanilla['img_ids'])):\n",
    "    if train_vanilla['img_ids'][ii] == i and np.all(np.equal(train_vanilla['centres'][ii], c)):\n",
    "        break\n",
    "print ii\n",
    "plt.imshow(train['patches'][target])\n",
    "plt.figure()\n",
    "plt.imshow(train_vanilla['patches'][ii])\n",
    "print train['labels'][target]\n",
    "print train_vanilla['labels'][ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Probability Weight Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_size = 27\n",
    "context = 5\n",
    "test['probabilities'], test['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods(sess, test, patch_model, bin_size=bin_size, context_length=context)\n",
    "validation['probabilities'], validation['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods(sess, validation, patch_model, bin_size=bin_size, context_length=context)\n",
    "train_vanilla['probabilities'], train_vanilla['weight_neighbourhoods'] = \\\n",
    "    context_classifier.compute_probability_neighbourhoods(sess, train_vanilla, patch_model, bin_size=bin_size, context_length=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's just try to balance out the classes a little\n",
    "selectors = []\n",
    "for c in xrange(train_vanilla['labels'].shape[1]):\n",
    "    selectors.append(np.nonzero(train_vanilla['labels'][:,c])[0])\n",
    "largest_class_size = max([len(s) for s in selectors])\n",
    "#print largest_class_size\n",
    "expanded_selectors = []\n",
    "for s in selectors:\n",
    "    expansion_factor = largest_class_size / len(s) + 1\n",
    "    expanded_selectors.append(np.repeat(s, expansion_factor)[:largest_class_size])\n",
    "    \n",
    "np.random.seed(649) # repeatability\n",
    "balanced_train_vanilla = {}\n",
    "N = len(selectors) * largest_class_size\n",
    "perm = np.random.permutation(N)\n",
    "for (k, v) in train_vanilla.iteritems():\n",
    "    new = np.concatenate([v[s] for s in expanded_selectors], axis=0)\n",
    "    #print new.shape\n",
    "    balanced_train_vanilla[k] = new[perm]\n",
    "    #print balanced_train_vanilla[k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches (20696, 27, 27, 3)\n",
      "probabilities (20696, 4)\n",
      "labels (20696, 4)\n",
      "weight_neighbourhoods (20696, 5, 5, 4)\n",
      "centres (20696, 2)\n",
      "img_ids (20696,)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in balanced_train_vanilla.iteritems():\n",
    "    print k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174\n",
      "5174\n",
      "5174\n",
      "5174\n"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,0])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,1])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,2])\n",
    "print np.count_nonzero(balanced_train_vanilla['labels'][:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'context_classifier' from 'context_classifier.pyc'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(context_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass # sess doesn't exist yet!\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "learning_rate = tf.Variable(0.001, trainable=False)\n",
    "context_model = context_classifier.ContextModel(learning_rate=learning_rate, context_length=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From context_classifier.py:145 in train_loop.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0, step 0, training loss 1.717754, test_loss 1.717083, accuracy = 0.246844/0.383544, f1 = nan\n",
      "Epoch 0, step 25, training loss 1.330503, test_loss 1.288229, accuracy = 0.400522/0.269047, f1 = nan\n",
      "Epoch 0, step 50, training loss 1.137076, test_loss 1.138435, accuracy = 0.515020/0.275142, f1 = nan\n",
      "Epoch 0, step 75, training loss 1.052572, test_loss 1.061964, accuracy = 0.566391/0.278189, f1 = nan\n",
      "Epoch 0, step 100, training loss 1.028090, test_loss 0.992262, accuracy = 0.628211/0.261210, f1 = nan\n",
      "Epoch 0, step 125, training loss 0.938842, test_loss 0.972623, accuracy = 0.639965/0.261210, f1 = nan\n",
      "Epoch 0, step 150, training loss 1.038469, test_loss 0.962677, accuracy = 0.645625/0.261210, f1 = nan\n",
      "Epoch 0, step 175, training loss 0.849236, test_loss 0.953923, accuracy = 0.656073/0.261210, f1 = nan\n",
      "Epoch 0, step 200, training loss 0.834316, test_loss 0.914633, accuracy = 0.680453/0.261210, f1 = nan\n",
      "Epoch 0, step 225, training loss 0.779052, test_loss 0.925041, accuracy = 0.684371/0.261210, f1 = nan\n",
      "Epoch 0, step 250, training loss 0.872042, test_loss 0.916918, accuracy = 0.682630/0.261210, f1 = nan\n",
      "Epoch 0, step 275, training loss 0.781838, test_loss 0.896438, accuracy = 0.693949/0.261210, f1 = nan\n",
      "Epoch 0, step 300, training loss 0.790150, test_loss 0.885699, accuracy = 0.702656/0.261210, f1 = nan\n",
      "Epoch 0, step 325, training loss 0.888742, test_loss 0.892962, accuracy = 0.713975/0.261210, f1 = nan\n",
      "Epoch 0, step 350, training loss 0.860270, test_loss 0.887689, accuracy = 0.702656/0.261210, f1 = nan\n",
      "Epoch 0, step 375, training loss 0.956777, test_loss 0.885484, accuracy = 0.689160/0.261210, f1 = nan\n",
      "Epoch 0, step 400, training loss 0.898133, test_loss 0.878598, accuracy = 0.710057/0.261210, f1 = nan\n",
      "End of epoch 0, training loss 0.749710, test_loss 0.867629, accuracy = 0.728341/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 1, step 0, training loss 0.755952, test_loss 0.859053, accuracy = 0.724859/0.261210, f1 = nan\n",
      "Epoch 1, step 25, training loss 0.751798, test_loss 0.882015, accuracy = 0.716587/0.261210, f1 = nan\n",
      "Epoch 1, step 50, training loss 0.781579, test_loss 0.850368, accuracy = 0.730953/0.261210, f1 = nan\n",
      "Epoch 1, step 75, training loss 0.780726, test_loss 0.846154, accuracy = 0.732695/0.261210, f1 = nan\n",
      "Epoch 1, step 100, training loss 0.796382, test_loss 0.846362, accuracy = 0.727471/0.261210, f1 = nan\n",
      "Epoch 1, step 125, training loss 0.689148, test_loss 0.845796, accuracy = 0.724859/0.261210, f1 = nan\n",
      "Epoch 1, step 150, training loss 0.793097, test_loss 0.837254, accuracy = 0.725729/0.261210, f1 = nan\n",
      "Epoch 1, step 175, training loss 0.840542, test_loss 0.836495, accuracy = 0.737919/0.261210, f1 = nan\n",
      "Epoch 1, step 200, training loss 0.717767, test_loss 0.833854, accuracy = 0.733566/0.261210, f1 = nan\n",
      "Epoch 1, step 225, training loss 0.641004, test_loss 0.839218, accuracy = 0.728341/0.261210, f1 = nan\n",
      "Epoch 1, step 250, training loss 0.791101, test_loss 0.838482, accuracy = 0.734872/0.261210, f1 = nan\n",
      "Epoch 1, step 275, training loss 0.812235, test_loss 0.838081, accuracy = 0.737048/0.261210, f1 = nan\n",
      "Epoch 1, step 300, training loss 0.840390, test_loss 0.832057, accuracy = 0.742708/0.261210, f1 = nan\n",
      "Epoch 1, step 325, training loss 0.855497, test_loss 0.829420, accuracy = 0.750980/0.261210, f1 = nan\n",
      "Epoch 1, step 350, training loss 0.834296, test_loss 0.837367, accuracy = 0.725294/0.261210, f1 = nan\n",
      "Epoch 1, step 375, training loss 0.911940, test_loss 0.854815, accuracy = 0.722682/0.261210, f1 = nan\n",
      "Epoch 1, step 400, training loss 0.730589, test_loss 0.850804, accuracy = 0.726164/0.261210, f1 = nan\n",
      "End of epoch 1, training loss 0.676215, test_loss 0.841794, accuracy = 0.730083/0.261210, f1 = nan\n",
      "Confusion matrix:\n",
      "[[  0 937   0   0]\n",
      " [  0 600   0   0]\n",
      " [  0 553   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 2, step 0, training loss 0.879688, test_loss 0.853706, accuracy = 0.730953/0.261210, f1 = nan\n",
      "Epoch 2, step 25, training loss 0.741666, test_loss 0.839402, accuracy = 0.737919/0.261210, f1 = nan\n",
      "Epoch 2, step 50, training loss 0.741006, test_loss 0.836716, accuracy = 0.737048/0.261210, f1 = nan\n",
      "Epoch 2, step 75, training loss 0.723892, test_loss 0.827866, accuracy = 0.737919/0.261210, f1 = nan\n",
      "Epoch 2, step 100, training loss 0.764310, test_loss 0.815353, accuracy = 0.743579/0.261210, f1 = nan\n",
      "Epoch 2, step 125, training loss 0.632152, test_loss 0.834711, accuracy = 0.737484/0.261210, f1 = nan\n",
      "Epoch 2, step 150, training loss 0.734395, test_loss 0.816962, accuracy = 0.743143/0.261210, f1 = nan\n",
      "Epoch 2, step 175, training loss 0.939253, test_loss 0.819988, accuracy = 0.744014/0.261210, f1 = nan\n",
      "Epoch 2, step 200, training loss 0.649955, test_loss 0.830363, accuracy = 0.737484/0.261210, f1 = nan\n",
      "Epoch 2, step 225, training loss 0.685583, test_loss 0.827988, accuracy = 0.734436/0.261210, f1 = nan\n",
      "Epoch 2, step 250, training loss 0.756036, test_loss 0.828503, accuracy = 0.742273/0.261210, f1 = nan\n",
      "Epoch 2, step 275, training loss 0.756114, test_loss 0.830005, accuracy = 0.744885/0.261210, f1 = nan\n",
      "Epoch 2, step 300, training loss 0.731380, test_loss 0.828527, accuracy = 0.744449/0.261210, f1 = nan\n",
      "Epoch 2, step 325, training loss 0.893981, test_loss 0.828442, accuracy = 0.742708/0.261210, f1 = nan\n",
      "Epoch 2, step 350, training loss 0.763797, test_loss 0.827568, accuracy = 0.738354/0.271223, f1 = nan\n",
      "Epoch 2, step 375, training loss 0.840790, test_loss 0.823583, accuracy = 0.746191/0.273400, f1 = nan\n",
      "Epoch 2, step 400, training loss 0.748802, test_loss 0.830889, accuracy = 0.735307/0.272529, f1 = nan\n",
      "End of epoch 2, training loss 0.635507, test_loss 0.815079, accuracy = 0.752286/0.273400, f1 = nan\n",
      "Confusion matrix:\n",
      "[[ 28 909   0   0]\n",
      " [  0 600   0   0]\n",
      " [  1 552   0   0]\n",
      " [  0 207   0   0]]\n",
      "Epoch 3, step 0, training loss 0.670658, test_loss 0.832006, accuracy = 0.741837/0.273400, f1 = nan\n",
      "Epoch 3, step 25, training loss 0.618087, test_loss 0.816206, accuracy = 0.749674/0.282107, f1 = nan\n",
      "Epoch 3, step 50, training loss 0.647575, test_loss 0.818417, accuracy = 0.738790/0.286461, f1 = nan\n",
      "Epoch 3, step 75, training loss 0.718135, test_loss 0.823716, accuracy = 0.748367/0.286461, f1 = nan\n",
      "Epoch 3, step 100, training loss 0.731797, test_loss 0.806891, accuracy = 0.749673/0.286461, f1 = nan\n",
      "Epoch 3, step 125, training loss 0.629628, test_loss 0.816405, accuracy = 0.754462/0.282542, f1 = nan\n",
      "Epoch 3, step 150, training loss 0.777704, test_loss 0.813185, accuracy = 0.744449/0.290814, f1 = nan\n",
      "Epoch 3, step 175, training loss 0.828874, test_loss 0.829004, accuracy = 0.742272/0.316500, f1 = nan\n",
      "Epoch 3, step 200, training loss 0.659920, test_loss 0.831623, accuracy = 0.737484/0.313888, f1 = nan\n",
      "Epoch 3, step 225, training loss 0.686861, test_loss 0.828023, accuracy = 0.731389/0.324336, f1 = nan\n",
      "Epoch 3, step 250, training loss 0.795931, test_loss 0.820034, accuracy = 0.737919/0.345668, f1 = nan\n",
      "Epoch 3, step 275, training loss 0.763286, test_loss 0.820481, accuracy = 0.740967/0.356117, f1 = nan\n",
      "Epoch 3, step 300, training loss 0.722938, test_loss 0.819715, accuracy = 0.747497/0.365259, f1 = nan\n",
      "Epoch 3, step 325, training loss 0.823300, test_loss 0.825138, accuracy = 0.743579/0.388768, f1 = nan\n",
      "Epoch 3, step 350, training loss 0.803998, test_loss 0.829610, accuracy = 0.735307/0.389203, f1 = nan\n",
      "Epoch 3, step 375, training loss 0.853457, test_loss 0.825859, accuracy = 0.740966/0.391815, f1 = nan\n",
      "Epoch 3, step 400, training loss 0.823543, test_loss 0.823267, accuracy = 0.747932/0.410100, f1 = nan\n",
      "End of epoch 3, training loss 0.636156, test_loss 0.824309, accuracy = 0.739225/0.434044, f1 = nan\n",
      "Confusion matrix:\n",
      "[[394 543   0   0]\n",
      " [  0 600   0   0]\n",
      " [  2 551   0   0]\n",
      " [  1 203   0   3]]\n",
      "Epoch 4, step 0, training loss 0.720318, test_loss 0.827590, accuracy = 0.739660/0.436221, f1 = nan\n",
      "Epoch 4, step 25, training loss 0.662367, test_loss 0.817074, accuracy = 0.738354/0.482368, f1 = nan\n",
      "Epoch 4, step 50, training loss 0.709333, test_loss 0.812425, accuracy = 0.751850/0.483239, f1 = nan\n",
      "Epoch 4, step 75, training loss 0.704126, test_loss 0.817421, accuracy = 0.745755/0.484545, f1 = nan\n",
      "Epoch 4, step 100, training loss 0.657242, test_loss 0.805159, accuracy = 0.757945/0.480627, f1 = nan\n",
      "Epoch 4, step 125, training loss 0.751239, test_loss 0.815611, accuracy = 0.752721/0.486722, f1 = nan\n",
      "Epoch 4, step 150, training loss 0.713360, test_loss 0.809903, accuracy = 0.744449/0.485851, f1 = nan\n",
      "Epoch 4, step 175, training loss 0.774967, test_loss 0.820529, accuracy = 0.738790/0.509360, f1 = nan\n",
      "Epoch 4, step 200, training loss 0.665650, test_loss 0.820332, accuracy = 0.747932/0.513278, f1 = nan\n",
      "Epoch 4, step 225, training loss 0.687064, test_loss 0.812076, accuracy = 0.746626/0.528080, f1 = nan\n",
      "Epoch 4, step 250, training loss 0.829580, test_loss 0.828114, accuracy = 0.735742/0.537222, f1 = nan\n",
      "Epoch 4, step 275, training loss 0.672725, test_loss 0.808614, accuracy = 0.747061/0.537222, f1 = nan\n",
      "Epoch 4, step 300, training loss 0.742055, test_loss 0.817785, accuracy = 0.744885/0.538529, f1 = nan\n",
      "Epoch 4, step 325, training loss 0.855016, test_loss 0.812321, accuracy = 0.753156/0.556813, f1 = nan\n",
      "Epoch 4, step 350, training loss 0.800976, test_loss 0.818205, accuracy = 0.745755/0.564650, f1 = nan\n",
      "Epoch 4, step 375, training loss 0.948395, test_loss 0.824812, accuracy = 0.727471/0.565085, f1 = nan\n",
      "Epoch 4, step 400, training loss 0.718887, test_loss 0.829079, accuracy = 0.734436/0.571615, f1 = nan\n",
      "End of epoch 4, training loss 0.694448, test_loss 0.830487, accuracy = 0.741837/0.573357, f1 = nan\n",
      "Confusion matrix:\n",
      "[[690 247   0   0]\n",
      " [  5 595   0   0]\n",
      " [  5 542   0   6]\n",
      " [  7 168   0  32]]\n",
      "Epoch 5, step 0, training loss 0.689583, test_loss 0.822112, accuracy = 0.735742/0.572921, f1 = nan\n",
      "Epoch 5, step 25, training loss 0.678263, test_loss 0.811544, accuracy = 0.742273/0.584676, f1 = nan\n",
      "Epoch 5, step 50, training loss 0.678347, test_loss 0.811380, accuracy = 0.747061/0.581193, f1 = nan\n",
      "Epoch 5, step 75, training loss 0.710183, test_loss 0.809067, accuracy = 0.742708/0.581193, f1 = nan\n",
      "Epoch 5, step 100, training loss 0.679399, test_loss 0.798459, accuracy = 0.749673/0.580758, f1 = nan\n",
      "Epoch 5, step 125, training loss 0.685201, test_loss 0.815034, accuracy = 0.750979/0.592947, f1 = nan\n",
      "Epoch 5, step 150, training loss 0.780613, test_loss 0.811751, accuracy = 0.749238/0.594253, f1 = 0.530942\n",
      "Epoch 5, step 175, training loss 0.823525, test_loss 0.812412, accuracy = 0.743579/0.596430, f1 = 0.531250\n",
      "Epoch 5, step 200, training loss 0.611389, test_loss 0.810573, accuracy = 0.742708/0.592077, f1 = 0.527655\n",
      "Epoch 5, step 225, training loss 0.628150, test_loss 0.812365, accuracy = 0.738790/0.595124, f1 = 0.530016\n",
      "Epoch 5, step 250, training loss 0.754663, test_loss 0.810909, accuracy = 0.751850/0.601219, f1 = 0.536978\n",
      "Epoch 5, step 275, training loss 0.721953, test_loss 0.805841, accuracy = 0.750109/0.614279, f1 = 0.557710\n",
      "Epoch 5, step 300, training loss 0.682052, test_loss 0.816598, accuracy = 0.740096/0.613844, f1 = 0.554800\n",
      "Epoch 5, step 325, training loss 0.780602, test_loss 0.815716, accuracy = 0.749238/0.629081, f1 = 0.576946\n",
      "Epoch 5, step 350, training loss 0.820567, test_loss 0.830198, accuracy = 0.735742/0.630387, f1 = 0.576382\n",
      "Epoch 5, step 375, training loss 0.830614, test_loss 0.814572, accuracy = 0.741402/0.631693, f1 = 0.578156\n",
      "Epoch 5, step 400, training loss 0.739997, test_loss 0.811748, accuracy = 0.739225/0.643883, f1 = 0.598266\n",
      "End of epoch 5, training loss 0.641240, test_loss 0.822368, accuracy = 0.737484/0.637353, f1 = 0.586683\n",
      "Confusion matrix:\n",
      "[[775 158   0   4]\n",
      " [ 17 578   0   5]\n",
      " [  8 498  29  18]\n",
      " [ 18 105   2  82]]\n",
      "Epoch 6, step 0, training loss 0.641697, test_loss 0.816346, accuracy = 0.738354/0.636918, f1 = 0.586179\n",
      "Epoch 6, step 25, training loss 0.585403, test_loss 0.823857, accuracy = 0.739660/0.635612, f1 = 0.574960\n",
      "Epoch 6, step 50, training loss 0.646516, test_loss 0.820746, accuracy = 0.744449/0.643883, f1 = 0.597321\n",
      "Epoch 6, step 75, training loss 0.649104, test_loss 0.813095, accuracy = 0.746191/0.635612, f1 = 0.587834\n",
      "Epoch 6, step 100, training loss 0.711821, test_loss 0.811212, accuracy = 0.749673/0.640400, f1 = 0.594765\n",
      "Epoch 6, step 125, training loss 0.596115, test_loss 0.815396, accuracy = 0.749674/0.648672, f1 = 0.606664\n",
      "Epoch 6, step 150, training loss 0.717090, test_loss 0.811545, accuracy = 0.741402/0.658685, f1 = 0.625219\n",
      "Epoch 6, step 175, training loss 0.730318, test_loss 0.816237, accuracy = 0.746191/0.673487, f1 = 0.646301\n",
      "Epoch 6, step 200, training loss 0.592104, test_loss 0.822794, accuracy = 0.739225/0.667392, f1 = 0.637205\n",
      "Epoch 6, step 225, training loss 0.599502, test_loss 0.808453, accuracy = 0.746191/0.670004, f1 = 0.638059\n",
      "Epoch 6, step 250, training loss 0.763283, test_loss 0.823355, accuracy = 0.744885/0.680017, f1 = 0.652264\n",
      "Epoch 6, step 275, training loss 0.833794, test_loss 0.812434, accuracy = 0.734872/0.690466, f1 = 0.667401\n",
      "Epoch 6, step 300, training loss 0.662995, test_loss 0.812696, accuracy = 0.751415/0.692207, f1 = 0.670643\n",
      "Epoch 6, step 325, training loss 0.789092, test_loss 0.813468, accuracy = 0.741837/0.697431, f1 = 0.674828\n",
      "Epoch 6, step 350, training loss 0.647880, test_loss 0.818760, accuracy = 0.738354/0.693949, f1 = 0.667942\n",
      "Epoch 6, step 375, training loss 0.837969, test_loss 0.815706, accuracy = 0.731824/0.695690, f1 = 0.668940\n",
      "Epoch 6, step 400, training loss 0.725105, test_loss 0.823899, accuracy = 0.733566/0.705703, f1 = 0.685739\n",
      "End of epoch 6, training loss 0.648956, test_loss 0.819163, accuracy = 0.740966/0.704397, f1 = 0.683437\n",
      "Confusion matrix:\n",
      "[[814 109   4  10]\n",
      " [ 24 563   4   9]\n",
      " [ 11 381 134  27]\n",
      " [ 21  70   9 107]]\n",
      "Epoch 7, step 0, training loss 0.688353, test_loss 0.813455, accuracy = 0.742272/0.705268, f1 = 0.684752\n",
      "Epoch 7, step 25, training loss 0.661017, test_loss 0.818260, accuracy = 0.743143/0.708315, f1 = 0.687952\n",
      "Epoch 7, step 50, training loss 0.724614, test_loss 0.826629, accuracy = 0.731824/0.724423, f1 = 0.710877\n",
      "Epoch 7, step 75, training loss 0.734156, test_loss 0.807708, accuracy = 0.750109/0.730518, f1 = 0.721049\n",
      "Epoch 7, step 100, training loss 0.768359, test_loss 0.813303, accuracy = 0.742273/0.736613, f1 = 0.728512\n",
      "Epoch 7, step 125, training loss 0.676009, test_loss 0.808664, accuracy = 0.747061/0.736178, f1 = 0.726928\n",
      "Epoch 7, step 150, training loss 0.737099, test_loss 0.819383, accuracy = 0.738790/0.739225, f1 = 0.731681\n",
      "Epoch 7, step 175, training loss 0.819560, test_loss 0.805923, accuracy = 0.744014/0.737048, f1 = 0.728218\n",
      "Epoch 7, step 200, training loss 0.559625, test_loss 0.811810, accuracy = 0.738790/0.737048, f1 = 0.728580\n",
      "Epoch 7, step 225, training loss 0.636115, test_loss 0.806660, accuracy = 0.737919/0.739661, f1 = 0.731721\n",
      "Epoch 7, step 250, training loss 0.687473, test_loss 0.831481, accuracy = 0.734001/0.740096, f1 = 0.732463\n",
      "Epoch 7, step 275, training loss 0.666079, test_loss 0.814819, accuracy = 0.746626/0.743143, f1 = 0.736899\n",
      "Epoch 7, step 300, training loss 0.699633, test_loss 0.824316, accuracy = 0.739225/0.743579, f1 = 0.737172\n",
      "Epoch 7, step 325, training loss 0.808686, test_loss 0.807876, accuracy = 0.748803/0.747497, f1 = 0.740822\n",
      "Epoch 7, step 350, training loss 0.734780, test_loss 0.826722, accuracy = 0.736613/0.748367, f1 = 0.741699\n",
      "Epoch 7, step 375, training loss 0.797378, test_loss 0.811167, accuracy = 0.740531/0.749238, f1 = 0.743142\n",
      "Epoch 7, step 400, training loss 0.705508, test_loss 0.798256, accuracy = 0.749673/0.757074, f1 = 0.753104\n",
      "End of epoch 7, training loss 0.661849, test_loss 0.817242, accuracy = 0.747061/0.752721, f1 = 0.747958\n",
      "Confusion matrix:\n",
      "[[822  96   5  14]\n",
      " [ 27 540  18  15]\n",
      " [ 16 259 246  32]\n",
      " [ 22  49  15 121]]\n",
      "Epoch 8, step 0, training loss 0.712301, test_loss 0.816662, accuracy = 0.743579/0.753592, f1 = 0.749029\n",
      "Epoch 8, step 25, training loss 0.621419, test_loss 0.821338, accuracy = 0.731824/0.750109, f1 = 0.742549\n",
      "Epoch 8, step 50, training loss 0.606820, test_loss 0.816912, accuracy = 0.740096/0.751415, f1 = 0.745315\n",
      "Epoch 8, step 75, training loss 0.669229, test_loss 0.807649, accuracy = 0.745755/0.751850, f1 = 0.747809\n",
      "Epoch 8, step 100, training loss 0.732974, test_loss 0.824596, accuracy = 0.742708/0.758816, f1 = 0.756288\n",
      "Epoch 8, step 125, training loss 0.587738, test_loss 0.816758, accuracy = 0.739661/0.760557, f1 = 0.758357\n",
      "Epoch 8, step 150, training loss 0.619170, test_loss 0.819281, accuracy = 0.741402/0.768394, f1 = 0.766845\n",
      "Epoch 8, step 175, training loss 0.818398, test_loss 0.816110, accuracy = 0.739660/0.768394, f1 = 0.765946\n",
      "Epoch 8, step 200, training loss 0.553255, test_loss 0.820846, accuracy = 0.744449/0.760993, f1 = 0.758341\n",
      "Epoch 8, step 225, training loss 0.599844, test_loss 0.822703, accuracy = 0.735307/0.769264, f1 = 0.767748\n",
      "Epoch 8, step 250, training loss 0.718289, test_loss 0.817159, accuracy = 0.738354/0.767523, f1 = 0.765881\n",
      "Epoch 8, step 275, training loss 0.721950, test_loss 0.820852, accuracy = 0.736178/0.770570, f1 = 0.769111\n",
      "Epoch 8, step 300, training loss 0.695573, test_loss 0.818195, accuracy = 0.730083/0.771441, f1 = 0.770249\n",
      "Epoch 8, step 325, training loss 0.739226, test_loss 0.813515, accuracy = 0.739661/0.767087, f1 = 0.764399\n",
      "Epoch 8, step 350, training loss 0.756514, test_loss 0.830517, accuracy = 0.730953/0.769264, f1 = 0.765865\n",
      "Epoch 8, step 375, training loss 0.822731, test_loss 0.832476, accuracy = 0.740096/0.772747, f1 = 0.770539\n",
      "Epoch 8, step 400, training loss 0.745920, test_loss 0.813688, accuracy = 0.742273/0.777971, f1 = 0.776638\n",
      "End of epoch 8, training loss 0.606808, test_loss 0.818643, accuracy = 0.744014/0.775795, f1 = 0.774014\n",
      "Confusion matrix:\n",
      "[[832  80   9  16]\n",
      " [ 31 527  23  19]\n",
      " [ 17 197 301  38]\n",
      " [ 23  43  19 122]]\n",
      "Epoch 9, step 0, training loss 0.614055, test_loss 0.812367, accuracy = 0.741402/0.776230, f1 = 0.774526\n",
      "Epoch 9, step 25, training loss 0.660794, test_loss 0.811697, accuracy = 0.742272/0.767087, f1 = 0.763667\n",
      "Epoch 9, step 50, training loss 0.618916, test_loss 0.814766, accuracy = 0.738354/0.773618, f1 = 0.770921\n",
      "Epoch 9, step 75, training loss 0.697712, test_loss 0.806462, accuracy = 0.741837/0.781019, f1 = 0.779908\n",
      "Epoch 9, step 100, training loss 0.696376, test_loss 0.794518, accuracy = 0.747061/0.785808, f1 = 0.785743\n",
      "Epoch 9, step 125, training loss 0.680312, test_loss 0.799921, accuracy = 0.750109/0.786678, f1 = 0.786957\n",
      "Epoch 9, step 150, training loss 0.670957, test_loss 0.819992, accuracy = 0.733566/0.790161, f1 = 0.790773\n",
      "Epoch 9, step 175, training loss 0.668260, test_loss 0.829424, accuracy = 0.730083/0.789290, f1 = 0.789379\n",
      "Epoch 9, step 200, training loss 0.582183, test_loss 0.811415, accuracy = 0.738790/0.785372, f1 = 0.785850\n",
      "Epoch 9, step 225, training loss 0.689023, test_loss 0.813029, accuracy = 0.741837/0.787549, f1 = 0.787983\n",
      "Epoch 9, step 250, training loss 0.753151, test_loss 0.817764, accuracy = 0.741837/0.788855, f1 = 0.789382\n",
      "Epoch 9, step 275, training loss 0.733177, test_loss 0.813064, accuracy = 0.745755/0.786678, f1 = 0.787352\n",
      "Epoch 9, step 300, training loss 0.689031, test_loss 0.821296, accuracy = 0.737484/0.786678, f1 = 0.787198\n",
      "Epoch 9, step 325, training loss 0.845426, test_loss 0.812572, accuracy = 0.733565/0.784502, f1 = 0.784556\n",
      "Epoch 9, step 350, training loss 0.672319, test_loss 0.821331, accuracy = 0.742708/0.791467, f1 = 0.791477\n",
      "Epoch 9, step 375, training loss 0.868737, test_loss 0.805655, accuracy = 0.746626/0.787984, f1 = 0.788193\n",
      "Epoch 9, step 400, training loss 0.740030, test_loss 0.799518, accuracy = 0.747932/0.793644, f1 = 0.794856\n",
      "End of epoch 9, training loss 0.581434, test_loss 0.813883, accuracy = 0.744014/0.792773, f1 = 0.793924\n",
      "Confusion matrix:\n",
      "[[828  78  10  21]\n",
      " [ 33 507  31  29]\n",
      " [ 20 130 357  46]\n",
      " [ 24  34  20 129]]\n",
      "Epoch 10, step 0, training loss 0.629426, test_loss 0.827725, accuracy = 0.737484/0.792773, f1 = 0.793999\n",
      "Epoch 10, step 25, training loss 0.580552, test_loss 0.822101, accuracy = 0.736178/0.781889, f1 = 0.781611\n",
      "Epoch 10, step 50, training loss 0.686107, test_loss 0.819242, accuracy = 0.740096/0.789290, f1 = 0.789712\n",
      "Epoch 10, step 75, training loss 0.614087, test_loss 0.818737, accuracy = 0.736178/0.793209, f1 = 0.793985\n",
      "Epoch 10, step 100, training loss 0.698227, test_loss 0.804401, accuracy = 0.743143/0.797127, f1 = 0.798448\n",
      "Epoch 10, step 125, training loss 0.583424, test_loss 0.806637, accuracy = 0.748367/0.790596, f1 = 0.791456\n",
      "Epoch 10, step 150, training loss 0.637337, test_loss 0.798465, accuracy = 0.750544/0.794079, f1 = 0.795330\n",
      "Epoch 10, step 175, training loss 0.791985, test_loss 0.820263, accuracy = 0.738790/0.796691, f1 = 0.797818\n",
      "Epoch 10, step 200, training loss 0.622720, test_loss 0.807629, accuracy = 0.739225/0.795385, f1 = 0.796523\n",
      "Epoch 10, step 225, training loss 0.622924, test_loss 0.806743, accuracy = 0.741402/0.794515, f1 = 0.796035\n",
      "Epoch 10, step 250, training loss 0.695680, test_loss 0.813281, accuracy = 0.737048/0.797127, f1 = 0.798815\n",
      "Epoch 10, step 275, training loss 0.644189, test_loss 0.824489, accuracy = 0.735742/0.795385, f1 = 0.797289\n",
      "Epoch 10, step 300, training loss 0.659973, test_loss 0.818398, accuracy = 0.734001/0.791467, f1 = 0.793340\n",
      "Epoch 10, step 325, training loss 0.747042, test_loss 0.813316, accuracy = 0.733566/0.794515, f1 = 0.795495\n",
      "Epoch 10, step 350, training loss 0.683535, test_loss 0.825432, accuracy = 0.726600/0.793209, f1 = 0.794119\n",
      "Epoch 10, step 375, training loss 0.794737, test_loss 0.821513, accuracy = 0.740096/0.789726, f1 = 0.791456\n",
      "Epoch 10, step 400, training loss 0.693393, test_loss 0.816549, accuracy = 0.733130/0.791467, f1 = 0.793715\n",
      "End of epoch 10, training loss 0.599695, test_loss 0.813203, accuracy = 0.731389/0.790161, f1 = 0.792397\n",
      "Confusion matrix:\n",
      "[[824  76  12  25]\n",
      " [ 31 498  38  33]\n",
      " [ 17 126 363  47]\n",
      " [ 18  35  24 130]]\n",
      "Epoch 11, step 0, training loss 0.726376, test_loss 0.813709, accuracy = 0.736613/0.790161, f1 = 0.792427\n",
      "Epoch 11, step 25, training loss 0.624613, test_loss 0.827116, accuracy = 0.737048/0.788855, f1 = 0.790919\n",
      "Epoch 11, step 50, training loss 0.683074, test_loss 0.832939, accuracy = 0.732259/0.791902, f1 = 0.793721\n",
      "Epoch 11, step 75, training loss 0.630037, test_loss 0.802508, accuracy = 0.742708/0.797562, f1 = 0.799759\n",
      "Epoch 11, step 100, training loss 0.614745, test_loss 0.806113, accuracy = 0.745320/0.798868, f1 = 0.801551\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 11, step 125, training loss 0.604316, test_loss 0.813638, accuracy = 0.742708/0.795821, f1 = 0.799119\n",
      "Epoch 11, step 150, training loss 0.723712, test_loss 0.834312, accuracy = 0.724859/0.796256, f1 = 0.799142\n",
      "Epoch 11, step 175, training loss 0.823662, test_loss 0.820423, accuracy = 0.740531/0.794079, f1 = 0.796553\n",
      "Epoch 11, step 200, training loss 0.538595, test_loss 0.821628, accuracy = 0.734001/0.794515, f1 = 0.796050\n",
      "Epoch 11, step 225, training loss 0.603360, test_loss 0.823658, accuracy = 0.724859/0.792338, f1 = 0.794364\n",
      "Epoch 11, step 250, training loss 0.664977, test_loss 0.831494, accuracy = 0.732695/0.792338, f1 = 0.794556\n",
      "Epoch 11, step 275, training loss 0.680270, test_loss 0.823730, accuracy = 0.728777/0.797562, f1 = 0.799913\n",
      "Epoch 11, step 300, training loss 0.646851, test_loss 0.830486, accuracy = 0.734436/0.791032, f1 = 0.793433\n",
      "Epoch 11, step 325, training loss 0.747431, test_loss 0.816631, accuracy = 0.733566/0.791467, f1 = 0.793712\n",
      "Epoch 11, step 350, training loss 0.765260, test_loss 0.829896, accuracy = 0.730083/0.791902, f1 = 0.793570\n",
      "Epoch 11, step 375, training loss 0.785231, test_loss 0.818855, accuracy = 0.740096/0.792773, f1 = 0.795016\n",
      "Epoch 11, step 400, training loss 0.652046, test_loss 0.809060, accuracy = 0.740096/0.794950, f1 = 0.797351\n",
      "End of epoch 11, training loss 0.603905, test_loss 0.813923, accuracy = 0.737484/0.794950, f1 = 0.797272\n",
      "Confusion matrix:\n",
      "[[824  74  13  26]\n",
      " [ 31 490  47  32]\n",
      " [ 18 106 384  45]\n",
      " [ 18  33  28 128]]\n",
      "Epoch 12, step 0, training loss 0.609360, test_loss 0.823492, accuracy = 0.742708/0.794950, f1 = 0.797272\n",
      "Epoch 12, step 25, training loss 0.643634, test_loss 0.816236, accuracy = 0.740967/0.792773, f1 = 0.795008\n",
      "Epoch 12, step 50, training loss 0.629730, test_loss 0.821025, accuracy = 0.740096/0.794950, f1 = 0.797191\n",
      "Epoch 12, step 75, training loss 0.687212, test_loss 0.820171, accuracy = 0.747497/0.797562, f1 = 0.799917\n",
      "Epoch 12, step 100, training loss 0.669978, test_loss 0.817253, accuracy = 0.737919/0.798868, f1 = 0.801593\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 12, step 125, training loss 0.624477, test_loss 0.818028, accuracy = 0.731824/0.797127, f1 = 0.800233\n",
      "Epoch 12, step 150, training loss 0.704089, test_loss 0.809940, accuracy = 0.744014/0.795385, f1 = 0.798591\n",
      "Epoch 12, step 175, training loss 0.756829, test_loss 0.818463, accuracy = 0.730083/0.796256, f1 = 0.799060\n",
      "Epoch 12, step 200, training loss 0.617304, test_loss 0.812380, accuracy = 0.737484/0.799739, f1 = 0.801801\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 12, step 225, training loss 0.593901, test_loss 0.825165, accuracy = 0.737048/0.797997, f1 = 0.800457\n",
      "Epoch 12, step 250, training loss 0.710689, test_loss 0.820176, accuracy = 0.742708/0.799303, f1 = 0.801662\n",
      "Epoch 12, step 275, training loss 0.680318, test_loss 0.822700, accuracy = 0.734872/0.797127, f1 = 0.799892\n",
      "Epoch 12, step 300, training loss 0.717013, test_loss 0.820755, accuracy = 0.734001/0.797127, f1 = 0.799943\n",
      "Epoch 12, step 325, training loss 0.754791, test_loss 0.820409, accuracy = 0.728341/0.796691, f1 = 0.798918\n",
      "Epoch 12, step 350, training loss 0.721527, test_loss 0.817276, accuracy = 0.731824/0.800174, f1 = 0.801901\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 12, step 375, training loss 0.795052, test_loss 0.818746, accuracy = 0.730953/0.797127, f1 = 0.799688\n",
      "Epoch 12, step 400, training loss 0.707524, test_loss 0.822211, accuracy = 0.737919/0.801480, f1 = 0.804446\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "End of epoch 12, training loss 0.605318, test_loss 0.824415, accuracy = 0.726165/0.801045, f1 = 0.803892\n",
      "Confusion matrix:\n",
      "[[818  75  15  29]\n",
      " [ 26 491  51  32]\n",
      " [ 17  95 400  41]\n",
      " [ 16  32  28 131]]\n",
      "Epoch 13, step 0, training loss 0.595861, test_loss 0.822572, accuracy = 0.731824/0.800610, f1 = 0.803466\n",
      "Epoch 13, step 25, training loss 0.636308, test_loss 0.821591, accuracy = 0.734436/0.797127, f1 = 0.799629\n",
      "Epoch 13, step 50, training loss 0.618244, test_loss 0.803742, accuracy = 0.741837/0.797997, f1 = 0.800328\n",
      "Epoch 13, step 75, training loss 0.640123, test_loss 0.806588, accuracy = 0.744014/0.798868, f1 = 0.801584\n",
      "Epoch 13, step 100, training loss 0.719983, test_loss 0.794106, accuracy = 0.746626/0.802351, f1 = 0.805821\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 13, step 125, training loss 0.618660, test_loss 0.821449, accuracy = 0.730083/0.799739, f1 = 0.803297\n",
      "Epoch 13, step 150, training loss 0.670820, test_loss 0.822090, accuracy = 0.734001/0.800174, f1 = 0.803252\n",
      "Epoch 13, step 175, training loss 0.756779, test_loss 0.811960, accuracy = 0.741837/0.802351, f1 = 0.804887\n",
      "Epoch 13, step 200, training loss 0.630961, test_loss 0.806730, accuracy = 0.742273/0.804092, f1 = 0.806110\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 13, step 225, training loss 0.567278, test_loss 0.801533, accuracy = 0.735742/0.805398, f1 = 0.807373\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 13, step 250, training loss 0.709778, test_loss 0.814054, accuracy = 0.743579/0.804528, f1 = 0.806809\n",
      "Epoch 13, step 275, training loss 0.708587, test_loss 0.806452, accuracy = 0.741837/0.800610, f1 = 0.802905\n",
      "Epoch 13, step 300, training loss 0.709686, test_loss 0.818343, accuracy = 0.737484/0.798868, f1 = 0.801268\n",
      "Epoch 13, step 325, training loss 0.780230, test_loss 0.819685, accuracy = 0.729647/0.798433, f1 = 0.800915\n",
      "Epoch 13, step 350, training loss 0.687164, test_loss 0.825827, accuracy = 0.730518/0.798433, f1 = 0.800528\n",
      "Epoch 13, step 375, training loss 0.727649, test_loss 0.823694, accuracy = 0.732695/0.802351, f1 = 0.805098\n",
      "Epoch 13, step 400, training loss 0.695535, test_loss 0.824912, accuracy = 0.736178/0.804963, f1 = 0.807625\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "End of epoch 13, training loss 0.556812, test_loss 0.826805, accuracy = 0.736613/0.803222, f1 = 0.805818\n",
      "Confusion matrix:\n",
      "[[820  70  18  29]\n",
      " [ 26 483  58  33]\n",
      " [ 16  81 417  39]\n",
      " [ 16  30  36 125]]\n",
      "Epoch 14, step 0, training loss 0.598257, test_loss 0.814953, accuracy = 0.731824/0.803657, f1 = 0.806185\n",
      "Epoch 14, step 25, training loss 0.669230, test_loss 0.819018, accuracy = 0.734872/0.797127, f1 = 0.799508\n",
      "Epoch 14, step 50, training loss 0.688119, test_loss 0.828051, accuracy = 0.733566/0.801916, f1 = 0.804145\n",
      "Epoch 14, step 75, training loss 0.757284, test_loss 0.818897, accuracy = 0.735307/0.802351, f1 = 0.804688\n",
      "Epoch 14, step 100, training loss 0.671241, test_loss 0.812906, accuracy = 0.734001/0.799739, f1 = 0.802528\n",
      "Epoch 14, step 125, training loss 0.626851, test_loss 0.822716, accuracy = 0.738790/0.799739, f1 = 0.802803\n",
      "Epoch 14, step 150, training loss 0.705774, test_loss 0.832431, accuracy = 0.730953/0.799303, f1 = 0.802484\n",
      "Epoch 14, step 175, training loss 0.734966, test_loss 0.813413, accuracy = 0.736178/0.800174, f1 = 0.803221\n",
      "Epoch 14, step 200, training loss 0.647176, test_loss 0.821948, accuracy = 0.731389/0.800610, f1 = 0.803081\n",
      "Epoch 14, step 225, training loss 0.620118, test_loss 0.827303, accuracy = 0.734872/0.800610, f1 = 0.803248\n",
      "Epoch 14, step 250, training loss 0.653909, test_loss 0.808877, accuracy = 0.737919/0.801480, f1 = 0.804200\n",
      "Epoch 14, step 275, training loss 0.700630, test_loss 0.821042, accuracy = 0.730953/0.801916, f1 = 0.804221\n",
      "Epoch 14, step 300, training loss 0.657859, test_loss 0.806957, accuracy = 0.744449/0.797127, f1 = 0.799440\n",
      "Epoch 14, step 325, training loss 0.753463, test_loss 0.818441, accuracy = 0.737048/0.798433, f1 = 0.800872\n",
      "Epoch 14, step 350, training loss 0.679440, test_loss 0.818804, accuracy = 0.730083/0.798433, f1 = 0.800305\n",
      "Epoch 14, step 375, training loss 0.747133, test_loss 0.832805, accuracy = 0.728777/0.799739, f1 = 0.802542\n",
      "Epoch 14, step 400, training loss 0.690283, test_loss 0.830032, accuracy = 0.730083/0.800174, f1 = 0.803338\n",
      "End of epoch 14, training loss 0.576898, test_loss 0.822735, accuracy = 0.733130/0.800610, f1 = 0.803626\n",
      "Confusion matrix:\n",
      "[[817  69  18  33]\n",
      " [ 28 481  56  35]\n",
      " [ 18  83 411  41]\n",
      " [ 16  28  33 130]]\n",
      "Epoch 15, step 0, training loss 0.668316, test_loss 0.827548, accuracy = 0.725294/0.800610, f1 = 0.803656\n",
      "Epoch 15, step 25, training loss 0.594150, test_loss 0.825371, accuracy = 0.728777/0.799303, f1 = 0.802417\n",
      "Epoch 15, step 50, training loss 0.631771, test_loss 0.819642, accuracy = 0.735307/0.797562, f1 = 0.800576\n",
      "Epoch 15, step 75, training loss 0.614397, test_loss 0.805450, accuracy = 0.741402/0.800610, f1 = 0.803111\n",
      "Epoch 15, step 100, training loss 0.667510, test_loss 0.803442, accuracy = 0.743579/0.799303, f1 = 0.802076\n",
      "Epoch 15, step 125, training loss 0.630494, test_loss 0.810995, accuracy = 0.736178/0.800610, f1 = 0.803588\n",
      "Epoch 15, step 150, training loss 0.766961, test_loss 0.817352, accuracy = 0.743143/0.801480, f1 = 0.804221\n",
      "Epoch 15, step 175, training loss 0.778368, test_loss 0.808600, accuracy = 0.736178/0.802786, f1 = 0.805422\n",
      "Epoch 15, step 200, training loss 0.597834, test_loss 0.816011, accuracy = 0.731389/0.803657, f1 = 0.806119\n",
      "Epoch 15, step 225, training loss 0.612622, test_loss 0.826465, accuracy = 0.738790/0.805398, f1 = 0.807784\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 15, step 250, training loss 0.720730, test_loss 0.840251, accuracy = 0.730953/0.803657, f1 = 0.806185\n",
      "Epoch 15, step 275, training loss 0.638379, test_loss 0.832313, accuracy = 0.734436/0.801480, f1 = 0.804184\n",
      "Epoch 15, step 300, training loss 0.632154, test_loss 0.817398, accuracy = 0.732695/0.800610, f1 = 0.803199\n",
      "Epoch 15, step 325, training loss 0.775690, test_loss 0.828737, accuracy = 0.730518/0.799739, f1 = 0.802273\n",
      "Epoch 15, step 350, training loss 0.700066, test_loss 0.841210, accuracy = 0.724423/0.805398, f1 = 0.806808\n",
      "Epoch 15, step 375, training loss 0.774148, test_loss 0.814407, accuracy = 0.730953/0.802786, f1 = 0.805240\n",
      "Epoch 15, step 400, training loss 0.667930, test_loss 0.821985, accuracy = 0.738354/0.802351, f1 = 0.804809\n",
      "End of epoch 15, training loss 0.583072, test_loss 0.822658, accuracy = 0.740096/0.802351, f1 = 0.804910\n",
      "Confusion matrix:\n",
      "[[821  70  19  27]\n",
      " [ 26 482  59  33]\n",
      " [ 14  80 419  40]\n",
      " [ 14  32  40 121]]\n",
      "Epoch 16, step 0, training loss 0.665188, test_loss 0.813275, accuracy = 0.737048/0.802351, f1 = 0.804910\n",
      "Epoch 16, step 25, training loss 0.588076, test_loss 0.812151, accuracy = 0.741837/0.800174, f1 = 0.802783\n",
      "Epoch 16, step 50, training loss 0.664701, test_loss 0.825527, accuracy = 0.733130/0.799739, f1 = 0.802082\n",
      "Epoch 16, step 75, training loss 0.638640, test_loss 0.812226, accuracy = 0.739660/0.802786, f1 = 0.805337\n",
      "Epoch 16, step 100, training loss 0.642825, test_loss 0.817997, accuracy = 0.735742/0.803657, f1 = 0.806645\n",
      "Epoch 16, step 125, training loss 0.599476, test_loss 0.804535, accuracy = 0.746191/0.802351, f1 = 0.805274\n",
      "Epoch 16, step 150, training loss 0.660606, test_loss 0.816478, accuracy = 0.734872/0.801045, f1 = 0.804191\n",
      "Epoch 16, step 175, training loss 0.795798, test_loss 0.822589, accuracy = 0.730518/0.801045, f1 = 0.804378\n",
      "Epoch 16, step 200, training loss 0.646265, test_loss 0.813312, accuracy = 0.737919/0.803222, f1 = 0.806297\n",
      "Epoch 16, step 225, training loss 0.605735, test_loss 0.812076, accuracy = 0.739660/0.803222, f1 = 0.806192\n",
      "Epoch 16, step 250, training loss 0.706309, test_loss 0.812725, accuracy = 0.740096/0.801045, f1 = 0.804318\n",
      "Epoch 16, step 275, training loss 0.656917, test_loss 0.826871, accuracy = 0.739660/0.801045, f1 = 0.804326\n",
      "Epoch 16, step 300, training loss 0.659422, test_loss 0.822935, accuracy = 0.740966/0.801045, f1 = 0.804264\n",
      "Epoch 16, step 325, training loss 0.636747, test_loss 0.813504, accuracy = 0.743579/0.797562, f1 = 0.800416\n",
      "Epoch 16, step 350, training loss 0.720382, test_loss 0.829852, accuracy = 0.723988/0.800610, f1 = 0.803032\n",
      "Epoch 16, step 375, training loss 0.783775, test_loss 0.820852, accuracy = 0.735307/0.799303, f1 = 0.802571\n",
      "Epoch 16, step 400, training loss 0.699334, test_loss 0.819646, accuracy = 0.730083/0.798868, f1 = 0.802440\n",
      "End of epoch 16, training loss 0.635889, test_loss 0.824341, accuracy = 0.734436/0.802351, f1 = 0.806199\n",
      "Confusion matrix:\n",
      "[[819  61  18  39]\n",
      " [ 31 473  59  37]\n",
      " [ 15  73 417  48]\n",
      " [ 14  26  33 134]]\n",
      "Epoch 17, step 0, training loss 0.666253, test_loss 0.828583, accuracy = 0.724859/0.802351, f1 = 0.806199\n",
      "Epoch 17, step 25, training loss 0.694473, test_loss 0.834436, accuracy = 0.730518/0.797562, f1 = 0.801466\n",
      "Epoch 17, step 50, training loss 0.695071, test_loss 0.811943, accuracy = 0.736613/0.798868, f1 = 0.802345\n",
      "Epoch 17, step 75, training loss 0.674807, test_loss 0.803307, accuracy = 0.742708/0.800610, f1 = 0.803527\n",
      "Epoch 17, step 100, training loss 0.721280, test_loss 0.811591, accuracy = 0.730083/0.803657, f1 = 0.806692\n",
      "Epoch 17, step 125, training loss 0.640288, test_loss 0.820232, accuracy = 0.735307/0.800610, f1 = 0.804068\n",
      "Epoch 17, step 150, training loss 0.621273, test_loss 0.823392, accuracy = 0.728341/0.800174, f1 = 0.803432\n",
      "Epoch 17, step 175, training loss 0.769490, test_loss 0.820812, accuracy = 0.729647/0.800610, f1 = 0.803705\n",
      "Epoch 17, step 200, training loss 0.590462, test_loss 0.818559, accuracy = 0.734436/0.801480, f1 = 0.804197\n",
      "Epoch 17, step 225, training loss 0.599149, test_loss 0.821333, accuracy = 0.728341/0.801916, f1 = 0.805306\n",
      "Epoch 17, step 250, training loss 0.693086, test_loss 0.819379, accuracy = 0.741837/0.804528, f1 = 0.807443\n",
      "Epoch 17, step 275, training loss 0.649605, test_loss 0.811049, accuracy = 0.742708/0.805834, f1 = 0.809010\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 17, step 300, training loss 0.681649, test_loss 0.823925, accuracy = 0.722682/0.801480, f1 = 0.804644\n",
      "Epoch 17, step 325, training loss 0.771763, test_loss 0.823932, accuracy = 0.741402/0.801916, f1 = 0.804826\n",
      "Epoch 17, step 350, training loss 0.649805, test_loss 0.822398, accuracy = 0.734001/0.801916, f1 = 0.804747\n",
      "Epoch 17, step 375, training loss 0.719863, test_loss 0.822625, accuracy = 0.725294/0.800174, f1 = 0.803580\n",
      "Epoch 17, step 400, training loss 0.670239, test_loss 0.816500, accuracy = 0.737484/0.801045, f1 = 0.804634\n",
      "End of epoch 17, training loss 0.637262, test_loss 0.820599, accuracy = 0.733566/0.800610, f1 = 0.804003\n",
      "Confusion matrix:\n",
      "[[817  69  16  35]\n",
      " [ 27 483  55  35]\n",
      " [ 17  84 408  44]\n",
      " [ 14  28  34 131]]\n",
      "Epoch 18, step 0, training loss 0.612552, test_loss 0.827743, accuracy = 0.730083/0.800174, f1 = 0.803598\n",
      "Epoch 18, step 25, training loss 0.661971, test_loss 0.813956, accuracy = 0.733130/0.797997, f1 = 0.801428\n",
      "Epoch 18, step 50, training loss 0.598626, test_loss 0.816325, accuracy = 0.738354/0.800174, f1 = 0.803962\n",
      "Epoch 18, step 75, training loss 0.617731, test_loss 0.804484, accuracy = 0.741837/0.800610, f1 = 0.804186\n",
      "Epoch 18, step 100, training loss 0.606224, test_loss 0.802237, accuracy = 0.738354/0.801045, f1 = 0.804795\n",
      "Epoch 18, step 125, training loss 0.573244, test_loss 0.808754, accuracy = 0.726165/0.801480, f1 = 0.806085\n",
      "Epoch 18, step 150, training loss 0.609204, test_loss 0.822178, accuracy = 0.730083/0.801480, f1 = 0.806103\n",
      "Epoch 18, step 175, training loss 0.769445, test_loss 0.815556, accuracy = 0.733130/0.801480, f1 = 0.805445\n",
      "Epoch 18, step 200, training loss 0.591756, test_loss 0.816262, accuracy = 0.734436/0.801480, f1 = 0.805135\n",
      "Epoch 18, step 225, training loss 0.580172, test_loss 0.811804, accuracy = 0.742708/0.801045, f1 = 0.804944\n",
      "Epoch 18, step 250, training loss 0.692771, test_loss 0.820437, accuracy = 0.731389/0.804963, f1 = 0.808732\n",
      "Epoch 18, step 275, training loss 0.650839, test_loss 0.818433, accuracy = 0.740096/0.804963, f1 = 0.808163\n",
      "Epoch 18, step 300, training loss 0.646399, test_loss 0.817656, accuracy = 0.725729/0.801916, f1 = 0.805348\n",
      "Epoch 18, step 325, training loss 0.761846, test_loss 0.813963, accuracy = 0.737919/0.800174, f1 = 0.803273\n",
      "Epoch 18, step 350, training loss 0.636851, test_loss 0.819957, accuracy = 0.731824/0.797997, f1 = 0.801174\n",
      "Epoch 18, step 375, training loss 0.747657, test_loss 0.826425, accuracy = 0.726165/0.803222, f1 = 0.807337\n",
      "Epoch 18, step 400, training loss 0.724223, test_loss 0.827870, accuracy = 0.737048/0.801480, f1 = 0.805809\n",
      "End of epoch 18, training loss 0.520440, test_loss 0.835803, accuracy = 0.719199/0.800610, f1 = 0.805021\n",
      "Confusion matrix:\n",
      "[[818  63  17  39]\n",
      " [ 28 472  58  42]\n",
      " [ 14  75 415  49]\n",
      " [ 13  26  34 134]]\n",
      "Epoch 19, step 0, training loss 0.649885, test_loss 0.837707, accuracy = 0.720940/0.800174, f1 = 0.804639\n",
      "Epoch 19, step 25, training loss 0.653541, test_loss 0.838152, accuracy = 0.730083/0.798433, f1 = 0.802671\n",
      "Epoch 19, step 50, training loss 0.606556, test_loss 0.818238, accuracy = 0.727471/0.802351, f1 = 0.806217\n",
      "Epoch 19, step 75, training loss 0.611813, test_loss 0.813773, accuracy = 0.732695/0.802351, f1 = 0.805494\n",
      "Epoch 19, step 100, training loss 0.670864, test_loss 0.815972, accuracy = 0.740096/0.800610, f1 = 0.804116\n",
      "Epoch 19, step 125, training loss 0.600861, test_loss 0.816550, accuracy = 0.725729/0.801480, f1 = 0.805523\n",
      "Epoch 19, step 150, training loss 0.743731, test_loss 0.813423, accuracy = 0.736178/0.801480, f1 = 0.805714\n",
      "Epoch 19, step 175, training loss 0.833812, test_loss 0.815229, accuracy = 0.728341/0.799303, f1 = 0.803248\n",
      "Epoch 19, step 200, training loss 0.596404, test_loss 0.816499, accuracy = 0.740966/0.802351, f1 = 0.805730\n",
      "Epoch 19, step 225, training loss 0.640622, test_loss 0.822352, accuracy = 0.734436/0.802786, f1 = 0.806256\n",
      "Epoch 19, step 250, training loss 0.644610, test_loss 0.834031, accuracy = 0.723552/0.804528, f1 = 0.807600\n",
      "Epoch 19, step 275, training loss 0.605532, test_loss 0.826138, accuracy = 0.737048/0.808011, f1 = 0.810894\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 19, step 300, training loss 0.718175, test_loss 0.824177, accuracy = 0.733130/0.801045, f1 = 0.804126\n",
      "Epoch 19, step 325, training loss 0.761115, test_loss 0.820550, accuracy = 0.730083/0.798433, f1 = 0.801887\n",
      "Epoch 19, step 350, training loss 0.727037, test_loss 0.840490, accuracy = 0.719199/0.801480, f1 = 0.804510\n",
      "Epoch 19, step 375, training loss 0.847782, test_loss 0.824779, accuracy = 0.728777/0.799739, f1 = 0.803477\n",
      "Epoch 19, step 400, training loss 0.650608, test_loss 0.834333, accuracy = 0.721376/0.797997, f1 = 0.802086\n",
      "End of epoch 19, training loss 0.650702, test_loss 0.828735, accuracy = 0.736178/0.798433, f1 = 0.802654\n",
      "Confusion matrix:\n",
      "[[818  64  17  38]\n",
      " [ 28 467  61  44]\n",
      " [ 13  76 419  45]\n",
      " [ 14  24  39 130]]\n",
      "Epoch 20, step 0, training loss 0.642676, test_loss 0.830762, accuracy = 0.723117/0.797127, f1 = 0.801463\n",
      "Epoch 20, step 25, training loss 0.546775, test_loss 0.831759, accuracy = 0.725294/0.797562, f1 = 0.801916\n",
      "Epoch 20, step 50, training loss 0.645030, test_loss 0.808056, accuracy = 0.737048/0.801045, f1 = 0.805153\n",
      "Epoch 20, step 75, training loss 0.638301, test_loss 0.802633, accuracy = 0.738790/0.802786, f1 = 0.805945\n",
      "Epoch 20, step 100, training loss 0.689474, test_loss 0.810090, accuracy = 0.734872/0.802786, f1 = 0.806210\n",
      "Epoch 20, step 125, training loss 0.629626, test_loss 0.829521, accuracy = 0.726165/0.801045, f1 = 0.805589\n",
      "Epoch 20, step 150, training loss 0.691928, test_loss 0.821093, accuracy = 0.728341/0.801480, f1 = 0.805369\n",
      "Epoch 20, step 175, training loss 0.736630, test_loss 0.808372, accuracy = 0.736178/0.802351, f1 = 0.805846\n",
      "Epoch 20, step 200, training loss 0.597586, test_loss 0.828234, accuracy = 0.729647/0.801916, f1 = 0.805178\n",
      "Epoch 20, step 225, training loss 0.582948, test_loss 0.816475, accuracy = 0.730518/0.802786, f1 = 0.806072\n",
      "Epoch 20, step 250, training loss 0.646058, test_loss 0.826615, accuracy = 0.727471/0.803222, f1 = 0.806307\n",
      "Epoch 20, step 275, training loss 0.717065, test_loss 0.824239, accuracy = 0.733130/0.804092, f1 = 0.807450\n",
      "Epoch 20, step 300, training loss 0.680670, test_loss 0.812325, accuracy = 0.747932/0.798868, f1 = 0.802522\n",
      "Epoch 20, step 325, training loss 0.711106, test_loss 0.822584, accuracy = 0.728341/0.795385, f1 = 0.799657\n",
      "Epoch 20, step 350, training loss 0.801111, test_loss 0.839709, accuracy = 0.725294/0.798433, f1 = 0.802077\n",
      "Epoch 20, step 375, training loss 0.656972, test_loss 0.827234, accuracy = 0.731824/0.799739, f1 = 0.803818\n",
      "Epoch 20, step 400, training loss 0.691899, test_loss 0.825673, accuracy = 0.725729/0.794950, f1 = 0.800037\n",
      "End of epoch 20, training loss 0.578533, test_loss 0.821361, accuracy = 0.726164/0.795385, f1 = 0.800342\n",
      "Confusion matrix:\n",
      "[[819  58  18  42]\n",
      " [ 31 455  65  49]\n",
      " [ 16  65 420  52]\n",
      " [ 13  23  38 133]]\n",
      "Epoch 21, step 0, training loss 0.601630, test_loss 0.822728, accuracy = 0.734436/0.794950, f1 = 0.799869\n",
      "Epoch 21, step 25, training loss 0.633137, test_loss 0.830457, accuracy = 0.721376/0.797127, f1 = 0.801739\n",
      "Epoch 21, step 50, training loss 0.617414, test_loss 0.830637, accuracy = 0.730518/0.800174, f1 = 0.804834\n",
      "Epoch 21, step 75, training loss 0.630477, test_loss 0.812229, accuracy = 0.734872/0.800610, f1 = 0.804901\n",
      "Epoch 21, step 100, training loss 0.635166, test_loss 0.801196, accuracy = 0.730953/0.802351, f1 = 0.806433\n",
      "Epoch 21, step 125, training loss 0.565062, test_loss 0.836580, accuracy = 0.724423/0.800174, f1 = 0.804718\n",
      "Epoch 21, step 150, training loss 0.672872, test_loss 0.828348, accuracy = 0.729647/0.801045, f1 = 0.805769\n",
      "Epoch 21, step 175, training loss 0.722676, test_loss 0.811531, accuracy = 0.736178/0.799739, f1 = 0.804294\n",
      "Epoch 21, step 200, training loss 0.531627, test_loss 0.818952, accuracy = 0.738790/0.801916, f1 = 0.805756\n",
      "Epoch 21, step 225, training loss 0.538718, test_loss 0.812103, accuracy = 0.732695/0.801480, f1 = 0.805403\n",
      "Epoch 21, step 250, training loss 0.757117, test_loss 0.824343, accuracy = 0.730518/0.802786, f1 = 0.806265\n",
      "Epoch 21, step 275, training loss 0.720319, test_loss 0.808970, accuracy = 0.739225/0.804092, f1 = 0.807303\n",
      "Epoch 21, step 300, training loss 0.688951, test_loss 0.828569, accuracy = 0.732259/0.799739, f1 = 0.803381\n",
      "Epoch 21, step 325, training loss 0.681339, test_loss 0.817055, accuracy = 0.736178/0.801916, f1 = 0.805108\n",
      "Epoch 21, step 350, training loss 0.657012, test_loss 0.830068, accuracy = 0.719634/0.802786, f1 = 0.805318\n",
      "Epoch 21, step 375, training loss 0.802123, test_loss 0.825857, accuracy = 0.719199/0.797562, f1 = 0.801633\n",
      "Epoch 21, step 400, training loss 0.680175, test_loss 0.834185, accuracy = 0.724423/0.795821, f1 = 0.799733\n",
      "End of epoch 21, training loss 0.599264, test_loss 0.818439, accuracy = 0.740531/0.794950, f1 = 0.798925\n",
      "Confusion matrix:\n",
      "[[822  59  19  37]\n",
      " [ 31 453  67  49]\n",
      " [ 17  68 422  46]\n",
      " [ 18  23  37 129]]\n",
      "Epoch 22, step 0, training loss 0.658894, test_loss 0.815615, accuracy = 0.735742/0.797127, f1 = 0.801071\n",
      "Epoch 22, step 25, training loss 0.625175, test_loss 0.820411, accuracy = 0.732695/0.797562, f1 = 0.801694\n",
      "Epoch 22, step 50, training loss 0.632003, test_loss 0.830312, accuracy = 0.723988/0.800174, f1 = 0.803755\n",
      "Epoch 22, step 75, training loss 0.669982, test_loss 0.803822, accuracy = 0.738354/0.802351, f1 = 0.805206\n",
      "Epoch 22, step 100, training loss 0.657953, test_loss 0.816747, accuracy = 0.739660/0.802351, f1 = 0.805426\n",
      "Epoch 22, step 125, training loss 0.570289, test_loss 0.814736, accuracy = 0.736178/0.804963, f1 = 0.808456\n",
      "Epoch 22, step 150, training loss 0.654012, test_loss 0.827964, accuracy = 0.728777/0.806269, f1 = 0.809755\n",
      "Epoch 22, step 175, training loss 0.818033, test_loss 0.823906, accuracy = 0.734436/0.806269, f1 = 0.809207\n",
      "Epoch 22, step 200, training loss 0.627128, test_loss 0.818841, accuracy = 0.738354/0.804092, f1 = 0.806953\n",
      "Epoch 22, step 225, training loss 0.587119, test_loss 0.809230, accuracy = 0.737048/0.804092, f1 = 0.807056\n",
      "Epoch 22, step 250, training loss 0.647774, test_loss 0.831474, accuracy = 0.726600/0.804528, f1 = 0.807048\n",
      "Epoch 22, step 275, training loss 0.602106, test_loss 0.819105, accuracy = 0.723117/0.806269, f1 = 0.809009\n",
      "Epoch 22, step 300, training loss 0.679444, test_loss 0.815366, accuracy = 0.735742/0.802786, f1 = 0.805992\n",
      "Epoch 22, step 325, training loss 0.734155, test_loss 0.821340, accuracy = 0.735307/0.801480, f1 = 0.804972\n",
      "Epoch 22, step 350, training loss 0.627874, test_loss 0.833320, accuracy = 0.717458/0.804963, f1 = 0.807696\n",
      "Epoch 22, step 375, training loss 0.759062, test_loss 0.826937, accuracy = 0.727471/0.802351, f1 = 0.806132\n",
      "Epoch 22, step 400, training loss 0.628118, test_loss 0.811616, accuracy = 0.733130/0.799303, f1 = 0.803481\n",
      "End of epoch 22, training loss 0.610657, test_loss 0.831748, accuracy = 0.722682/0.798868, f1 = 0.803302\n",
      "Confusion matrix:\n",
      "[[814  65  19  39]\n",
      " [ 27 460  64  49]\n",
      " [ 12  67 432  42]\n",
      " [ 16  23  39 129]]\n",
      "Epoch 23, step 0, training loss 0.627063, test_loss 0.823252, accuracy = 0.733130/0.798433, f1 = 0.802891\n",
      "Epoch 23, step 25, training loss 0.570918, test_loss 0.841898, accuracy = 0.727906/0.797997, f1 = 0.802511\n",
      "Epoch 23, step 50, training loss 0.621310, test_loss 0.829826, accuracy = 0.720940/0.800174, f1 = 0.804503\n",
      "Epoch 23, step 75, training loss 0.722475, test_loss 0.812820, accuracy = 0.730953/0.801045, f1 = 0.804199\n",
      "Epoch 23, step 100, training loss 0.599689, test_loss 0.812217, accuracy = 0.727471/0.802786, f1 = 0.806085\n",
      "Epoch 23, step 125, training loss 0.584903, test_loss 0.813217, accuracy = 0.737919/0.801480, f1 = 0.805330\n",
      "Epoch 23, step 150, training loss 0.654554, test_loss 0.828631, accuracy = 0.723988/0.804092, f1 = 0.808177\n",
      "Epoch 23, step 175, training loss 0.796822, test_loss 0.814211, accuracy = 0.733130/0.803657, f1 = 0.807318\n",
      "Epoch 23, step 200, training loss 0.628911, test_loss 0.830736, accuracy = 0.732695/0.803222, f1 = 0.806376\n",
      "Epoch 23, step 225, training loss 0.558458, test_loss 0.820681, accuracy = 0.726165/0.804092, f1 = 0.807307\n",
      "Epoch 23, step 250, training loss 0.697812, test_loss 0.819036, accuracy = 0.737919/0.807140, f1 = 0.809337\n",
      "Epoch 23, step 275, training loss 0.638783, test_loss 0.828240, accuracy = 0.734872/0.804092, f1 = 0.806952\n",
      "Epoch 23, step 300, training loss 0.621883, test_loss 0.824041, accuracy = 0.732695/0.802786, f1 = 0.805804\n",
      "Epoch 23, step 325, training loss 0.744096, test_loss 0.818656, accuracy = 0.734872/0.801480, f1 = 0.804666\n",
      "Epoch 23, step 350, training loss 0.707236, test_loss 0.822197, accuracy = 0.730953/0.801916, f1 = 0.804653\n",
      "Epoch 23, step 375, training loss 0.806766, test_loss 0.841257, accuracy = 0.732260/0.799303, f1 = 0.803133\n",
      "Epoch 23, step 400, training loss 0.693813, test_loss 0.830960, accuracy = 0.725294/0.797562, f1 = 0.801956\n",
      "End of epoch 23, training loss 0.581795, test_loss 0.835156, accuracy = 0.722682/0.800174, f1 = 0.804380\n",
      "Confusion matrix:\n",
      "[[824  58  18  37]\n",
      " [ 30 462  60  48]\n",
      " [ 15  69 421  48]\n",
      " [ 16  23  37 131]]\n",
      "Epoch 24, step 0, training loss 0.649258, test_loss 0.828236, accuracy = 0.729212/0.800610, f1 = 0.804818\n",
      "Epoch 24, step 25, training loss 0.590119, test_loss 0.818552, accuracy = 0.729647/0.801480, f1 = 0.805720\n",
      "Epoch 24, step 50, training loss 0.610720, test_loss 0.835502, accuracy = 0.725729/0.802351, f1 = 0.806099\n",
      "Epoch 24, step 75, training loss 0.581612, test_loss 0.814106, accuracy = 0.730953/0.803657, f1 = 0.806596\n",
      "Epoch 24, step 100, training loss 0.707579, test_loss 0.816613, accuracy = 0.734436/0.803222, f1 = 0.806425\n",
      "Epoch 24, step 125, training loss 0.602228, test_loss 0.819966, accuracy = 0.730083/0.801480, f1 = 0.804752\n",
      "Epoch 24, step 150, training loss 0.715832, test_loss 0.817517, accuracy = 0.732259/0.803657, f1 = 0.806825\n",
      "Epoch 24, step 175, training loss 0.739238, test_loss 0.823537, accuracy = 0.725729/0.801045, f1 = 0.803794\n",
      "Epoch 24, step 200, training loss 0.588286, test_loss 0.828285, accuracy = 0.729212/0.803657, f1 = 0.806028\n",
      "Epoch 24, step 225, training loss 0.511649, test_loss 0.814761, accuracy = 0.727035/0.804092, f1 = 0.806698\n",
      "Epoch 24, step 250, training loss 0.589626, test_loss 0.821938, accuracy = 0.728341/0.801045, f1 = 0.803520\n",
      "Epoch 24, step 275, training loss 0.678210, test_loss 0.825506, accuracy = 0.730518/0.807140, f1 = 0.809549\n",
      "Epoch 24, step 300, training loss 0.610511, test_loss 0.831959, accuracy = 0.728777/0.804528, f1 = 0.807342\n",
      "Epoch 24, step 325, training loss 0.803959, test_loss 0.828769, accuracy = 0.726600/0.801916, f1 = 0.804620\n",
      "Epoch 24, step 350, training loss 0.582561, test_loss 0.816321, accuracy = 0.732695/0.803222, f1 = 0.805728\n",
      "Epoch 24, step 375, training loss 0.723972, test_loss 0.834458, accuracy = 0.720070/0.798433, f1 = 0.802127\n",
      "Epoch 24, step 400, training loss 0.725218, test_loss 0.813971, accuracy = 0.736613/0.798433, f1 = 0.802197\n",
      "End of epoch 24, training loss 0.566598, test_loss 0.819174, accuracy = 0.720070/0.798868, f1 = 0.802800\n",
      "Confusion matrix:\n",
      "[[818  63  19  37]\n",
      " [ 28 463  65  44]\n",
      " [ 18  68 423  44]\n",
      " [ 13  23  40 131]]\n",
      "Epoch 25, step 0, training loss 0.633812, test_loss 0.827029, accuracy = 0.730083/0.798433, f1 = 0.802388\n",
      "Epoch 25, step 25, training loss 0.657816, test_loss 0.822533, accuracy = 0.730083/0.804528, f1 = 0.807980\n",
      "Epoch 25, step 50, training loss 0.627338, test_loss 0.836442, accuracy = 0.720070/0.804963, f1 = 0.808242\n",
      "Epoch 25, step 75, training loss 0.638040, test_loss 0.813324, accuracy = 0.731824/0.804092, f1 = 0.806325\n",
      "Epoch 25, step 100, training loss 0.678773, test_loss 0.830227, accuracy = 0.726165/0.803657, f1 = 0.806400\n",
      "Epoch 25, step 125, training loss 0.558187, test_loss 0.827163, accuracy = 0.730083/0.803222, f1 = 0.806696\n",
      "Epoch 25, step 150, training loss 0.632005, test_loss 0.839258, accuracy = 0.718764/0.802786, f1 = 0.806824\n",
      "Epoch 25, step 175, training loss 0.824168, test_loss 0.820621, accuracy = 0.729647/0.807140, f1 = 0.810416\n",
      "Epoch 25, step 200, training loss 0.581055, test_loss 0.814102, accuracy = 0.735307/0.801916, f1 = 0.804583\n",
      "Epoch 25, step 225, training loss 0.665315, test_loss 0.816447, accuracy = 0.737484/0.805398, f1 = 0.808237\n",
      "Epoch 25, step 250, training loss 0.740771, test_loss 0.828533, accuracy = 0.733130/0.803222, f1 = 0.806194\n",
      "Epoch 25, step 275, training loss 0.666617, test_loss 0.816923, accuracy = 0.737484/0.804092, f1 = 0.807097\n",
      "Epoch 25, step 300, training loss 0.662888, test_loss 0.826627, accuracy = 0.726600/0.801045, f1 = 0.804421\n",
      "Epoch 25, step 325, training loss 0.747625, test_loss 0.829586, accuracy = 0.720940/0.799303, f1 = 0.802234\n",
      "Epoch 25, step 350, training loss 0.699567, test_loss 0.836044, accuracy = 0.721376/0.801916, f1 = 0.804547\n",
      "Epoch 25, step 375, training loss 0.806717, test_loss 0.825881, accuracy = 0.717893/0.795385, f1 = 0.800286\n",
      "Epoch 25, step 400, training loss 0.691760, test_loss 0.828233, accuracy = 0.727906/0.798868, f1 = 0.802930\n",
      "End of epoch 25, training loss 0.559519, test_loss 0.825851, accuracy = 0.720505/0.797997, f1 = 0.801937\n",
      "Confusion matrix:\n",
      "[[822  60  21  34]\n",
      " [ 32 455  66  47]\n",
      " [ 15  67 424  47]\n",
      " [ 14  22  39 132]]\n",
      "Epoch 26, step 0, training loss 0.610788, test_loss 0.820361, accuracy = 0.727906/0.798433, f1 = 0.802370\n",
      "Epoch 26, step 25, training loss 0.582141, test_loss 0.820196, accuracy = 0.734001/0.797997, f1 = 0.801670\n",
      "Epoch 26, step 50, training loss 0.665230, test_loss 0.836076, accuracy = 0.719199/0.803222, f1 = 0.806437\n",
      "Epoch 26, step 75, training loss 0.589330, test_loss 0.827813, accuracy = 0.723988/0.801916, f1 = 0.805269\n",
      "Epoch 26, step 100, training loss 0.715238, test_loss 0.816035, accuracy = 0.734001/0.801480, f1 = 0.805049\n",
      "Epoch 26, step 125, training loss 0.524409, test_loss 0.822818, accuracy = 0.730518/0.803657, f1 = 0.807082\n",
      "Epoch 26, step 150, training loss 0.666485, test_loss 0.828519, accuracy = 0.721811/0.799303, f1 = 0.803400\n",
      "Epoch 26, step 175, training loss 0.752241, test_loss 0.822491, accuracy = 0.728341/0.801480, f1 = 0.805598\n",
      "Epoch 26, step 200, training loss 0.613877, test_loss 0.831586, accuracy = 0.728341/0.798868, f1 = 0.802610\n",
      "Epoch 26, step 225, training loss 0.586860, test_loss 0.824504, accuracy = 0.721811/0.798433, f1 = 0.802045\n",
      "Epoch 26, step 250, training loss 0.729198, test_loss 0.812423, accuracy = 0.724859/0.800174, f1 = 0.803538\n",
      "Epoch 26, step 275, training loss 0.618263, test_loss 0.812739, accuracy = 0.728777/0.801916, f1 = 0.805060\n",
      "Epoch 26, step 300, training loss 0.696204, test_loss 0.821990, accuracy = 0.728777/0.799303, f1 = 0.802566\n",
      "Epoch 26, step 325, training loss 0.757182, test_loss 0.823812, accuracy = 0.728341/0.802351, f1 = 0.805669\n",
      "Epoch 26, step 350, training loss 0.715383, test_loss 0.815266, accuracy = 0.724859/0.800174, f1 = 0.803115\n",
      "Epoch 26, step 375, training loss 0.811071, test_loss 0.833608, accuracy = 0.726165/0.800174, f1 = 0.803458\n",
      "Epoch 26, step 400, training loss 0.741944, test_loss 0.814555, accuracy = 0.726165/0.799303, f1 = 0.803029\n",
      "End of epoch 26, training loss 0.667401, test_loss 0.822791, accuracy = 0.724423/0.798868, f1 = 0.802841\n",
      "Confusion matrix:\n",
      "[[815  66  21  35]\n",
      " [ 27 469  63  41]\n",
      " [ 15  69 423  46]\n",
      " [ 12  26  41 128]]\n",
      "Epoch 27, step 0, training loss 0.624202, test_loss 0.832522, accuracy = 0.720940/0.799303, f1 = 0.803271\n",
      "Epoch 27, step 25, training loss 0.637578, test_loss 0.829370, accuracy = 0.720070/0.798433, f1 = 0.802736\n",
      "Epoch 27, step 50, training loss 0.604909, test_loss 0.832342, accuracy = 0.717458/0.801045, f1 = 0.805026\n",
      "Epoch 27, step 75, training loss 0.554567, test_loss 0.815383, accuracy = 0.735742/0.803657, f1 = 0.806772\n",
      "Epoch 27, step 100, training loss 0.607924, test_loss 0.819057, accuracy = 0.730518/0.804528, f1 = 0.808155\n",
      "Epoch 27, step 125, training loss 0.630582, test_loss 0.816073, accuracy = 0.734872/0.801480, f1 = 0.806043\n",
      "Epoch 27, step 150, training loss 0.641818, test_loss 0.830002, accuracy = 0.724423/0.799739, f1 = 0.804246\n",
      "Epoch 27, step 175, training loss 0.671887, test_loss 0.804021, accuracy = 0.742272/0.798433, f1 = 0.802490\n",
      "Epoch 27, step 200, training loss 0.580836, test_loss 0.819934, accuracy = 0.735307/0.801480, f1 = 0.804890\n",
      "Epoch 27, step 225, training loss 0.571480, test_loss 0.816526, accuracy = 0.729212/0.800174, f1 = 0.804011\n",
      "Epoch 27, step 250, training loss 0.683753, test_loss 0.825498, accuracy = 0.734436/0.801045, f1 = 0.805169\n",
      "Epoch 27, step 275, training loss 0.756375, test_loss 0.818790, accuracy = 0.728777/0.800610, f1 = 0.804076\n",
      "Epoch 27, step 300, training loss 0.561379, test_loss 0.808448, accuracy = 0.741402/0.799739, f1 = 0.803184\n",
      "Epoch 27, step 325, training loss 0.779414, test_loss 0.832031, accuracy = 0.724859/0.797997, f1 = 0.801328\n",
      "Epoch 27, step 350, training loss 0.694932, test_loss 0.830981, accuracy = 0.728341/0.798868, f1 = 0.802310\n",
      "Epoch 27, step 375, training loss 0.802935, test_loss 0.826061, accuracy = 0.720070/0.794515, f1 = 0.799507\n",
      "Epoch 27, step 400, training loss 0.770191, test_loss 0.822575, accuracy = 0.729647/0.794079, f1 = 0.799286\n",
      "End of epoch 27, training loss 0.604184, test_loss 0.822294, accuracy = 0.731824/0.795385, f1 = 0.800318\n",
      "Confusion matrix:\n",
      "[[808  68  22  39]\n",
      " [ 27 456  72  45]\n",
      " [ 12  66 428  47]\n",
      " [  9  24  39 135]]\n",
      "Epoch 28, step 0, training loss 0.627215, test_loss 0.821570, accuracy = 0.728777/0.795821, f1 = 0.800695\n",
      "Epoch 28, step 25, training loss 0.614524, test_loss 0.811801, accuracy = 0.730953/0.798868, f1 = 0.803501\n",
      "Epoch 28, step 50, training loss 0.633396, test_loss 0.826382, accuracy = 0.727906/0.799303, f1 = 0.803802\n",
      "Epoch 28, step 75, training loss 0.595129, test_loss 0.822144, accuracy = 0.725729/0.799303, f1 = 0.802908\n",
      "Epoch 28, step 100, training loss 0.564810, test_loss 0.812538, accuracy = 0.738790/0.799739, f1 = 0.803715\n",
      "Epoch 28, step 125, training loss 0.612877, test_loss 0.811081, accuracy = 0.734001/0.796256, f1 = 0.801127\n",
      "Epoch 28, step 150, training loss 0.666661, test_loss 0.830169, accuracy = 0.727035/0.797562, f1 = 0.802303\n",
      "Epoch 28, step 175, training loss 0.744809, test_loss 0.830029, accuracy = 0.722682/0.801480, f1 = 0.805962\n",
      "Epoch 28, step 200, training loss 0.572287, test_loss 0.821683, accuracy = 0.730518/0.797127, f1 = 0.801425\n",
      "Epoch 28, step 225, training loss 0.607277, test_loss 0.829617, accuracy = 0.730953/0.797997, f1 = 0.802361\n",
      "Epoch 28, step 250, training loss 0.634778, test_loss 0.805906, accuracy = 0.735307/0.801916, f1 = 0.805497\n",
      "Epoch 28, step 275, training loss 0.685956, test_loss 0.811491, accuracy = 0.731824/0.800609, f1 = 0.804199\n",
      "Epoch 28, step 300, training loss 0.726452, test_loss 0.817375, accuracy = 0.730953/0.799739, f1 = 0.803355\n",
      "Epoch 28, step 325, training loss 0.716526, test_loss 0.820147, accuracy = 0.726600/0.799303, f1 = 0.802479\n",
      "Epoch 28, step 350, training loss 0.628772, test_loss 0.833239, accuracy = 0.712669/0.801480, f1 = 0.804240\n",
      "Epoch 28, step 375, training loss 0.736460, test_loss 0.816867, accuracy = 0.724423/0.799303, f1 = 0.802691\n",
      "Epoch 28, step 400, training loss 0.717935, test_loss 0.816961, accuracy = 0.725294/0.798868, f1 = 0.802458\n",
      "End of epoch 28, training loss 0.536285, test_loss 0.822775, accuracy = 0.728777/0.795821, f1 = 0.799093\n",
      "Confusion matrix:\n",
      "[[818  64  21  34]\n",
      " [ 29 467  67  37]\n",
      " [ 17  73 418  45]\n",
      " [ 15  25  42 125]]\n",
      "Epoch 29, step 0, training loss 0.617030, test_loss 0.823699, accuracy = 0.723552/0.795385, f1 = 0.798707\n",
      "Epoch 29, step 25, training loss 0.587781, test_loss 0.825234, accuracy = 0.728777/0.794079, f1 = 0.797743\n",
      "Epoch 29, step 50, training loss 0.654492, test_loss 0.838784, accuracy = 0.719634/0.797562, f1 = 0.801649\n",
      "Epoch 29, step 75, training loss 0.626546, test_loss 0.810022, accuracy = 0.732695/0.802786, f1 = 0.805665\n",
      "Epoch 29, step 100, training loss 0.681545, test_loss 0.812437, accuracy = 0.733130/0.805398, f1 = 0.807824\n",
      "Epoch 29, step 125, training loss 0.619555, test_loss 0.817053, accuracy = 0.727035/0.801480, f1 = 0.805371\n",
      "Epoch 29, step 150, training loss 0.682489, test_loss 0.823761, accuracy = 0.734436/0.800174, f1 = 0.804321\n",
      "Epoch 29, step 175, training loss 0.737334, test_loss 0.823987, accuracy = 0.730953/0.798433, f1 = 0.802544\n",
      "Epoch 29, step 200, training loss 0.605015, test_loss 0.823888, accuracy = 0.724859/0.802351, f1 = 0.805373\n",
      "Epoch 29, step 225, training loss 0.527623, test_loss 0.806910, accuracy = 0.737484/0.799739, f1 = 0.802930\n",
      "Epoch 29, step 250, training loss 0.696101, test_loss 0.822167, accuracy = 0.725729/0.800610, f1 = 0.803814\n",
      "Epoch 29, step 275, training loss 0.685667, test_loss 0.823987, accuracy = 0.731824/0.801916, f1 = 0.804348\n",
      "Epoch 29, step 300, training loss 0.676418, test_loss 0.823859, accuracy = 0.727906/0.800610, f1 = 0.803901\n",
      "Epoch 29, step 325, training loss 0.695102, test_loss 0.830439, accuracy = 0.727471/0.801045, f1 = 0.804196\n",
      "Epoch 29, step 350, training loss 0.637942, test_loss 0.834087, accuracy = 0.715716/0.803222, f1 = 0.805914\n",
      "Epoch 29, step 375, training loss 0.701492, test_loss 0.842051, accuracy = 0.717893/0.800174, f1 = 0.803755\n",
      "Epoch 29, step 400, training loss 0.663715, test_loss 0.824655, accuracy = 0.724423/0.797127, f1 = 0.801471\n",
      "End of epoch 29, training loss 0.604975, test_loss 0.822308, accuracy = 0.724423/0.798868, f1 = 0.802935\n",
      "Confusion matrix:\n",
      "[[820  59  17  41]\n",
      " [ 28 469  62  41]\n",
      " [ 18  71 417  47]\n",
      " [ 13  24  41 129]]\n",
      "Epoch 30, step 0, training loss 0.692250, test_loss 0.844885, accuracy = 0.720505/0.798868, f1 = 0.802935\n",
      "Epoch 30, step 25, training loss 0.676471, test_loss 0.828914, accuracy = 0.730953/0.797562, f1 = 0.802170\n",
      "Epoch 30, step 50, training loss 0.599455, test_loss 0.823876, accuracy = 0.722682/0.800610, f1 = 0.804742\n",
      "Epoch 30, step 75, training loss 0.619735, test_loss 0.821951, accuracy = 0.733130/0.797997, f1 = 0.800845\n",
      "Epoch 30, step 100, training loss 0.717099, test_loss 0.812099, accuracy = 0.733566/0.800610, f1 = 0.803596\n",
      "Epoch 30, step 125, training loss 0.622805, test_loss 0.804851, accuracy = 0.738790/0.802351, f1 = 0.806533\n",
      "Epoch 30, step 150, training loss 0.713908, test_loss 0.829160, accuracy = 0.732695/0.801045, f1 = 0.805174\n",
      "Epoch 30, step 175, training loss 0.770010, test_loss 0.818552, accuracy = 0.739660/0.804092, f1 = 0.807665\n",
      "Epoch 30, step 200, training loss 0.578005, test_loss 0.812131, accuracy = 0.725729/0.803657, f1 = 0.806762\n",
      "Epoch 30, step 225, training loss 0.574790, test_loss 0.813971, accuracy = 0.734872/0.799739, f1 = 0.802927\n",
      "Epoch 30, step 250, training loss 0.670375, test_loss 0.811588, accuracy = 0.741837/0.801480, f1 = 0.804874\n",
      "Epoch 30, step 275, training loss 0.639675, test_loss 0.818998, accuracy = 0.734436/0.803222, f1 = 0.806635\n",
      "Epoch 30, step 300, training loss 0.593164, test_loss 0.825055, accuracy = 0.727471/0.801045, f1 = 0.804453\n",
      "Epoch 30, step 325, training loss 0.750746, test_loss 0.834137, accuracy = 0.729212/0.800610, f1 = 0.803916\n",
      "Epoch 30, step 350, training loss 0.720479, test_loss 0.828945, accuracy = 0.730518/0.800174, f1 = 0.803210\n",
      "Epoch 30, step 375, training loss 0.782567, test_loss 0.820450, accuracy = 0.724423/0.797997, f1 = 0.802042\n",
      "Epoch 30, step 400, training loss 0.672248, test_loss 0.824335, accuracy = 0.734872/0.797127, f1 = 0.801493\n",
      "End of epoch 30, training loss 0.620995, test_loss 0.823232, accuracy = 0.728341/0.799303, f1 = 0.803305\n",
      "Confusion matrix:\n",
      "[[816  62  19  40]\n",
      " [ 33 464  65  38]\n",
      " [ 15  64 425  49]\n",
      " [ 13  23  40 131]]\n",
      "Epoch 31, step 0, training loss 0.648238, test_loss 0.832034, accuracy = 0.713104/0.799303, f1 = 0.803305\n",
      "Epoch 31, step 25, training loss 0.576488, test_loss 0.835444, accuracy = 0.724859/0.795821, f1 = 0.799711\n",
      "Epoch 31, step 50, training loss 0.640086, test_loss 0.829493, accuracy = 0.724423/0.795821, f1 = 0.799560\n",
      "Epoch 31, step 75, training loss 0.681512, test_loss 0.816112, accuracy = 0.739225/0.799303, f1 = 0.802211\n",
      "Epoch 31, step 100, training loss 0.568660, test_loss 0.827787, accuracy = 0.730518/0.799303, f1 = 0.802723\n",
      "Epoch 31, step 125, training loss 0.559314, test_loss 0.826451, accuracy = 0.724859/0.798868, f1 = 0.802933\n",
      "Epoch 31, step 150, training loss 0.688086, test_loss 0.825194, accuracy = 0.729212/0.798868, f1 = 0.802972\n",
      "Epoch 31, step 175, training loss 0.684353, test_loss 0.831290, accuracy = 0.721811/0.801480, f1 = 0.804906\n",
      "Epoch 31, step 200, training loss 0.601140, test_loss 0.820082, accuracy = 0.733566/0.801045, f1 = 0.804093\n",
      "Epoch 31, step 225, training loss 0.561328, test_loss 0.827677, accuracy = 0.714845/0.800610, f1 = 0.803854\n",
      "Epoch 31, step 250, training loss 0.644208, test_loss 0.839233, accuracy = 0.725294/0.801480, f1 = 0.804472\n",
      "Epoch 31, step 275, training loss 0.672276, test_loss 0.810944, accuracy = 0.734436/0.801916, f1 = 0.805079\n",
      "Epoch 31, step 300, training loss 0.596559, test_loss 0.832156, accuracy = 0.726165/0.797562, f1 = 0.801042\n",
      "Epoch 31, step 325, training loss 0.714487, test_loss 0.822534, accuracy = 0.729212/0.797127, f1 = 0.800403\n",
      "Epoch 31, step 350, training loss 0.694866, test_loss 0.840339, accuracy = 0.715716/0.797562, f1 = 0.800402\n",
      "Epoch 31, step 375, training loss 0.834547, test_loss 0.820324, accuracy = 0.730953/0.797127, f1 = 0.801147\n",
      "Epoch 31, step 400, training loss 0.601095, test_loss 0.821069, accuracy = 0.724423/0.798433, f1 = 0.802197\n",
      "End of epoch 31, training loss 0.658094, test_loss 0.831695, accuracy = 0.718764/0.797562, f1 = 0.801414\n",
      "Confusion matrix:\n",
      "[[815  64  18  40]\n",
      " [ 30 466  63  41]\n",
      " [ 16  69 424  44]\n",
      " [ 16  25  39 127]]\n",
      "Epoch 32, step 0, training loss 0.615106, test_loss 0.833721, accuracy = 0.721811/0.797127, f1 = 0.800967\n",
      "Epoch 32, step 25, training loss 0.571198, test_loss 0.837350, accuracy = 0.724859/0.797127, f1 = 0.800982\n",
      "Epoch 32, step 50, training loss 0.615741, test_loss 0.833293, accuracy = 0.726165/0.801480, f1 = 0.804749\n",
      "Epoch 32, step 75, training loss 0.669581, test_loss 0.818495, accuracy = 0.741837/0.797127, f1 = 0.800251\n",
      "Epoch 32, step 100, training loss 0.639399, test_loss 0.815857, accuracy = 0.730083/0.800610, f1 = 0.804202\n",
      "Epoch 32, step 125, training loss 0.556116, test_loss 0.814928, accuracy = 0.730518/0.797997, f1 = 0.802469\n",
      "Epoch 32, step 150, training loss 0.632299, test_loss 0.822728, accuracy = 0.728777/0.799739, f1 = 0.804166\n",
      "Epoch 32, step 175, training loss 0.729192, test_loss 0.821284, accuracy = 0.723988/0.800174, f1 = 0.804206\n",
      "Epoch 32, step 200, training loss 0.626428, test_loss 0.832341, accuracy = 0.727035/0.801045, f1 = 0.804686\n",
      "Epoch 32, step 225, training loss 0.588642, test_loss 0.827276, accuracy = 0.732260/0.802786, f1 = 0.806527\n",
      "Epoch 32, step 250, training loss 0.652844, test_loss 0.818770, accuracy = 0.727906/0.802351, f1 = 0.805917\n",
      "Epoch 32, step 275, training loss 0.660443, test_loss 0.822976, accuracy = 0.739225/0.801045, f1 = 0.804939\n",
      "Epoch 32, step 300, training loss 0.597323, test_loss 0.831930, accuracy = 0.728777/0.798868, f1 = 0.802895\n",
      "Epoch 32, step 325, training loss 0.742058, test_loss 0.812911, accuracy = 0.730083/0.798868, f1 = 0.802948\n",
      "Epoch 32, step 350, training loss 0.676023, test_loss 0.830673, accuracy = 0.720070/0.798868, f1 = 0.802511\n",
      "Epoch 32, step 375, training loss 0.670964, test_loss 0.835771, accuracy = 0.719199/0.796256, f1 = 0.801250\n",
      "Epoch 32, step 400, training loss 0.717754, test_loss 0.826966, accuracy = 0.727035/0.794079, f1 = 0.798979\n",
      "End of epoch 32, training loss 0.621617, test_loss 0.825945, accuracy = 0.719199/0.796256, f1 = 0.800990\n",
      "Confusion matrix:\n",
      "[[816  58  20  43]\n",
      " [ 31 451  68  50]\n",
      " [ 16  61 430  46]\n",
      " [ 13  22  40 132]]\n",
      "Epoch 33, step 0, training loss 0.641127, test_loss 0.837071, accuracy = 0.730518/0.795385, f1 = 0.800109\n",
      "Epoch 33, step 25, training loss 0.648883, test_loss 0.838352, accuracy = 0.726165/0.795385, f1 = 0.800662\n",
      "Epoch 33, step 50, training loss 0.666703, test_loss 0.825232, accuracy = 0.733130/0.794950, f1 = 0.800010\n",
      "Epoch 33, step 75, training loss 0.705207, test_loss 0.820702, accuracy = 0.730083/0.799739, f1 = 0.803743\n",
      "Epoch 33, step 100, training loss 0.699753, test_loss 0.818254, accuracy = 0.738790/0.801480, f1 = 0.805959\n",
      "Epoch 33, step 125, training loss 0.574805, test_loss 0.818641, accuracy = 0.729647/0.797997, f1 = 0.803462\n",
      "Epoch 33, step 150, training loss 0.599341, test_loss 0.822369, accuracy = 0.727471/0.797127, f1 = 0.802161\n",
      "Epoch 33, step 175, training loss 0.696295, test_loss 0.812001, accuracy = 0.732695/0.801045, f1 = 0.805080\n",
      "Epoch 33, step 200, training loss 0.659761, test_loss 0.813528, accuracy = 0.726165/0.806269, f1 = 0.809657\n",
      "Epoch 33, step 225, training loss 0.636105, test_loss 0.821581, accuracy = 0.730953/0.803222, f1 = 0.806465\n",
      "Epoch 33, step 250, training loss 0.757703, test_loss 0.839688, accuracy = 0.739225/0.804092, f1 = 0.807180\n",
      "Epoch 33, step 275, training loss 0.657896, test_loss 0.818851, accuracy = 0.731389/0.802786, f1 = 0.805823\n",
      "Epoch 33, step 300, training loss 0.700552, test_loss 0.826807, accuracy = 0.730083/0.798868, f1 = 0.802137\n",
      "Epoch 33, step 325, training loss 0.730592, test_loss 0.812583, accuracy = 0.734872/0.801480, f1 = 0.804744\n",
      "Epoch 33, step 350, training loss 0.705719, test_loss 0.830804, accuracy = 0.724423/0.799739, f1 = 0.802979\n",
      "Epoch 33, step 375, training loss 0.811143, test_loss 0.821734, accuracy = 0.739225/0.800174, f1 = 0.803934\n",
      "Epoch 33, step 400, training loss 0.670674, test_loss 0.821741, accuracy = 0.725294/0.795385, f1 = 0.800066\n",
      "End of epoch 33, training loss 0.614770, test_loss 0.835448, accuracy = 0.718764/0.795385, f1 = 0.800428\n",
      "Confusion matrix:\n",
      "[[817  62  19  39]\n",
      " [ 25 458  67  50]\n",
      " [ 15  71 417  50]\n",
      " [ 13  25  34 135]]\n",
      "Epoch 34, step 0, training loss 0.657501, test_loss 0.825907, accuracy = 0.724423/0.794515, f1 = 0.799586\n",
      "Epoch 34, step 25, training loss 0.573550, test_loss 0.827436, accuracy = 0.731824/0.793644, f1 = 0.798979\n",
      "Epoch 34, step 50, training loss 0.594533, test_loss 0.832030, accuracy = 0.723988/0.798433, f1 = 0.802701\n",
      "Epoch 34, step 75, training loss 0.665990, test_loss 0.809172, accuracy = 0.745755/0.802786, f1 = 0.806181\n",
      "Epoch 34, step 100, training loss 0.606055, test_loss 0.817366, accuracy = 0.736178/0.799739, f1 = 0.803916\n",
      "Epoch 34, step 125, training loss 0.674012, test_loss 0.819228, accuracy = 0.720940/0.799739, f1 = 0.803992\n",
      "Epoch 34, step 150, training loss 0.637095, test_loss 0.826137, accuracy = 0.721376/0.799739, f1 = 0.803772\n",
      "Epoch 34, step 175, training loss 0.759043, test_loss 0.822777, accuracy = 0.727035/0.800610, f1 = 0.804081\n",
      "Epoch 34, step 200, training loss 0.561636, test_loss 0.831376, accuracy = 0.719634/0.801916, f1 = 0.804439\n",
      "Epoch 34, step 225, training loss 0.558184, test_loss 0.821912, accuracy = 0.724859/0.802786, f1 = 0.805301\n",
      "Epoch 34, step 250, training loss 0.659699, test_loss 0.823422, accuracy = 0.717893/0.802786, f1 = 0.805240\n",
      "Epoch 34, step 275, training loss 0.653872, test_loss 0.836083, accuracy = 0.723553/0.801916, f1 = 0.804720\n",
      "Epoch 34, step 300, training loss 0.636313, test_loss 0.822527, accuracy = 0.728777/0.797997, f1 = 0.801445\n",
      "Epoch 34, step 325, training loss 0.707909, test_loss 0.837249, accuracy = 0.723117/0.799739, f1 = 0.803381\n",
      "Epoch 34, step 350, training loss 0.626607, test_loss 0.841389, accuracy = 0.716587/0.799303, f1 = 0.803066\n",
      "Epoch 34, step 375, training loss 0.757544, test_loss 0.826084, accuracy = 0.721376/0.792773, f1 = 0.798221\n",
      "Epoch 34, step 400, training loss 0.661853, test_loss 0.821239, accuracy = 0.727471/0.792773, f1 = 0.797741\n",
      "End of epoch 34, training loss 0.640596, test_loss 0.837462, accuracy = 0.720070/0.792338, f1 = 0.797472\n",
      "Confusion matrix:\n",
      "[[811  61  20  45]\n",
      " [ 29 448  72  51]\n",
      " [ 15  64 427  47]\n",
      " [ 15  22  36 134]]\n",
      "Epoch 35, step 0, training loss 0.616788, test_loss 0.828780, accuracy = 0.725294/0.791467, f1 = 0.796622\n",
      "Epoch 35, step 25, training loss 0.505978, test_loss 0.834218, accuracy = 0.724423/0.795385, f1 = 0.800965\n",
      "Epoch 35, step 50, training loss 0.701957, test_loss 0.813357, accuracy = 0.731824/0.799303, f1 = 0.804190\n",
      "Epoch 35, step 75, training loss 0.670464, test_loss 0.823776, accuracy = 0.725729/0.799303, f1 = 0.803126\n",
      "Epoch 35, step 100, training loss 0.634810, test_loss 0.816156, accuracy = 0.737484/0.797127, f1 = 0.801622\n",
      "Epoch 35, step 125, training loss 0.588354, test_loss 0.822355, accuracy = 0.724423/0.798433, f1 = 0.802858\n",
      "Epoch 35, step 150, training loss 0.709490, test_loss 0.823376, accuracy = 0.730953/0.799303, f1 = 0.803566\n",
      "Epoch 35, step 175, training loss 0.781920, test_loss 0.823346, accuracy = 0.734436/0.800174, f1 = 0.804312\n",
      "Epoch 35, step 200, training loss 0.629452, test_loss 0.832732, accuracy = 0.724859/0.801916, f1 = 0.805227\n",
      "Epoch 35, step 225, training loss 0.563872, test_loss 0.831429, accuracy = 0.727906/0.800174, f1 = 0.803361\n",
      "Epoch 35, step 250, training loss 0.653177, test_loss 0.820904, accuracy = 0.731389/0.802786, f1 = 0.805396\n",
      "Epoch 35, step 275, training loss 0.656237, test_loss 0.824635, accuracy = 0.731824/0.801480, f1 = 0.804143\n",
      "Epoch 35, step 300, training loss 0.642078, test_loss 0.828340, accuracy = 0.723988/0.801480, f1 = 0.804226\n",
      "Epoch 35, step 325, training loss 0.703727, test_loss 0.823386, accuracy = 0.727906/0.800174, f1 = 0.802333\n",
      "Epoch 35, step 350, training loss 0.738648, test_loss 0.844932, accuracy = 0.725729/0.798433, f1 = 0.800459\n",
      "Epoch 35, step 375, training loss 0.845556, test_loss 0.827376, accuracy = 0.724423/0.798868, f1 = 0.802413\n",
      "Epoch 35, step 400, training loss 0.666877, test_loss 0.830071, accuracy = 0.722246/0.795385, f1 = 0.799741\n",
      "End of epoch 35, training loss 0.638680, test_loss 0.828640, accuracy = 0.724858/0.796256, f1 = 0.800371\n",
      "Confusion matrix:\n",
      "[[819  61  21  36]\n",
      " [ 30 458  66  46]\n",
      " [ 16  70 420  47]\n",
      " [ 14  23  38 132]]\n",
      "Epoch 36, step 0, training loss 0.649241, test_loss 0.828608, accuracy = 0.729212/0.795821, f1 = 0.799894\n",
      "Epoch 36, step 25, training loss 0.577614, test_loss 0.839379, accuracy = 0.729212/0.800174, f1 = 0.803977\n",
      "Epoch 36, step 50, training loss 0.598418, test_loss 0.826571, accuracy = 0.728777/0.801480, f1 = 0.805333\n",
      "Epoch 36, step 75, training loss 0.588101, test_loss 0.799250, accuracy = 0.734001/0.799739, f1 = 0.802991\n",
      "Epoch 36, step 100, training loss 0.702398, test_loss 0.807596, accuracy = 0.732695/0.802351, f1 = 0.805549\n",
      "Epoch 36, step 125, training loss 0.577648, test_loss 0.823257, accuracy = 0.721811/0.802786, f1 = 0.806591\n",
      "Epoch 36, step 150, training loss 0.602007, test_loss 0.831865, accuracy = 0.729212/0.801480, f1 = 0.805755\n",
      "Epoch 36, step 175, training loss 0.726078, test_loss 0.836268, accuracy = 0.721811/0.799739, f1 = 0.803593\n",
      "Epoch 36, step 200, training loss 0.581454, test_loss 0.828492, accuracy = 0.726600/0.802786, f1 = 0.805642\n",
      "Epoch 36, step 225, training loss 0.578549, test_loss 0.827657, accuracy = 0.727906/0.803222, f1 = 0.806334\n",
      "Epoch 36, step 250, training loss 0.698703, test_loss 0.824707, accuracy = 0.723552/0.806269, f1 = 0.809242\n",
      "Epoch 36, step 275, training loss 0.599214, test_loss 0.820255, accuracy = 0.724859/0.801480, f1 = 0.804730\n",
      "Epoch 36, step 300, training loss 0.600764, test_loss 0.827712, accuracy = 0.731389/0.798868, f1 = 0.802141\n",
      "Epoch 36, step 325, training loss 0.714647, test_loss 0.833478, accuracy = 0.731824/0.797997, f1 = 0.801580\n",
      "Epoch 36, step 350, training loss 0.624117, test_loss 0.833598, accuracy = 0.724423/0.796256, f1 = 0.799510\n",
      "Epoch 36, step 375, training loss 0.868071, test_loss 0.819799, accuracy = 0.732695/0.800610, f1 = 0.804859\n",
      "Epoch 36, step 400, training loss 0.676769, test_loss 0.841404, accuracy = 0.719199/0.798433, f1 = 0.802729\n",
      "End of epoch 36, training loss 0.575764, test_loss 0.823937, accuracy = 0.724859/0.797562, f1 = 0.801661\n",
      "Confusion matrix:\n",
      "[[814  63  23  37]\n",
      " [ 27 457  74  42]\n",
      " [ 13  65 431  44]\n",
      " [ 13  24  40 130]]\n",
      "Epoch 37, step 0, training loss 0.577924, test_loss 0.824295, accuracy = 0.729212/0.797997, f1 = 0.802041\n",
      "Epoch 37, step 25, training loss 0.608302, test_loss 0.812802, accuracy = 0.731824/0.798433, f1 = 0.802511\n",
      "Epoch 37, step 50, training loss 0.702737, test_loss 0.824042, accuracy = 0.736613/0.799739, f1 = 0.803312\n",
      "Epoch 37, step 75, training loss 0.665806, test_loss 0.813257, accuracy = 0.735742/0.804528, f1 = 0.807306\n",
      "Epoch 37, step 100, training loss 0.615431, test_loss 0.809927, accuracy = 0.734001/0.804092, f1 = 0.806676\n",
      "Epoch 37, step 125, training loss 0.639547, test_loss 0.821326, accuracy = 0.729212/0.801916, f1 = 0.805007\n",
      "Epoch 37, step 150, training loss 0.634552, test_loss 0.823141, accuracy = 0.731824/0.802786, f1 = 0.805870\n",
      "Epoch 37, step 175, training loss 0.749067, test_loss 0.824637, accuracy = 0.727471/0.801480, f1 = 0.804829\n",
      "Epoch 37, step 200, training loss 0.562860, test_loss 0.806300, accuracy = 0.730953/0.802351, f1 = 0.804787\n",
      "Epoch 37, step 225, training loss 0.625114, test_loss 0.811861, accuracy = 0.732260/0.804528, f1 = 0.806809\n",
      "Epoch 37, step 250, training loss 0.620156, test_loss 0.818758, accuracy = 0.725294/0.804963, f1 = 0.807437\n",
      "Epoch 37, step 275, training loss 0.711095, test_loss 0.818096, accuracy = 0.727906/0.804092, f1 = 0.806748\n",
      "Epoch 37, step 300, training loss 0.716836, test_loss 0.826022, accuracy = 0.730083/0.801045, f1 = 0.804194\n",
      "Epoch 37, step 325, training loss 0.684675, test_loss 0.822325, accuracy = 0.729647/0.798868, f1 = 0.801923\n",
      "Epoch 37, step 350, training loss 0.676030, test_loss 0.830190, accuracy = 0.722682/0.801480, f1 = 0.804095\n",
      "Epoch 37, step 375, training loss 0.821003, test_loss 0.827486, accuracy = 0.721376/0.795821, f1 = 0.799802\n",
      "Epoch 37, step 400, training loss 0.610196, test_loss 0.829147, accuracy = 0.722682/0.797997, f1 = 0.802045\n",
      "End of epoch 37, training loss 0.561977, test_loss 0.834566, accuracy = 0.719634/0.796691, f1 = 0.800916\n",
      "Confusion matrix:\n",
      "[[816  64  22  35]\n",
      " [ 24 457  72  47]\n",
      " [ 14  66 431  42]\n",
      " [ 11  26  44 126]]\n",
      "Epoch 38, step 0, training loss 0.611307, test_loss 0.817326, accuracy = 0.732695/0.797127, f1 = 0.801366\n",
      "Epoch 38, step 25, training loss 0.625073, test_loss 0.825852, accuracy = 0.725294/0.796256, f1 = 0.800666\n",
      "Epoch 38, step 50, training loss 0.624192, test_loss 0.821635, accuracy = 0.726165/0.799739, f1 = 0.803565\n",
      "Epoch 38, step 75, training loss 0.691370, test_loss 0.816692, accuracy = 0.735307/0.800174, f1 = 0.803800\n",
      "Epoch 38, step 100, training loss 0.593154, test_loss 0.821119, accuracy = 0.730953/0.801916, f1 = 0.806460\n",
      "Epoch 38, step 125, training loss 0.614471, test_loss 0.812603, accuracy = 0.732695/0.797562, f1 = 0.803047\n",
      "Epoch 38, step 150, training loss 0.670722, test_loss 0.826121, accuracy = 0.723117/0.799739, f1 = 0.804498\n",
      "Epoch 38, step 175, training loss 0.853532, test_loss 0.827489, accuracy = 0.727035/0.799739, f1 = 0.803384\n",
      "Epoch 38, step 200, training loss 0.558200, test_loss 0.829841, accuracy = 0.727035/0.803657, f1 = 0.806915\n",
      "Epoch 38, step 225, training loss 0.544692, test_loss 0.830168, accuracy = 0.724859/0.804092, f1 = 0.807016\n",
      "Epoch 38, step 250, training loss 0.612918, test_loss 0.832191, accuracy = 0.728777/0.804528, f1 = 0.807562\n",
      "Epoch 38, step 275, training loss 0.692526, test_loss 0.835164, accuracy = 0.727035/0.805834, f1 = 0.808980\n",
      "Epoch 38, step 300, training loss 0.633584, test_loss 0.833826, accuracy = 0.712233/0.804092, f1 = 0.807484\n",
      "Epoch 38, step 325, training loss 0.764468, test_loss 0.827995, accuracy = 0.722246/0.799739, f1 = 0.803472\n",
      "Epoch 38, step 350, training loss 0.629265, test_loss 0.846331, accuracy = 0.720505/0.800610, f1 = 0.803857\n",
      "Epoch 38, step 375, training loss 0.833658, test_loss 0.844214, accuracy = 0.717893/0.796256, f1 = 0.800528\n",
      "Epoch 38, step 400, training loss 0.656432, test_loss 0.826061, accuracy = 0.723988/0.796691, f1 = 0.800964\n",
      "End of epoch 38, training loss 0.608273, test_loss 0.816370, accuracy = 0.727471/0.792773, f1 = 0.797414\n",
      "Confusion matrix:\n",
      "[[819  54  20  44]\n",
      " [ 33 451  67  49]\n",
      " [ 17  65 423  48]\n",
      " [ 14  24  41 128]]\n",
      "Epoch 39, step 0, training loss 0.647240, test_loss 0.822966, accuracy = 0.717458/0.792773, f1 = 0.797378\n",
      "Epoch 39, step 25, training loss 0.734512, test_loss 0.834009, accuracy = 0.723988/0.794515, f1 = 0.798379\n",
      "Epoch 39, step 50, training loss 0.617250, test_loss 0.820266, accuracy = 0.726165/0.801045, f1 = 0.804182\n",
      "Epoch 39, step 75, training loss 0.591103, test_loss 0.808192, accuracy = 0.731824/0.803222, f1 = 0.806616\n",
      "Epoch 39, step 100, training loss 0.807440, test_loss 0.820203, accuracy = 0.730953/0.800610, f1 = 0.804970\n",
      "Epoch 39, step 125, training loss 0.607023, test_loss 0.831484, accuracy = 0.721811/0.795385, f1 = 0.801021\n",
      "Epoch 39, step 150, training loss 0.716545, test_loss 0.823177, accuracy = 0.724423/0.797127, f1 = 0.801753\n",
      "Epoch 39, step 175, training loss 0.766535, test_loss 0.818069, accuracy = 0.730518/0.801045, f1 = 0.804654\n",
      "Epoch 39, step 200, training loss 0.569059, test_loss 0.834275, accuracy = 0.723988/0.802351, f1 = 0.804949\n",
      "Epoch 39, step 225, training loss 0.643156, test_loss 0.827702, accuracy = 0.719634/0.801480, f1 = 0.804742\n",
      "Epoch 39, step 250, training loss 0.647141, test_loss 0.833826, accuracy = 0.722682/0.803657, f1 = 0.806970\n",
      "Epoch 39, step 275, training loss 0.701921, test_loss 0.818300, accuracy = 0.736613/0.801045, f1 = 0.804183\n",
      "Epoch 39, step 300, training loss 0.668359, test_loss 0.819502, accuracy = 0.724859/0.800610, f1 = 0.804207\n",
      "Epoch 39, step 325, training loss 0.787097, test_loss 0.821453, accuracy = 0.723988/0.798868, f1 = 0.802638\n",
      "Epoch 39, step 350, training loss 0.625877, test_loss 0.823128, accuracy = 0.733566/0.799739, f1 = 0.802884\n",
      "Epoch 39, step 375, training loss 0.667100, test_loss 0.819778, accuracy = 0.722246/0.797127, f1 = 0.800846\n",
      "Epoch 39, step 400, training loss 0.657095, test_loss 0.827638, accuracy = 0.723988/0.795385, f1 = 0.799569\n",
      "End of epoch 39, training loss 0.583319, test_loss 0.828472, accuracy = 0.730083/0.797127, f1 = 0.801478\n",
      "Confusion matrix:\n",
      "[[817  62  20  38]\n",
      " [ 28 458  67  47]\n",
      " [ 16  62 429  46]\n",
      " [ 12  26  42 127]]\n",
      "Epoch 40, step 0, training loss 0.633180, test_loss 0.822940, accuracy = 0.731824/0.796256, f1 = 0.800581\n",
      "Epoch 40, step 25, training loss 0.562511, test_loss 0.836429, accuracy = 0.726165/0.793644, f1 = 0.797722\n",
      "Epoch 40, step 50, training loss 0.660230, test_loss 0.841521, accuracy = 0.713975/0.798868, f1 = 0.802478\n",
      "Epoch 40, step 75, training loss 0.661233, test_loss 0.822056, accuracy = 0.730083/0.802786, f1 = 0.805860\n",
      "Epoch 40, step 100, training loss 0.677259, test_loss 0.804929, accuracy = 0.734872/0.801480, f1 = 0.805019\n",
      "Epoch 40, step 125, training loss 0.575960, test_loss 0.824976, accuracy = 0.730518/0.799303, f1 = 0.803383\n",
      "Epoch 40, step 150, training loss 0.715576, test_loss 0.829307, accuracy = 0.728341/0.798868, f1 = 0.803023\n",
      "Epoch 40, step 175, training loss 0.773177, test_loss 0.822028, accuracy = 0.731389/0.799303, f1 = 0.802939\n",
      "Epoch 40, step 200, training loss 0.574563, test_loss 0.825018, accuracy = 0.727906/0.800610, f1 = 0.803368\n",
      "Epoch 40, step 225, training loss 0.579139, test_loss 0.830474, accuracy = 0.730083/0.801045, f1 = 0.803638\n",
      "Epoch 40, step 250, training loss 0.700484, test_loss 0.826413, accuracy = 0.723988/0.801045, f1 = 0.803880\n",
      "Epoch 40, step 275, training loss 0.664224, test_loss 0.825468, accuracy = 0.721811/0.802351, f1 = 0.805379\n",
      "Epoch 40, step 300, training loss 0.662766, test_loss 0.817052, accuracy = 0.733566/0.798433, f1 = 0.802070\n",
      "Epoch 40, step 325, training loss 0.703927, test_loss 0.818181, accuracy = 0.728341/0.797127, f1 = 0.800736\n",
      "Epoch 40, step 350, training loss 0.622656, test_loss 0.824964, accuracy = 0.722682/0.799739, f1 = 0.803047\n",
      "Epoch 40, step 375, training loss 0.650144, test_loss 0.838890, accuracy = 0.725729/0.797997, f1 = 0.802171\n",
      "Epoch 40, step 400, training loss 0.668698, test_loss 0.830662, accuracy = 0.727035/0.796256, f1 = 0.800344\n",
      "End of epoch 40, training loss 0.622978, test_loss 0.832380, accuracy = 0.714410/0.797997, f1 = 0.802064\n",
      "Confusion matrix:\n",
      "[[821  58  21  37]\n",
      " [ 30 453  68  49]\n",
      " [ 17  60 431  45]\n",
      " [ 14  24  41 128]]\n",
      "Epoch 41, step 0, training loss 0.698756, test_loss 0.821391, accuracy = 0.724423/0.797997, f1 = 0.802108\n",
      "Epoch 41, step 25, training loss 0.615150, test_loss 0.825622, accuracy = 0.720505/0.794515, f1 = 0.798887\n",
      "Epoch 41, step 50, training loss 0.606077, test_loss 0.836782, accuracy = 0.718764/0.795385, f1 = 0.799712\n",
      "Epoch 41, step 75, training loss 0.682688, test_loss 0.803701, accuracy = 0.730518/0.799739, f1 = 0.803310\n",
      "Epoch 41, step 100, training loss 0.658691, test_loss 0.820226, accuracy = 0.739225/0.798433, f1 = 0.802627\n",
      "Epoch 41, step 125, training loss 0.561808, test_loss 0.814646, accuracy = 0.725729/0.796691, f1 = 0.801723\n",
      "Epoch 41, step 150, training loss 0.682277, test_loss 0.819414, accuracy = 0.721376/0.795821, f1 = 0.800749\n",
      "Epoch 41, step 175, training loss 0.816808, test_loss 0.821538, accuracy = 0.724423/0.797562, f1 = 0.801520\n",
      "Epoch 41, step 200, training loss 0.646888, test_loss 0.809969, accuracy = 0.731824/0.799303, f1 = 0.802870\n",
      "Epoch 41, step 225, training loss 0.566488, test_loss 0.827681, accuracy = 0.725729/0.798433, f1 = 0.801937\n",
      "Epoch 41, step 250, training loss 0.681034, test_loss 0.828155, accuracy = 0.723988/0.800174, f1 = 0.802822\n",
      "Epoch 41, step 275, training loss 0.667848, test_loss 0.818568, accuracy = 0.740966/0.800174, f1 = 0.802936\n",
      "Epoch 41, step 300, training loss 0.672176, test_loss 0.817871, accuracy = 0.729212/0.802786, f1 = 0.805946\n",
      "Epoch 41, step 325, training loss 0.693769, test_loss 0.819667, accuracy = 0.734872/0.799739, f1 = 0.802870\n",
      "Epoch 41, step 350, training loss 0.756370, test_loss 0.828256, accuracy = 0.726165/0.801045, f1 = 0.803437\n",
      "Epoch 41, step 375, training loss 0.750156, test_loss 0.812758, accuracy = 0.729647/0.797562, f1 = 0.801269\n",
      "Epoch 41, step 400, training loss 0.618755, test_loss 0.826236, accuracy = 0.723988/0.796256, f1 = 0.800963\n",
      "End of epoch 41, training loss 0.557893, test_loss 0.826052, accuracy = 0.730953/0.796256, f1 = 0.800585\n",
      "Confusion matrix:\n",
      "[[818  60  19  40]\n",
      " [ 31 457  67  45]\n",
      " [ 15  68 422  48]\n",
      " [ 15  22  38 132]]\n",
      "Epoch 42, step 0, training loss 0.613710, test_loss 0.819790, accuracy = 0.725729/0.797562, f1 = 0.801710\n",
      "Epoch 42, step 25, training loss 0.586521, test_loss 0.813699, accuracy = 0.729647/0.794950, f1 = 0.799443\n",
      "Epoch 42, step 50, training loss 0.646007, test_loss 0.816416, accuracy = 0.733130/0.797997, f1 = 0.801896\n",
      "Epoch 42, step 75, training loss 0.612445, test_loss 0.809901, accuracy = 0.738354/0.798868, f1 = 0.801552\n",
      "Epoch 42, step 100, training loss 0.629310, test_loss 0.811643, accuracy = 0.735742/0.800174, f1 = 0.803167\n",
      "Epoch 42, step 125, training loss 0.573754, test_loss 0.817673, accuracy = 0.728341/0.798433, f1 = 0.802056\n",
      "Epoch 42, step 150, training loss 0.605574, test_loss 0.834517, accuracy = 0.732259/0.800174, f1 = 0.803443\n",
      "Epoch 42, step 175, training loss 0.766101, test_loss 0.826969, accuracy = 0.728777/0.800610, f1 = 0.803910\n",
      "Epoch 42, step 200, training loss 0.580735, test_loss 0.816736, accuracy = 0.727906/0.800609, f1 = 0.803741\n",
      "Epoch 42, step 225, training loss 0.630059, test_loss 0.823408, accuracy = 0.733565/0.798433, f1 = 0.801984\n",
      "Epoch 42, step 250, training loss 0.630297, test_loss 0.818067, accuracy = 0.724423/0.800174, f1 = 0.803294\n",
      "Epoch 42, step 275, training loss 0.661574, test_loss 0.810724, accuracy = 0.741837/0.801480, f1 = 0.804762\n",
      "Epoch 42, step 300, training loss 0.634776, test_loss 0.819269, accuracy = 0.732259/0.798433, f1 = 0.802341\n",
      "Epoch 42, step 325, training loss 0.696767, test_loss 0.822097, accuracy = 0.718328/0.798868, f1 = 0.802509\n",
      "Epoch 42, step 350, training loss 0.658765, test_loss 0.833697, accuracy = 0.722682/0.799739, f1 = 0.802499\n",
      "Epoch 42, step 375, training loss 0.753023, test_loss 0.836635, accuracy = 0.712669/0.795385, f1 = 0.799350\n",
      "Epoch 42, step 400, training loss 0.645524, test_loss 0.816670, accuracy = 0.725294/0.796256, f1 = 0.799899\n",
      "End of epoch 42, training loss 0.589763, test_loss 0.833997, accuracy = 0.728777/0.799303, f1 = 0.802736\n",
      "Confusion matrix:\n",
      "[[819  58  23  37]\n",
      " [ 32 447  78  43]\n",
      " [ 13  57 443  40]\n",
      " [ 14  22  44 127]]\n",
      "Epoch 43, step 0, training loss 0.662807, test_loss 0.811959, accuracy = 0.732695/0.799303, f1 = 0.802736\n",
      "Epoch 43, step 25, training loss 0.615361, test_loss 0.827970, accuracy = 0.723117/0.799303, f1 = 0.803425\n",
      "Epoch 43, step 50, training loss 0.641938, test_loss 0.830500, accuracy = 0.724423/0.799303, f1 = 0.803486\n",
      "Epoch 43, step 75, training loss 0.623616, test_loss 0.821555, accuracy = 0.729212/0.800174, f1 = 0.803840\n",
      "Epoch 43, step 100, training loss 0.651024, test_loss 0.811117, accuracy = 0.731389/0.798868, f1 = 0.802696\n",
      "Epoch 43, step 125, training loss 0.596345, test_loss 0.823997, accuracy = 0.729212/0.797997, f1 = 0.802293\n",
      "Epoch 43, step 150, training loss 0.622433, test_loss 0.820768, accuracy = 0.721811/0.798868, f1 = 0.802508\n",
      "Epoch 43, step 175, training loss 0.731070, test_loss 0.824552, accuracy = 0.727471/0.801045, f1 = 0.804019\n",
      "Epoch 43, step 200, training loss 0.494474, test_loss 0.828504, accuracy = 0.725294/0.800174, f1 = 0.802762\n",
      "Epoch 43, step 225, training loss 0.677898, test_loss 0.834711, accuracy = 0.717458/0.800609, f1 = 0.803601\n",
      "Epoch 43, step 250, training loss 0.636122, test_loss 0.814444, accuracy = 0.734872/0.800610, f1 = 0.803675\n",
      "Epoch 43, step 275, training loss 0.636481, test_loss 0.827434, accuracy = 0.726165/0.803657, f1 = 0.806789\n",
      "Epoch 43, step 300, training loss 0.761725, test_loss 0.826477, accuracy = 0.720070/0.802786, f1 = 0.806033\n",
      "Epoch 43, step 325, training loss 0.721625, test_loss 0.817669, accuracy = 0.737919/0.799739, f1 = 0.802888\n",
      "Epoch 43, step 350, training loss 0.677569, test_loss 0.838370, accuracy = 0.717458/0.799739, f1 = 0.802738\n",
      "Epoch 43, step 375, training loss 0.719610, test_loss 0.821001, accuracy = 0.727906/0.791903, f1 = 0.796244\n",
      "Epoch 43, step 400, training loss 0.724092, test_loss 0.810233, accuracy = 0.726600/0.791467, f1 = 0.796090\n",
      "End of epoch 43, training loss 0.635905, test_loss 0.828920, accuracy = 0.718328/0.792773, f1 = 0.797530\n",
      "Confusion matrix:\n",
      "[[821  52  22  42]\n",
      " [ 31 437  77  55]\n",
      " [ 16  53 436  48]\n",
      " [ 16  21  43 127]]\n",
      "Epoch 44, step 0, training loss 0.570737, test_loss 0.818705, accuracy = 0.720505/0.793644, f1 = 0.798389\n",
      "Epoch 44, step 25, training loss 0.643860, test_loss 0.838355, accuracy = 0.719634/0.795385, f1 = 0.800611\n",
      "Epoch 44, step 50, training loss 0.651731, test_loss 0.823530, accuracy = 0.728777/0.798868, f1 = 0.803085\n",
      "Epoch 44, step 75, training loss 0.637185, test_loss 0.826496, accuracy = 0.723988/0.798433, f1 = 0.801596\n",
      "Epoch 44, step 100, training loss 0.687162, test_loss 0.813961, accuracy = 0.742708/0.799303, f1 = 0.802733\n",
      "Epoch 44, step 125, training loss 0.531185, test_loss 0.828321, accuracy = 0.725294/0.797127, f1 = 0.801047\n",
      "Epoch 44, step 150, training loss 0.656539, test_loss 0.830835, accuracy = 0.719199/0.795385, f1 = 0.799180\n",
      "Epoch 44, step 175, training loss 0.739001, test_loss 0.825679, accuracy = 0.727471/0.799303, f1 = 0.802793\n",
      "Epoch 44, step 200, training loss 0.574611, test_loss 0.818429, accuracy = 0.726165/0.798433, f1 = 0.801653\n",
      "Epoch 44, step 225, training loss 0.588508, test_loss 0.833442, accuracy = 0.718764/0.798433, f1 = 0.801978\n",
      "Epoch 44, step 250, training loss 0.644663, test_loss 0.820881, accuracy = 0.729212/0.801480, f1 = 0.804639\n",
      "Epoch 44, step 275, training loss 0.651610, test_loss 0.816358, accuracy = 0.722682/0.805398, f1 = 0.808547\n",
      "Epoch 44, step 300, training loss 0.674159, test_loss 0.825605, accuracy = 0.729212/0.800609, f1 = 0.803967\n",
      "Epoch 44, step 325, training loss 0.774983, test_loss 0.823069, accuracy = 0.729212/0.800174, f1 = 0.802846\n",
      "Epoch 44, step 350, training loss 0.659170, test_loss 0.832912, accuracy = 0.723552/0.801916, f1 = 0.804185\n",
      "Epoch 44, step 375, training loss 0.862742, test_loss 0.832969, accuracy = 0.727906/0.796256, f1 = 0.800183\n",
      "Epoch 44, step 400, training loss 0.632669, test_loss 0.820192, accuracy = 0.735307/0.795821, f1 = 0.800217\n",
      "End of epoch 44, training loss 0.592106, test_loss 0.813890, accuracy = 0.724859/0.794950, f1 = 0.799144\n",
      "Confusion matrix:\n",
      "[[817  58  24  38]\n",
      " [ 30 441  78  51]\n",
      " [ 15  56 439  43]\n",
      " [ 14  21  43 129]]\n",
      "Epoch 45, step 0, training loss 0.581627, test_loss 0.828710, accuracy = 0.720505/0.796256, f1 = 0.800266\n",
      "Epoch 45, step 25, training loss 0.626110, test_loss 0.824269, accuracy = 0.726165/0.799303, f1 = 0.803031\n",
      "Epoch 45, step 50, training loss 0.654944, test_loss 0.807435, accuracy = 0.738354/0.799303, f1 = 0.802870\n",
      "Epoch 45, step 75, training loss 0.586706, test_loss 0.810638, accuracy = 0.735742/0.800610, f1 = 0.804068\n",
      "Epoch 45, step 100, training loss 0.653311, test_loss 0.810902, accuracy = 0.732695/0.798868, f1 = 0.802387\n",
      "Epoch 45, step 125, training loss 0.633495, test_loss 0.816302, accuracy = 0.727906/0.797997, f1 = 0.802208\n",
      "Epoch 45, step 150, training loss 0.637086, test_loss 0.823347, accuracy = 0.723988/0.797562, f1 = 0.801836\n",
      "Epoch 45, step 175, training loss 0.767522, test_loss 0.810237, accuracy = 0.723117/0.795385, f1 = 0.799430\n",
      "Epoch 45, step 200, training loss 0.594759, test_loss 0.821560, accuracy = 0.734436/0.802786, f1 = 0.805639\n",
      "Epoch 45, step 225, training loss 0.572282, test_loss 0.824971, accuracy = 0.732695/0.800174, f1 = 0.803583\n",
      "Epoch 45, step 250, training loss 0.717846, test_loss 0.828355, accuracy = 0.728777/0.801916, f1 = 0.805247\n",
      "Epoch 45, step 275, training loss 0.596870, test_loss 0.826202, accuracy = 0.735307/0.802786, f1 = 0.806535\n",
      "Epoch 45, step 300, training loss 0.666970, test_loss 0.826951, accuracy = 0.720505/0.799303, f1 = 0.802886\n",
      "Epoch 45, step 325, training loss 0.737147, test_loss 0.826025, accuracy = 0.726600/0.801916, f1 = 0.805026\n",
      "Epoch 45, step 350, training loss 0.705292, test_loss 0.825019, accuracy = 0.726600/0.802786, f1 = 0.805588\n",
      "Epoch 45, step 375, training loss 0.885263, test_loss 0.840382, accuracy = 0.718764/0.797997, f1 = 0.801780\n",
      "Epoch 45, step 400, training loss 0.686757, test_loss 0.818075, accuracy = 0.723552/0.797562, f1 = 0.801888\n",
      "End of epoch 45, training loss 0.584619, test_loss 0.825026, accuracy = 0.729212/0.797127, f1 = 0.801517\n",
      "Confusion matrix:\n",
      "[[822  55  21  39]\n",
      " [ 30 450  73  47]\n",
      " [ 15  58 430  50]\n",
      " [ 15  22  41 129]]\n",
      "Epoch 46, step 0, training loss 0.649771, test_loss 0.824318, accuracy = 0.721376/0.797127, f1 = 0.801517\n",
      "Epoch 46, step 25, training loss 0.562910, test_loss 0.835244, accuracy = 0.718328/0.801480, f1 = 0.805019\n",
      "Epoch 46, step 50, training loss 0.607211, test_loss 0.824679, accuracy = 0.720505/0.798433, f1 = 0.802319\n",
      "Epoch 46, step 75, training loss 0.702673, test_loss 0.816347, accuracy = 0.731824/0.802786, f1 = 0.805571\n",
      "Epoch 46, step 100, training loss 0.653122, test_loss 0.826337, accuracy = 0.730953/0.801045, f1 = 0.804233\n",
      "Epoch 46, step 125, training loss 0.632655, test_loss 0.819201, accuracy = 0.727471/0.801045, f1 = 0.804829\n",
      "Epoch 46, step 150, training loss 0.666564, test_loss 0.812259, accuracy = 0.732695/0.797997, f1 = 0.802544\n",
      "Epoch 46, step 175, training loss 0.709010, test_loss 0.803663, accuracy = 0.740096/0.798433, f1 = 0.802516\n",
      "Epoch 46, step 200, training loss 0.590252, test_loss 0.827885, accuracy = 0.730953/0.801480, f1 = 0.804639\n",
      "Epoch 46, step 225, training loss 0.651998, test_loss 0.816788, accuracy = 0.732695/0.800174, f1 = 0.803159\n",
      "Epoch 46, step 250, training loss 0.706408, test_loss 0.832493, accuracy = 0.726600/0.802351, f1 = 0.805157\n",
      "Epoch 46, step 275, training loss 0.653582, test_loss 0.817126, accuracy = 0.734001/0.804528, f1 = 0.807391\n",
      "Epoch 46, step 300, training loss 0.645768, test_loss 0.823608, accuracy = 0.724423/0.802351, f1 = 0.804873\n",
      "Epoch 46, step 325, training loss 0.743486, test_loss 0.831070, accuracy = 0.725294/0.799739, f1 = 0.803104\n",
      "Epoch 46, step 350, training loss 0.691366, test_loss 0.822516, accuracy = 0.720505/0.801916, f1 = 0.804811\n",
      "Epoch 46, step 375, training loss 0.725050, test_loss 0.837516, accuracy = 0.710057/0.798868, f1 = 0.802494\n",
      "Epoch 46, step 400, training loss 0.652914, test_loss 0.821620, accuracy = 0.723552/0.799739, f1 = 0.803749\n",
      "End of epoch 46, training loss 0.607055, test_loss 0.829151, accuracy = 0.728777/0.800610, f1 = 0.804908\n",
      "Confusion matrix:\n",
      "[[819  60  18  40]\n",
      " [ 27 465  64  44]\n",
      " [ 14  68 426  45]\n",
      " [ 13  25  40 129]]\n",
      "Epoch 47, step 0, training loss 0.632296, test_loss 0.837307, accuracy = 0.724423/0.800610, f1 = 0.804893\n",
      "Epoch 47, step 25, training loss 0.592389, test_loss 0.835327, accuracy = 0.715716/0.799739, f1 = 0.804186\n",
      "Epoch 47, step 50, training loss 0.645015, test_loss 0.827829, accuracy = 0.727471/0.800610, f1 = 0.804398\n",
      "Epoch 47, step 75, training loss 0.621136, test_loss 0.807046, accuracy = 0.733566/0.802786, f1 = 0.805989\n",
      "Epoch 47, step 100, training loss 0.669219, test_loss 0.802102, accuracy = 0.736613/0.802786, f1 = 0.806177\n",
      "Epoch 47, step 125, training loss 0.630482, test_loss 0.819437, accuracy = 0.727471/0.801480, f1 = 0.805449\n",
      "Epoch 47, step 150, training loss 0.659630, test_loss 0.819889, accuracy = 0.731389/0.801480, f1 = 0.805696\n",
      "Epoch 47, step 175, training loss 0.739241, test_loss 0.820219, accuracy = 0.725294/0.800609, f1 = 0.803804\n",
      "Epoch 47, step 200, training loss 0.581206, test_loss 0.823182, accuracy = 0.726600/0.803657, f1 = 0.806409\n",
      "Epoch 47, step 225, training loss 0.627473, test_loss 0.818123, accuracy = 0.728777/0.804092, f1 = 0.806893\n",
      "Epoch 47, step 250, training loss 0.731738, test_loss 0.828945, accuracy = 0.720940/0.801916, f1 = 0.804536\n",
      "Epoch 47, step 275, training loss 0.609377, test_loss 0.807811, accuracy = 0.738790/0.802786, f1 = 0.805384\n",
      "Epoch 47, step 300, training loss 0.548651, test_loss 0.820292, accuracy = 0.735307/0.801916, f1 = 0.805426\n",
      "Epoch 47, step 325, training loss 0.685645, test_loss 0.836584, accuracy = 0.730518/0.798868, f1 = 0.802289\n",
      "Epoch 47, step 350, training loss 0.545701, test_loss 0.826804, accuracy = 0.731389/0.800174, f1 = 0.803658\n",
      "Epoch 47, step 375, training loss 0.851471, test_loss 0.825695, accuracy = 0.725729/0.797997, f1 = 0.802079\n",
      "Epoch 47, step 400, training loss 0.643311, test_loss 0.838486, accuracy = 0.724423/0.798868, f1 = 0.803019\n",
      "End of epoch 47, training loss 0.550455, test_loss 0.815062, accuracy = 0.723988/0.799303, f1 = 0.803349\n",
      "Confusion matrix:\n",
      "[[823  56  20  38]\n",
      " [ 28 460  67  45]\n",
      " [ 15  63 428  47]\n",
      " [ 15  25  42 125]]\n",
      "Epoch 48, step 0, training loss 0.606840, test_loss 0.827460, accuracy = 0.726600/0.799303, f1 = 0.803349\n",
      "Epoch 48, step 25, training loss 0.613202, test_loss 0.844943, accuracy = 0.709621/0.797997, f1 = 0.801474\n",
      "Epoch 48, step 50, training loss 0.603440, test_loss 0.827596, accuracy = 0.728341/0.800610, f1 = 0.804345\n",
      "Epoch 48, step 75, training loss 0.559169, test_loss 0.829100, accuracy = 0.726600/0.802351, f1 = 0.805685\n",
      "Epoch 48, step 100, training loss 0.654646, test_loss 0.824927, accuracy = 0.721811/0.803222, f1 = 0.806917\n",
      "Epoch 48, step 125, training loss 0.601890, test_loss 0.831054, accuracy = 0.728341/0.800609, f1 = 0.805170\n",
      "Epoch 48, step 150, training loss 0.619281, test_loss 0.820549, accuracy = 0.730083/0.797562, f1 = 0.802312\n",
      "Epoch 48, step 175, training loss 0.744440, test_loss 0.818031, accuracy = 0.728341/0.800174, f1 = 0.804609\n",
      "Epoch 48, step 200, training loss 0.506825, test_loss 0.817646, accuracy = 0.730953/0.802351, f1 = 0.805871\n",
      "Epoch 48, step 225, training loss 0.557399, test_loss 0.822398, accuracy = 0.734001/0.798868, f1 = 0.803085\n",
      "Epoch 48, step 250, training loss 0.657761, test_loss 0.829213, accuracy = 0.727035/0.801480, f1 = 0.805175\n",
      "Epoch 48, step 275, training loss 0.647393, test_loss 0.812680, accuracy = 0.727471/0.803657, f1 = 0.807320\n",
      "Epoch 48, step 300, training loss 0.682504, test_loss 0.830946, accuracy = 0.716587/0.799739, f1 = 0.803709\n",
      "Epoch 48, step 325, training loss 0.765760, test_loss 0.837056, accuracy = 0.710492/0.801480, f1 = 0.804901\n",
      "Epoch 48, step 350, training loss 0.640177, test_loss 0.833368, accuracy = 0.719199/0.800610, f1 = 0.803781\n",
      "Epoch 48, step 375, training loss 0.777928, test_loss 0.830525, accuracy = 0.717022/0.794515, f1 = 0.799454\n",
      "Epoch 48, step 400, training loss 0.701683, test_loss 0.829942, accuracy = 0.716152/0.794515, f1 = 0.800031\n",
      "End of epoch 48, training loss 0.597024, test_loss 0.837753, accuracy = 0.723988/0.794515, f1 = 0.799480\n",
      "Confusion matrix:\n",
      "[[814  60  21  42]\n",
      " [ 27 453  70  50]\n",
      " [ 15  60 430  48]\n",
      " [ 14  23  42 128]]\n",
      "Epoch 49, step 0, training loss 0.645356, test_loss 0.838902, accuracy = 0.718328/0.794515, f1 = 0.799480\n",
      "Epoch 49, step 25, training loss 0.658078, test_loss 0.827304, accuracy = 0.721811/0.796256, f1 = 0.800840\n",
      "Epoch 49, step 50, training loss 0.685361, test_loss 0.825729, accuracy = 0.729647/0.799739, f1 = 0.804325\n",
      "Epoch 49, step 75, training loss 0.627639, test_loss 0.809986, accuracy = 0.730953/0.804092, f1 = 0.807504\n",
      "Epoch 49, step 100, training loss 0.753951, test_loss 0.807619, accuracy = 0.735307/0.801916, f1 = 0.805733\n",
      "Epoch 49, step 125, training loss 0.730690, test_loss 0.820820, accuracy = 0.725729/0.798868, f1 = 0.803520\n",
      "Epoch 49, step 150, training loss 0.606568, test_loss 0.823242, accuracy = 0.733566/0.798433, f1 = 0.803129\n",
      "Epoch 49, step 175, training loss 0.800566, test_loss 0.820207, accuracy = 0.729212/0.798868, f1 = 0.803268\n",
      "Epoch 49, step 200, training loss 0.603228, test_loss 0.825924, accuracy = 0.722682/0.800610, f1 = 0.804114\n",
      "Epoch 49, step 225, training loss 0.541527, test_loss 0.812112, accuracy = 0.733130/0.800610, f1 = 0.804236\n",
      "Epoch 49, step 250, training loss 0.622662, test_loss 0.826866, accuracy = 0.727906/0.804963, f1 = 0.808477\n",
      "Epoch 49, step 275, training loss 0.667397, test_loss 0.823288, accuracy = 0.721811/0.801480, f1 = 0.804664\n",
      "Epoch 49, step 300, training loss 0.615405, test_loss 0.823639, accuracy = 0.727035/0.804528, f1 = 0.807863\n",
      "Epoch 49, step 325, training loss 0.668229, test_loss 0.821396, accuracy = 0.716587/0.802351, f1 = 0.805368\n",
      "Epoch 49, step 350, training loss 0.656851, test_loss 0.833706, accuracy = 0.726600/0.803222, f1 = 0.806381\n",
      "Epoch 49, step 375, training loss 0.797158, test_loss 0.811900, accuracy = 0.733566/0.797562, f1 = 0.802122\n",
      "Epoch 49, step 400, training loss 0.645164, test_loss 0.842622, accuracy = 0.714845/0.795821, f1 = 0.800223\n",
      "End of epoch 49, training loss 0.571624, test_loss 0.832190, accuracy = 0.717458/0.795385, f1 = 0.799486\n",
      "Confusion matrix:\n",
      "[[813  65  21  38]\n",
      " [ 27 456  72  45]\n",
      " [ 14  65 432  42]\n",
      " [ 14  23  44 126]]\n",
      "Epoch 50, step 0, training loss 0.613256, test_loss 0.829200, accuracy = 0.724423/0.795821, f1 = 0.799863\n",
      "Epoch 50, step 25, training loss 0.588281, test_loss 0.832376, accuracy = 0.720940/0.797562, f1 = 0.802015\n",
      "Epoch 50, step 50, training loss 0.639985, test_loss 0.818639, accuracy = 0.720940/0.801045, f1 = 0.805357\n",
      "Epoch 50, step 75, training loss 0.581948, test_loss 0.820628, accuracy = 0.727471/0.801480, f1 = 0.805219\n",
      "Epoch 50, step 100, training loss 0.663009, test_loss 0.811402, accuracy = 0.730953/0.800610, f1 = 0.805285\n",
      "Epoch 50, step 125, training loss 0.587455, test_loss 0.823576, accuracy = 0.723552/0.795385, f1 = 0.800586\n",
      "Epoch 50, step 150, training loss 0.655352, test_loss 0.813688, accuracy = 0.725729/0.799303, f1 = 0.803870\n",
      "Epoch 50, step 175, training loss 0.714946, test_loss 0.823202, accuracy = 0.728777/0.797562, f1 = 0.802691\n",
      "Epoch 50, step 200, training loss 0.591075, test_loss 0.828975, accuracy = 0.721811/0.797997, f1 = 0.802348\n",
      "Epoch 50, step 225, training loss 0.525064, test_loss 0.810191, accuracy = 0.735307/0.796691, f1 = 0.801118\n",
      "Epoch 50, step 250, training loss 0.672162, test_loss 0.816022, accuracy = 0.732695/0.799739, f1 = 0.803724\n",
      "Epoch 50, step 275, training loss 0.748258, test_loss 0.815391, accuracy = 0.737484/0.803222, f1 = 0.807015\n",
      "Epoch 50, step 300, training loss 0.638089, test_loss 0.817792, accuracy = 0.730083/0.797562, f1 = 0.801316\n",
      "Epoch 50, step 325, training loss 0.757565, test_loss 0.840505, accuracy = 0.734001/0.801045, f1 = 0.804405\n",
      "Epoch 50, step 350, training loss 0.578876, test_loss 0.832532, accuracy = 0.720070/0.804092, f1 = 0.806924\n",
      "Epoch 50, step 375, training loss 0.653624, test_loss 0.845737, accuracy = 0.714845/0.797562, f1 = 0.802104\n",
      "Epoch 50, step 400, training loss 0.654008, test_loss 0.824057, accuracy = 0.725729/0.798868, f1 = 0.802909\n",
      "End of epoch 50, training loss 0.496859, test_loss 0.829794, accuracy = 0.727035/0.799739, f1 = 0.803453\n",
      "Confusion matrix:\n",
      "[[815  64  20  38]\n",
      " [ 27 464  68  41]\n",
      " [ 14  67 432  40]\n",
      " [ 14  25  42 126]]\n",
      "Epoch 51, step 0, training loss 0.564797, test_loss 0.832308, accuracy = 0.721376/0.799303, f1 = 0.803002\n",
      "Epoch 51, step 25, training loss 0.633053, test_loss 0.824897, accuracy = 0.723988/0.800610, f1 = 0.805387\n",
      "Epoch 51, step 50, training loss 0.664973, test_loss 0.836304, accuracy = 0.720940/0.798433, f1 = 0.802883\n",
      "Epoch 51, step 75, training loss 0.572217, test_loss 0.822823, accuracy = 0.730518/0.800174, f1 = 0.803960\n",
      "Epoch 51, step 100, training loss 0.645509, test_loss 0.806991, accuracy = 0.734872/0.801045, f1 = 0.804989\n",
      "Epoch 51, step 125, training loss 0.555128, test_loss 0.835804, accuracy = 0.728777/0.797127, f1 = 0.801571\n",
      "Epoch 51, step 150, training loss 0.684036, test_loss 0.826159, accuracy = 0.726165/0.799739, f1 = 0.803924\n",
      "Epoch 51, step 175, training loss 0.788675, test_loss 0.832825, accuracy = 0.726165/0.797997, f1 = 0.802691\n",
      "Epoch 51, step 200, training loss 0.564712, test_loss 0.827622, accuracy = 0.729212/0.797997, f1 = 0.802250\n",
      "Epoch 51, step 225, training loss 0.574666, test_loss 0.814916, accuracy = 0.726165/0.798433, f1 = 0.802482\n",
      "Epoch 51, step 250, training loss 0.657289, test_loss 0.828618, accuracy = 0.724859/0.799303, f1 = 0.802999\n",
      "Epoch 51, step 275, training loss 0.662940, test_loss 0.825572, accuracy = 0.722682/0.799303, f1 = 0.802893\n",
      "Epoch 51, step 300, training loss 0.679042, test_loss 0.818074, accuracy = 0.727906/0.798868, f1 = 0.803155\n",
      "Epoch 51, step 325, training loss 0.878694, test_loss 0.827173, accuracy = 0.725294/0.797997, f1 = 0.802197\n",
      "Epoch 51, step 350, training loss 0.680159, test_loss 0.839978, accuracy = 0.723552/0.802351, f1 = 0.805661\n",
      "Epoch 51, step 375, training loss 0.721194, test_loss 0.826447, accuracy = 0.725294/0.797127, f1 = 0.802315\n",
      "Epoch 51, step 400, training loss 0.694766, test_loss 0.829824, accuracy = 0.723988/0.795821, f1 = 0.801454\n",
      "End of epoch 51, training loss 0.620264, test_loss 0.840141, accuracy = 0.717022/0.796691, f1 = 0.801945\n",
      "Confusion matrix:\n",
      "[[815  59  19  44]\n",
      " [ 24 456  70  50]\n",
      " [ 12  67 428  46]\n",
      " [ 13  24  39 131]]\n",
      "Epoch 52, step 0, training loss 0.586089, test_loss 0.838404, accuracy = 0.731389/0.796256, f1 = 0.801504\n",
      "Epoch 52, step 25, training loss 0.601925, test_loss 0.835740, accuracy = 0.724859/0.792338, f1 = 0.798028\n",
      "Epoch 52, step 50, training loss 0.613982, test_loss 0.827187, accuracy = 0.724423/0.794950, f1 = 0.799781\n",
      "Epoch 52, step 75, training loss 0.581946, test_loss 0.805272, accuracy = 0.737919/0.797127, f1 = 0.801417\n",
      "Epoch 52, step 100, training loss 0.668162, test_loss 0.823643, accuracy = 0.725729/0.795385, f1 = 0.800408\n",
      "Epoch 52, step 125, training loss 0.676964, test_loss 0.821982, accuracy = 0.725729/0.795821, f1 = 0.800963\n",
      "Epoch 52, step 150, training loss 0.811119, test_loss 0.821857, accuracy = 0.729647/0.797997, f1 = 0.802596\n",
      "Epoch 52, step 175, training loss 0.710638, test_loss 0.823748, accuracy = 0.726600/0.800174, f1 = 0.804162\n",
      "Epoch 52, step 200, training loss 0.563715, test_loss 0.833618, accuracy = 0.724859/0.797127, f1 = 0.800930\n",
      "Epoch 52, step 225, training loss 0.546322, test_loss 0.827192, accuracy = 0.727035/0.798868, f1 = 0.802911\n",
      "Epoch 52, step 250, training loss 0.595898, test_loss 0.820224, accuracy = 0.727035/0.797997, f1 = 0.801889\n",
      "Epoch 52, step 275, training loss 0.612916, test_loss 0.828396, accuracy = 0.726165/0.801480, f1 = 0.804977\n",
      "Epoch 52, step 300, training loss 0.636483, test_loss 0.817885, accuracy = 0.733130/0.801480, f1 = 0.805454\n",
      "Epoch 52, step 325, training loss 0.728064, test_loss 0.806321, accuracy = 0.737484/0.801045, f1 = 0.804974\n",
      "Epoch 52, step 350, training loss 0.673244, test_loss 0.830635, accuracy = 0.722246/0.802786, f1 = 0.806608\n",
      "Epoch 52, step 375, training loss 0.810369, test_loss 0.829754, accuracy = 0.719199/0.801045, f1 = 0.805317\n",
      "Epoch 52, step 400, training loss 0.689888, test_loss 0.828977, accuracy = 0.724423/0.800610, f1 = 0.804815\n",
      "End of epoch 52, training loss 0.582795, test_loss 0.828655, accuracy = 0.723988/0.800174, f1 = 0.803932\n",
      "Confusion matrix:\n",
      "[[818  61  20  38]\n",
      " [ 28 470  62  40]\n",
      " [ 14  73 423  43]\n",
      " [ 14  26  40 127]]\n",
      "Epoch 53, step 0, training loss 0.654336, test_loss 0.829580, accuracy = 0.722682/0.800174, f1 = 0.803873\n",
      "Epoch 53, step 25, training loss 0.568686, test_loss 0.838481, accuracy = 0.717022/0.797562, f1 = 0.800994\n",
      "Epoch 53, step 50, training loss 0.673562, test_loss 0.829068, accuracy = 0.726165/0.800610, f1 = 0.804355\n",
      "Epoch 53, step 75, training loss 0.631109, test_loss 0.800624, accuracy = 0.730518/0.799739, f1 = 0.802734\n",
      "Epoch 53, step 100, training loss 0.637129, test_loss 0.815646, accuracy = 0.737048/0.801045, f1 = 0.805125\n",
      "Epoch 53, step 125, training loss 0.549138, test_loss 0.819911, accuracy = 0.727471/0.798868, f1 = 0.803522\n",
      "Epoch 53, step 150, training loss 0.584199, test_loss 0.830426, accuracy = 0.723988/0.803222, f1 = 0.807278\n",
      "Epoch 53, step 175, training loss 0.734609, test_loss 0.830816, accuracy = 0.725294/0.803222, f1 = 0.807134\n",
      "Epoch 53, step 200, training loss 0.609645, test_loss 0.818092, accuracy = 0.726600/0.800174, f1 = 0.803693\n",
      "Epoch 53, step 225, training loss 0.559682, test_loss 0.812904, accuracy = 0.728341/0.802351, f1 = 0.805963\n",
      "Epoch 53, step 250, training loss 0.735839, test_loss 0.824249, accuracy = 0.719199/0.803222, f1 = 0.806655\n",
      "Epoch 53, step 275, training loss 0.631000, test_loss 0.812974, accuracy = 0.731824/0.804963, f1 = 0.808335\n",
      "Epoch 53, step 300, training loss 0.595733, test_loss 0.830426, accuracy = 0.722246/0.802351, f1 = 0.805947\n",
      "Epoch 53, step 325, training loss 0.732257, test_loss 0.815025, accuracy = 0.724858/0.802351, f1 = 0.805618\n",
      "Epoch 53, step 350, training loss 0.703149, test_loss 0.826311, accuracy = 0.733565/0.799739, f1 = 0.802610\n",
      "Epoch 53, step 375, training loss 0.767256, test_loss 0.837956, accuracy = 0.717022/0.799303, f1 = 0.803139\n",
      "Epoch 53, step 400, training loss 0.610619, test_loss 0.836520, accuracy = 0.718328/0.796256, f1 = 0.800566\n",
      "End of epoch 53, training loss 0.541655, test_loss 0.834979, accuracy = 0.723988/0.797997, f1 = 0.802206\n",
      "Confusion matrix:\n",
      "[[818  61  22  36]\n",
      " [ 30 455  69  46]\n",
      " [ 15  62 429  47]\n",
      " [ 12  24  40 131]]\n",
      "Epoch 54, step 0, training loss 0.611343, test_loss 0.816788, accuracy = 0.731389/0.797997, f1 = 0.802265\n",
      "Epoch 54, step 25, training loss 0.642046, test_loss 0.835266, accuracy = 0.724423/0.797997, f1 = 0.802069\n",
      "Epoch 54, step 50, training loss 0.620431, test_loss 0.823114, accuracy = 0.737048/0.797127, f1 = 0.801325\n",
      "Epoch 54, step 75, training loss 0.636568, test_loss 0.814366, accuracy = 0.737484/0.798868, f1 = 0.802794\n",
      "Epoch 54, step 100, training loss 0.667053, test_loss 0.818998, accuracy = 0.730083/0.800610, f1 = 0.804947\n",
      "Epoch 54, step 125, training loss 0.624748, test_loss 0.820368, accuracy = 0.736178/0.797997, f1 = 0.802694\n",
      "Epoch 54, step 150, training loss 0.662376, test_loss 0.825365, accuracy = 0.726600/0.797562, f1 = 0.802340\n",
      "Epoch 54, step 175, training loss 0.719135, test_loss 0.833166, accuracy = 0.717893/0.800174, f1 = 0.804460\n",
      "Epoch 54, step 200, training loss 0.532190, test_loss 0.824232, accuracy = 0.731389/0.796691, f1 = 0.800616\n",
      "Epoch 54, step 225, training loss 0.571274, test_loss 0.824668, accuracy = 0.724423/0.800610, f1 = 0.804547\n",
      "Epoch 54, step 250, training loss 0.623682, test_loss 0.829020, accuracy = 0.725294/0.801045, f1 = 0.804266\n",
      "Epoch 54, step 275, training loss 0.581483, test_loss 0.823651, accuracy = 0.727035/0.799739, f1 = 0.803372\n",
      "Epoch 54, step 300, training loss 0.571924, test_loss 0.825743, accuracy = 0.721811/0.797997, f1 = 0.801666\n",
      "Epoch 54, step 325, training loss 0.680247, test_loss 0.830565, accuracy = 0.720505/0.797997, f1 = 0.801865\n",
      "Epoch 54, step 350, training loss 0.656809, test_loss 0.829152, accuracy = 0.728777/0.797562, f1 = 0.800938\n",
      "Epoch 54, step 375, training loss 0.769309, test_loss 0.826344, accuracy = 0.726600/0.792773, f1 = 0.797454\n",
      "Epoch 54, step 400, training loss 0.587150, test_loss 0.841460, accuracy = 0.721811/0.792338, f1 = 0.797593\n",
      "End of epoch 54, training loss 0.566490, test_loss 0.833900, accuracy = 0.713975/0.792338, f1 = 0.797618\n",
      "Confusion matrix:\n",
      "[[814  60  19  44]\n",
      " [ 28 453  68  51]\n",
      " [ 15  64 424  50]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 55, step 0, training loss 0.598623, test_loss 0.822596, accuracy = 0.723988/0.792338, f1 = 0.797555\n",
      "Epoch 55, step 25, training loss 0.638852, test_loss 0.835654, accuracy = 0.711363/0.797127, f1 = 0.802006\n",
      "Epoch 55, step 50, training loss 0.676375, test_loss 0.833930, accuracy = 0.723117/0.796256, f1 = 0.800403\n",
      "Epoch 55, step 75, training loss 0.602125, test_loss 0.821067, accuracy = 0.723988/0.800610, f1 = 0.803591\n",
      "Epoch 55, step 100, training loss 0.686028, test_loss 0.818807, accuracy = 0.726165/0.800610, f1 = 0.804197\n",
      "Epoch 55, step 125, training loss 0.581098, test_loss 0.818659, accuracy = 0.731389/0.800610, f1 = 0.805035\n",
      "Epoch 55, step 150, training loss 0.807675, test_loss 0.832794, accuracy = 0.717893/0.798433, f1 = 0.802907\n",
      "Epoch 55, step 175, training loss 0.761071, test_loss 0.830963, accuracy = 0.721376/0.799303, f1 = 0.803698\n",
      "Epoch 55, step 200, training loss 0.550335, test_loss 0.834739, accuracy = 0.715281/0.800174, f1 = 0.803712\n",
      "Epoch 55, step 225, training loss 0.550494, test_loss 0.833474, accuracy = 0.716587/0.799739, f1 = 0.803645\n",
      "Epoch 55, step 250, training loss 0.661793, test_loss 0.836808, accuracy = 0.724859/0.803222, f1 = 0.806992\n",
      "Epoch 55, step 275, training loss 0.625385, test_loss 0.834348, accuracy = 0.718328/0.801916, f1 = 0.805737\n",
      "Epoch 55, step 300, training loss 0.627427, test_loss 0.830259, accuracy = 0.719634/0.801916, f1 = 0.805349\n",
      "Epoch 55, step 325, training loss 0.690947, test_loss 0.833169, accuracy = 0.721376/0.801045, f1 = 0.803527\n",
      "Epoch 55, step 350, training loss 0.612593, test_loss 0.836176, accuracy = 0.712233/0.800610, f1 = 0.803075\n",
      "Epoch 55, step 375, training loss 0.722504, test_loss 0.839080, accuracy = 0.721376/0.801916, f1 = 0.804786\n",
      "Epoch 55, step 400, training loss 0.683837, test_loss 0.811074, accuracy = 0.728341/0.800174, f1 = 0.803354\n",
      "End of epoch 55, training loss 0.589712, test_loss 0.831852, accuracy = 0.719634/0.798868, f1 = 0.802223\n",
      "Confusion matrix:\n",
      "[[825  55  21  36]\n",
      " [ 33 450  75  42]\n",
      " [ 17  57 433  46]\n",
      " [ 16  22  42 127]]\n",
      "Epoch 56, step 0, training loss 0.620565, test_loss 0.832599, accuracy = 0.728777/0.798868, f1 = 0.802279\n",
      "Epoch 56, step 25, training loss 0.624876, test_loss 0.830423, accuracy = 0.715716/0.801045, f1 = 0.804871\n",
      "Epoch 56, step 50, training loss 0.657704, test_loss 0.824617, accuracy = 0.725294/0.800610, f1 = 0.804189\n",
      "Epoch 56, step 75, training loss 0.596320, test_loss 0.809639, accuracy = 0.735742/0.803657, f1 = 0.806004\n",
      "Epoch 56, step 100, training loss 0.617956, test_loss 0.820674, accuracy = 0.727035/0.806269, f1 = 0.808727\n",
      "Epoch 56, step 125, training loss 0.571448, test_loss 0.815805, accuracy = 0.737484/0.802351, f1 = 0.805607\n",
      "Epoch 56, step 150, training loss 0.670929, test_loss 0.821904, accuracy = 0.723117/0.804528, f1 = 0.807741\n",
      "Epoch 56, step 175, training loss 0.729834, test_loss 0.807419, accuracy = 0.729212/0.804092, f1 = 0.807049\n",
      "Epoch 56, step 200, training loss 0.610344, test_loss 0.825652, accuracy = 0.721811/0.803657, f1 = 0.806370\n",
      "Epoch 56, step 225, training loss 0.550822, test_loss 0.830698, accuracy = 0.723117/0.804963, f1 = 0.807674\n",
      "Epoch 56, step 250, training loss 0.700652, test_loss 0.818648, accuracy = 0.730953/0.806269, f1 = 0.808999\n",
      "Epoch 56, step 275, training loss 0.623524, test_loss 0.828901, accuracy = 0.728777/0.804092, f1 = 0.807798\n",
      "Epoch 56, step 300, training loss 0.607782, test_loss 0.815210, accuracy = 0.731389/0.800174, f1 = 0.803863\n",
      "Epoch 56, step 325, training loss 0.752738, test_loss 0.843739, accuracy = 0.720505/0.799739, f1 = 0.802858\n",
      "Epoch 56, step 350, training loss 0.635959, test_loss 0.842268, accuracy = 0.720505/0.801916, f1 = 0.804401\n",
      "Epoch 56, step 375, training loss 0.667155, test_loss 0.822436, accuracy = 0.727471/0.800174, f1 = 0.804181\n",
      "Epoch 56, step 400, training loss 0.594406, test_loss 0.824788, accuracy = 0.723988/0.797562, f1 = 0.801597\n",
      "End of epoch 56, training loss 0.710674, test_loss 0.828053, accuracy = 0.719634/0.800610, f1 = 0.804329\n",
      "Confusion matrix:\n",
      "[[824  58  19  36]\n",
      " [ 31 461  67  41]\n",
      " [ 17  63 423  50]\n",
      " [ 16  24  36 131]]\n",
      "Epoch 57, step 0, training loss 0.629647, test_loss 0.841550, accuracy = 0.716587/0.800610, f1 = 0.804386\n",
      "Epoch 57, step 25, training loss 0.609769, test_loss 0.830173, accuracy = 0.714845/0.801480, f1 = 0.805101\n",
      "Epoch 57, step 50, training loss 0.629038, test_loss 0.833779, accuracy = 0.717022/0.802351, f1 = 0.805814\n",
      "Epoch 57, step 75, training loss 0.693145, test_loss 0.813219, accuracy = 0.727471/0.801045, f1 = 0.803705\n",
      "Epoch 57, step 100, training loss 0.649011, test_loss 0.815299, accuracy = 0.728341/0.805398, f1 = 0.807922\n",
      "Epoch 57, step 125, training loss 0.606250, test_loss 0.825737, accuracy = 0.725729/0.798868, f1 = 0.802270\n",
      "Epoch 57, step 150, training loss 0.697284, test_loss 0.828445, accuracy = 0.718764/0.802351, f1 = 0.805835\n",
      "Epoch 57, step 175, training loss 0.751270, test_loss 0.834371, accuracy = 0.722246/0.800610, f1 = 0.804352\n",
      "Epoch 57, step 200, training loss 0.581209, test_loss 0.831007, accuracy = 0.730083/0.800174, f1 = 0.803721\n",
      "Epoch 57, step 225, training loss 0.515419, test_loss 0.817810, accuracy = 0.728341/0.800610, f1 = 0.804637\n",
      "Epoch 57, step 250, training loss 0.681015, test_loss 0.819628, accuracy = 0.728777/0.801480, f1 = 0.805037\n",
      "Epoch 57, step 275, training loss 0.705457, test_loss 0.820517, accuracy = 0.725294/0.803657, f1 = 0.806924\n",
      "Epoch 57, step 300, training loss 0.621559, test_loss 0.828772, accuracy = 0.726600/0.801045, f1 = 0.804441\n",
      "Epoch 57, step 325, training loss 0.731410, test_loss 0.830684, accuracy = 0.716152/0.798868, f1 = 0.801898\n",
      "Epoch 57, step 350, training loss 0.675097, test_loss 0.836647, accuracy = 0.725729/0.797127, f1 = 0.800607\n",
      "Epoch 57, step 375, training loss 0.694049, test_loss 0.824863, accuracy = 0.721811/0.796256, f1 = 0.800328\n",
      "Epoch 57, step 400, training loss 0.617184, test_loss 0.835231, accuracy = 0.722246/0.801045, f1 = 0.804690\n",
      "End of epoch 57, training loss 0.617917, test_loss 0.830246, accuracy = 0.714410/0.799303, f1 = 0.802550\n",
      "Confusion matrix:\n",
      "[[818  62  19  38]\n",
      " [ 33 463  67  37]\n",
      " [ 16  67 427  43]\n",
      " [ 17  23  39 128]]\n",
      "Epoch 58, step 0, training loss 0.669450, test_loss 0.830895, accuracy = 0.721376/0.798868, f1 = 0.802018\n",
      "Epoch 58, step 25, training loss 0.583367, test_loss 0.818448, accuracy = 0.727906/0.796691, f1 = 0.800329\n",
      "Epoch 58, step 50, training loss 0.584553, test_loss 0.823294, accuracy = 0.733566/0.801916, f1 = 0.805946\n",
      "Epoch 58, step 75, training loss 0.673225, test_loss 0.825362, accuracy = 0.717458/0.804528, f1 = 0.807974\n",
      "Epoch 58, step 100, training loss 0.671525, test_loss 0.827703, accuracy = 0.730083/0.803657, f1 = 0.807283\n",
      "Epoch 58, step 125, training loss 0.644909, test_loss 0.830430, accuracy = 0.720505/0.801480, f1 = 0.805441\n",
      "Epoch 58, step 150, training loss 0.612634, test_loss 0.825851, accuracy = 0.732260/0.801045, f1 = 0.805586\n",
      "Epoch 58, step 175, training loss 0.697800, test_loss 0.817219, accuracy = 0.730953/0.802786, f1 = 0.806697\n",
      "Epoch 58, step 200, training loss 0.527622, test_loss 0.825614, accuracy = 0.731824/0.802351, f1 = 0.805610\n",
      "Epoch 58, step 225, training loss 0.549333, test_loss 0.820383, accuracy = 0.730518/0.802786, f1 = 0.805974\n",
      "Epoch 58, step 250, training loss 0.647977, test_loss 0.823040, accuracy = 0.730518/0.803222, f1 = 0.806538\n",
      "Epoch 58, step 275, training loss 0.639781, test_loss 0.823111, accuracy = 0.729647/0.804963, f1 = 0.808345\n",
      "Epoch 58, step 300, training loss 0.693558, test_loss 0.832356, accuracy = 0.719634/0.802351, f1 = 0.806155\n",
      "Epoch 58, step 325, training loss 0.757729, test_loss 0.831063, accuracy = 0.723988/0.801480, f1 = 0.805045\n",
      "Epoch 58, step 350, training loss 0.662861, test_loss 0.829547, accuracy = 0.716587/0.801480, f1 = 0.804442\n",
      "Epoch 58, step 375, training loss 0.829646, test_loss 0.829244, accuracy = 0.724858/0.800610, f1 = 0.804225\n",
      "Epoch 58, step 400, training loss 0.733026, test_loss 0.836058, accuracy = 0.718764/0.799303, f1 = 0.803771\n",
      "End of epoch 58, training loss 0.568786, test_loss 0.821926, accuracy = 0.726165/0.798433, f1 = 0.802536\n",
      "Confusion matrix:\n",
      "[[821  58  19  39]\n",
      " [ 30 457  66  47]\n",
      " [ 17  67 424  45]\n",
      " [ 15  22  38 132]]\n",
      "Epoch 59, step 0, training loss 0.546064, test_loss 0.835426, accuracy = 0.719199/0.798433, f1 = 0.802536\n",
      "Epoch 59, step 25, training loss 0.596866, test_loss 0.827030, accuracy = 0.721376/0.800609, f1 = 0.804455\n",
      "Epoch 59, step 50, training loss 0.667868, test_loss 0.841726, accuracy = 0.717893/0.801045, f1 = 0.804289\n",
      "Epoch 59, step 75, training loss 0.622250, test_loss 0.806850, accuracy = 0.731824/0.803222, f1 = 0.806640\n",
      "Epoch 59, step 100, training loss 0.628245, test_loss 0.820020, accuracy = 0.723988/0.801916, f1 = 0.806014\n",
      "Epoch 59, step 125, training loss 0.593612, test_loss 0.814482, accuracy = 0.732695/0.800174, f1 = 0.805105\n",
      "Epoch 59, step 150, training loss 0.571571, test_loss 0.821710, accuracy = 0.733130/0.799303, f1 = 0.803744\n",
      "Epoch 59, step 175, training loss 0.759550, test_loss 0.825663, accuracy = 0.724423/0.797997, f1 = 0.802198\n",
      "Epoch 59, step 200, training loss 0.570220, test_loss 0.828921, accuracy = 0.723988/0.801916, f1 = 0.804951\n",
      "Epoch 59, step 225, training loss 0.595711, test_loss 0.819570, accuracy = 0.724859/0.802786, f1 = 0.806048\n",
      "Epoch 59, step 250, training loss 0.643082, test_loss 0.813233, accuracy = 0.732260/0.802351, f1 = 0.805186\n",
      "Epoch 59, step 275, training loss 0.734537, test_loss 0.822760, accuracy = 0.727906/0.801480, f1 = 0.804629\n",
      "Epoch 59, step 300, training loss 0.617320, test_loss 0.813080, accuracy = 0.730953/0.801045, f1 = 0.804195\n",
      "Epoch 59, step 325, training loss 0.703764, test_loss 0.831788, accuracy = 0.724859/0.801480, f1 = 0.804052\n",
      "Epoch 59, step 350, training loss 0.744173, test_loss 0.821620, accuracy = 0.732260/0.798868, f1 = 0.801454\n",
      "Epoch 59, step 375, training loss 0.778968, test_loss 0.831075, accuracy = 0.715281/0.794950, f1 = 0.799259\n",
      "Epoch 59, step 400, training loss 0.698021, test_loss 0.839306, accuracy = 0.717893/0.795385, f1 = 0.799542\n",
      "End of epoch 59, training loss 0.569521, test_loss 0.823989, accuracy = 0.732259/0.793209, f1 = 0.797331\n",
      "Confusion matrix:\n",
      "[[818  59  19  41]\n",
      " [ 35 451  69  45]\n",
      " [ 17  66 423  47]\n",
      " [ 14  24  39 130]]\n",
      "Epoch 60, step 0, training loss 0.668471, test_loss 0.826913, accuracy = 0.727471/0.793644, f1 = 0.797684\n",
      "Epoch 60, step 25, training loss 0.649945, test_loss 0.825031, accuracy = 0.725294/0.796691, f1 = 0.801078\n",
      "Epoch 60, step 50, training loss 0.614240, test_loss 0.833527, accuracy = 0.719199/0.795821, f1 = 0.799833\n",
      "Epoch 60, step 75, training loss 0.608342, test_loss 0.811410, accuracy = 0.734001/0.799739, f1 = 0.803232\n",
      "Epoch 60, step 100, training loss 0.600578, test_loss 0.819280, accuracy = 0.727906/0.800610, f1 = 0.804355\n",
      "Epoch 60, step 125, training loss 0.607738, test_loss 0.824860, accuracy = 0.728341/0.799739, f1 = 0.803385\n",
      "Epoch 60, step 150, training loss 0.695796, test_loss 0.803087, accuracy = 0.737048/0.803222, f1 = 0.806583\n",
      "Epoch 60, step 175, training loss 0.784694, test_loss 0.812089, accuracy = 0.727906/0.801480, f1 = 0.804722\n",
      "Epoch 60, step 200, training loss 0.576661, test_loss 0.821033, accuracy = 0.723988/0.801480, f1 = 0.804641\n",
      "Epoch 60, step 225, training loss 0.645180, test_loss 0.799743, accuracy = 0.726600/0.801480, f1 = 0.804456\n",
      "Epoch 60, step 250, training loss 0.622754, test_loss 0.815355, accuracy = 0.729212/0.801480, f1 = 0.804627\n",
      "Epoch 60, step 275, training loss 0.678633, test_loss 0.827148, accuracy = 0.726165/0.801916, f1 = 0.804922\n",
      "Epoch 60, step 300, training loss 0.672703, test_loss 0.822993, accuracy = 0.723988/0.802351, f1 = 0.805192\n",
      "Epoch 60, step 325, training loss 0.731366, test_loss 0.830826, accuracy = 0.715716/0.803222, f1 = 0.806222\n",
      "Epoch 60, step 350, training loss 0.616996, test_loss 0.833130, accuracy = 0.723988/0.801045, f1 = 0.804213\n",
      "Epoch 60, step 375, training loss 0.770352, test_loss 0.831167, accuracy = 0.723117/0.797127, f1 = 0.800910\n",
      "Epoch 60, step 400, training loss 0.655750, test_loss 0.826460, accuracy = 0.721376/0.795385, f1 = 0.799247\n",
      "End of epoch 60, training loss 0.616788, test_loss 0.832756, accuracy = 0.718328/0.796256, f1 = 0.799957\n",
      "Confusion matrix:\n",
      "[[818  61  22  36]\n",
      " [ 31 453  73  43]\n",
      " [ 15  63 430  45]\n",
      " [ 16  24  39 128]]\n",
      "Epoch 61, step 0, training loss 0.653198, test_loss 0.810585, accuracy = 0.727035/0.796256, f1 = 0.799883\n",
      "Epoch 61, step 25, training loss 0.622051, test_loss 0.840895, accuracy = 0.717893/0.799303, f1 = 0.802730\n",
      "Epoch 61, step 50, training loss 0.586493, test_loss 0.835063, accuracy = 0.719634/0.803657, f1 = 0.806570\n",
      "Epoch 61, step 75, training loss 0.662791, test_loss 0.837178, accuracy = 0.717893/0.802786, f1 = 0.805292\n",
      "Epoch 61, step 100, training loss 0.688378, test_loss 0.814791, accuracy = 0.729647/0.801480, f1 = 0.804727\n",
      "Epoch 61, step 125, training loss 0.547310, test_loss 0.817914, accuracy = 0.730083/0.802786, f1 = 0.805904\n",
      "Epoch 61, step 150, training loss 0.638784, test_loss 0.819449, accuracy = 0.727471/0.799303, f1 = 0.802924\n",
      "Epoch 61, step 175, training loss 0.707372, test_loss 0.809140, accuracy = 0.731389/0.802786, f1 = 0.806258\n",
      "Epoch 61, step 200, training loss 0.628324, test_loss 0.818722, accuracy = 0.730953/0.801916, f1 = 0.804670\n",
      "Epoch 61, step 225, training loss 0.499847, test_loss 0.813827, accuracy = 0.740531/0.803657, f1 = 0.806264\n",
      "Epoch 61, step 250, training loss 0.604484, test_loss 0.830314, accuracy = 0.720940/0.802351, f1 = 0.804745\n",
      "Epoch 61, step 275, training loss 0.606866, test_loss 0.814080, accuracy = 0.737048/0.803222, f1 = 0.805746\n",
      "Epoch 61, step 300, training loss 0.627064, test_loss 0.824065, accuracy = 0.728777/0.804528, f1 = 0.807261\n",
      "Epoch 61, step 325, training loss 0.680727, test_loss 0.826860, accuracy = 0.721376/0.802351, f1 = 0.804873\n",
      "Epoch 61, step 350, training loss 0.591749, test_loss 0.823769, accuracy = 0.721811/0.801480, f1 = 0.804227\n",
      "Epoch 61, step 375, training loss 0.770942, test_loss 0.819189, accuracy = 0.739225/0.801045, f1 = 0.804517\n",
      "Epoch 61, step 400, training loss 0.687962, test_loss 0.814063, accuracy = 0.727471/0.798868, f1 = 0.802756\n",
      "End of epoch 61, training loss 0.610184, test_loss 0.821820, accuracy = 0.734001/0.796691, f1 = 0.800901\n",
      "Confusion matrix:\n",
      "[[821  52  21  43]\n",
      " [ 32 444  80  44]\n",
      " [ 14  60 433  46]\n",
      " [ 14  22  39 132]]\n",
      "Epoch 62, step 0, training loss 0.636379, test_loss 0.824305, accuracy = 0.724859/0.796256, f1 = 0.800601\n",
      "Epoch 62, step 25, training loss 0.590253, test_loss 0.835699, accuracy = 0.721376/0.797127, f1 = 0.801524\n",
      "Epoch 62, step 50, training loss 0.661755, test_loss 0.817479, accuracy = 0.726165/0.801045, f1 = 0.804603\n",
      "Epoch 62, step 75, training loss 0.582136, test_loss 0.814258, accuracy = 0.729647/0.801480, f1 = 0.804094\n",
      "Epoch 62, step 100, training loss 0.600104, test_loss 0.814017, accuracy = 0.726165/0.801480, f1 = 0.804133\n",
      "Epoch 62, step 125, training loss 0.600787, test_loss 0.814626, accuracy = 0.727035/0.797997, f1 = 0.801553\n",
      "Epoch 62, step 150, training loss 0.583026, test_loss 0.819191, accuracy = 0.726600/0.800174, f1 = 0.804200\n",
      "Epoch 62, step 175, training loss 0.711189, test_loss 0.831789, accuracy = 0.717458/0.801480, f1 = 0.805184\n",
      "Epoch 62, step 200, training loss 0.575929, test_loss 0.835102, accuracy = 0.713975/0.806269, f1 = 0.809258\n",
      "Epoch 62, step 225, training loss 0.601462, test_loss 0.823743, accuracy = 0.723117/0.802786, f1 = 0.805926\n",
      "Epoch 62, step 250, training loss 0.673475, test_loss 0.829497, accuracy = 0.726165/0.803657, f1 = 0.806380\n",
      "Epoch 62, step 275, training loss 0.688460, test_loss 0.818245, accuracy = 0.735307/0.804528, f1 = 0.807342\n",
      "Epoch 62, step 300, training loss 0.641008, test_loss 0.829751, accuracy = 0.729212/0.798433, f1 = 0.801466\n",
      "Epoch 62, step 325, training loss 0.658361, test_loss 0.822333, accuracy = 0.720505/0.800610, f1 = 0.803715\n",
      "Epoch 62, step 350, training loss 0.696566, test_loss 0.836099, accuracy = 0.720940/0.801480, f1 = 0.804309\n",
      "Epoch 62, step 375, training loss 0.705535, test_loss 0.822882, accuracy = 0.723552/0.800610, f1 = 0.804384\n",
      "Epoch 62, step 400, training loss 0.683775, test_loss 0.830587, accuracy = 0.727035/0.798433, f1 = 0.802264\n",
      "End of epoch 62, training loss 0.618081, test_loss 0.826322, accuracy = 0.720505/0.801045, f1 = 0.804784\n",
      "Confusion matrix:\n",
      "[[823  55  22  37]\n",
      " [ 27 457  73  43]\n",
      " [ 16  62 431  44]\n",
      " [ 15  24  39 129]]\n",
      "Epoch 63, step 0, training loss 0.665142, test_loss 0.834924, accuracy = 0.724423/0.801045, f1 = 0.804784\n",
      "Epoch 63, step 25, training loss 0.615742, test_loss 0.829395, accuracy = 0.721376/0.801045, f1 = 0.804736\n",
      "Epoch 63, step 50, training loss 0.678096, test_loss 0.832888, accuracy = 0.725294/0.800610, f1 = 0.804062\n",
      "Epoch 63, step 75, training loss 0.599629, test_loss 0.805500, accuracy = 0.736178/0.804963, f1 = 0.807763\n",
      "Epoch 63, step 100, training loss 0.645578, test_loss 0.830390, accuracy = 0.734436/0.806269, f1 = 0.809314\n",
      "Epoch 63, step 125, training loss 0.593789, test_loss 0.818885, accuracy = 0.729647/0.804092, f1 = 0.807774\n",
      "Epoch 63, step 150, training loss 0.671736, test_loss 0.828538, accuracy = 0.728341/0.802351, f1 = 0.806404\n",
      "Epoch 63, step 175, training loss 0.673599, test_loss 0.819237, accuracy = 0.732695/0.802786, f1 = 0.806538\n",
      "Epoch 63, step 200, training loss 0.513081, test_loss 0.819787, accuracy = 0.734001/0.801916, f1 = 0.805450\n",
      "Epoch 63, step 225, training loss 0.556210, test_loss 0.830874, accuracy = 0.724859/0.805398, f1 = 0.808757\n",
      "Epoch 63, step 250, training loss 0.627166, test_loss 0.828942, accuracy = 0.732260/0.804963, f1 = 0.808137\n",
      "Epoch 63, step 275, training loss 0.580243, test_loss 0.829666, accuracy = 0.724423/0.803222, f1 = 0.806587\n",
      "Epoch 63, step 300, training loss 0.717631, test_loss 0.824937, accuracy = 0.721376/0.798868, f1 = 0.802603\n",
      "Epoch 63, step 325, training loss 0.756162, test_loss 0.819320, accuracy = 0.731824/0.800174, f1 = 0.803233\n",
      "Epoch 63, step 350, training loss 0.658134, test_loss 0.824631, accuracy = 0.713975/0.800610, f1 = 0.803506\n",
      "Epoch 63, step 375, training loss 0.739674, test_loss 0.824908, accuracy = 0.721811/0.800174, f1 = 0.804821\n",
      "Epoch 63, step 400, training loss 0.643310, test_loss 0.831582, accuracy = 0.724423/0.798868, f1 = 0.802862\n",
      "End of epoch 63, training loss 0.571564, test_loss 0.828910, accuracy = 0.716587/0.797562, f1 = 0.801650\n",
      "Confusion matrix:\n",
      "[[822  54  22  39]\n",
      " [ 30 451  69  50]\n",
      " [ 16  65 430  42]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 64, step 0, training loss 0.597399, test_loss 0.833153, accuracy = 0.716587/0.797562, f1 = 0.801590\n",
      "Epoch 64, step 25, training loss 0.712099, test_loss 0.813006, accuracy = 0.734872/0.798433, f1 = 0.802093\n",
      "Epoch 64, step 50, training loss 0.629103, test_loss 0.826511, accuracy = 0.718328/0.797127, f1 = 0.800608\n",
      "Epoch 64, step 75, training loss 0.624339, test_loss 0.815177, accuracy = 0.734872/0.800174, f1 = 0.803106\n",
      "Epoch 64, step 100, training loss 0.666715, test_loss 0.816447, accuracy = 0.731389/0.801480, f1 = 0.805410\n",
      "Epoch 64, step 125, training loss 0.579485, test_loss 0.829387, accuracy = 0.722246/0.800610, f1 = 0.804615\n",
      "Epoch 64, step 150, training loss 0.621384, test_loss 0.817804, accuracy = 0.737048/0.801480, f1 = 0.805933\n",
      "Epoch 64, step 175, training loss 0.723355, test_loss 0.821081, accuracy = 0.723552/0.800174, f1 = 0.804584\n",
      "Epoch 64, step 200, training loss 0.592702, test_loss 0.824784, accuracy = 0.725294/0.800610, f1 = 0.804011\n",
      "Epoch 64, step 225, training loss 0.585688, test_loss 0.829274, accuracy = 0.729647/0.798433, f1 = 0.802358\n",
      "Epoch 64, step 250, training loss 0.681905, test_loss 0.827091, accuracy = 0.727906/0.800610, f1 = 0.803959\n",
      "Epoch 64, step 275, training loss 0.637584, test_loss 0.831096, accuracy = 0.730083/0.803657, f1 = 0.807195\n",
      "Epoch 64, step 300, training loss 0.648186, test_loss 0.841016, accuracy = 0.720940/0.802786, f1 = 0.806540\n",
      "Epoch 64, step 325, training loss 0.661061, test_loss 0.828560, accuracy = 0.727471/0.803222, f1 = 0.806781\n",
      "Epoch 64, step 350, training loss 0.703096, test_loss 0.843509, accuracy = 0.726600/0.801480, f1 = 0.804739\n",
      "Epoch 64, step 375, training loss 0.773860, test_loss 0.824882, accuracy = 0.722246/0.802786, f1 = 0.806051\n",
      "Epoch 64, step 400, training loss 0.616498, test_loss 0.827802, accuracy = 0.723552/0.803222, f1 = 0.807016\n",
      "End of epoch 64, training loss 0.542970, test_loss 0.838992, accuracy = 0.722246/0.802351, f1 = 0.806668\n",
      "Confusion matrix:\n",
      "[[818  57  21  41]\n",
      " [ 28 462  66  44]\n",
      " [ 14  64 430  45]\n",
      " [ 14  22  38 133]]\n",
      "Epoch 65, step 0, training loss 0.636787, test_loss 0.820295, accuracy = 0.727906/0.802351, f1 = 0.806668\n",
      "Epoch 65, step 25, training loss 0.572749, test_loss 0.824227, accuracy = 0.734436/0.801916, f1 = 0.806524\n",
      "Epoch 65, step 50, training loss 0.619731, test_loss 0.831724, accuracy = 0.723117/0.804528, f1 = 0.808525\n",
      "Epoch 65, step 75, training loss 0.691808, test_loss 0.829131, accuracy = 0.720940/0.804528, f1 = 0.807415\n",
      "Epoch 65, step 100, training loss 0.661391, test_loss 0.806868, accuracy = 0.737484/0.806704, f1 = 0.809965\n",
      "Epoch 65, step 125, training loss 0.587119, test_loss 0.826744, accuracy = 0.735742/0.802786, f1 = 0.807141\n",
      "Epoch 65, step 150, training loss 0.570619, test_loss 0.824058, accuracy = 0.735307/0.801916, f1 = 0.806256\n",
      "Epoch 65, step 175, training loss 0.710293, test_loss 0.819933, accuracy = 0.723988/0.800610, f1 = 0.803979\n",
      "Epoch 65, step 200, training loss 0.608650, test_loss 0.813830, accuracy = 0.730953/0.804963, f1 = 0.807629\n",
      "Epoch 65, step 225, training loss 0.580223, test_loss 0.817727, accuracy = 0.734436/0.804092, f1 = 0.806553\n",
      "Epoch 65, step 250, training loss 0.586520, test_loss 0.815736, accuracy = 0.728777/0.806704, f1 = 0.809672\n",
      "Epoch 65, step 275, training loss 0.714435, test_loss 0.811387, accuracy = 0.726165/0.801480, f1 = 0.804331\n",
      "Epoch 65, step 300, training loss 0.569425, test_loss 0.822692, accuracy = 0.725294/0.803657, f1 = 0.806860\n",
      "Epoch 65, step 325, training loss 0.770979, test_loss 0.830507, accuracy = 0.720940/0.803657, f1 = 0.807142\n",
      "Epoch 65, step 350, training loss 0.727116, test_loss 0.827280, accuracy = 0.717893/0.804528, f1 = 0.807447\n",
      "Epoch 65, step 375, training loss 0.701341, test_loss 0.827750, accuracy = 0.719199/0.797997, f1 = 0.801752\n",
      "Epoch 65, step 400, training loss 0.699552, test_loss 0.831800, accuracy = 0.722246/0.799739, f1 = 0.804051\n",
      "End of epoch 65, training loss 0.550991, test_loss 0.823683, accuracy = 0.721811/0.800174, f1 = 0.804319\n",
      "Confusion matrix:\n",
      "[[820  56  23  38]\n",
      " [ 27 452  76  45]\n",
      " [ 12  57 439  45]\n",
      " [ 14  24  42 127]]\n",
      "Epoch 66, step 0, training loss 0.579758, test_loss 0.817661, accuracy = 0.730083/0.801045, f1 = 0.805120\n",
      "Epoch 66, step 25, training loss 0.571243, test_loss 0.838238, accuracy = 0.718328/0.802351, f1 = 0.806610\n",
      "Epoch 66, step 50, training loss 0.603405, test_loss 0.834827, accuracy = 0.719199/0.804528, f1 = 0.807708\n",
      "Epoch 66, step 75, training loss 0.605098, test_loss 0.811184, accuracy = 0.727035/0.802351, f1 = 0.805203\n",
      "Epoch 66, step 100, training loss 0.672964, test_loss 0.816011, accuracy = 0.724859/0.798868, f1 = 0.802467\n",
      "Epoch 66, step 125, training loss 0.597322, test_loss 0.826890, accuracy = 0.726600/0.801045, f1 = 0.804964\n",
      "Epoch 66, step 150, training loss 0.672692, test_loss 0.829536, accuracy = 0.720505/0.803657, f1 = 0.807590\n",
      "Epoch 66, step 175, training loss 0.804511, test_loss 0.830861, accuracy = 0.719634/0.804528, f1 = 0.808216\n",
      "Epoch 66, step 200, training loss 0.563687, test_loss 0.814668, accuracy = 0.740096/0.803222, f1 = 0.806381\n",
      "Epoch 66, step 225, training loss 0.618470, test_loss 0.826232, accuracy = 0.730083/0.803657, f1 = 0.807082\n",
      "Epoch 66, step 250, training loss 0.672207, test_loss 0.823681, accuracy = 0.723988/0.804963, f1 = 0.807987\n",
      "Epoch 66, step 275, training loss 0.574116, test_loss 0.816021, accuracy = 0.731389/0.803657, f1 = 0.806351\n",
      "Epoch 66, step 300, training loss 0.730396, test_loss 0.821556, accuracy = 0.727035/0.806704, f1 = 0.809334\n",
      "Epoch 66, step 325, training loss 0.732435, test_loss 0.814076, accuracy = 0.733566/0.805398, f1 = 0.808296\n",
      "Epoch 66, step 350, training loss 0.665900, test_loss 0.829950, accuracy = 0.717022/0.805398, f1 = 0.807592\n",
      "Epoch 66, step 375, training loss 0.743969, test_loss 0.818596, accuracy = 0.732695/0.803657, f1 = 0.806792\n",
      "Epoch 66, step 400, training loss 0.648987, test_loss 0.829565, accuracy = 0.723988/0.805834, f1 = 0.808592\n",
      "End of epoch 66, training loss 0.532667, test_loss 0.823225, accuracy = 0.733130/0.807140, f1 = 0.809741\n",
      "Confusion matrix:\n",
      "[[829  55  23  30]\n",
      " [ 29 461  72  38]\n",
      " [ 12  59 441  41]\n",
      " [ 17  24  43 123]]\n",
      "Epoch 67, step 0, training loss 0.603863, test_loss 0.828893, accuracy = 0.716151/0.807575, f1 = 0.810240\n",
      "Epoch 67, step 25, training loss 0.597028, test_loss 0.827120, accuracy = 0.717022/0.804528, f1 = 0.807154\n",
      "Epoch 67, step 50, training loss 0.609617, test_loss 0.819998, accuracy = 0.731389/0.804092, f1 = 0.806696\n",
      "Epoch 67, step 75, training loss 0.635807, test_loss 0.821500, accuracy = 0.723117/0.803222, f1 = 0.806184\n",
      "Epoch 67, step 100, training loss 0.662221, test_loss 0.812235, accuracy = 0.736613/0.804963, f1 = 0.807963\n",
      "Epoch 67, step 125, training loss 0.583638, test_loss 0.834181, accuracy = 0.716587/0.801480, f1 = 0.805452\n",
      "Epoch 67, step 150, training loss 0.661826, test_loss 0.815636, accuracy = 0.727471/0.798868, f1 = 0.803384\n",
      "Epoch 67, step 175, training loss 0.794807, test_loss 0.823358, accuracy = 0.725729/0.801916, f1 = 0.805835\n",
      "Epoch 67, step 200, training loss 0.592030, test_loss 0.820764, accuracy = 0.727471/0.801045, f1 = 0.804063\n",
      "Epoch 67, step 225, training loss 0.552070, test_loss 0.828881, accuracy = 0.735742/0.803222, f1 = 0.806475\n",
      "Epoch 67, step 250, training loss 0.715348, test_loss 0.818477, accuracy = 0.729647/0.807140, f1 = 0.810088\n",
      "Epoch 67, step 275, training loss 0.660125, test_loss 0.825529, accuracy = 0.729647/0.805834, f1 = 0.808618\n",
      "Epoch 67, step 300, training loss 0.638213, test_loss 0.798570, accuracy = 0.731824/0.804528, f1 = 0.807319\n",
      "Epoch 67, step 325, training loss 0.723457, test_loss 0.831468, accuracy = 0.719634/0.804528, f1 = 0.807167\n",
      "Epoch 67, step 350, training loss 0.657787, test_loss 0.825535, accuracy = 0.729647/0.804963, f1 = 0.807363\n",
      "Epoch 67, step 375, training loss 0.771705, test_loss 0.828825, accuracy = 0.721376/0.801480, f1 = 0.804937\n",
      "Epoch 67, step 400, training loss 0.725520, test_loss 0.811420, accuracy = 0.731389/0.802786, f1 = 0.806000\n",
      "End of epoch 67, training loss 0.575694, test_loss 0.823767, accuracy = 0.731389/0.803657, f1 = 0.807191\n",
      "Confusion matrix:\n",
      "[[822  57  21  37]\n",
      " [ 28 472  61  39]\n",
      " [ 13  69 427  44]\n",
      " [ 15  26  41 125]]\n",
      "Epoch 68, step 0, training loss 0.595668, test_loss 0.826839, accuracy = 0.715281/0.804528, f1 = 0.807981\n",
      "Epoch 68, step 25, training loss 0.635137, test_loss 0.827316, accuracy = 0.724859/0.799303, f1 = 0.803645\n",
      "Epoch 68, step 50, training loss 0.697580, test_loss 0.819846, accuracy = 0.725294/0.801916, f1 = 0.806107\n",
      "Epoch 68, step 75, training loss 0.618692, test_loss 0.814605, accuracy = 0.733566/0.801916, f1 = 0.805211\n",
      "Epoch 68, step 100, training loss 0.706012, test_loss 0.814116, accuracy = 0.733130/0.804528, f1 = 0.808043\n",
      "Epoch 68, step 125, training loss 0.593008, test_loss 0.828192, accuracy = 0.720940/0.803657, f1 = 0.806927\n",
      "Epoch 68, step 150, training loss 0.688777, test_loss 0.832061, accuracy = 0.722682/0.803657, f1 = 0.807233\n",
      "Epoch 68, step 175, training loss 0.734947, test_loss 0.819065, accuracy = 0.720070/0.804528, f1 = 0.807787\n",
      "Epoch 68, step 200, training loss 0.532183, test_loss 0.821608, accuracy = 0.724423/0.805834, f1 = 0.808720\n",
      "Epoch 68, step 225, training loss 0.601616, test_loss 0.834514, accuracy = 0.729212/0.808011, f1 = 0.810947\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 68, step 250, training loss 0.682511, test_loss 0.820175, accuracy = 0.732260/0.808881, f1 = 0.811561\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Model is best seen so far. Saved to: context_models/neighbourhood_models/tmp/model.ckpt\n",
      "Epoch 68, step 275, training loss 0.656962, test_loss 0.818270, accuracy = 0.736613/0.806269, f1 = 0.809032\n",
      "Epoch 68, step 300, training loss 0.606830, test_loss 0.828906, accuracy = 0.727471/0.804528, f1 = 0.807604\n",
      "Epoch 68, step 325, training loss 0.777776, test_loss 0.826151, accuracy = 0.727471/0.803657, f1 = 0.806518\n",
      "Epoch 68, step 350, training loss 0.662332, test_loss 0.827374, accuracy = 0.727035/0.803222, f1 = 0.805085\n",
      "Epoch 68, step 375, training loss 0.713289, test_loss 0.833201, accuracy = 0.720940/0.800610, f1 = 0.803767\n",
      "Epoch 68, step 400, training loss 0.713345, test_loss 0.837389, accuracy = 0.714846/0.800174, f1 = 0.804232\n",
      "End of epoch 68, training loss 0.550543, test_loss 0.827454, accuracy = 0.725729/0.801916, f1 = 0.806362\n",
      "Confusion matrix:\n",
      "[[820  54  20  43]\n",
      " [ 29 463  65  43]\n",
      " [ 15  67 425  46]\n",
      " [ 11  25  37 134]]\n",
      "Epoch 69, step 0, training loss 0.634994, test_loss 0.844726, accuracy = 0.710492/0.801480, f1 = 0.805962\n",
      "Epoch 69, step 25, training loss 0.635381, test_loss 0.822891, accuracy = 0.724423/0.802351, f1 = 0.806581\n",
      "Epoch 69, step 50, training loss 0.563660, test_loss 0.813308, accuracy = 0.725729/0.802786, f1 = 0.806123\n",
      "Epoch 69, step 75, training loss 0.610130, test_loss 0.821182, accuracy = 0.734001/0.804092, f1 = 0.807159\n",
      "Epoch 69, step 100, training loss 0.693096, test_loss 0.802926, accuracy = 0.730953/0.803657, f1 = 0.807259\n",
      "Epoch 69, step 125, training loss 0.704639, test_loss 0.827345, accuracy = 0.730518/0.799303, f1 = 0.804534\n",
      "Epoch 69, step 150, training loss 0.587295, test_loss 0.833865, accuracy = 0.723552/0.799303, f1 = 0.804547\n",
      "Epoch 69, step 175, training loss 0.794312, test_loss 0.822031, accuracy = 0.731824/0.802786, f1 = 0.807137\n",
      "Epoch 69, step 200, training loss 0.543023, test_loss 0.825979, accuracy = 0.721811/0.804092, f1 = 0.807759\n",
      "Epoch 69, step 225, training loss 0.520712, test_loss 0.824809, accuracy = 0.717893/0.802786, f1 = 0.807018\n",
      "Epoch 69, step 250, training loss 0.745223, test_loss 0.815362, accuracy = 0.734872/0.803657, f1 = 0.807595\n",
      "Epoch 69, step 275, training loss 0.602946, test_loss 0.809555, accuracy = 0.733130/0.802351, f1 = 0.806129\n",
      "Epoch 69, step 300, training loss 0.708763, test_loss 0.826715, accuracy = 0.723117/0.800174, f1 = 0.804208\n",
      "Epoch 69, step 325, training loss 0.680523, test_loss 0.818213, accuracy = 0.737484/0.801916, f1 = 0.805338\n",
      "Epoch 69, step 350, training loss 0.661251, test_loss 0.823777, accuracy = 0.720505/0.803222, f1 = 0.806523\n",
      "Epoch 69, step 375, training loss 0.795049, test_loss 0.833269, accuracy = 0.717893/0.797562, f1 = 0.802140\n",
      "Epoch 69, step 400, training loss 0.696964, test_loss 0.824720, accuracy = 0.723988/0.798433, f1 = 0.802453\n",
      "End of epoch 69, training loss 0.570499, test_loss 0.826287, accuracy = 0.719634/0.797997, f1 = 0.802070\n",
      "Confusion matrix:\n",
      "[[819  57  21  40]\n",
      " [ 29 461  68  42]\n",
      " [ 15  67 425  46]\n",
      " [ 14  26  39 128]]\n",
      "Epoch 70, step 0, training loss 0.704932, test_loss 0.831327, accuracy = 0.726600/0.797562, f1 = 0.801659\n",
      "Epoch 70, step 25, training loss 0.592895, test_loss 0.831989, accuracy = 0.723988/0.797997, f1 = 0.802736\n",
      "Epoch 70, step 50, training loss 0.681212, test_loss 0.831196, accuracy = 0.717893/0.800174, f1 = 0.803783\n",
      "Epoch 70, step 75, training loss 0.674549, test_loss 0.834497, accuracy = 0.711798/0.799739, f1 = 0.803168\n",
      "Epoch 70, step 100, training loss 0.637320, test_loss 0.816172, accuracy = 0.726165/0.797997, f1 = 0.802322\n",
      "Epoch 70, step 125, training loss 0.540914, test_loss 0.819115, accuracy = 0.727471/0.798868, f1 = 0.803688\n",
      "Epoch 70, step 150, training loss 0.653292, test_loss 0.817751, accuracy = 0.726165/0.798433, f1 = 0.803586\n",
      "Epoch 70, step 175, training loss 0.709537, test_loss 0.818745, accuracy = 0.735307/0.798868, f1 = 0.803618\n",
      "Epoch 70, step 200, training loss 0.535246, test_loss 0.828526, accuracy = 0.723117/0.802786, f1 = 0.806468\n",
      "Epoch 70, step 225, training loss 0.603751, test_loss 0.832773, accuracy = 0.719199/0.801916, f1 = 0.806071\n",
      "Epoch 70, step 250, training loss 0.700307, test_loss 0.833045, accuracy = 0.731824/0.805398, f1 = 0.808712\n",
      "Epoch 70, step 275, training loss 0.633613, test_loss 0.825388, accuracy = 0.724423/0.804528, f1 = 0.807865\n",
      "Epoch 70, step 300, training loss 0.610208, test_loss 0.825757, accuracy = 0.720940/0.803657, f1 = 0.806967\n",
      "Epoch 70, step 325, training loss 0.740367, test_loss 0.822902, accuracy = 0.725729/0.802351, f1 = 0.805745\n",
      "Epoch 70, step 350, training loss 0.665095, test_loss 0.838379, accuracy = 0.703526/0.801480, f1 = 0.805020\n",
      "Epoch 70, step 375, training loss 0.898076, test_loss 0.834168, accuracy = 0.725294/0.797562, f1 = 0.802591\n",
      "Epoch 70, step 400, training loss 0.594659, test_loss 0.812446, accuracy = 0.732260/0.797997, f1 = 0.803426\n",
      "End of epoch 70, training loss 0.580264, test_loss 0.822664, accuracy = 0.728777/0.800174, f1 = 0.805312\n",
      "Confusion matrix:\n",
      "[[814  58  20  45]\n",
      " [ 24 454  75  47]\n",
      " [ 13  61 434  45]\n",
      " [ 10  23  38 136]]\n",
      "Epoch 71, step 0, training loss 0.616040, test_loss 0.827930, accuracy = 0.716151/0.800174, f1 = 0.805312\n",
      "Epoch 71, step 25, training loss 0.649384, test_loss 0.847636, accuracy = 0.718764/0.800174, f1 = 0.805010\n",
      "Epoch 71, step 50, training loss 0.743005, test_loss 0.832460, accuracy = 0.724423/0.800610, f1 = 0.805298\n",
      "Epoch 71, step 75, training loss 0.669233, test_loss 0.806594, accuracy = 0.733130/0.804963, f1 = 0.809303\n",
      "Epoch 71, step 100, training loss 0.672813, test_loss 0.805067, accuracy = 0.722246/0.801045, f1 = 0.805817\n",
      "Epoch 71, step 125, training loss 0.630670, test_loss 0.828884, accuracy = 0.727035/0.801480, f1 = 0.806824\n",
      "Epoch 71, step 150, training loss 0.673801, test_loss 0.835235, accuracy = 0.723553/0.799303, f1 = 0.804745\n",
      "Epoch 71, step 175, training loss 0.746900, test_loss 0.826817, accuracy = 0.723988/0.804963, f1 = 0.809752\n",
      "Epoch 71, step 200, training loss 0.589278, test_loss 0.829880, accuracy = 0.729647/0.805834, f1 = 0.809418\n",
      "Epoch 71, step 225, training loss 0.627753, test_loss 0.844587, accuracy = 0.713975/0.805398, f1 = 0.808994\n",
      "Epoch 71, step 250, training loss 0.740413, test_loss 0.837417, accuracy = 0.721811/0.803657, f1 = 0.807513\n",
      "Epoch 71, step 275, training loss 0.613271, test_loss 0.820151, accuracy = 0.732695/0.800174, f1 = 0.804422\n",
      "Epoch 71, step 300, training loss 0.558139, test_loss 0.823818, accuracy = 0.733130/0.799303, f1 = 0.804254\n",
      "Epoch 71, step 325, training loss 0.765251, test_loss 0.829242, accuracy = 0.727035/0.800174, f1 = 0.804589\n",
      "Epoch 71, step 350, training loss 0.586949, test_loss 0.828661, accuracy = 0.716152/0.800610, f1 = 0.804807\n",
      "Epoch 71, step 375, training loss 0.813070, test_loss 0.821393, accuracy = 0.729212/0.798868, f1 = 0.804175\n",
      "Epoch 71, step 400, training loss 0.684455, test_loss 0.848794, accuracy = 0.712669/0.799739, f1 = 0.804379\n",
      "End of epoch 71, training loss 0.524069, test_loss 0.834206, accuracy = 0.717893/0.800610, f1 = 0.805102\n",
      "Confusion matrix:\n",
      "[[810  60  25  42]\n",
      " [ 25 460  71  44]\n",
      " [ 13  56 441  43]\n",
      " [ 13  23  43 128]]\n",
      "Epoch 72, step 0, training loss 0.593053, test_loss 0.831956, accuracy = 0.721376/0.800610, f1 = 0.805204\n",
      "Epoch 72, step 25, training loss 0.620706, test_loss 0.814273, accuracy = 0.735307/0.801045, f1 = 0.805733\n",
      "Epoch 72, step 50, training loss 0.608137, test_loss 0.832555, accuracy = 0.723988/0.800610, f1 = 0.805327\n",
      "Epoch 72, step 75, training loss 0.622707, test_loss 0.814408, accuracy = 0.736178/0.800610, f1 = 0.804637\n",
      "Epoch 72, step 100, training loss 0.595846, test_loss 0.820217, accuracy = 0.726165/0.801480, f1 = 0.805586\n",
      "Epoch 72, step 125, training loss 0.637930, test_loss 0.814990, accuracy = 0.730083/0.797997, f1 = 0.802800\n",
      "Epoch 72, step 150, training loss 0.602760, test_loss 0.821826, accuracy = 0.727471/0.798433, f1 = 0.803163\n",
      "Epoch 72, step 175, training loss 0.770517, test_loss 0.818065, accuracy = 0.727906/0.801045, f1 = 0.804971\n",
      "Epoch 72, step 200, training loss 0.648233, test_loss 0.822274, accuracy = 0.738790/0.800610, f1 = 0.804682\n",
      "Epoch 72, step 225, training loss 0.575401, test_loss 0.822021, accuracy = 0.721376/0.801916, f1 = 0.805984\n",
      "Epoch 72, step 250, training loss 0.668733, test_loss 0.818008, accuracy = 0.725729/0.804963, f1 = 0.808274\n",
      "Epoch 72, step 275, training loss 0.708220, test_loss 0.816060, accuracy = 0.735307/0.800610, f1 = 0.804153\n",
      "Epoch 72, step 300, training loss 0.641808, test_loss 0.817143, accuracy = 0.720505/0.802351, f1 = 0.806016\n",
      "Epoch 72, step 325, training loss 0.769859, test_loss 0.836263, accuracy = 0.721376/0.803222, f1 = 0.806375\n",
      "Epoch 72, step 350, training loss 0.692766, test_loss 0.826209, accuracy = 0.720940/0.801916, f1 = 0.804844\n",
      "Epoch 72, step 375, training loss 0.634227, test_loss 0.823688, accuracy = 0.719634/0.797562, f1 = 0.801205\n",
      "Epoch 72, step 400, training loss 0.683172, test_loss 0.812747, accuracy = 0.727471/0.794515, f1 = 0.799128\n",
      "End of epoch 72, training loss 0.571001, test_loss 0.814556, accuracy = 0.727471/0.795821, f1 = 0.800068\n",
      "Confusion matrix:\n",
      "[[819  53  22  43]\n",
      " [ 36 440  72  52]\n",
      " [ 15  56 440  42]\n",
      " [ 13  23  42 129]]\n",
      "Epoch 73, step 0, training loss 0.642790, test_loss 0.828481, accuracy = 0.726165/0.795385, f1 = 0.799642\n",
      "Epoch 73, step 25, training loss 0.693860, test_loss 0.818376, accuracy = 0.729212/0.791902, f1 = 0.796761\n",
      "Epoch 73, step 50, training loss 0.550408, test_loss 0.819833, accuracy = 0.721811/0.798433, f1 = 0.802385\n",
      "Epoch 73, step 75, training loss 0.551778, test_loss 0.819030, accuracy = 0.718328/0.799739, f1 = 0.803166\n",
      "Epoch 73, step 100, training loss 0.646197, test_loss 0.814083, accuracy = 0.729647/0.798433, f1 = 0.801978\n",
      "Epoch 73, step 125, training loss 0.572278, test_loss 0.823947, accuracy = 0.732260/0.796256, f1 = 0.800627\n",
      "Epoch 73, step 150, training loss 0.618047, test_loss 0.818942, accuracy = 0.727906/0.799303, f1 = 0.803462\n",
      "Epoch 73, step 175, training loss 0.807790, test_loss 0.826745, accuracy = 0.725294/0.799739, f1 = 0.803827\n",
      "Epoch 73, step 200, training loss 0.581619, test_loss 0.821309, accuracy = 0.723117/0.799739, f1 = 0.803375\n",
      "Epoch 73, step 225, training loss 0.586243, test_loss 0.847819, accuracy = 0.717022/0.799303, f1 = 0.803527\n",
      "Epoch 73, step 250, training loss 0.669468, test_loss 0.830313, accuracy = 0.724423/0.800610, f1 = 0.804367\n",
      "Epoch 73, step 275, training loss 0.659592, test_loss 0.796087, accuracy = 0.729212/0.801045, f1 = 0.804600\n",
      "Epoch 73, step 300, training loss 0.683168, test_loss 0.818273, accuracy = 0.732695/0.800174, f1 = 0.803785\n",
      "Epoch 73, step 325, training loss 0.738185, test_loss 0.836944, accuracy = 0.721376/0.798868, f1 = 0.802717\n",
      "Epoch 73, step 350, training loss 0.649722, test_loss 0.833310, accuracy = 0.718764/0.801916, f1 = 0.805253\n",
      "Epoch 73, step 375, training loss 0.732761, test_loss 0.826945, accuracy = 0.728341/0.794950, f1 = 0.799384\n",
      "Epoch 73, step 400, training loss 0.639789, test_loss 0.829543, accuracy = 0.718764/0.795821, f1 = 0.799901\n",
      "End of epoch 73, training loss 0.571276, test_loss 0.822388, accuracy = 0.724423/0.797997, f1 = 0.801915\n",
      "Confusion matrix:\n",
      "[[818  58  23  38]\n",
      " [ 30 448  77  45]\n",
      " [ 12  59 440  42]\n",
      " [ 13  24  43 127]]\n",
      "Epoch 74, step 0, training loss 0.687417, test_loss 0.826778, accuracy = 0.717893/0.797997, f1 = 0.801915\n",
      "Epoch 74, step 25, training loss 0.572552, test_loss 0.830187, accuracy = 0.730518/0.797127, f1 = 0.801983\n",
      "Epoch 74, step 50, training loss 0.605766, test_loss 0.835084, accuracy = 0.725729/0.799739, f1 = 0.803653\n",
      "Epoch 74, step 75, training loss 0.599920, test_loss 0.812236, accuracy = 0.725294/0.803222, f1 = 0.806523\n",
      "Epoch 74, step 100, training loss 0.688184, test_loss 0.826961, accuracy = 0.724859/0.802351, f1 = 0.806014\n",
      "Epoch 74, step 125, training loss 0.609974, test_loss 0.818322, accuracy = 0.720940/0.800174, f1 = 0.804517\n",
      "Epoch 74, step 150, training loss 0.738645, test_loss 0.821289, accuracy = 0.726600/0.797997, f1 = 0.802132\n",
      "Epoch 74, step 175, training loss 0.816030, test_loss 0.822952, accuracy = 0.723552/0.798433, f1 = 0.802421\n",
      "Epoch 74, step 200, training loss 0.519999, test_loss 0.821315, accuracy = 0.733130/0.799303, f1 = 0.802215\n",
      "Epoch 74, step 225, training loss 0.575411, test_loss 0.812741, accuracy = 0.726600/0.797997, f1 = 0.801230\n",
      "Epoch 74, step 250, training loss 0.664261, test_loss 0.827157, accuracy = 0.730083/0.799303, f1 = 0.802286\n",
      "Epoch 74, step 275, training loss 0.634573, test_loss 0.827852, accuracy = 0.729647/0.798868, f1 = 0.802129\n",
      "Epoch 74, step 300, training loss 0.654998, test_loss 0.835912, accuracy = 0.721811/0.798868, f1 = 0.802186\n",
      "Epoch 74, step 325, training loss 0.778187, test_loss 0.825602, accuracy = 0.722682/0.798868, f1 = 0.801695\n",
      "Epoch 74, step 350, training loss 0.737251, test_loss 0.843403, accuracy = 0.708751/0.798433, f1 = 0.801073\n",
      "Epoch 74, step 375, training loss 0.855267, test_loss 0.837331, accuracy = 0.713104/0.794950, f1 = 0.798477\n",
      "Epoch 74, step 400, training loss 0.661126, test_loss 0.833638, accuracy = 0.724423/0.790161, f1 = 0.795246\n",
      "End of epoch 74, training loss 0.582594, test_loss 0.829041, accuracy = 0.717893/0.791032, f1 = 0.796138\n",
      "Confusion matrix:\n",
      "[[819  51  21  46]\n",
      " [ 32 438  74  56]\n",
      " [ 15  61 431  46]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 75, step 0, training loss 0.648103, test_loss 0.832555, accuracy = 0.723552/0.791032, f1 = 0.796159\n",
      "Epoch 75, step 25, training loss 0.570529, test_loss 0.837013, accuracy = 0.719634/0.794515, f1 = 0.799627\n",
      "Epoch 75, step 50, training loss 0.569274, test_loss 0.825170, accuracy = 0.726165/0.796691, f1 = 0.800763\n",
      "Epoch 75, step 75, training loss 0.662869, test_loss 0.831609, accuracy = 0.721376/0.798868, f1 = 0.802684\n",
      "Epoch 75, step 100, training loss 0.649859, test_loss 0.827563, accuracy = 0.725294/0.800174, f1 = 0.804037\n",
      "Epoch 75, step 125, training loss 0.551369, test_loss 0.819413, accuracy = 0.724859/0.797562, f1 = 0.801629\n",
      "Epoch 75, step 150, training loss 0.659946, test_loss 0.830172, accuracy = 0.729212/0.797127, f1 = 0.801808\n",
      "Epoch 75, step 175, training loss 0.798658, test_loss 0.821596, accuracy = 0.723552/0.799303, f1 = 0.802755\n",
      "Epoch 75, step 200, training loss 0.591465, test_loss 0.837626, accuracy = 0.718764/0.802786, f1 = 0.805538\n",
      "Epoch 75, step 225, training loss 0.583879, test_loss 0.832503, accuracy = 0.719199/0.801916, f1 = 0.805007\n",
      "Epoch 75, step 250, training loss 0.569751, test_loss 0.822311, accuracy = 0.723988/0.803222, f1 = 0.805969\n",
      "Epoch 75, step 275, training loss 0.684185, test_loss 0.829367, accuracy = 0.716587/0.801045, f1 = 0.804360\n",
      "Epoch 75, step 300, training loss 0.609778, test_loss 0.821752, accuracy = 0.729647/0.802351, f1 = 0.805786\n",
      "Epoch 75, step 325, training loss 0.696675, test_loss 0.838763, accuracy = 0.717022/0.799739, f1 = 0.803432\n",
      "Epoch 75, step 350, training loss 0.661910, test_loss 0.836335, accuracy = 0.716151/0.801480, f1 = 0.804574\n",
      "Epoch 75, step 375, training loss 0.810345, test_loss 0.833440, accuracy = 0.718328/0.798433, f1 = 0.802651\n",
      "Epoch 75, step 400, training loss 0.700159, test_loss 0.840681, accuracy = 0.719634/0.794950, f1 = 0.799695\n",
      "End of epoch 75, training loss 0.601207, test_loss 0.825347, accuracy = 0.725729/0.795821, f1 = 0.800503\n",
      "Confusion matrix:\n",
      "[[826  49  20  42]\n",
      " [ 33 449  64  54]\n",
      " [ 19  63 421  50]\n",
      " [ 16  22  37 132]]\n",
      "Epoch 76, step 0, training loss 0.672086, test_loss 0.837561, accuracy = 0.716152/0.795821, f1 = 0.800535\n",
      "Epoch 76, step 25, training loss 0.588692, test_loss 0.827330, accuracy = 0.723988/0.800174, f1 = 0.804443\n",
      "Epoch 76, step 50, training loss 0.534751, test_loss 0.834067, accuracy = 0.729647/0.801045, f1 = 0.804369\n",
      "Epoch 76, step 75, training loss 0.634972, test_loss 0.828519, accuracy = 0.720940/0.801480, f1 = 0.804439\n",
      "Epoch 76, step 100, training loss 0.605115, test_loss 0.819363, accuracy = 0.726165/0.799739, f1 = 0.803275\n",
      "Epoch 76, step 125, training loss 0.613013, test_loss 0.816531, accuracy = 0.731824/0.795385, f1 = 0.800651\n",
      "Epoch 76, step 150, training loss 0.620120, test_loss 0.829977, accuracy = 0.727906/0.795385, f1 = 0.800546\n",
      "Epoch 76, step 175, training loss 0.732571, test_loss 0.817475, accuracy = 0.726165/0.799739, f1 = 0.804176\n",
      "Epoch 76, step 200, training loss 0.604005, test_loss 0.819732, accuracy = 0.728341/0.802351, f1 = 0.805009\n",
      "Epoch 76, step 225, training loss 0.529061, test_loss 0.832550, accuracy = 0.720505/0.801480, f1 = 0.804061\n",
      "Epoch 76, step 250, training loss 0.652624, test_loss 0.829882, accuracy = 0.723553/0.801045, f1 = 0.803808\n",
      "Epoch 76, step 275, training loss 0.590164, test_loss 0.818425, accuracy = 0.728777/0.802351, f1 = 0.805545\n",
      "Epoch 76, step 300, training loss 0.668322, test_loss 0.821088, accuracy = 0.723117/0.802351, f1 = 0.805805\n",
      "Epoch 76, step 325, training loss 0.683887, test_loss 0.830985, accuracy = 0.714845/0.801916, f1 = 0.804911\n",
      "Epoch 76, step 350, training loss 0.631900, test_loss 0.825892, accuracy = 0.723552/0.803222, f1 = 0.805635\n",
      "Epoch 76, step 375, training loss 0.671829, test_loss 0.838982, accuracy = 0.719634/0.801480, f1 = 0.804948\n",
      "Epoch 76, step 400, training loss 0.683877, test_loss 0.822542, accuracy = 0.727471/0.798868, f1 = 0.802673\n",
      "End of epoch 76, training loss 0.548272, test_loss 0.831071, accuracy = 0.720505/0.798868, f1 = 0.802995\n",
      "Confusion matrix:\n",
      "[[819  58  23  37]\n",
      " [ 27 458  70  45]\n",
      " [ 14  63 430  46]\n",
      " [ 15  23  41 128]]\n",
      "Epoch 77, step 0, training loss 0.602704, test_loss 0.825887, accuracy = 0.724859/0.798433, f1 = 0.802560\n",
      "Epoch 77, step 25, training loss 0.593426, test_loss 0.842492, accuracy = 0.710492/0.796691, f1 = 0.801779\n",
      "Epoch 77, step 50, training loss 0.693937, test_loss 0.809559, accuracy = 0.727471/0.801480, f1 = 0.805739\n",
      "Epoch 77, step 75, training loss 0.574158, test_loss 0.824058, accuracy = 0.732695/0.804963, f1 = 0.808268\n",
      "Epoch 77, step 100, training loss 0.725424, test_loss 0.823304, accuracy = 0.730518/0.804092, f1 = 0.807533\n",
      "Epoch 77, step 125, training loss 0.561837, test_loss 0.811165, accuracy = 0.730083/0.800174, f1 = 0.804385\n",
      "Epoch 77, step 150, training loss 0.715665, test_loss 0.826938, accuracy = 0.722682/0.801045, f1 = 0.805143\n",
      "Epoch 77, step 175, training loss 0.792505, test_loss 0.829207, accuracy = 0.723117/0.802351, f1 = 0.805526\n",
      "Epoch 77, step 200, training loss 0.589768, test_loss 0.824598, accuracy = 0.717458/0.801480, f1 = 0.804866\n",
      "Epoch 77, step 225, training loss 0.608263, test_loss 0.824096, accuracy = 0.720070/0.798868, f1 = 0.802812\n",
      "Epoch 77, step 250, training loss 0.714459, test_loss 0.830660, accuracy = 0.719199/0.800174, f1 = 0.803567\n",
      "Epoch 77, step 275, training loss 0.625565, test_loss 0.816199, accuracy = 0.727906/0.801480, f1 = 0.804566\n",
      "Epoch 77, step 300, training loss 0.615022, test_loss 0.806556, accuracy = 0.734872/0.802351, f1 = 0.806115\n",
      "Epoch 77, step 325, training loss 0.674537, test_loss 0.826226, accuracy = 0.724859/0.803657, f1 = 0.807189\n",
      "Epoch 77, step 350, training loss 0.621514, test_loss 0.837698, accuracy = 0.720940/0.802351, f1 = 0.805769\n",
      "Epoch 77, step 375, training loss 0.770159, test_loss 0.841388, accuracy = 0.713975/0.800174, f1 = 0.804515\n",
      "Epoch 77, step 400, training loss 0.723669, test_loss 0.833464, accuracy = 0.714410/0.795385, f1 = 0.800193\n",
      "End of epoch 77, training loss 0.566863, test_loss 0.821328, accuracy = 0.735307/0.795385, f1 = 0.800143\n",
      "Confusion matrix:\n",
      "[[811  62  22  42]\n",
      " [ 24 460  71  45]\n",
      " [ 14  69 426  44]\n",
      " [ 12  25  40 130]]\n",
      "Epoch 78, step 0, training loss 0.710385, test_loss 0.830086, accuracy = 0.720505/0.795385, f1 = 0.800143\n",
      "Epoch 78, step 25, training loss 0.542097, test_loss 0.829649, accuracy = 0.719634/0.794950, f1 = 0.799481\n",
      "Epoch 78, step 50, training loss 0.619716, test_loss 0.821756, accuracy = 0.723552/0.797562, f1 = 0.802108\n",
      "Epoch 78, step 75, training loss 0.690106, test_loss 0.831793, accuracy = 0.721811/0.800174, f1 = 0.803815\n",
      "Epoch 78, step 100, training loss 0.685153, test_loss 0.816450, accuracy = 0.725294/0.797997, f1 = 0.802567\n",
      "Epoch 78, step 125, training loss 0.565780, test_loss 0.831146, accuracy = 0.723988/0.798433, f1 = 0.803256\n",
      "Epoch 78, step 150, training loss 0.611915, test_loss 0.830706, accuracy = 0.729212/0.801480, f1 = 0.805678\n",
      "Epoch 78, step 175, training loss 0.680393, test_loss 0.831175, accuracy = 0.727471/0.799739, f1 = 0.803589\n",
      "Epoch 78, step 200, training loss 0.560990, test_loss 0.828676, accuracy = 0.721376/0.801916, f1 = 0.804825\n",
      "Epoch 78, step 225, training loss 0.527356, test_loss 0.836033, accuracy = 0.718764/0.799739, f1 = 0.803149\n",
      "Epoch 78, step 250, training loss 0.669946, test_loss 0.830572, accuracy = 0.727471/0.801916, f1 = 0.804985\n",
      "Epoch 78, step 275, training loss 0.613198, test_loss 0.825543, accuracy = 0.734001/0.804092, f1 = 0.807112\n",
      "Epoch 78, step 300, training loss 0.574041, test_loss 0.826895, accuracy = 0.726600/0.802786, f1 = 0.806172\n",
      "Epoch 78, step 325, training loss 0.787074, test_loss 0.831801, accuracy = 0.723117/0.799739, f1 = 0.803298\n",
      "Epoch 78, step 350, training loss 0.709367, test_loss 0.844474, accuracy = 0.710927/0.800174, f1 = 0.803505\n",
      "Epoch 78, step 375, training loss 0.816087, test_loss 0.841166, accuracy = 0.721811/0.796691, f1 = 0.801419\n",
      "Epoch 78, step 400, training loss 0.670343, test_loss 0.837119, accuracy = 0.720940/0.795385, f1 = 0.800604\n",
      "End of epoch 78, training loss 0.560210, test_loss 0.835048, accuracy = 0.718328/0.797127, f1 = 0.801447\n",
      "Confusion matrix:\n",
      "[[817  58  22  40]\n",
      " [ 31 458  67  44]\n",
      " [ 14  69 424  46]\n",
      " [ 12  25  38 132]]\n",
      "Epoch 79, step 0, training loss 0.575874, test_loss 0.830635, accuracy = 0.722246/0.797127, f1 = 0.801392\n",
      "Epoch 79, step 25, training loss 0.656848, test_loss 0.838612, accuracy = 0.711798/0.796691, f1 = 0.800427\n",
      "Epoch 79, step 50, training loss 0.684021, test_loss 0.828210, accuracy = 0.713104/0.795821, f1 = 0.799372\n",
      "Epoch 79, step 75, training loss 0.569257, test_loss 0.818442, accuracy = 0.724423/0.801480, f1 = 0.804760\n",
      "Epoch 79, step 100, training loss 0.604566, test_loss 0.809724, accuracy = 0.733566/0.801480, f1 = 0.804772\n",
      "Epoch 79, step 125, training loss 0.576690, test_loss 0.823503, accuracy = 0.719199/0.797562, f1 = 0.800725\n",
      "Epoch 79, step 150, training loss 0.637475, test_loss 0.821398, accuracy = 0.726600/0.801045, f1 = 0.804531\n",
      "Epoch 79, step 175, training loss 0.795328, test_loss 0.827999, accuracy = 0.721811/0.799739, f1 = 0.803083\n",
      "Epoch 79, step 200, training loss 0.571379, test_loss 0.822982, accuracy = 0.728341/0.801045, f1 = 0.803920\n",
      "Epoch 79, step 225, training loss 0.523077, test_loss 0.828211, accuracy = 0.723117/0.799739, f1 = 0.803010\n",
      "Epoch 79, step 250, training loss 0.610326, test_loss 0.833931, accuracy = 0.720070/0.801045, f1 = 0.804108\n",
      "Epoch 79, step 275, training loss 0.596259, test_loss 0.814220, accuracy = 0.734872/0.801045, f1 = 0.804659\n",
      "Epoch 79, step 300, training loss 0.596996, test_loss 0.834106, accuracy = 0.721376/0.798433, f1 = 0.802111\n",
      "Epoch 79, step 325, training loss 0.838418, test_loss 0.827059, accuracy = 0.720505/0.798868, f1 = 0.802346\n",
      "Epoch 79, step 350, training loss 0.707400, test_loss 0.817007, accuracy = 0.721811/0.799739, f1 = 0.803136\n",
      "Epoch 79, step 375, training loss 0.740420, test_loss 0.820412, accuracy = 0.720070/0.796691, f1 = 0.800556\n",
      "Epoch 79, step 400, training loss 0.629898, test_loss 0.830634, accuracy = 0.720505/0.792773, f1 = 0.797294\n",
      "End of epoch 79, training loss 0.641925, test_loss 0.825456, accuracy = 0.729212/0.793209, f1 = 0.797514\n",
      "Confusion matrix:\n",
      "[[821  52  21  43]\n",
      " [ 34 449  69  48]\n",
      " [ 17  63 425  48]\n",
      " [ 17  23  40 127]]\n",
      "Epoch 80, step 0, training loss 0.639142, test_loss 0.830508, accuracy = 0.725294/0.794079, f1 = 0.798395\n",
      "Epoch 80, step 25, training loss 0.616877, test_loss 0.828308, accuracy = 0.726600/0.798868, f1 = 0.803035\n",
      "Epoch 80, step 50, training loss 0.591181, test_loss 0.819272, accuracy = 0.728341/0.801045, f1 = 0.804540\n",
      "Epoch 80, step 75, training loss 0.659041, test_loss 0.824127, accuracy = 0.711363/0.801045, f1 = 0.804467\n",
      "Epoch 80, step 100, training loss 0.607426, test_loss 0.821181, accuracy = 0.729647/0.797127, f1 = 0.801682\n",
      "Epoch 80, step 125, training loss 0.538177, test_loss 0.819016, accuracy = 0.733130/0.796256, f1 = 0.801488\n",
      "Epoch 80, step 150, training loss 0.656694, test_loss 0.814109, accuracy = 0.731389/0.796691, f1 = 0.801498\n",
      "Epoch 80, step 175, training loss 0.767158, test_loss 0.830804, accuracy = 0.727035/0.798868, f1 = 0.803512\n",
      "Epoch 80, step 200, training loss 0.574180, test_loss 0.822107, accuracy = 0.727035/0.800174, f1 = 0.804056\n",
      "Epoch 80, step 225, training loss 0.534287, test_loss 0.814019, accuracy = 0.725294/0.802786, f1 = 0.806575\n",
      "Epoch 80, step 250, training loss 0.660222, test_loss 0.813251, accuracy = 0.735307/0.801480, f1 = 0.804877\n",
      "Epoch 80, step 275, training loss 0.643903, test_loss 0.814230, accuracy = 0.725729/0.801480, f1 = 0.804513\n",
      "Epoch 80, step 300, training loss 0.592798, test_loss 0.827112, accuracy = 0.723552/0.801045, f1 = 0.804503\n",
      "Epoch 80, step 325, training loss 0.749886, test_loss 0.829264, accuracy = 0.725729/0.800174, f1 = 0.804046\n",
      "Epoch 80, step 350, training loss 0.693506, test_loss 0.837047, accuracy = 0.722682/0.798868, f1 = 0.802687\n",
      "Epoch 80, step 375, training loss 0.721079, test_loss 0.841138, accuracy = 0.717022/0.796256, f1 = 0.801401\n",
      "Epoch 80, step 400, training loss 0.670794, test_loss 0.830277, accuracy = 0.722246/0.799303, f1 = 0.803903\n",
      "End of epoch 80, training loss 0.642634, test_loss 0.837754, accuracy = 0.708751/0.799303, f1 = 0.803756\n",
      "Confusion matrix:\n",
      "[[819  53  20  45]\n",
      " [ 33 454  68  45]\n",
      " [ 15  65 428  45]\n",
      " [ 12  23  37 135]]\n",
      "Epoch 81, step 0, training loss 0.581956, test_loss 0.828739, accuracy = 0.723988/0.799303, f1 = 0.803756\n",
      "Epoch 81, step 25, training loss 0.638586, test_loss 0.831689, accuracy = 0.716151/0.797127, f1 = 0.801486\n",
      "Epoch 81, step 50, training loss 0.528087, test_loss 0.827302, accuracy = 0.720505/0.799303, f1 = 0.803379\n",
      "Epoch 81, step 75, training loss 0.608399, test_loss 0.816335, accuracy = 0.730953/0.802351, f1 = 0.805368\n",
      "Epoch 81, step 100, training loss 0.634215, test_loss 0.807647, accuracy = 0.731824/0.802351, f1 = 0.805746\n",
      "Epoch 81, step 125, training loss 0.546101, test_loss 0.822076, accuracy = 0.730083/0.802351, f1 = 0.805941\n",
      "Epoch 81, step 150, training loss 0.636408, test_loss 0.830864, accuracy = 0.722246/0.801916, f1 = 0.805731\n",
      "Epoch 81, step 175, training loss 0.730620, test_loss 0.846889, accuracy = 0.712669/0.798433, f1 = 0.802118\n",
      "Epoch 81, step 200, training loss 0.570075, test_loss 0.824512, accuracy = 0.722682/0.807140, f1 = 0.809543\n",
      "Epoch 81, step 225, training loss 0.584880, test_loss 0.824333, accuracy = 0.725729/0.803657, f1 = 0.806253\n",
      "Epoch 81, step 250, training loss 0.692914, test_loss 0.812764, accuracy = 0.729647/0.804528, f1 = 0.807070\n",
      "Epoch 81, step 275, training loss 0.678539, test_loss 0.833740, accuracy = 0.718328/0.801480, f1 = 0.804514\n",
      "Epoch 81, step 300, training loss 0.553733, test_loss 0.827688, accuracy = 0.723117/0.801916, f1 = 0.805430\n",
      "Epoch 81, step 325, training loss 0.585358, test_loss 0.829384, accuracy = 0.724859/0.799739, f1 = 0.803506\n",
      "Epoch 81, step 350, training loss 0.616562, test_loss 0.844807, accuracy = 0.717893/0.801045, f1 = 0.804378\n",
      "Epoch 81, step 375, training loss 0.774335, test_loss 0.828746, accuracy = 0.728341/0.797997, f1 = 0.802222\n",
      "Epoch 81, step 400, training loss 0.643776, test_loss 0.842332, accuracy = 0.713975/0.795821, f1 = 0.800435\n",
      "End of epoch 81, training loss 0.681802, test_loss 0.827063, accuracy = 0.713975/0.796256, f1 = 0.800177\n",
      "Confusion matrix:\n",
      "[[825  50  22  40]\n",
      " [ 34 444  73  49]\n",
      " [ 14  62 433  44]\n",
      " [ 16  23  41 127]]\n",
      "Epoch 82, step 0, training loss 0.573703, test_loss 0.824521, accuracy = 0.726600/0.796691, f1 = 0.800451\n",
      "Epoch 82, step 25, training loss 0.618928, test_loss 0.840414, accuracy = 0.725294/0.795821, f1 = 0.799362\n",
      "Epoch 82, step 50, training loss 0.641943, test_loss 0.830997, accuracy = 0.720940/0.799739, f1 = 0.802768\n",
      "Epoch 82, step 75, training loss 0.595369, test_loss 0.821388, accuracy = 0.727035/0.802786, f1 = 0.805616\n",
      "Epoch 82, step 100, training loss 0.650291, test_loss 0.821608, accuracy = 0.725729/0.798433, f1 = 0.802041\n",
      "Epoch 82, step 125, training loss 0.578588, test_loss 0.835113, accuracy = 0.727471/0.792773, f1 = 0.797172\n",
      "Epoch 82, step 150, training loss 0.610837, test_loss 0.818797, accuracy = 0.728777/0.795385, f1 = 0.799714\n",
      "Epoch 82, step 175, training loss 0.736928, test_loss 0.821175, accuracy = 0.718328/0.796256, f1 = 0.800225\n",
      "Epoch 82, step 200, training loss 0.611999, test_loss 0.828419, accuracy = 0.723553/0.799303, f1 = 0.802711\n",
      "Epoch 82, step 225, training loss 0.556650, test_loss 0.826122, accuracy = 0.728341/0.798868, f1 = 0.802041\n",
      "Epoch 82, step 250, training loss 0.644357, test_loss 0.827667, accuracy = 0.723552/0.799739, f1 = 0.802808\n",
      "Epoch 82, step 275, training loss 0.640811, test_loss 0.811651, accuracy = 0.729212/0.804092, f1 = 0.807579\n",
      "Epoch 82, step 300, training loss 0.665154, test_loss 0.829152, accuracy = 0.714846/0.800610, f1 = 0.804516\n",
      "Epoch 82, step 325, training loss 0.714052, test_loss 0.830669, accuracy = 0.717893/0.802786, f1 = 0.806168\n",
      "Epoch 82, step 350, training loss 0.688428, test_loss 0.831508, accuracy = 0.718328/0.800610, f1 = 0.803085\n",
      "Epoch 82, step 375, training loss 0.742039, test_loss 0.820725, accuracy = 0.723553/0.797997, f1 = 0.801472\n",
      "Epoch 82, step 400, training loss 0.724067, test_loss 0.823958, accuracy = 0.721811/0.794950, f1 = 0.798658\n",
      "End of epoch 82, training loss 0.612281, test_loss 0.842559, accuracy = 0.715716/0.794079, f1 = 0.797687\n",
      "Confusion matrix:\n",
      "[[828  50  22  37]\n",
      " [ 34 443  73  50]\n",
      " [ 17  61 429  46]\n",
      " [ 19  23  41 124]]\n",
      "Epoch 83, step 0, training loss 0.634780, test_loss 0.825410, accuracy = 0.722246/0.793644, f1 = 0.797297\n",
      "Epoch 83, step 25, training loss 0.566606, test_loss 0.835160, accuracy = 0.714845/0.795385, f1 = 0.799474\n",
      "Epoch 83, step 50, training loss 0.649555, test_loss 0.832596, accuracy = 0.724423/0.794079, f1 = 0.797883\n",
      "Epoch 83, step 75, training loss 0.632688, test_loss 0.821003, accuracy = 0.731824/0.798868, f1 = 0.801984\n",
      "Epoch 83, step 100, training loss 0.614936, test_loss 0.817021, accuracy = 0.727035/0.799303, f1 = 0.802438\n",
      "Epoch 83, step 125, training loss 0.593273, test_loss 0.817573, accuracy = 0.726600/0.796691, f1 = 0.800196\n",
      "Epoch 83, step 150, training loss 0.663297, test_loss 0.833261, accuracy = 0.726600/0.796256, f1 = 0.800586\n",
      "Epoch 83, step 175, training loss 0.703249, test_loss 0.825445, accuracy = 0.725294/0.796256, f1 = 0.800229\n",
      "Epoch 83, step 200, training loss 0.564767, test_loss 0.825194, accuracy = 0.727906/0.802351, f1 = 0.805319\n",
      "Epoch 83, step 225, training loss 0.505680, test_loss 0.829159, accuracy = 0.725294/0.798433, f1 = 0.801370\n",
      "Epoch 83, step 250, training loss 0.655836, test_loss 0.825382, accuracy = 0.721376/0.798868, f1 = 0.801169\n",
      "Epoch 83, step 275, training loss 0.608801, test_loss 0.828671, accuracy = 0.727906/0.801045, f1 = 0.803818\n",
      "Epoch 83, step 300, training loss 0.678730, test_loss 0.829327, accuracy = 0.713539/0.801480, f1 = 0.804698\n",
      "Epoch 83, step 325, training loss 0.764966, test_loss 0.828132, accuracy = 0.722246/0.800174, f1 = 0.803003\n",
      "Epoch 83, step 350, training loss 0.686821, test_loss 0.837220, accuracy = 0.721811/0.800174, f1 = 0.803120\n",
      "Epoch 83, step 375, training loss 0.728949, test_loss 0.840305, accuracy = 0.717893/0.798433, f1 = 0.802441\n",
      "Epoch 83, step 400, training loss 0.673475, test_loss 0.829520, accuracy = 0.722246/0.799739, f1 = 0.803696\n",
      "End of epoch 83, training loss 0.596625, test_loss 0.818652, accuracy = 0.722246/0.796256, f1 = 0.800428\n",
      "Confusion matrix:\n",
      "[[823  51  24  39]\n",
      " [ 30 445  75  50]\n",
      " [ 16  60 433  44]\n",
      " [ 13  25  41 128]]\n",
      "Epoch 84, step 0, training loss 0.578539, test_loss 0.823435, accuracy = 0.729647/0.797562, f1 = 0.801731\n",
      "Epoch 84, step 25, training loss 0.646401, test_loss 0.818660, accuracy = 0.724859/0.791467, f1 = 0.795961\n",
      "Epoch 84, step 50, training loss 0.581219, test_loss 0.820331, accuracy = 0.722246/0.795821, f1 = 0.799802\n",
      "Epoch 84, step 75, training loss 0.622689, test_loss 0.815525, accuracy = 0.724859/0.798433, f1 = 0.802358\n",
      "Epoch 84, step 100, training loss 0.672716, test_loss 0.810049, accuracy = 0.728341/0.797562, f1 = 0.801611\n",
      "Epoch 84, step 125, training loss 0.546960, test_loss 0.828375, accuracy = 0.723988/0.797562, f1 = 0.801858\n",
      "Epoch 84, step 150, training loss 0.663466, test_loss 0.828811, accuracy = 0.727906/0.796691, f1 = 0.801768\n",
      "Epoch 84, step 175, training loss 0.742346, test_loss 0.829452, accuracy = 0.719634/0.798433, f1 = 0.803156\n",
      "Epoch 84, step 200, training loss 0.526986, test_loss 0.834048, accuracy = 0.714846/0.799739, f1 = 0.802775\n",
      "Epoch 84, step 225, training loss 0.529532, test_loss 0.816043, accuracy = 0.726165/0.796691, f1 = 0.800018\n",
      "Epoch 84, step 250, training loss 0.630709, test_loss 0.820772, accuracy = 0.719634/0.800174, f1 = 0.803268\n",
      "Epoch 84, step 275, training loss 0.592260, test_loss 0.831469, accuracy = 0.721376/0.796691, f1 = 0.800290\n",
      "Epoch 84, step 300, training loss 0.647417, test_loss 0.830250, accuracy = 0.723988/0.797562, f1 = 0.800955\n",
      "Epoch 84, step 325, training loss 0.695429, test_loss 0.821006, accuracy = 0.727035/0.800174, f1 = 0.803395\n",
      "Epoch 84, step 350, training loss 0.643910, test_loss 0.834150, accuracy = 0.718764/0.796256, f1 = 0.799587\n",
      "Epoch 84, step 375, training loss 0.677128, test_loss 0.833972, accuracy = 0.720505/0.794079, f1 = 0.798026\n",
      "Epoch 84, step 400, training loss 0.691192, test_loss 0.838404, accuracy = 0.714410/0.794515, f1 = 0.798724\n",
      "End of epoch 84, training loss 0.570609, test_loss 0.832482, accuracy = 0.719199/0.796256, f1 = 0.800471\n",
      "Confusion matrix:\n",
      "[[822  54  23  38]\n",
      " [ 30 449  72  49]\n",
      " [ 16  60 430  47]\n",
      " [ 15  23  41 128]]\n",
      "Epoch 85, step 0, training loss 0.621370, test_loss 0.825982, accuracy = 0.721376/0.796256, f1 = 0.800388\n",
      "Epoch 85, step 25, training loss 0.612253, test_loss 0.836222, accuracy = 0.722682/0.794079, f1 = 0.798462\n",
      "Epoch 85, step 50, training loss 0.641118, test_loss 0.829184, accuracy = 0.717893/0.796691, f1 = 0.800422\n",
      "Epoch 85, step 75, training loss 0.629896, test_loss 0.819998, accuracy = 0.730083/0.804092, f1 = 0.806937\n",
      "Epoch 85, step 100, training loss 0.679801, test_loss 0.821894, accuracy = 0.725294/0.801916, f1 = 0.805484\n",
      "Epoch 85, step 125, training loss 0.669587, test_loss 0.830046, accuracy = 0.720940/0.797997, f1 = 0.802209\n",
      "Epoch 85, step 150, training loss 0.616205, test_loss 0.828245, accuracy = 0.723117/0.798433, f1 = 0.802429\n",
      "Epoch 85, step 175, training loss 0.796925, test_loss 0.826213, accuracy = 0.724859/0.798433, f1 = 0.801821\n",
      "Epoch 85, step 200, training loss 0.581470, test_loss 0.826177, accuracy = 0.734872/0.802351, f1 = 0.804924\n",
      "Epoch 85, step 225, training loss 0.600000, test_loss 0.832709, accuracy = 0.725729/0.798868, f1 = 0.802426\n",
      "Epoch 85, step 250, training loss 0.604319, test_loss 0.823479, accuracy = 0.720940/0.799739, f1 = 0.803278\n",
      "Epoch 85, step 275, training loss 0.624921, test_loss 0.811430, accuracy = 0.732695/0.797127, f1 = 0.801023\n",
      "Epoch 85, step 300, training loss 0.568731, test_loss 0.812501, accuracy = 0.725294/0.794950, f1 = 0.799240\n",
      "Epoch 85, step 325, training loss 0.694332, test_loss 0.831904, accuracy = 0.717893/0.801045, f1 = 0.804449\n",
      "Epoch 85, step 350, training loss 0.684441, test_loss 0.837156, accuracy = 0.722246/0.801480, f1 = 0.804275\n",
      "Epoch 85, step 375, training loss 0.771649, test_loss 0.826927, accuracy = 0.721811/0.796691, f1 = 0.800641\n",
      "Epoch 85, step 400, training loss 0.731380, test_loss 0.821744, accuracy = 0.724859/0.800174, f1 = 0.803979\n",
      "End of epoch 85, training loss 0.552625, test_loss 0.829330, accuracy = 0.722246/0.800174, f1 = 0.803977\n",
      "Confusion matrix:\n",
      "[[818  58  24  37]\n",
      " [ 28 453  76  43]\n",
      " [ 14  62 437  40]\n",
      " [ 11  22  44 130]]\n",
      "Epoch 86, step 0, training loss 0.603064, test_loss 0.832022, accuracy = 0.724859/0.800174, f1 = 0.804009\n",
      "Epoch 86, step 25, training loss 0.636186, test_loss 0.834765, accuracy = 0.712233/0.798433, f1 = 0.802867\n",
      "Epoch 86, step 50, training loss 0.621296, test_loss 0.817491, accuracy = 0.723988/0.798433, f1 = 0.802850\n",
      "Epoch 86, step 75, training loss 0.598091, test_loss 0.828908, accuracy = 0.732260/0.802786, f1 = 0.806543\n",
      "Epoch 86, step 100, training loss 0.642806, test_loss 0.820969, accuracy = 0.729212/0.802351, f1 = 0.806505\n",
      "Epoch 86, step 125, training loss 0.535676, test_loss 0.828854, accuracy = 0.730953/0.797997, f1 = 0.803235\n",
      "Epoch 86, step 150, training loss 0.668847, test_loss 0.806457, accuracy = 0.733566/0.797562, f1 = 0.802462\n",
      "Epoch 86, step 175, training loss 0.776483, test_loss 0.830533, accuracy = 0.723988/0.797562, f1 = 0.801631\n",
      "Epoch 86, step 200, training loss 0.608921, test_loss 0.810743, accuracy = 0.733130/0.800610, f1 = 0.803994\n",
      "Epoch 86, step 225, training loss 0.577193, test_loss 0.833191, accuracy = 0.732260/0.800174, f1 = 0.804222\n",
      "Epoch 86, step 250, training loss 0.655356, test_loss 0.831148, accuracy = 0.728341/0.801916, f1 = 0.805483\n",
      "Epoch 86, step 275, training loss 0.603151, test_loss 0.816337, accuracy = 0.727906/0.802786, f1 = 0.806386\n",
      "Epoch 86, step 300, training loss 0.712325, test_loss 0.821727, accuracy = 0.723117/0.800174, f1 = 0.804026\n",
      "Epoch 86, step 325, training loss 0.718088, test_loss 0.826414, accuracy = 0.720505/0.800610, f1 = 0.804183\n",
      "Epoch 86, step 350, training loss 0.672069, test_loss 0.821886, accuracy = 0.717022/0.803222, f1 = 0.805838\n",
      "Epoch 86, step 375, training loss 0.734797, test_loss 0.823153, accuracy = 0.727471/0.798433, f1 = 0.802075\n",
      "Epoch 86, step 400, training loss 0.630941, test_loss 0.817126, accuracy = 0.732260/0.800610, f1 = 0.804865\n",
      "End of epoch 86, training loss 0.559403, test_loss 0.838935, accuracy = 0.714845/0.801916, f1 = 0.806498\n",
      "Confusion matrix:\n",
      "[[817  59  21  40]\n",
      " [ 25 463  68  44]\n",
      " [ 13  63 431  46]\n",
      " [ 11  26  39 131]]\n",
      "Epoch 87, step 0, training loss 0.634962, test_loss 0.848470, accuracy = 0.710057/0.801916, f1 = 0.806498\n",
      "Epoch 87, step 25, training loss 0.591241, test_loss 0.845627, accuracy = 0.717022/0.798868, f1 = 0.803652\n",
      "Epoch 87, step 50, training loss 0.609464, test_loss 0.831994, accuracy = 0.719199/0.799739, f1 = 0.803837\n",
      "Epoch 87, step 75, training loss 0.550853, test_loss 0.819992, accuracy = 0.713539/0.803657, f1 = 0.806881\n",
      "Epoch 87, step 100, training loss 0.718724, test_loss 0.817293, accuracy = 0.732695/0.802351, f1 = 0.806280\n",
      "Epoch 87, step 125, training loss 0.610079, test_loss 0.820323, accuracy = 0.724859/0.798433, f1 = 0.802961\n",
      "Epoch 87, step 150, training loss 0.669875, test_loss 0.834733, accuracy = 0.726165/0.797997, f1 = 0.802451\n",
      "Epoch 87, step 175, training loss 0.694313, test_loss 0.812201, accuracy = 0.738790/0.801045, f1 = 0.804876\n",
      "Epoch 87, step 200, training loss 0.592406, test_loss 0.828742, accuracy = 0.725294/0.801045, f1 = 0.804366\n",
      "Epoch 87, step 225, training loss 0.500036, test_loss 0.807790, accuracy = 0.722247/0.799739, f1 = 0.803168\n",
      "Epoch 87, step 250, training loss 0.648369, test_loss 0.827382, accuracy = 0.719199/0.802786, f1 = 0.806346\n",
      "Epoch 87, step 275, training loss 0.576329, test_loss 0.818393, accuracy = 0.732695/0.803222, f1 = 0.806897\n",
      "Epoch 87, step 300, training loss 0.626066, test_loss 0.824455, accuracy = 0.722246/0.802786, f1 = 0.806536\n",
      "Epoch 87, step 325, training loss 0.686074, test_loss 0.826536, accuracy = 0.732260/0.801916, f1 = 0.805329\n",
      "Epoch 87, step 350, training loss 0.695369, test_loss 0.826611, accuracy = 0.716587/0.800174, f1 = 0.803060\n",
      "Epoch 87, step 375, training loss 0.747065, test_loss 0.830940, accuracy = 0.724859/0.797127, f1 = 0.801129\n",
      "Epoch 87, step 400, training loss 0.668323, test_loss 0.823241, accuracy = 0.723117/0.796256, f1 = 0.800482\n",
      "End of epoch 87, training loss 0.558869, test_loss 0.815409, accuracy = 0.731389/0.796256, f1 = 0.800297\n",
      "Confusion matrix:\n",
      "[[821  54  23  39]\n",
      " [ 32 451  67  50]\n",
      " [ 16  64 430  43]\n",
      " [ 15  24  41 127]]\n",
      "Epoch 88, step 0, training loss 0.606758, test_loss 0.822573, accuracy = 0.723988/0.796256, f1 = 0.800297\n",
      "Epoch 88, step 25, training loss 0.638332, test_loss 0.830209, accuracy = 0.720940/0.793209, f1 = 0.798407\n",
      "Epoch 88, step 50, training loss 0.554636, test_loss 0.828078, accuracy = 0.723117/0.799303, f1 = 0.803025\n",
      "Epoch 88, step 75, training loss 0.507789, test_loss 0.813100, accuracy = 0.732695/0.801916, f1 = 0.804786\n",
      "Epoch 88, step 100, training loss 0.622600, test_loss 0.816051, accuracy = 0.721376/0.801480, f1 = 0.804777\n",
      "Epoch 88, step 125, training loss 0.571028, test_loss 0.820399, accuracy = 0.726165/0.797997, f1 = 0.802347\n",
      "Epoch 88, step 150, training loss 0.694912, test_loss 0.833952, accuracy = 0.722682/0.796691, f1 = 0.801223\n",
      "Epoch 88, step 175, training loss 0.739214, test_loss 0.832608, accuracy = 0.717022/0.799739, f1 = 0.804163\n",
      "Epoch 88, step 200, training loss 0.622742, test_loss 0.823704, accuracy = 0.717022/0.799303, f1 = 0.803088\n",
      "Epoch 88, step 225, training loss 0.515765, test_loss 0.818394, accuracy = 0.729647/0.797562, f1 = 0.801390\n",
      "Epoch 88, step 250, training loss 0.639902, test_loss 0.829597, accuracy = 0.723988/0.797127, f1 = 0.800274\n",
      "Epoch 88, step 275, training loss 0.620840, test_loss 0.835523, accuracy = 0.717458/0.798868, f1 = 0.802531\n",
      "Epoch 88, step 300, training loss 0.613713, test_loss 0.837422, accuracy = 0.723988/0.800174, f1 = 0.803731\n",
      "Epoch 88, step 325, training loss 0.693340, test_loss 0.837543, accuracy = 0.720505/0.798868, f1 = 0.802633\n",
      "Epoch 88, step 350, training loss 0.635640, test_loss 0.828770, accuracy = 0.723117/0.799303, f1 = 0.802266\n",
      "Epoch 88, step 375, training loss 0.698556, test_loss 0.830342, accuracy = 0.710927/0.797127, f1 = 0.801149\n",
      "Epoch 88, step 400, training loss 0.644609, test_loss 0.833210, accuracy = 0.720505/0.794950, f1 = 0.798496\n",
      "End of epoch 88, training loss 0.553752, test_loss 0.832241, accuracy = 0.727035/0.797127, f1 = 0.800529\n",
      "Confusion matrix:\n",
      "[[820  57  25  35]\n",
      " [ 31 455  69  45]\n",
      " [ 15  68 430  40]\n",
      " [ 16  22  43 126]]\n",
      "Epoch 89, step 0, training loss 0.613627, test_loss 0.842087, accuracy = 0.716152/0.796691, f1 = 0.800003\n",
      "Epoch 89, step 25, training loss 0.646323, test_loss 0.839430, accuracy = 0.721376/0.794950, f1 = 0.798175\n",
      "Epoch 89, step 50, training loss 0.590095, test_loss 0.831092, accuracy = 0.730518/0.795385, f1 = 0.798485\n",
      "Epoch 89, step 75, training loss 0.645497, test_loss 0.813020, accuracy = 0.730953/0.798868, f1 = 0.802257\n",
      "Epoch 89, step 100, training loss 0.692444, test_loss 0.814682, accuracy = 0.722246/0.801480, f1 = 0.805454\n",
      "Epoch 89, step 125, training loss 0.585081, test_loss 0.814405, accuracy = 0.734436/0.796256, f1 = 0.800507\n",
      "Epoch 89, step 150, training loss 0.600241, test_loss 0.813629, accuracy = 0.726600/0.798868, f1 = 0.803182\n",
      "Epoch 89, step 175, training loss 0.754119, test_loss 0.823611, accuracy = 0.732259/0.798433, f1 = 0.802796\n",
      "Epoch 89, step 200, training loss 0.532220, test_loss 0.815287, accuracy = 0.732695/0.800174, f1 = 0.804217\n",
      "Epoch 89, step 225, training loss 0.626345, test_loss 0.831278, accuracy = 0.721811/0.799739, f1 = 0.803841\n",
      "Epoch 89, step 250, training loss 0.622508, test_loss 0.812955, accuracy = 0.735742/0.801480, f1 = 0.804684\n",
      "Epoch 89, step 275, training loss 0.569944, test_loss 0.829230, accuracy = 0.721376/0.804092, f1 = 0.807381\n",
      "Epoch 89, step 300, training loss 0.569721, test_loss 0.830202, accuracy = 0.720070/0.801916, f1 = 0.805233\n",
      "Epoch 89, step 325, training loss 0.662678, test_loss 0.832510, accuracy = 0.718764/0.801480, f1 = 0.804456\n",
      "Epoch 89, step 350, training loss 0.657275, test_loss 0.839343, accuracy = 0.711363/0.801480, f1 = 0.804322\n",
      "Epoch 89, step 375, training loss 0.799696, test_loss 0.837670, accuracy = 0.722246/0.794950, f1 = 0.799351\n",
      "Epoch 89, step 400, training loss 0.696545, test_loss 0.842108, accuracy = 0.721811/0.794079, f1 = 0.798478\n",
      "End of epoch 89, training loss 0.581906, test_loss 0.836948, accuracy = 0.716151/0.794079, f1 = 0.798457\n",
      "Confusion matrix:\n",
      "[[822  53  20  42]\n",
      " [ 32 444  72  52]\n",
      " [ 16  61 431  45]\n",
      " [ 16  21  43 127]]\n",
      "Epoch 90, step 0, training loss 0.679641, test_loss 0.830738, accuracy = 0.717458/0.793209, f1 = 0.797535\n",
      "Epoch 90, step 25, training loss 0.580340, test_loss 0.834733, accuracy = 0.717893/0.795385, f1 = 0.799890\n",
      "Epoch 90, step 50, training loss 0.662905, test_loss 0.833839, accuracy = 0.729212/0.797127, f1 = 0.801483\n",
      "Epoch 90, step 75, training loss 0.631184, test_loss 0.815056, accuracy = 0.735742/0.797127, f1 = 0.801447\n",
      "Epoch 90, step 100, training loss 0.708366, test_loss 0.797768, accuracy = 0.734872/0.797127, f1 = 0.802055\n",
      "Epoch 90, step 125, training loss 0.545736, test_loss 0.820750, accuracy = 0.730518/0.797127, f1 = 0.802195\n",
      "Epoch 90, step 150, training loss 0.626077, test_loss 0.831209, accuracy = 0.717458/0.796256, f1 = 0.801109\n",
      "Epoch 90, step 175, training loss 0.764831, test_loss 0.829095, accuracy = 0.727906/0.797127, f1 = 0.800978\n",
      "Epoch 90, step 200, training loss 0.544857, test_loss 0.822381, accuracy = 0.726165/0.805398, f1 = 0.808006\n",
      "Epoch 90, step 225, training loss 0.486546, test_loss 0.832563, accuracy = 0.724423/0.800174, f1 = 0.803442\n",
      "Epoch 90, step 250, training loss 0.695537, test_loss 0.827694, accuracy = 0.720070/0.800610, f1 = 0.804166\n",
      "Epoch 90, step 275, training loss 0.632091, test_loss 0.813952, accuracy = 0.728777/0.802351, f1 = 0.806014\n",
      "Epoch 90, step 300, training loss 0.637253, test_loss 0.825283, accuracy = 0.728341/0.801045, f1 = 0.804936\n",
      "Epoch 90, step 325, training loss 0.710023, test_loss 0.839072, accuracy = 0.712669/0.800174, f1 = 0.804092\n",
      "Epoch 90, step 350, training loss 0.668383, test_loss 0.837174, accuracy = 0.716587/0.798433, f1 = 0.802075\n",
      "Epoch 90, step 375, training loss 0.665089, test_loss 0.829774, accuracy = 0.719634/0.795385, f1 = 0.800367\n",
      "Epoch 90, step 400, training loss 0.730019, test_loss 0.825082, accuracy = 0.715281/0.795385, f1 = 0.799995\n",
      "End of epoch 90, training loss 0.542038, test_loss 0.822728, accuracy = 0.718764/0.797127, f1 = 0.801365\n",
      "Confusion matrix:\n",
      "[[820  55  22  40]\n",
      " [ 29 457  67  47]\n",
      " [ 16  68 425  44]\n",
      " [ 13  25  40 129]]\n",
      "Epoch 91, step 0, training loss 0.605456, test_loss 0.836404, accuracy = 0.713975/0.797127, f1 = 0.801465\n",
      "Epoch 91, step 25, training loss 0.592846, test_loss 0.848791, accuracy = 0.710057/0.795821, f1 = 0.800450\n",
      "Epoch 91, step 50, training loss 0.606656, test_loss 0.826342, accuracy = 0.723988/0.799739, f1 = 0.804358\n",
      "Epoch 91, step 75, training loss 0.634524, test_loss 0.815941, accuracy = 0.721376/0.797562, f1 = 0.801588\n",
      "Epoch 91, step 100, training loss 0.651507, test_loss 0.812934, accuracy = 0.728341/0.797127, f1 = 0.801532\n",
      "Epoch 91, step 125, training loss 0.582710, test_loss 0.835754, accuracy = 0.711798/0.794515, f1 = 0.799412\n",
      "Epoch 91, step 150, training loss 0.659021, test_loss 0.827417, accuracy = 0.733566/0.796256, f1 = 0.800271\n",
      "Epoch 91, step 175, training loss 0.755122, test_loss 0.828041, accuracy = 0.731824/0.794515, f1 = 0.799076\n",
      "Epoch 91, step 200, training loss 0.550420, test_loss 0.818234, accuracy = 0.723117/0.797562, f1 = 0.801317\n",
      "Epoch 91, step 225, training loss 0.598781, test_loss 0.824697, accuracy = 0.734001/0.795821, f1 = 0.799282\n",
      "Epoch 91, step 250, training loss 0.628319, test_loss 0.822854, accuracy = 0.732260/0.801480, f1 = 0.804378\n",
      "Epoch 91, step 275, training loss 0.644895, test_loss 0.830867, accuracy = 0.723117/0.799303, f1 = 0.803056\n",
      "Epoch 91, step 300, training loss 0.686986, test_loss 0.835127, accuracy = 0.714410/0.797997, f1 = 0.801970\n",
      "Epoch 91, step 325, training loss 0.688580, test_loss 0.828400, accuracy = 0.716587/0.797127, f1 = 0.801441\n",
      "Epoch 91, step 350, training loss 0.660083, test_loss 0.842745, accuracy = 0.712669/0.799303, f1 = 0.803054\n",
      "Epoch 91, step 375, training loss 0.748385, test_loss 0.842143, accuracy = 0.706138/0.796256, f1 = 0.800814\n",
      "Epoch 91, step 400, training loss 0.722057, test_loss 0.833068, accuracy = 0.718764/0.795385, f1 = 0.799399\n",
      "End of epoch 91, training loss 0.604733, test_loss 0.842176, accuracy = 0.716152/0.794079, f1 = 0.798122\n",
      "Confusion matrix:\n",
      "[[826  52  20  39]\n",
      " [ 34 448  68  50]\n",
      " [ 16  68 423  46]\n",
      " [ 15  25  40 127]]\n",
      "Epoch 92, step 0, training loss 0.585897, test_loss 0.833035, accuracy = 0.721811/0.794079, f1 = 0.798187\n",
      "Epoch 92, step 25, training loss 0.629055, test_loss 0.830177, accuracy = 0.721376/0.796691, f1 = 0.801096\n",
      "Epoch 92, step 50, training loss 0.637420, test_loss 0.841582, accuracy = 0.713975/0.797127, f1 = 0.801174\n",
      "Epoch 92, step 75, training loss 0.594255, test_loss 0.836541, accuracy = 0.720070/0.800174, f1 = 0.803794\n",
      "Epoch 92, step 100, training loss 0.671544, test_loss 0.834279, accuracy = 0.722246/0.799303, f1 = 0.802785\n",
      "Epoch 92, step 125, training loss 0.557684, test_loss 0.828504, accuracy = 0.723552/0.796691, f1 = 0.800667\n",
      "Epoch 92, step 150, training loss 0.655292, test_loss 0.819140, accuracy = 0.726165/0.797127, f1 = 0.801863\n",
      "Epoch 92, step 175, training loss 0.756664, test_loss 0.834483, accuracy = 0.720940/0.795385, f1 = 0.799976\n",
      "Epoch 92, step 200, training loss 0.589541, test_loss 0.827090, accuracy = 0.723988/0.799739, f1 = 0.803698\n",
      "Epoch 92, step 225, training loss 0.505183, test_loss 0.825652, accuracy = 0.726600/0.798433, f1 = 0.802628\n",
      "Epoch 92, step 250, training loss 0.677289, test_loss 0.830234, accuracy = 0.725729/0.799303, f1 = 0.803732\n",
      "Epoch 92, step 275, training loss 0.629447, test_loss 0.818568, accuracy = 0.735742/0.797562, f1 = 0.801991\n",
      "Epoch 92, step 300, training loss 0.569219, test_loss 0.828263, accuracy = 0.722682/0.796256, f1 = 0.801021\n",
      "Epoch 92, step 325, training loss 0.668586, test_loss 0.819551, accuracy = 0.732695/0.794950, f1 = 0.799383\n",
      "Epoch 92, step 350, training loss 0.693106, test_loss 0.834461, accuracy = 0.726600/0.797127, f1 = 0.800951\n",
      "Epoch 92, step 375, training loss 0.709502, test_loss 0.832172, accuracy = 0.722246/0.791032, f1 = 0.796452\n",
      "Epoch 92, step 400, training loss 0.669885, test_loss 0.837500, accuracy = 0.717893/0.792338, f1 = 0.797868\n",
      "End of epoch 92, training loss 0.667237, test_loss 0.836358, accuracy = 0.717022/0.793209, f1 = 0.798150\n",
      "Confusion matrix:\n",
      "[[818  53  21  45]\n",
      " [ 32 441  74  53]\n",
      " [ 14  62 432  45]\n",
      " [ 12  24  40 131]]\n",
      "Epoch 93, step 0, training loss 0.660411, test_loss 0.823884, accuracy = 0.725729/0.793644, f1 = 0.798466\n",
      "Epoch 93, step 25, training loss 0.531957, test_loss 0.827967, accuracy = 0.722682/0.794950, f1 = 0.800115\n",
      "Epoch 93, step 50, training loss 0.549474, test_loss 0.834339, accuracy = 0.719199/0.799303, f1 = 0.804072\n",
      "Epoch 93, step 75, training loss 0.585643, test_loss 0.805153, accuracy = 0.728777/0.801045, f1 = 0.804283\n",
      "Epoch 93, step 100, training loss 0.668525, test_loss 0.812663, accuracy = 0.731389/0.799739, f1 = 0.803619\n",
      "Epoch 93, step 125, training loss 0.575313, test_loss 0.819916, accuracy = 0.725729/0.799739, f1 = 0.803874\n",
      "Epoch 93, step 150, training loss 0.642440, test_loss 0.817941, accuracy = 0.724423/0.801045, f1 = 0.805257\n",
      "Epoch 93, step 175, training loss 0.744610, test_loss 0.822704, accuracy = 0.724859/0.797127, f1 = 0.801497\n",
      "Epoch 93, step 200, training loss 0.562785, test_loss 0.822812, accuracy = 0.717893/0.800174, f1 = 0.804045\n",
      "Epoch 93, step 225, training loss 0.546286, test_loss 0.827957, accuracy = 0.726165/0.799303, f1 = 0.803399\n",
      "Epoch 93, step 250, training loss 0.698250, test_loss 0.835004, accuracy = 0.724859/0.801045, f1 = 0.804514\n",
      "Epoch 93, step 275, training loss 0.664283, test_loss 0.833284, accuracy = 0.717458/0.801045, f1 = 0.804498\n",
      "Epoch 93, step 300, training loss 0.645675, test_loss 0.837742, accuracy = 0.717893/0.798868, f1 = 0.803028\n",
      "Epoch 93, step 325, training loss 0.723150, test_loss 0.832358, accuracy = 0.718764/0.799739, f1 = 0.803488\n",
      "Epoch 93, step 350, training loss 0.760844, test_loss 0.833338, accuracy = 0.714845/0.802351, f1 = 0.805241\n",
      "Epoch 93, step 375, training loss 0.751105, test_loss 0.839823, accuracy = 0.715716/0.798868, f1 = 0.802656\n",
      "Epoch 93, step 400, training loss 0.666661, test_loss 0.831836, accuracy = 0.722246/0.797127, f1 = 0.801410\n",
      "End of epoch 93, training loss 0.553226, test_loss 0.838375, accuracy = 0.720505/0.797997, f1 = 0.802662\n",
      "Confusion matrix:\n",
      "[[816  61  19  41]\n",
      " [ 25 461  68  46]\n",
      " [ 14  65 429  45]\n",
      " [ 11  27  42 127]]\n",
      "Epoch 94, step 0, training loss 0.623024, test_loss 0.828212, accuracy = 0.720505/0.797997, f1 = 0.802662\n",
      "Epoch 94, step 25, training loss 0.569955, test_loss 0.844419, accuracy = 0.714410/0.794950, f1 = 0.799082\n",
      "Epoch 94, step 50, training loss 0.650238, test_loss 0.826823, accuracy = 0.726600/0.801480, f1 = 0.804700\n",
      "Epoch 94, step 75, training loss 0.655941, test_loss 0.822464, accuracy = 0.720940/0.803222, f1 = 0.806108\n",
      "Epoch 94, step 100, training loss 0.684321, test_loss 0.818139, accuracy = 0.727906/0.802351, f1 = 0.805749\n",
      "Epoch 94, step 125, training loss 0.543678, test_loss 0.817569, accuracy = 0.734436/0.796691, f1 = 0.801329\n",
      "Epoch 94, step 150, training loss 0.760399, test_loss 0.829533, accuracy = 0.725729/0.796691, f1 = 0.800845\n",
      "Epoch 94, step 175, training loss 0.724605, test_loss 0.830692, accuracy = 0.727035/0.800174, f1 = 0.803214\n",
      "Epoch 94, step 200, training loss 0.547800, test_loss 0.837286, accuracy = 0.724423/0.803222, f1 = 0.805060\n",
      "Epoch 94, step 225, training loss 0.662649, test_loss 0.817210, accuracy = 0.734436/0.802351, f1 = 0.805396\n",
      "Epoch 94, step 250, training loss 0.667234, test_loss 0.825777, accuracy = 0.722682/0.804528, f1 = 0.806988\n",
      "Epoch 94, step 275, training loss 0.646542, test_loss 0.809533, accuracy = 0.737484/0.804528, f1 = 0.807580\n",
      "Epoch 94, step 300, training loss 0.692630, test_loss 0.832973, accuracy = 0.722246/0.802351, f1 = 0.805611\n",
      "Epoch 94, step 325, training loss 0.752639, test_loss 0.818195, accuracy = 0.724859/0.803222, f1 = 0.806377\n",
      "Epoch 94, step 350, training loss 0.634281, test_loss 0.831598, accuracy = 0.712669/0.803657, f1 = 0.805996\n",
      "Epoch 94, step 375, training loss 0.815386, test_loss 0.819851, accuracy = 0.736178/0.799303, f1 = 0.803343\n",
      "Epoch 94, step 400, training loss 0.660109, test_loss 0.828391, accuracy = 0.720940/0.798433, f1 = 0.802523\n",
      "End of epoch 94, training loss 0.592545, test_loss 0.830106, accuracy = 0.726165/0.800174, f1 = 0.803875\n",
      "Confusion matrix:\n",
      "[[822  54  23  38]\n",
      " [ 31 447  78  44]\n",
      " [ 14  58 439  42]\n",
      " [ 13  23  41 130]]\n",
      "Epoch 95, step 0, training loss 0.611618, test_loss 0.830689, accuracy = 0.726165/0.799739, f1 = 0.803440\n",
      "Epoch 95, step 25, training loss 0.629489, test_loss 0.832066, accuracy = 0.712669/0.799303, f1 = 0.803283\n",
      "Epoch 95, step 50, training loss 0.662777, test_loss 0.833521, accuracy = 0.721376/0.799739, f1 = 0.803569\n",
      "Epoch 95, step 75, training loss 0.638096, test_loss 0.823237, accuracy = 0.728341/0.804528, f1 = 0.807592\n",
      "Epoch 95, step 100, training loss 0.682507, test_loss 0.812252, accuracy = 0.736178/0.798868, f1 = 0.802352\n",
      "Epoch 95, step 125, training loss 0.568618, test_loss 0.824353, accuracy = 0.717458/0.797127, f1 = 0.801232\n",
      "Epoch 95, step 150, training loss 0.671636, test_loss 0.827233, accuracy = 0.717022/0.797997, f1 = 0.802375\n",
      "Epoch 95, step 175, training loss 0.692985, test_loss 0.823291, accuracy = 0.728777/0.798868, f1 = 0.802682\n",
      "Epoch 95, step 200, training loss 0.557774, test_loss 0.834450, accuracy = 0.721376/0.801045, f1 = 0.804211\n",
      "Epoch 95, step 225, training loss 0.521419, test_loss 0.826696, accuracy = 0.726165/0.803222, f1 = 0.806422\n",
      "Epoch 95, step 250, training loss 0.764446, test_loss 0.819333, accuracy = 0.730518/0.802351, f1 = 0.805835\n",
      "Epoch 95, step 275, training loss 0.665895, test_loss 0.823163, accuracy = 0.730083/0.801916, f1 = 0.805292\n",
      "Epoch 95, step 300, training loss 0.589342, test_loss 0.834957, accuracy = 0.720070/0.800174, f1 = 0.803796\n",
      "Epoch 95, step 325, training loss 0.698075, test_loss 0.827929, accuracy = 0.715716/0.799303, f1 = 0.802917\n",
      "Epoch 95, step 350, training loss 0.626513, test_loss 0.831133, accuracy = 0.716151/0.798868, f1 = 0.802296\n",
      "Epoch 95, step 375, training loss 0.814435, test_loss 0.829301, accuracy = 0.714846/0.796691, f1 = 0.801135\n",
      "Epoch 95, step 400, training loss 0.677631, test_loss 0.841943, accuracy = 0.717458/0.795385, f1 = 0.800063\n",
      "End of epoch 95, training loss 0.574594, test_loss 0.838642, accuracy = 0.720505/0.795821, f1 = 0.800267\n",
      "Confusion matrix:\n",
      "[[821  53  20  43]\n",
      " [ 30 449  74  47]\n",
      " [ 15  63 429  46]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 96, step 0, training loss 0.640681, test_loss 0.816184, accuracy = 0.737048/0.796256, f1 = 0.800618\n",
      "Epoch 96, step 25, training loss 0.616928, test_loss 0.835100, accuracy = 0.716587/0.797127, f1 = 0.801364\n",
      "Epoch 96, step 50, training loss 0.580757, test_loss 0.823662, accuracy = 0.726165/0.797997, f1 = 0.802214\n",
      "Epoch 96, step 75, training loss 0.690657, test_loss 0.820266, accuracy = 0.720940/0.806704, f1 = 0.809420\n",
      "Epoch 96, step 100, training loss 0.634243, test_loss 0.821893, accuracy = 0.713104/0.801916, f1 = 0.805658\n",
      "Epoch 96, step 125, training loss 0.616900, test_loss 0.823887, accuracy = 0.727906/0.801480, f1 = 0.806087\n",
      "Epoch 96, step 150, training loss 0.704670, test_loss 0.829567, accuracy = 0.724858/0.799739, f1 = 0.804157\n",
      "Epoch 96, step 175, training loss 0.754532, test_loss 0.823997, accuracy = 0.730953/0.800174, f1 = 0.804601\n",
      "Epoch 96, step 200, training loss 0.552512, test_loss 0.811526, accuracy = 0.730083/0.800610, f1 = 0.804124\n",
      "Epoch 96, step 225, training loss 0.560351, test_loss 0.821295, accuracy = 0.723988/0.801480, f1 = 0.805036\n",
      "Epoch 96, step 250, training loss 0.731931, test_loss 0.820625, accuracy = 0.722246/0.802351, f1 = 0.805530\n",
      "Epoch 96, step 275, training loss 0.702290, test_loss 0.826302, accuracy = 0.732695/0.801480, f1 = 0.805182\n",
      "Epoch 96, step 300, training loss 0.684723, test_loss 0.819699, accuracy = 0.729647/0.798433, f1 = 0.802486\n",
      "Epoch 96, step 325, training loss 0.829476, test_loss 0.827532, accuracy = 0.723552/0.800174, f1 = 0.804292\n",
      "Epoch 96, step 350, training loss 0.648263, test_loss 0.832813, accuracy = 0.715716/0.802351, f1 = 0.806051\n",
      "Epoch 96, step 375, training loss 0.790167, test_loss 0.831261, accuracy = 0.721376/0.797127, f1 = 0.801969\n",
      "Epoch 96, step 400, training loss 0.613330, test_loss 0.839667, accuracy = 0.715716/0.794950, f1 = 0.799643\n",
      "End of epoch 96, training loss 0.589347, test_loss 0.819215, accuracy = 0.722682/0.799303, f1 = 0.803947\n",
      "Confusion matrix:\n",
      "[[814  58  20  45]\n",
      " [ 26 462  69  43]\n",
      " [ 13  66 430  44]\n",
      " [ 13  23  41 130]]\n",
      "Epoch 97, step 0, training loss 0.676962, test_loss 0.826804, accuracy = 0.717022/0.799739, f1 = 0.804381\n",
      "Epoch 97, step 25, training loss 0.577704, test_loss 0.848729, accuracy = 0.716587/0.799739, f1 = 0.804016\n",
      "Epoch 97, step 50, training loss 0.572468, test_loss 0.836453, accuracy = 0.726600/0.801480, f1 = 0.805538\n",
      "Epoch 97, step 75, training loss 0.638829, test_loss 0.817089, accuracy = 0.722682/0.800174, f1 = 0.803883\n",
      "Epoch 97, step 100, training loss 0.623513, test_loss 0.813827, accuracy = 0.732695/0.800174, f1 = 0.804330\n",
      "Epoch 97, step 125, training loss 0.541612, test_loss 0.827936, accuracy = 0.720940/0.798433, f1 = 0.803306\n",
      "Epoch 97, step 150, training loss 0.682905, test_loss 0.844035, accuracy = 0.715281/0.796691, f1 = 0.801753\n",
      "Epoch 97, step 175, training loss 0.684756, test_loss 0.824571, accuracy = 0.727035/0.802786, f1 = 0.806783\n",
      "Epoch 97, step 200, training loss 0.546474, test_loss 0.819549, accuracy = 0.730953/0.803657, f1 = 0.806571\n",
      "Epoch 97, step 225, training loss 0.597322, test_loss 0.829122, accuracy = 0.724858/0.801045, f1 = 0.804975\n",
      "Epoch 97, step 250, training loss 0.715031, test_loss 0.818136, accuracy = 0.724859/0.801480, f1 = 0.805093\n",
      "Epoch 97, step 275, training loss 0.547205, test_loss 0.819442, accuracy = 0.726165/0.804092, f1 = 0.807233\n",
      "Epoch 97, step 300, training loss 0.615716, test_loss 0.843440, accuracy = 0.711363/0.805398, f1 = 0.808520\n",
      "Epoch 97, step 325, training loss 0.664201, test_loss 0.828357, accuracy = 0.714845/0.798868, f1 = 0.802295\n",
      "Epoch 97, step 350, training loss 0.640779, test_loss 0.839445, accuracy = 0.714410/0.799739, f1 = 0.803439\n",
      "Epoch 97, step 375, training loss 0.819868, test_loss 0.838100, accuracy = 0.721376/0.797127, f1 = 0.801659\n",
      "Epoch 97, step 400, training loss 0.662319, test_loss 0.844087, accuracy = 0.711363/0.798433, f1 = 0.802801\n",
      "End of epoch 97, training loss 0.625994, test_loss 0.824714, accuracy = 0.719634/0.798433, f1 = 0.802830\n",
      "Confusion matrix:\n",
      "[[825  52  22  38]\n",
      " [ 29 449  73  49]\n",
      " [ 14  60 431  48]\n",
      " [ 13  23  42 129]]\n",
      "Epoch 98, step 0, training loss 0.602083, test_loss 0.823390, accuracy = 0.719199/0.801045, f1 = 0.805027\n",
      "Epoch 98, step 25, training loss 0.577438, test_loss 0.821769, accuracy = 0.729647/0.797562, f1 = 0.801351\n",
      "Epoch 98, step 50, training loss 0.623816, test_loss 0.837763, accuracy = 0.717893/0.801480, f1 = 0.804766\n",
      "Epoch 98, step 75, training loss 0.660750, test_loss 0.814890, accuracy = 0.725294/0.799739, f1 = 0.802649\n",
      "Epoch 98, step 100, training loss 0.641168, test_loss 0.835454, accuracy = 0.714845/0.800174, f1 = 0.803770\n",
      "Epoch 98, step 125, training loss 0.618157, test_loss 0.807972, accuracy = 0.730083/0.797127, f1 = 0.801389\n",
      "Epoch 98, step 150, training loss 0.606220, test_loss 0.838572, accuracy = 0.718764/0.799303, f1 = 0.804005\n",
      "Epoch 98, step 175, training loss 0.824846, test_loss 0.823816, accuracy = 0.730518/0.798868, f1 = 0.802832\n",
      "Epoch 98, step 200, training loss 0.568747, test_loss 0.819509, accuracy = 0.727906/0.801916, f1 = 0.805088\n",
      "Epoch 98, step 225, training loss 0.589827, test_loss 0.846254, accuracy = 0.725294/0.800174, f1 = 0.803714\n",
      "Epoch 98, step 250, training loss 0.647109, test_loss 0.833024, accuracy = 0.724423/0.801045, f1 = 0.804403\n",
      "Epoch 98, step 275, training loss 0.697841, test_loss 0.825132, accuracy = 0.726165/0.803222, f1 = 0.806823\n",
      "Epoch 98, step 300, training loss 0.643734, test_loss 0.823765, accuracy = 0.720940/0.800610, f1 = 0.804788\n",
      "Epoch 98, step 325, training loss 0.687481, test_loss 0.819180, accuracy = 0.729647/0.801480, f1 = 0.804976\n",
      "Epoch 98, step 350, training loss 0.679360, test_loss 0.835543, accuracy = 0.709186/0.804963, f1 = 0.807921\n",
      "Epoch 98, step 375, training loss 0.827356, test_loss 0.832667, accuracy = 0.722682/0.798433, f1 = 0.802506\n",
      "Epoch 98, step 400, training loss 0.617196, test_loss 0.825286, accuracy = 0.723552/0.797997, f1 = 0.802379\n",
      "End of epoch 98, training loss 0.632650, test_loss 0.829709, accuracy = 0.717458/0.799739, f1 = 0.803941\n",
      "Confusion matrix:\n",
      "[[823  55  21  38]\n",
      " [ 28 456  69  47]\n",
      " [ 15  64 428  46]\n",
      " [ 14  23  40 130]]\n",
      "Epoch 99, step 0, training loss 0.659273, test_loss 0.828065, accuracy = 0.717022/0.799739, f1 = 0.803941\n",
      "Epoch 99, step 25, training loss 0.654987, test_loss 0.823975, accuracy = 0.717458/0.798868, f1 = 0.803392\n",
      "Epoch 99, step 50, training loss 0.585112, test_loss 0.839952, accuracy = 0.708751/0.800174, f1 = 0.804862\n",
      "Epoch 99, step 75, training loss 0.609202, test_loss 0.827647, accuracy = 0.724859/0.800610, f1 = 0.804337\n",
      "Epoch 99, step 100, training loss 0.621947, test_loss 0.815993, accuracy = 0.718764/0.799739, f1 = 0.804030\n",
      "Epoch 99, step 125, training loss 0.602575, test_loss 0.818064, accuracy = 0.731389/0.800174, f1 = 0.804479\n",
      "Epoch 99, step 150, training loss 0.677547, test_loss 0.821992, accuracy = 0.727035/0.802351, f1 = 0.806058\n",
      "Epoch 99, step 175, training loss 0.760340, test_loss 0.837303, accuracy = 0.720070/0.804092, f1 = 0.807342\n",
      "Epoch 99, step 200, training loss 0.598892, test_loss 0.813384, accuracy = 0.722682/0.801916, f1 = 0.804866\n",
      "Epoch 99, step 225, training loss 0.587429, test_loss 0.816022, accuracy = 0.726165/0.801480, f1 = 0.804885\n",
      "Epoch 99, step 250, training loss 0.634688, test_loss 0.821759, accuracy = 0.722682/0.803657, f1 = 0.806773\n",
      "Epoch 99, step 275, training loss 0.694764, test_loss 0.817687, accuracy = 0.731824/0.802351, f1 = 0.805570\n",
      "Epoch 99, step 300, training loss 0.609861, test_loss 0.827527, accuracy = 0.721376/0.801480, f1 = 0.805130\n",
      "Epoch 99, step 325, training loss 0.659830, test_loss 0.829493, accuracy = 0.725729/0.801045, f1 = 0.804285\n",
      "Epoch 99, step 350, training loss 0.591811, test_loss 0.836665, accuracy = 0.711363/0.799739, f1 = 0.802013\n",
      "Epoch 99, step 375, training loss 0.824613, test_loss 0.835776, accuracy = 0.716152/0.796691, f1 = 0.800141\n",
      "Epoch 99, step 400, training loss 0.639803, test_loss 0.836634, accuracy = 0.718328/0.794950, f1 = 0.798636\n",
      "End of epoch 99, training loss 0.665614, test_loss 0.824295, accuracy = 0.722246/0.797127, f1 = 0.800508\n",
      "Confusion matrix:\n",
      "[[824  53  24  36]\n",
      " [ 38 448  67  47]\n",
      " [ 15  63 432  43]\n",
      " [ 16  24  40 127]]\n",
      "Epoch 100, step 0, training loss 0.664212, test_loss 0.827449, accuracy = 0.714410/0.797997, f1 = 0.801457\n",
      "Epoch 100, step 25, training loss 0.557538, test_loss 0.834606, accuracy = 0.721376/0.796691, f1 = 0.800996\n",
      "Epoch 100, step 50, training loss 0.582568, test_loss 0.833304, accuracy = 0.719199/0.794950, f1 = 0.799194\n",
      "Epoch 100, step 75, training loss 0.617971, test_loss 0.814054, accuracy = 0.725729/0.803657, f1 = 0.806802\n",
      "Epoch 100, step 100, training loss 0.657250, test_loss 0.826401, accuracy = 0.725729/0.799303, f1 = 0.803580\n",
      "Epoch 100, step 125, training loss 0.618411, test_loss 0.820621, accuracy = 0.729647/0.798868, f1 = 0.803912\n",
      "Epoch 100, step 150, training loss 0.669154, test_loss 0.812562, accuracy = 0.730083/0.799303, f1 = 0.804392\n",
      "Epoch 100, step 175, training loss 0.759546, test_loss 0.825489, accuracy = 0.719634/0.801916, f1 = 0.806097\n",
      "Epoch 100, step 200, training loss 0.576612, test_loss 0.836160, accuracy = 0.724423/0.801480, f1 = 0.804943\n",
      "Epoch 100, step 225, training loss 0.550201, test_loss 0.820934, accuracy = 0.722682/0.803222, f1 = 0.806883\n",
      "Epoch 100, step 250, training loss 0.709772, test_loss 0.830529, accuracy = 0.721811/0.804963, f1 = 0.808061\n",
      "Epoch 100, step 275, training loss 0.655939, test_loss 0.819733, accuracy = 0.727035/0.802351, f1 = 0.805750\n",
      "Epoch 100, step 300, training loss 0.583914, test_loss 0.838170, accuracy = 0.721376/0.802786, f1 = 0.806561\n",
      "Epoch 100, step 325, training loss 0.705314, test_loss 0.819521, accuracy = 0.720505/0.804528, f1 = 0.807543\n",
      "Epoch 100, step 350, training loss 0.649264, test_loss 0.839019, accuracy = 0.716587/0.802351, f1 = 0.805269\n",
      "Epoch 100, step 375, training loss 0.701552, test_loss 0.823518, accuracy = 0.720940/0.800610, f1 = 0.804485\n",
      "Epoch 100, step 400, training loss 0.729165, test_loss 0.821409, accuracy = 0.713975/0.800610, f1 = 0.804499\n",
      "End of epoch 100, training loss 0.588417, test_loss 0.834112, accuracy = 0.720505/0.797997, f1 = 0.801867\n",
      "Confusion matrix:\n",
      "[[824  52  21  40]\n",
      " [ 35 447  71  47]\n",
      " [ 17  59 432  45]\n",
      " [ 14  24  39 130]]\n",
      "Epoch 101, step 0, training loss 0.685693, test_loss 0.816039, accuracy = 0.720940/0.798433, f1 = 0.802219\n",
      "Epoch 101, step 25, training loss 0.558097, test_loss 0.830264, accuracy = 0.715716/0.797127, f1 = 0.800852\n",
      "Epoch 101, step 50, training loss 0.593833, test_loss 0.832317, accuracy = 0.723117/0.798433, f1 = 0.802024\n",
      "Epoch 101, step 75, training loss 0.647789, test_loss 0.808891, accuracy = 0.732695/0.805398, f1 = 0.808215\n",
      "Epoch 101, step 100, training loss 0.690398, test_loss 0.808221, accuracy = 0.730953/0.804528, f1 = 0.807843\n",
      "Epoch 101, step 125, training loss 0.585333, test_loss 0.827967, accuracy = 0.722682/0.797562, f1 = 0.801587\n",
      "Epoch 101, step 150, training loss 0.642390, test_loss 0.828567, accuracy = 0.727471/0.796256, f1 = 0.801356\n",
      "Epoch 101, step 175, training loss 0.691799, test_loss 0.815898, accuracy = 0.721376/0.798433, f1 = 0.802803\n",
      "Epoch 101, step 200, training loss 0.589783, test_loss 0.832187, accuracy = 0.721811/0.802351, f1 = 0.805233\n",
      "Epoch 101, step 225, training loss 0.520991, test_loss 0.823981, accuracy = 0.725294/0.797562, f1 = 0.801037\n",
      "Epoch 101, step 250, training loss 0.703219, test_loss 0.828270, accuracy = 0.723988/0.800174, f1 = 0.803841\n",
      "Epoch 101, step 275, training loss 0.657240, test_loss 0.803771, accuracy = 0.729212/0.799739, f1 = 0.803887\n",
      "Epoch 101, step 300, training loss 0.588440, test_loss 0.834709, accuracy = 0.712233/0.801480, f1 = 0.805663\n",
      "Epoch 101, step 325, training loss 0.672283, test_loss 0.829073, accuracy = 0.725729/0.801916, f1 = 0.805952\n",
      "Epoch 101, step 350, training loss 0.611077, test_loss 0.842088, accuracy = 0.713104/0.799303, f1 = 0.802780\n",
      "Epoch 101, step 375, training loss 0.751539, test_loss 0.846941, accuracy = 0.712233/0.793209, f1 = 0.797753\n",
      "Epoch 101, step 400, training loss 0.697411, test_loss 0.825727, accuracy = 0.723552/0.795821, f1 = 0.799694\n",
      "End of epoch 101, training loss 0.568596, test_loss 0.832646, accuracy = 0.715716/0.797997, f1 = 0.801809\n",
      "Confusion matrix:\n",
      "[[818  54  24  41]\n",
      " [ 31 446  78  45]\n",
      " [ 13  59 442  39]\n",
      " [ 13  26  41 127]]\n",
      "Epoch 102, step 0, training loss 0.569749, test_loss 0.817785, accuracy = 0.726600/0.798433, f1 = 0.802192\n",
      "Epoch 102, step 25, training loss 0.592064, test_loss 0.847879, accuracy = 0.709186/0.798433, f1 = 0.802588\n",
      "Epoch 102, step 50, training loss 0.607881, test_loss 0.851775, accuracy = 0.715716/0.798433, f1 = 0.802342\n",
      "Epoch 102, step 75, training loss 0.642946, test_loss 0.827856, accuracy = 0.728341/0.798868, f1 = 0.802121\n",
      "Epoch 102, step 100, training loss 0.665047, test_loss 0.826266, accuracy = 0.721811/0.796256, f1 = 0.799633\n",
      "Epoch 102, step 125, training loss 0.656857, test_loss 0.833298, accuracy = 0.717893/0.797997, f1 = 0.801317\n",
      "Epoch 102, step 150, training loss 0.569267, test_loss 0.827953, accuracy = 0.718764/0.803657, f1 = 0.806968\n",
      "Epoch 102, step 175, training loss 0.828245, test_loss 0.820928, accuracy = 0.728341/0.803657, f1 = 0.806981\n",
      "Epoch 102, step 200, training loss 0.605268, test_loss 0.831500, accuracy = 0.721811/0.806269, f1 = 0.808737\n",
      "Epoch 102, step 225, training loss 0.573145, test_loss 0.830433, accuracy = 0.720505/0.803657, f1 = 0.806029\n",
      "Epoch 102, step 250, training loss 0.690328, test_loss 0.823939, accuracy = 0.726165/0.804963, f1 = 0.807048\n",
      "Epoch 102, step 275, training loss 0.535257, test_loss 0.816432, accuracy = 0.725294/0.804092, f1 = 0.806743\n",
      "Epoch 102, step 300, training loss 0.628157, test_loss 0.827917, accuracy = 0.719634/0.802351, f1 = 0.805821\n",
      "Epoch 102, step 325, training loss 0.695661, test_loss 0.825903, accuracy = 0.724423/0.801045, f1 = 0.804139\n",
      "Epoch 102, step 350, training loss 0.610802, test_loss 0.833600, accuracy = 0.717458/0.800174, f1 = 0.803596\n",
      "Epoch 102, step 375, training loss 0.670117, test_loss 0.820514, accuracy = 0.721811/0.798433, f1 = 0.802840\n",
      "Epoch 102, step 400, training loss 0.647604, test_loss 0.825411, accuracy = 0.724423/0.797127, f1 = 0.801324\n",
      "End of epoch 102, training loss 0.579630, test_loss 0.852527, accuracy = 0.709186/0.794515, f1 = 0.798743\n",
      "Confusion matrix:\n",
      "[[828  48  18  43]\n",
      " [ 35 443  71  51]\n",
      " [ 18  61 427  47]\n",
      " [ 15  25  40 127]]\n",
      "Epoch 103, step 0, training loss 0.672977, test_loss 0.833807, accuracy = 0.714845/0.794950, f1 = 0.799211\n",
      "Epoch 103, step 25, training loss 0.608991, test_loss 0.825591, accuracy = 0.723117/0.795821, f1 = 0.800297\n",
      "Epoch 103, step 50, training loss 0.650363, test_loss 0.830126, accuracy = 0.721376/0.796691, f1 = 0.800685\n",
      "Epoch 103, step 75, training loss 0.705041, test_loss 0.818745, accuracy = 0.727035/0.802351, f1 = 0.805883\n",
      "Epoch 103, step 100, training loss 0.686338, test_loss 0.813493, accuracy = 0.730953/0.798433, f1 = 0.803161\n",
      "Epoch 103, step 125, training loss 0.614697, test_loss 0.822591, accuracy = 0.730518/0.796691, f1 = 0.801943\n",
      "Epoch 103, step 150, training loss 0.671908, test_loss 0.820470, accuracy = 0.723988/0.797562, f1 = 0.802334\n",
      "Epoch 103, step 175, training loss 0.829706, test_loss 0.812712, accuracy = 0.723552/0.800174, f1 = 0.804664\n",
      "Epoch 103, step 200, training loss 0.474388, test_loss 0.822880, accuracy = 0.723553/0.801480, f1 = 0.804706\n",
      "Epoch 103, step 225, training loss 0.550433, test_loss 0.834543, accuracy = 0.727035/0.798868, f1 = 0.802586\n",
      "Epoch 103, step 250, training loss 0.669286, test_loss 0.834694, accuracy = 0.717458/0.803222, f1 = 0.806229\n",
      "Epoch 103, step 275, training loss 0.665222, test_loss 0.827987, accuracy = 0.728341/0.804528, f1 = 0.808053\n",
      "Epoch 103, step 300, training loss 0.616968, test_loss 0.823201, accuracy = 0.720505/0.802786, f1 = 0.806722\n",
      "Epoch 103, step 325, training loss 0.735005, test_loss 0.824028, accuracy = 0.720070/0.802351, f1 = 0.805922\n",
      "Epoch 103, step 350, training loss 0.700419, test_loss 0.830310, accuracy = 0.724423/0.798433, f1 = 0.800896\n",
      "Epoch 103, step 375, training loss 0.707133, test_loss 0.839929, accuracy = 0.723552/0.793209, f1 = 0.797518\n",
      "Epoch 103, step 400, training loss 0.752218, test_loss 0.825194, accuracy = 0.714845/0.794079, f1 = 0.798738\n",
      "End of epoch 103, training loss 0.492344, test_loss 0.823215, accuracy = 0.716587/0.797997, f1 = 0.802528\n",
      "Confusion matrix:\n",
      "[[823  50  19  45]\n",
      " [ 33 456  65  46]\n",
      " [ 14  63 427  49]\n",
      " [ 16  26  38 127]]\n",
      "Epoch 104, step 0, training loss 0.524540, test_loss 0.830347, accuracy = 0.718328/0.798868, f1 = 0.803250\n",
      "Epoch 104, step 25, training loss 0.619564, test_loss 0.830853, accuracy = 0.717893/0.797127, f1 = 0.801332\n",
      "Epoch 104, step 50, training loss 0.628491, test_loss 0.828353, accuracy = 0.729212/0.801916, f1 = 0.805659\n",
      "Epoch 104, step 75, training loss 0.660182, test_loss 0.812696, accuracy = 0.736178/0.803657, f1 = 0.806828\n",
      "Epoch 104, step 100, training loss 0.701301, test_loss 0.813269, accuracy = 0.733130/0.802351, f1 = 0.805700\n",
      "Epoch 104, step 125, training loss 0.552937, test_loss 0.833861, accuracy = 0.721811/0.800174, f1 = 0.804047\n",
      "Epoch 104, step 150, training loss 0.614740, test_loss 0.830186, accuracy = 0.724858/0.800610, f1 = 0.805425\n",
      "Epoch 104, step 175, training loss 0.738596, test_loss 0.820998, accuracy = 0.729647/0.799739, f1 = 0.804476\n",
      "Epoch 104, step 200, training loss 0.534082, test_loss 0.820975, accuracy = 0.727035/0.799739, f1 = 0.803181\n",
      "Epoch 104, step 225, training loss 0.518213, test_loss 0.826113, accuracy = 0.721376/0.799303, f1 = 0.803055\n",
      "Epoch 104, step 250, training loss 0.634769, test_loss 0.824110, accuracy = 0.722246/0.800174, f1 = 0.803391\n",
      "Epoch 104, step 275, training loss 0.564650, test_loss 0.830759, accuracy = 0.721811/0.801480, f1 = 0.804845\n",
      "Epoch 104, step 300, training loss 0.613554, test_loss 0.829959, accuracy = 0.730953/0.804528, f1 = 0.807628\n",
      "Epoch 104, step 325, training loss 0.747368, test_loss 0.824599, accuracy = 0.728777/0.804092, f1 = 0.807543\n",
      "Epoch 104, step 350, training loss 0.775740, test_loss 0.830790, accuracy = 0.723117/0.802786, f1 = 0.805911\n",
      "Epoch 104, step 375, training loss 0.735037, test_loss 0.829682, accuracy = 0.720940/0.795821, f1 = 0.799860\n",
      "Epoch 104, step 400, training loss 0.611868, test_loss 0.847522, accuracy = 0.713104/0.798433, f1 = 0.801924\n",
      "End of epoch 104, training loss 0.635796, test_loss 0.835960, accuracy = 0.718764/0.797562, f1 = 0.800950\n",
      "Confusion matrix:\n",
      "[[829  48  22  38]\n",
      " [ 36 445  71  48]\n",
      " [ 18  59 433  43]\n",
      " [ 15  24  43 125]]\n",
      "Epoch 105, step 0, training loss 0.681810, test_loss 0.819477, accuracy = 0.724423/0.797127, f1 = 0.800538\n",
      "Epoch 105, step 25, training loss 0.585488, test_loss 0.838133, accuracy = 0.723988/0.797127, f1 = 0.800747\n",
      "Epoch 105, step 50, training loss 0.587008, test_loss 0.829028, accuracy = 0.720505/0.800609, f1 = 0.804191\n",
      "Epoch 105, step 75, training loss 0.619542, test_loss 0.822861, accuracy = 0.716152/0.797562, f1 = 0.800634\n",
      "Epoch 105, step 100, training loss 0.620899, test_loss 0.822021, accuracy = 0.723988/0.797127, f1 = 0.800985\n",
      "Epoch 105, step 125, training loss 0.604629, test_loss 0.824565, accuracy = 0.725294/0.797562, f1 = 0.801767\n",
      "Epoch 105, step 150, training loss 0.635210, test_loss 0.831046, accuracy = 0.715281/0.797997, f1 = 0.802253\n",
      "Epoch 105, step 175, training loss 0.767464, test_loss 0.834538, accuracy = 0.720070/0.799739, f1 = 0.803942\n",
      "Epoch 105, step 200, training loss 0.519935, test_loss 0.826727, accuracy = 0.726165/0.797997, f1 = 0.802058\n",
      "Epoch 105, step 225, training loss 0.593912, test_loss 0.844027, accuracy = 0.717458/0.799739, f1 = 0.802884\n",
      "Epoch 105, step 250, training loss 0.609509, test_loss 0.817107, accuracy = 0.723552/0.803222, f1 = 0.805843\n",
      "Epoch 105, step 275, training loss 0.590200, test_loss 0.821851, accuracy = 0.723117/0.803222, f1 = 0.806460\n",
      "Epoch 105, step 300, training loss 0.643910, test_loss 0.827073, accuracy = 0.716152/0.803222, f1 = 0.806834\n",
      "Epoch 105, step 325, training loss 0.712682, test_loss 0.828808, accuracy = 0.707445/0.801480, f1 = 0.805064\n",
      "Epoch 105, step 350, training loss 0.610412, test_loss 0.837736, accuracy = 0.723552/0.801916, f1 = 0.804705\n",
      "Epoch 105, step 375, training loss 0.660828, test_loss 0.835312, accuracy = 0.712669/0.799739, f1 = 0.803097\n",
      "Epoch 105, step 400, training loss 0.719588, test_loss 0.837141, accuracy = 0.717893/0.797997, f1 = 0.802100\n",
      "End of epoch 105, training loss 0.541035, test_loss 0.826237, accuracy = 0.723552/0.799739, f1 = 0.804075\n",
      "Confusion matrix:\n",
      "[[825  50  21  41]\n",
      " [ 31 455  67  47]\n",
      " [ 15  65 426  47]\n",
      " [ 13  25  38 131]]\n",
      "Epoch 106, step 0, training loss 0.657252, test_loss 0.839479, accuracy = 0.715281/0.799303, f1 = 0.803603\n",
      "Epoch 106, step 25, training loss 0.688391, test_loss 0.823123, accuracy = 0.726600/0.796691, f1 = 0.801904\n",
      "Epoch 106, step 50, training loss 0.649296, test_loss 0.831658, accuracy = 0.717458/0.796691, f1 = 0.801986\n",
      "Epoch 106, step 75, training loss 0.690586, test_loss 0.808178, accuracy = 0.729647/0.801480, f1 = 0.805894\n",
      "Epoch 106, step 100, training loss 0.655696, test_loss 0.822111, accuracy = 0.727035/0.796256, f1 = 0.801268\n",
      "Epoch 106, step 125, training loss 0.642167, test_loss 0.809814, accuracy = 0.726600/0.795385, f1 = 0.800700\n",
      "Epoch 106, step 150, training loss 0.675359, test_loss 0.833574, accuracy = 0.717458/0.796256, f1 = 0.801181\n",
      "Epoch 106, step 175, training loss 0.733293, test_loss 0.815152, accuracy = 0.728341/0.797562, f1 = 0.802001\n",
      "Epoch 106, step 200, training loss 0.538847, test_loss 0.822337, accuracy = 0.713975/0.799303, f1 = 0.802460\n",
      "Epoch 106, step 225, training loss 0.573350, test_loss 0.827611, accuracy = 0.720070/0.797562, f1 = 0.800873\n",
      "Epoch 106, step 250, training loss 0.682934, test_loss 0.828602, accuracy = 0.719199/0.797997, f1 = 0.801189\n",
      "Epoch 106, step 275, training loss 0.565495, test_loss 0.816878, accuracy = 0.731824/0.800174, f1 = 0.804126\n",
      "Epoch 106, step 300, training loss 0.569525, test_loss 0.818910, accuracy = 0.720505/0.801480, f1 = 0.805173\n",
      "Epoch 106, step 325, training loss 0.638216, test_loss 0.823020, accuracy = 0.732259/0.798868, f1 = 0.802686\n",
      "Epoch 106, step 350, training loss 0.663324, test_loss 0.823854, accuracy = 0.730953/0.798433, f1 = 0.801850\n",
      "Epoch 106, step 375, training loss 0.718600, test_loss 0.828669, accuracy = 0.720505/0.796256, f1 = 0.801030\n",
      "Epoch 106, step 400, training loss 0.687755, test_loss 0.827968, accuracy = 0.723988/0.792338, f1 = 0.798289\n",
      "End of epoch 106, training loss 0.544289, test_loss 0.836010, accuracy = 0.722246/0.796691, f1 = 0.802027\n",
      "Confusion matrix:\n",
      "[[820  49  19  49]\n",
      " [ 28 452  69  51]\n",
      " [ 14  62 429  48]\n",
      " [ 15  23  40 129]]\n",
      "Epoch 107, step 0, training loss 0.561721, test_loss 0.833221, accuracy = 0.708315/0.797127, f1 = 0.802441\n",
      "Epoch 107, step 25, training loss 0.563475, test_loss 0.817892, accuracy = 0.717458/0.796256, f1 = 0.801338\n",
      "Epoch 107, step 50, training loss 0.593190, test_loss 0.834396, accuracy = 0.718764/0.801480, f1 = 0.805319\n",
      "Epoch 107, step 75, training loss 0.664863, test_loss 0.814200, accuracy = 0.721376/0.801480, f1 = 0.805586\n",
      "Epoch 107, step 100, training loss 0.668042, test_loss 0.822653, accuracy = 0.728341/0.799303, f1 = 0.804135\n",
      "Epoch 107, step 125, training loss 0.532507, test_loss 0.823260, accuracy = 0.730083/0.798868, f1 = 0.804033\n",
      "Epoch 107, step 150, training loss 0.611487, test_loss 0.819339, accuracy = 0.730518/0.798433, f1 = 0.803381\n",
      "Epoch 107, step 175, training loss 0.649025, test_loss 0.836409, accuracy = 0.719199/0.800610, f1 = 0.804959\n",
      "Epoch 107, step 200, training loss 0.622495, test_loss 0.825134, accuracy = 0.723117/0.798433, f1 = 0.802555\n",
      "Epoch 107, step 225, training loss 0.591924, test_loss 0.834219, accuracy = 0.722246/0.797562, f1 = 0.801704\n",
      "Epoch 107, step 250, training loss 0.592352, test_loss 0.836933, accuracy = 0.717022/0.795385, f1 = 0.798673\n",
      "Epoch 107, step 275, training loss 0.724274, test_loss 0.827382, accuracy = 0.727906/0.798433, f1 = 0.801748\n",
      "Epoch 107, step 300, training loss 0.600879, test_loss 0.829345, accuracy = 0.718328/0.800174, f1 = 0.803694\n",
      "Epoch 107, step 325, training loss 0.674186, test_loss 0.830361, accuracy = 0.721376/0.798868, f1 = 0.801793\n",
      "Epoch 107, step 350, training loss 0.662419, test_loss 0.832864, accuracy = 0.721811/0.799739, f1 = 0.802379\n",
      "Epoch 107, step 375, training loss 0.843932, test_loss 0.827254, accuracy = 0.723988/0.797127, f1 = 0.800444\n",
      "Epoch 107, step 400, training loss 0.693569, test_loss 0.831126, accuracy = 0.726165/0.799739, f1 = 0.803136\n",
      "End of epoch 107, training loss 0.537647, test_loss 0.832496, accuracy = 0.714410/0.798433, f1 = 0.802231\n",
      "Confusion matrix:\n",
      "[[819  57  23  38]\n",
      " [ 28 460  70  42]\n",
      " [ 15  67 428  43]\n",
      " [ 14  24  42 127]]\n",
      "Epoch 108, step 0, training loss 0.698597, test_loss 0.836860, accuracy = 0.716152/0.798433, f1 = 0.802231\n",
      "Epoch 108, step 25, training loss 0.584795, test_loss 0.832862, accuracy = 0.720505/0.800610, f1 = 0.804322\n",
      "Epoch 108, step 50, training loss 0.605030, test_loss 0.852825, accuracy = 0.703091/0.799739, f1 = 0.803707\n",
      "Epoch 108, step 75, training loss 0.631049, test_loss 0.827332, accuracy = 0.723552/0.799303, f1 = 0.802963\n",
      "Epoch 108, step 100, training loss 0.715548, test_loss 0.804296, accuracy = 0.728341/0.798433, f1 = 0.802359\n",
      "Epoch 108, step 125, training loss 0.637725, test_loss 0.829976, accuracy = 0.721811/0.797997, f1 = 0.802296\n",
      "Epoch 108, step 150, training loss 0.632520, test_loss 0.831041, accuracy = 0.714845/0.799739, f1 = 0.803909\n",
      "Epoch 108, step 175, training loss 0.674195, test_loss 0.833581, accuracy = 0.714846/0.801045, f1 = 0.805176\n",
      "Epoch 108, step 200, training loss 0.567178, test_loss 0.837396, accuracy = 0.720505/0.802786, f1 = 0.806387\n",
      "Epoch 108, step 225, training loss 0.517598, test_loss 0.831099, accuracy = 0.722682/0.800610, f1 = 0.804012\n",
      "Epoch 108, step 250, training loss 0.641723, test_loss 0.826250, accuracy = 0.725729/0.801916, f1 = 0.805510\n",
      "Epoch 108, step 275, training loss 0.639554, test_loss 0.821810, accuracy = 0.723117/0.801916, f1 = 0.805575\n",
      "Epoch 108, step 300, training loss 0.596099, test_loss 0.832197, accuracy = 0.709186/0.801480, f1 = 0.805315\n",
      "Epoch 108, step 325, training loss 0.728285, test_loss 0.825707, accuracy = 0.723117/0.801045, f1 = 0.804996\n",
      "Epoch 108, step 350, training loss 0.711147, test_loss 0.827509, accuracy = 0.726600/0.801045, f1 = 0.804576\n",
      "Epoch 108, step 375, training loss 0.748329, test_loss 0.835773, accuracy = 0.723117/0.797562, f1 = 0.801912\n",
      "Epoch 108, step 400, training loss 0.667198, test_loss 0.835019, accuracy = 0.713539/0.799303, f1 = 0.803779\n",
      "End of epoch 108, training loss 0.625556, test_loss 0.830587, accuracy = 0.722682/0.799303, f1 = 0.803236\n",
      "Confusion matrix:\n",
      "[[822  50  25  40]\n",
      " [ 32 446  76  46]\n",
      " [ 14  54 441  44]\n",
      " [ 14  23  43 127]]\n",
      "Epoch 109, step 0, training loss 0.622372, test_loss 0.819788, accuracy = 0.731824/0.798433, f1 = 0.802244\n",
      "Epoch 109, step 25, training loss 0.608763, test_loss 0.841723, accuracy = 0.712233/0.797562, f1 = 0.801867\n",
      "Epoch 109, step 50, training loss 0.692817, test_loss 0.827486, accuracy = 0.727906/0.800174, f1 = 0.803918\n",
      "Epoch 109, step 75, training loss 0.696837, test_loss 0.813371, accuracy = 0.736178/0.801045, f1 = 0.804286\n",
      "Epoch 109, step 100, training loss 0.708160, test_loss 0.829076, accuracy = 0.722682/0.801916, f1 = 0.805645\n",
      "Epoch 109, step 125, training loss 0.516264, test_loss 0.822947, accuracy = 0.724423/0.798868, f1 = 0.802879\n",
      "Epoch 109, step 150, training loss 0.643168, test_loss 0.831653, accuracy = 0.723552/0.799739, f1 = 0.803457\n",
      "Epoch 109, step 175, training loss 0.699309, test_loss 0.831704, accuracy = 0.720505/0.801916, f1 = 0.805312\n",
      "Epoch 109, step 200, training loss 0.540774, test_loss 0.817261, accuracy = 0.716587/0.801045, f1 = 0.804246\n",
      "Epoch 109, step 225, training loss 0.557971, test_loss 0.834493, accuracy = 0.722682/0.800610, f1 = 0.803994\n",
      "Epoch 109, step 250, training loss 0.651355, test_loss 0.814146, accuracy = 0.730083/0.801480, f1 = 0.805004\n",
      "Epoch 109, step 275, training loss 0.737362, test_loss 0.817205, accuracy = 0.739660/0.800609, f1 = 0.804698\n",
      "Epoch 109, step 300, training loss 0.635601, test_loss 0.838824, accuracy = 0.717022/0.800610, f1 = 0.805057\n",
      "Epoch 109, step 325, training loss 0.634061, test_loss 0.831094, accuracy = 0.720940/0.802786, f1 = 0.806721\n",
      "Epoch 109, step 350, training loss 0.673114, test_loss 0.830243, accuracy = 0.714845/0.803222, f1 = 0.806605\n",
      "Epoch 109, step 375, training loss 0.802117, test_loss 0.835335, accuracy = 0.724423/0.799303, f1 = 0.804899\n",
      "Epoch 109, step 400, training loss 0.669543, test_loss 0.832107, accuracy = 0.716587/0.796256, f1 = 0.801755\n",
      "End of epoch 109, training loss 0.557521, test_loss 0.832538, accuracy = 0.715716/0.795821, f1 = 0.801716\n",
      "Confusion matrix:\n",
      "[[823  49  19  46]\n",
      " [ 29 445  67  59]\n",
      " [ 15  59 426  53]\n",
      " [ 14  23  36 134]]\n",
      "Epoch 110, step 0, training loss 0.670203, test_loss 0.826949, accuracy = 0.716587/0.795821, f1 = 0.801716\n",
      "Epoch 110, step 25, training loss 0.602595, test_loss 0.841615, accuracy = 0.712233/0.794950, f1 = 0.800679\n",
      "Epoch 110, step 50, training loss 0.587480, test_loss 0.829087, accuracy = 0.716151/0.795385, f1 = 0.800802\n",
      "Epoch 110, step 75, training loss 0.584986, test_loss 0.822275, accuracy = 0.727906/0.801480, f1 = 0.805645\n",
      "Epoch 110, step 100, training loss 0.641040, test_loss 0.819637, accuracy = 0.724859/0.801916, f1 = 0.806525\n",
      "Epoch 110, step 125, training loss 0.576706, test_loss 0.815405, accuracy = 0.731389/0.801916, f1 = 0.806690\n",
      "Epoch 110, step 150, training loss 0.669902, test_loss 0.830949, accuracy = 0.725294/0.800174, f1 = 0.804451\n",
      "Epoch 110, step 175, training loss 0.776351, test_loss 0.829003, accuracy = 0.720940/0.798433, f1 = 0.803664\n",
      "Epoch 110, step 200, training loss 0.601649, test_loss 0.826790, accuracy = 0.715281/0.801916, f1 = 0.805942\n",
      "Epoch 110, step 225, training loss 0.585891, test_loss 0.831614, accuracy = 0.728341/0.801916, f1 = 0.806067\n",
      "Epoch 110, step 250, training loss 0.680015, test_loss 0.828129, accuracy = 0.729647/0.804092, f1 = 0.807705\n",
      "Epoch 110, step 275, training loss 0.624443, test_loss 0.825238, accuracy = 0.717893/0.802351, f1 = 0.806250\n",
      "Epoch 110, step 300, training loss 0.672961, test_loss 0.825715, accuracy = 0.723553/0.799303, f1 = 0.803680\n",
      "Epoch 110, step 325, training loss 0.658542, test_loss 0.826834, accuracy = 0.728777/0.797562, f1 = 0.801859\n",
      "Epoch 110, step 350, training loss 0.558431, test_loss 0.837413, accuracy = 0.717458/0.797997, f1 = 0.802033\n",
      "Epoch 110, step 375, training loss 0.740229, test_loss 0.838970, accuracy = 0.713975/0.795385, f1 = 0.800714\n",
      "Epoch 110, step 400, training loss 0.751528, test_loss 0.837296, accuracy = 0.720940/0.799303, f1 = 0.804176\n",
      "End of epoch 110, training loss 0.567739, test_loss 0.827677, accuracy = 0.715716/0.799739, f1 = 0.804260\n",
      "Confusion matrix:\n",
      "[[815  60  21  41]\n",
      " [ 25 458  71  46]\n",
      " [ 14  62 433  44]\n",
      " [ 14  23  39 131]]\n",
      "Epoch 111, step 0, training loss 0.614513, test_loss 0.832503, accuracy = 0.717022/0.798868, f1 = 0.803343\n",
      "Epoch 111, step 25, training loss 0.573414, test_loss 0.853418, accuracy = 0.712669/0.795385, f1 = 0.800212\n",
      "Epoch 111, step 50, training loss 0.592013, test_loss 0.843789, accuracy = 0.711798/0.798433, f1 = 0.802863\n",
      "Epoch 111, step 75, training loss 0.640199, test_loss 0.799474, accuracy = 0.737919/0.802786, f1 = 0.806754\n",
      "Epoch 111, step 100, training loss 0.644520, test_loss 0.807003, accuracy = 0.730518/0.798868, f1 = 0.803546\n",
      "Epoch 111, step 125, training loss 0.620565, test_loss 0.824395, accuracy = 0.726164/0.797562, f1 = 0.802261\n",
      "Epoch 111, step 150, training loss 0.762090, test_loss 0.827941, accuracy = 0.727906/0.804092, f1 = 0.808206\n",
      "Epoch 111, step 175, training loss 0.695046, test_loss 0.820983, accuracy = 0.724423/0.804963, f1 = 0.808674\n",
      "Epoch 111, step 200, training loss 0.553372, test_loss 0.828777, accuracy = 0.726600/0.804963, f1 = 0.808395\n",
      "Epoch 111, step 225, training loss 0.567937, test_loss 0.813258, accuracy = 0.723117/0.802786, f1 = 0.806355\n",
      "Epoch 111, step 250, training loss 0.566466, test_loss 0.830676, accuracy = 0.715281/0.802351, f1 = 0.805436\n",
      "Epoch 111, step 275, training loss 0.608060, test_loss 0.826000, accuracy = 0.733566/0.804963, f1 = 0.808334\n",
      "Epoch 111, step 300, training loss 0.651920, test_loss 0.827221, accuracy = 0.707880/0.801045, f1 = 0.804995\n",
      "Epoch 111, step 325, training loss 0.746344, test_loss 0.815533, accuracy = 0.729212/0.801480, f1 = 0.804968\n",
      "Epoch 111, step 350, training loss 0.614402, test_loss 0.828608, accuracy = 0.716587/0.801045, f1 = 0.804828\n",
      "Epoch 111, step 375, training loss 0.722019, test_loss 0.839022, accuracy = 0.717893/0.796691, f1 = 0.802015\n",
      "Epoch 111, step 400, training loss 0.674510, test_loss 0.836490, accuracy = 0.720940/0.791032, f1 = 0.796891\n",
      "End of epoch 111, training loss 0.590840, test_loss 0.834737, accuracy = 0.718328/0.794079, f1 = 0.799442\n",
      "Confusion matrix:\n",
      "[[828  49  19  41]\n",
      " [ 34 441  63  62]\n",
      " [ 17  61 421  54]\n",
      " [ 16  22  35 134]]\n",
      "Epoch 112, step 0, training loss 0.582890, test_loss 0.848983, accuracy = 0.710492/0.794950, f1 = 0.800325\n",
      "Epoch 112, step 25, training loss 0.561181, test_loss 0.828575, accuracy = 0.715716/0.796691, f1 = 0.801996\n",
      "Epoch 112, step 50, training loss 0.602446, test_loss 0.838863, accuracy = 0.720505/0.797562, f1 = 0.801919\n",
      "Epoch 112, step 75, training loss 0.659382, test_loss 0.815803, accuracy = 0.728777/0.801045, f1 = 0.804872\n",
      "Epoch 112, step 100, training loss 0.647261, test_loss 0.807492, accuracy = 0.724423/0.801045, f1 = 0.805232\n",
      "Epoch 112, step 125, training loss 0.591658, test_loss 0.825285, accuracy = 0.729647/0.800174, f1 = 0.804562\n",
      "Epoch 112, step 150, training loss 0.657343, test_loss 0.824627, accuracy = 0.723117/0.804963, f1 = 0.809130\n",
      "Epoch 112, step 175, training loss 0.793998, test_loss 0.839136, accuracy = 0.714410/0.799739, f1 = 0.803683\n",
      "Epoch 112, step 200, training loss 0.529033, test_loss 0.829458, accuracy = 0.723117/0.804963, f1 = 0.808095\n",
      "Epoch 112, step 225, training loss 0.582146, test_loss 0.823841, accuracy = 0.720070/0.807575, f1 = 0.810391\n",
      "Epoch 112, step 250, training loss 0.661036, test_loss 0.832324, accuracy = 0.722246/0.805398, f1 = 0.808205\n",
      "Epoch 112, step 275, training loss 0.620441, test_loss 0.840622, accuracy = 0.718764/0.802351, f1 = 0.805458\n",
      "Epoch 112, step 300, training loss 0.547509, test_loss 0.837062, accuracy = 0.710057/0.804528, f1 = 0.808180\n",
      "Epoch 112, step 325, training loss 0.829668, test_loss 0.831498, accuracy = 0.723117/0.805834, f1 = 0.809047\n",
      "Epoch 112, step 350, training loss 0.667102, test_loss 0.829345, accuracy = 0.723117/0.803222, f1 = 0.806148\n",
      "Epoch 112, step 375, training loss 0.696727, test_loss 0.828730, accuracy = 0.720070/0.795821, f1 = 0.799715\n",
      "Epoch 112, step 400, training loss 0.710592, test_loss 0.832956, accuracy = 0.718764/0.796691, f1 = 0.800834\n",
      "End of epoch 112, training loss 0.562226, test_loss 0.819182, accuracy = 0.723117/0.795821, f1 = 0.800047\n",
      "Confusion matrix:\n",
      "[[822  54  21  40]\n",
      " [ 33 452  69  46]\n",
      " [ 15  63 426  49]\n",
      " [ 15  24  40 128]]\n",
      "Epoch 113, step 0, training loss 0.645970, test_loss 0.842189, accuracy = 0.706574/0.795385, f1 = 0.799697\n",
      "Epoch 113, step 25, training loss 0.609636, test_loss 0.837791, accuracy = 0.709186/0.793209, f1 = 0.797111\n",
      "Epoch 113, step 50, training loss 0.638728, test_loss 0.816247, accuracy = 0.725294/0.794515, f1 = 0.798128\n",
      "Epoch 113, step 75, training loss 0.620336, test_loss 0.815708, accuracy = 0.733566/0.799303, f1 = 0.802118\n",
      "Epoch 113, step 100, training loss 0.609202, test_loss 0.821637, accuracy = 0.725729/0.801045, f1 = 0.804055\n",
      "Epoch 113, step 125, training loss 0.614227, test_loss 0.835015, accuracy = 0.720070/0.795385, f1 = 0.800081\n",
      "Epoch 113, step 150, training loss 0.691768, test_loss 0.843061, accuracy = 0.717893/0.794950, f1 = 0.800084\n",
      "Epoch 113, step 175, training loss 0.755284, test_loss 0.826606, accuracy = 0.725729/0.800174, f1 = 0.804306\n",
      "Epoch 113, step 200, training loss 0.575639, test_loss 0.826050, accuracy = 0.721376/0.801480, f1 = 0.805013\n",
      "Epoch 113, step 225, training loss 0.530662, test_loss 0.822422, accuracy = 0.735307/0.799303, f1 = 0.803838\n",
      "Epoch 113, step 250, training loss 0.569772, test_loss 0.831784, accuracy = 0.720940/0.801480, f1 = 0.804691\n",
      "Epoch 113, step 275, training loss 0.631163, test_loss 0.833403, accuracy = 0.716152/0.803657, f1 = 0.806636\n",
      "Epoch 113, step 300, training loss 0.613862, test_loss 0.816748, accuracy = 0.720505/0.801480, f1 = 0.804469\n",
      "Epoch 113, step 325, training loss 0.750175, test_loss 0.826280, accuracy = 0.722246/0.801916, f1 = 0.804424\n",
      "Epoch 113, step 350, training loss 0.724674, test_loss 0.843347, accuracy = 0.711363/0.801916, f1 = 0.804459\n",
      "Epoch 113, step 375, training loss 0.658719, test_loss 0.845659, accuracy = 0.705268/0.797127, f1 = 0.800343\n",
      "Epoch 113, step 400, training loss 0.599987, test_loss 0.831582, accuracy = 0.715716/0.795385, f1 = 0.799549\n",
      "End of epoch 113, training loss 0.594713, test_loss 0.843567, accuracy = 0.715716/0.797127, f1 = 0.801020\n",
      "Confusion matrix:\n",
      "[[824  53  23  37]\n",
      " [ 31 445  74  50]\n",
      " [ 16  58 435  44]\n",
      " [ 15  23  42 127]]\n",
      "Epoch 114, step 0, training loss 0.578426, test_loss 0.833675, accuracy = 0.717893/0.797127, f1 = 0.800959\n",
      "Epoch 114, step 25, training loss 0.641666, test_loss 0.839784, accuracy = 0.720070/0.797562, f1 = 0.801955\n",
      "Epoch 114, step 50, training loss 0.590347, test_loss 0.835635, accuracy = 0.723988/0.802351, f1 = 0.806272\n",
      "Epoch 114, step 75, training loss 0.599928, test_loss 0.816597, accuracy = 0.721376/0.802786, f1 = 0.806039\n",
      "Epoch 114, step 100, training loss 0.622364, test_loss 0.834204, accuracy = 0.727906/0.804528, f1 = 0.807893\n",
      "Epoch 114, step 125, training loss 0.563078, test_loss 0.819167, accuracy = 0.728777/0.802351, f1 = 0.805883\n",
      "Epoch 114, step 150, training loss 0.679261, test_loss 0.813168, accuracy = 0.726600/0.799303, f1 = 0.802993\n",
      "Epoch 114, step 175, training loss 0.774117, test_loss 0.834284, accuracy = 0.719199/0.800174, f1 = 0.803885\n",
      "Epoch 114, step 200, training loss 0.564781, test_loss 0.836315, accuracy = 0.712233/0.801045, f1 = 0.804283\n",
      "Epoch 114, step 225, training loss 0.516900, test_loss 0.824554, accuracy = 0.723988/0.799739, f1 = 0.803057\n",
      "Epoch 114, step 250, training loss 0.648662, test_loss 0.823414, accuracy = 0.722246/0.797997, f1 = 0.801398\n",
      "Epoch 114, step 275, training loss 0.639434, test_loss 0.824241, accuracy = 0.732695/0.805398, f1 = 0.808407\n",
      "Epoch 114, step 300, training loss 0.624382, test_loss 0.831857, accuracy = 0.719634/0.801916, f1 = 0.805782\n",
      "Epoch 114, step 325, training loss 0.653490, test_loss 0.834987, accuracy = 0.713975/0.800174, f1 = 0.803614\n",
      "Epoch 114, step 350, training loss 0.711565, test_loss 0.845535, accuracy = 0.711363/0.800610, f1 = 0.803360\n",
      "Epoch 114, step 375, training loss 0.763745, test_loss 0.825718, accuracy = 0.726165/0.798868, f1 = 0.802762\n",
      "Epoch 114, step 400, training loss 0.652757, test_loss 0.830608, accuracy = 0.722247/0.796691, f1 = 0.800574\n",
      "End of epoch 114, training loss 0.557997, test_loss 0.826611, accuracy = 0.717893/0.798868, f1 = 0.802472\n",
      "Confusion matrix:\n",
      "[[826  51  21  39]\n",
      " [ 38 447  67  48]\n",
      " [ 14  62 434  43]\n",
      " [ 16  22  41 128]]\n",
      "Epoch 115, step 0, training loss 0.644606, test_loss 0.829152, accuracy = 0.714846/0.798433, f1 = 0.802029\n",
      "Epoch 115, step 25, training loss 0.681756, test_loss 0.836332, accuracy = 0.715716/0.800174, f1 = 0.804126\n",
      "Epoch 115, step 50, training loss 0.622869, test_loss 0.839566, accuracy = 0.716587/0.797127, f1 = 0.801317\n",
      "Epoch 115, step 75, training loss 0.668864, test_loss 0.834276, accuracy = 0.716151/0.803222, f1 = 0.806131\n",
      "Epoch 115, step 100, training loss 0.651915, test_loss 0.816510, accuracy = 0.727471/0.801916, f1 = 0.805549\n",
      "Epoch 115, step 125, training loss 0.624917, test_loss 0.832714, accuracy = 0.724859/0.800610, f1 = 0.804461\n",
      "Epoch 115, step 150, training loss 0.686168, test_loss 0.813789, accuracy = 0.727035/0.801480, f1 = 0.805241\n",
      "Epoch 115, step 175, training loss 0.699790, test_loss 0.827113, accuracy = 0.726165/0.800174, f1 = 0.803177\n",
      "Epoch 115, step 200, training loss 0.520630, test_loss 0.831915, accuracy = 0.711798/0.800610, f1 = 0.803326\n",
      "Epoch 115, step 225, training loss 0.539278, test_loss 0.837012, accuracy = 0.725729/0.801916, f1 = 0.804993\n",
      "Epoch 115, step 250, training loss 0.643493, test_loss 0.827431, accuracy = 0.729647/0.800174, f1 = 0.803243\n",
      "Epoch 115, step 275, training loss 0.630515, test_loss 0.820087, accuracy = 0.729647/0.801916, f1 = 0.805090\n",
      "Epoch 115, step 300, training loss 0.571059, test_loss 0.821465, accuracy = 0.734872/0.800610, f1 = 0.804137\n",
      "Epoch 115, step 325, training loss 0.616297, test_loss 0.830166, accuracy = 0.721811/0.800174, f1 = 0.803434\n",
      "Epoch 115, step 350, training loss 0.742087, test_loss 0.835247, accuracy = 0.720505/0.801045, f1 = 0.803920\n",
      "Epoch 115, step 375, training loss 0.721495, test_loss 0.835841, accuracy = 0.723988/0.800174, f1 = 0.804824\n",
      "Epoch 115, step 400, training loss 0.692161, test_loss 0.834994, accuracy = 0.722247/0.794079, f1 = 0.799019\n",
      "End of epoch 115, training loss 0.613012, test_loss 0.834860, accuracy = 0.714410/0.797127, f1 = 0.801967\n",
      "Confusion matrix:\n",
      "[[818  57  19  43]\n",
      " [ 28 462  59  51]\n",
      " [ 16  67 423  47]\n",
      " [ 16  23  40 128]]\n",
      "Epoch 116, step 0, training loss 0.567820, test_loss 0.821158, accuracy = 0.723552/0.797127, f1 = 0.801967\n",
      "Epoch 116, step 25, training loss 0.637092, test_loss 0.838169, accuracy = 0.714410/0.798868, f1 = 0.803288\n",
      "Epoch 116, step 50, training loss 0.587247, test_loss 0.828805, accuracy = 0.727906/0.796691, f1 = 0.800494\n",
      "Epoch 116, step 75, training loss 0.623541, test_loss 0.804793, accuracy = 0.737048/0.801480, f1 = 0.804844\n",
      "Epoch 116, step 100, training loss 0.680106, test_loss 0.816298, accuracy = 0.722682/0.801916, f1 = 0.805928\n",
      "Epoch 116, step 125, training loss 0.624582, test_loss 0.816188, accuracy = 0.732695/0.801045, f1 = 0.805598\n",
      "Epoch 116, step 150, training loss 0.634087, test_loss 0.816003, accuracy = 0.720505/0.801045, f1 = 0.804834\n",
      "Epoch 116, step 175, training loss 0.740926, test_loss 0.838261, accuracy = 0.713539/0.802786, f1 = 0.806332\n",
      "Epoch 116, step 200, training loss 0.506979, test_loss 0.831397, accuracy = 0.723552/0.800174, f1 = 0.803819\n",
      "Epoch 116, step 225, training loss 0.574359, test_loss 0.815567, accuracy = 0.723988/0.797562, f1 = 0.801180\n",
      "Epoch 116, step 250, training loss 0.671082, test_loss 0.821967, accuracy = 0.719199/0.798433, f1 = 0.801369\n",
      "Epoch 116, step 275, training loss 0.598282, test_loss 0.818906, accuracy = 0.727471/0.801480, f1 = 0.804805\n",
      "Epoch 116, step 300, training loss 0.705420, test_loss 0.824126, accuracy = 0.720070/0.801045, f1 = 0.805021\n",
      "Epoch 116, step 325, training loss 0.728402, test_loss 0.833770, accuracy = 0.717458/0.800610, f1 = 0.804325\n",
      "Epoch 116, step 350, training loss 0.612733, test_loss 0.823896, accuracy = 0.729212/0.797127, f1 = 0.800886\n",
      "Epoch 116, step 375, training loss 0.766604, test_loss 0.838212, accuracy = 0.722246/0.793644, f1 = 0.799124\n",
      "Epoch 116, step 400, training loss 0.687639, test_loss 0.825231, accuracy = 0.723988/0.792338, f1 = 0.797791\n",
      "End of epoch 116, training loss 0.544860, test_loss 0.823918, accuracy = 0.723552/0.793209, f1 = 0.798561\n",
      "Confusion matrix:\n",
      "[[823  47  20  47]\n",
      " [ 34 440  68  58]\n",
      " [ 15  60 429  49]\n",
      " [ 15  23  39 130]]\n",
      "Epoch 117, step 0, training loss 0.588192, test_loss 0.837442, accuracy = 0.714846/0.794079, f1 = 0.799383\n",
      "Epoch 117, step 25, training loss 0.584899, test_loss 0.834083, accuracy = 0.717458/0.792773, f1 = 0.798329\n",
      "Epoch 117, step 50, training loss 0.660648, test_loss 0.836563, accuracy = 0.719199/0.795821, f1 = 0.801285\n",
      "Epoch 117, step 75, training loss 0.696578, test_loss 0.824505, accuracy = 0.723988/0.800174, f1 = 0.804853\n",
      "Epoch 117, step 100, training loss 0.683285, test_loss 0.821284, accuracy = 0.727906/0.799303, f1 = 0.803834\n",
      "Epoch 117, step 125, training loss 0.576779, test_loss 0.820264, accuracy = 0.722246/0.795821, f1 = 0.800869\n",
      "Epoch 117, step 150, training loss 0.705286, test_loss 0.839408, accuracy = 0.713104/0.796691, f1 = 0.802001\n",
      "Epoch 117, step 175, training loss 0.731280, test_loss 0.826461, accuracy = 0.725729/0.794950, f1 = 0.800061\n",
      "Epoch 117, step 200, training loss 0.509164, test_loss 0.822621, accuracy = 0.723988/0.800174, f1 = 0.804275\n",
      "Epoch 117, step 225, training loss 0.570998, test_loss 0.830357, accuracy = 0.717022/0.798868, f1 = 0.802856\n",
      "Epoch 117, step 250, training loss 0.715644, test_loss 0.855660, accuracy = 0.711798/0.800610, f1 = 0.804271\n",
      "Epoch 117, step 275, training loss 0.673702, test_loss 0.818420, accuracy = 0.724423/0.799303, f1 = 0.803160\n",
      "Epoch 117, step 300, training loss 0.671335, test_loss 0.836442, accuracy = 0.720070/0.799303, f1 = 0.803186\n",
      "Epoch 117, step 325, training loss 0.686774, test_loss 0.821234, accuracy = 0.732695/0.799739, f1 = 0.803044\n",
      "Epoch 117, step 350, training loss 0.584991, test_loss 0.824676, accuracy = 0.720505/0.797127, f1 = 0.800641\n",
      "Epoch 117, step 375, training loss 0.762843, test_loss 0.826362, accuracy = 0.720070/0.793209, f1 = 0.798156\n",
      "Epoch 117, step 400, training loss 0.688766, test_loss 0.835329, accuracy = 0.727906/0.792773, f1 = 0.798064\n",
      "End of epoch 117, training loss 0.571033, test_loss 0.832672, accuracy = 0.719199/0.793644, f1 = 0.798772\n",
      "Confusion matrix:\n",
      "[[816  54  21  46]\n",
      " [ 28 450  71  51]\n",
      " [ 14  62 430  47]\n",
      " [ 15  25  40 127]]\n",
      "Epoch 118, step 0, training loss 0.593507, test_loss 0.828574, accuracy = 0.717458/0.793644, f1 = 0.798772\n",
      "Epoch 118, step 25, training loss 0.613092, test_loss 0.832307, accuracy = 0.726165/0.791903, f1 = 0.797104\n",
      "Epoch 118, step 50, training loss 0.533291, test_loss 0.813124, accuracy = 0.728777/0.792773, f1 = 0.797762\n",
      "Epoch 118, step 75, training loss 0.623271, test_loss 0.820964, accuracy = 0.723552/0.799303, f1 = 0.803332\n",
      "Epoch 118, step 100, training loss 0.620265, test_loss 0.816522, accuracy = 0.733565/0.795821, f1 = 0.800612\n",
      "Epoch 118, step 125, training loss 0.554293, test_loss 0.828965, accuracy = 0.726165/0.794515, f1 = 0.800187\n",
      "Epoch 118, step 150, training loss 0.638022, test_loss 0.823961, accuracy = 0.721811/0.799739, f1 = 0.804384\n",
      "Epoch 118, step 175, training loss 0.769895, test_loss 0.826378, accuracy = 0.726600/0.800174, f1 = 0.803778\n",
      "Epoch 118, step 200, training loss 0.555750, test_loss 0.831808, accuracy = 0.724423/0.800610, f1 = 0.803762\n",
      "Epoch 118, step 225, training loss 0.568878, test_loss 0.828394, accuracy = 0.725729/0.800610, f1 = 0.803808\n",
      "Epoch 118, step 250, training loss 0.700401, test_loss 0.820547, accuracy = 0.717893/0.802786, f1 = 0.805976\n",
      "Epoch 118, step 275, training loss 0.695155, test_loss 0.825137, accuracy = 0.724859/0.801916, f1 = 0.805396\n",
      "Epoch 118, step 300, training loss 0.714241, test_loss 0.825502, accuracy = 0.726165/0.802786, f1 = 0.806692\n",
      "Epoch 118, step 325, training loss 0.703139, test_loss 0.815784, accuracy = 0.723553/0.801480, f1 = 0.805000\n",
      "Epoch 118, step 350, training loss 0.646959, test_loss 0.845063, accuracy = 0.710927/0.802786, f1 = 0.805350\n",
      "Epoch 118, step 375, training loss 0.892078, test_loss 0.829022, accuracy = 0.720070/0.795385, f1 = 0.799208\n",
      "Epoch 118, step 400, training loss 0.634485, test_loss 0.822159, accuracy = 0.727471/0.800174, f1 = 0.803931\n",
      "End of epoch 118, training loss 0.596901, test_loss 0.829589, accuracy = 0.721811/0.799739, f1 = 0.803263\n",
      "Confusion matrix:\n",
      "[[823  58  21  35]\n",
      " [ 32 453  70  45]\n",
      " [ 14  60 435  44]\n",
      " [ 16  25  40 126]]\n",
      "Epoch 119, step 0, training loss 0.638632, test_loss 0.827800, accuracy = 0.721811/0.800610, f1 = 0.804081\n",
      "Epoch 119, step 25, training loss 0.557480, test_loss 0.836804, accuracy = 0.720940/0.795385, f1 = 0.798648\n",
      "Epoch 119, step 50, training loss 0.586342, test_loss 0.824339, accuracy = 0.727906/0.800610, f1 = 0.803121\n",
      "Epoch 119, step 75, training loss 0.596385, test_loss 0.817456, accuracy = 0.724859/0.805398, f1 = 0.807283\n",
      "Epoch 119, step 100, training loss 0.692567, test_loss 0.821720, accuracy = 0.727471/0.805398, f1 = 0.808177\n",
      "Epoch 119, step 125, training loss 0.574293, test_loss 0.819320, accuracy = 0.730083/0.801480, f1 = 0.804525\n",
      "Epoch 119, step 150, training loss 0.639820, test_loss 0.821520, accuracy = 0.738790/0.799303, f1 = 0.803060\n",
      "Epoch 119, step 175, training loss 0.760100, test_loss 0.830677, accuracy = 0.717458/0.800610, f1 = 0.804435\n",
      "Epoch 119, step 200, training loss 0.606202, test_loss 0.812873, accuracy = 0.728777/0.807140, f1 = 0.809814\n",
      "Epoch 119, step 225, training loss 0.558002, test_loss 0.840238, accuracy = 0.723988/0.801916, f1 = 0.804784\n",
      "Epoch 119, step 250, training loss 0.695750, test_loss 0.826661, accuracy = 0.730083/0.803222, f1 = 0.806133\n",
      "Epoch 119, step 275, training loss 0.660769, test_loss 0.831286, accuracy = 0.726165/0.804092, f1 = 0.806616\n",
      "Epoch 119, step 300, training loss 0.652578, test_loss 0.827136, accuracy = 0.722247/0.804528, f1 = 0.807509\n",
      "Epoch 119, step 325, training loss 0.680998, test_loss 0.831922, accuracy = 0.720505/0.802351, f1 = 0.805469\n",
      "Epoch 119, step 350, training loss 0.681520, test_loss 0.844603, accuracy = 0.708751/0.804528, f1 = 0.806924\n",
      "Epoch 119, step 375, training loss 0.852174, test_loss 0.837449, accuracy = 0.723553/0.797997, f1 = 0.801912\n",
      "Epoch 119, step 400, training loss 0.705649, test_loss 0.831871, accuracy = 0.715716/0.799739, f1 = 0.803595\n",
      "End of epoch 119, training loss 0.579958, test_loss 0.840081, accuracy = 0.708315/0.801045, f1 = 0.804393\n",
      "Confusion matrix:\n",
      "[[821  57  22  37]\n",
      " [ 30 459  72  39]\n",
      " [ 16  64 431  42]\n",
      " [ 15  25  38 129]]\n",
      "Epoch 120, step 0, training loss 0.637057, test_loss 0.826769, accuracy = 0.713975/0.800610, f1 = 0.804035\n",
      "Epoch 120, step 25, training loss 0.540125, test_loss 0.838563, accuracy = 0.717893/0.795385, f1 = 0.799464\n",
      "Epoch 120, step 50, training loss 0.562354, test_loss 0.824824, accuracy = 0.711363/0.796691, f1 = 0.800674\n",
      "Epoch 120, step 75, training loss 0.699891, test_loss 0.825767, accuracy = 0.718328/0.800174, f1 = 0.803185\n",
      "Epoch 120, step 100, training loss 0.652967, test_loss 0.818808, accuracy = 0.733130/0.798868, f1 = 0.802335\n",
      "Epoch 120, step 125, training loss 0.595719, test_loss 0.832052, accuracy = 0.712669/0.797562, f1 = 0.801559\n",
      "Epoch 120, step 150, training loss 0.595319, test_loss 0.838350, accuracy = 0.710057/0.798868, f1 = 0.803505\n",
      "Epoch 120, step 175, training loss 0.758032, test_loss 0.828387, accuracy = 0.715281/0.797997, f1 = 0.802040\n",
      "Epoch 120, step 200, training loss 0.540093, test_loss 0.833905, accuracy = 0.716151/0.804092, f1 = 0.806885\n",
      "Epoch 120, step 225, training loss 0.512311, test_loss 0.822770, accuracy = 0.723552/0.800174, f1 = 0.803262\n",
      "Epoch 120, step 250, training loss 0.650699, test_loss 0.819410, accuracy = 0.720070/0.800609, f1 = 0.803607\n",
      "Epoch 120, step 275, training loss 0.632344, test_loss 0.829217, accuracy = 0.719199/0.801045, f1 = 0.804241\n",
      "Epoch 120, step 300, training loss 0.632081, test_loss 0.837255, accuracy = 0.717893/0.801916, f1 = 0.805026\n",
      "Epoch 120, step 325, training loss 0.749222, test_loss 0.831106, accuracy = 0.720070/0.802786, f1 = 0.805494\n",
      "Epoch 120, step 350, training loss 0.608876, test_loss 0.843353, accuracy = 0.708751/0.802786, f1 = 0.805488\n",
      "Epoch 120, step 375, training loss 0.817621, test_loss 0.834208, accuracy = 0.713975/0.797997, f1 = 0.801734\n",
      "Epoch 120, step 400, training loss 0.701102, test_loss 0.815390, accuracy = 0.730518/0.798868, f1 = 0.803169\n",
      "End of epoch 120, training loss 0.604630, test_loss 0.827495, accuracy = 0.721811/0.799303, f1 = 0.803152\n",
      "Confusion matrix:\n",
      "[[823  55  22  37]\n",
      " [ 27 453  75  45]\n",
      " [ 15  59 434  45]\n",
      " [ 16  25  40 126]]\n",
      "Epoch 121, step 0, training loss 0.618338, test_loss 0.824547, accuracy = 0.721376/0.799739, f1 = 0.803589\n",
      "Epoch 121, step 25, training loss 0.638205, test_loss 0.832048, accuracy = 0.721811/0.798868, f1 = 0.802217\n",
      "Epoch 121, step 50, training loss 0.543161, test_loss 0.827857, accuracy = 0.720505/0.799303, f1 = 0.802617\n",
      "Epoch 121, step 75, training loss 0.538843, test_loss 0.821875, accuracy = 0.727906/0.800610, f1 = 0.802992\n",
      "Epoch 121, step 100, training loss 0.630590, test_loss 0.820376, accuracy = 0.722682/0.801480, f1 = 0.804524\n",
      "Epoch 121, step 125, training loss 0.581742, test_loss 0.822263, accuracy = 0.721376/0.801480, f1 = 0.805144\n",
      "Epoch 121, step 150, training loss 0.636963, test_loss 0.840068, accuracy = 0.718764/0.801916, f1 = 0.805462\n",
      "Epoch 121, step 175, training loss 0.731647, test_loss 0.832132, accuracy = 0.716587/0.802786, f1 = 0.805618\n",
      "Epoch 121, step 200, training loss 0.545160, test_loss 0.837540, accuracy = 0.719634/0.805834, f1 = 0.807934\n",
      "Epoch 121, step 225, training loss 0.512792, test_loss 0.833430, accuracy = 0.722246/0.798868, f1 = 0.800924\n",
      "Epoch 121, step 250, training loss 0.642236, test_loss 0.835805, accuracy = 0.720940/0.801916, f1 = 0.804173\n",
      "Epoch 121, step 275, training loss 0.682507, test_loss 0.818347, accuracy = 0.732695/0.801480, f1 = 0.804347\n",
      "Epoch 121, step 300, training loss 0.650788, test_loss 0.831915, accuracy = 0.719634/0.802786, f1 = 0.805856\n",
      "Epoch 121, step 325, training loss 0.745689, test_loss 0.824509, accuracy = 0.733130/0.802786, f1 = 0.805841\n",
      "Epoch 121, step 350, training loss 0.659978, test_loss 0.827509, accuracy = 0.715716/0.799739, f1 = 0.802390\n",
      "Epoch 121, step 375, training loss 0.737323, test_loss 0.833099, accuracy = 0.722246/0.799303, f1 = 0.802965\n",
      "Epoch 121, step 400, training loss 0.661581, test_loss 0.826470, accuracy = 0.727471/0.797127, f1 = 0.801028\n",
      "End of epoch 121, training loss 0.544721, test_loss 0.827945, accuracy = 0.719199/0.797997, f1 = 0.801973\n",
      "Confusion matrix:\n",
      "[[823  53  21  40]\n",
      " [ 34 449  68  49]\n",
      " [ 16  60 433  44]\n",
      " [ 15  24  40 128]]\n",
      "Epoch 122, step 0, training loss 0.658342, test_loss 0.838350, accuracy = 0.718328/0.797127, f1 = 0.801084\n",
      "Epoch 122, step 25, training loss 0.619871, test_loss 0.832229, accuracy = 0.709621/0.797562, f1 = 0.801372\n",
      "Epoch 122, step 50, training loss 0.552021, test_loss 0.829367, accuracy = 0.730083/0.802351, f1 = 0.806747\n",
      "Epoch 122, step 75, training loss 0.654096, test_loss 0.808381, accuracy = 0.731389/0.801916, f1 = 0.804959\n",
      "Epoch 122, step 100, training loss 0.706468, test_loss 0.822302, accuracy = 0.730953/0.800174, f1 = 0.803865\n",
      "Epoch 122, step 125, training loss 0.545510, test_loss 0.822298, accuracy = 0.725729/0.799303, f1 = 0.803598\n",
      "Epoch 122, step 150, training loss 0.659531, test_loss 0.831795, accuracy = 0.720070/0.800610, f1 = 0.804665\n",
      "Epoch 122, step 175, training loss 0.748639, test_loss 0.837283, accuracy = 0.724423/0.799739, f1 = 0.803731\n",
      "Epoch 122, step 200, training loss 0.605944, test_loss 0.819045, accuracy = 0.722682/0.803657, f1 = 0.806867\n",
      "Epoch 122, step 225, training loss 0.564653, test_loss 0.829338, accuracy = 0.726165/0.802786, f1 = 0.805909\n",
      "Epoch 122, step 250, training loss 0.614873, test_loss 0.812754, accuracy = 0.723552/0.802351, f1 = 0.804950\n",
      "Epoch 122, step 275, training loss 0.563395, test_loss 0.822414, accuracy = 0.721376/0.802351, f1 = 0.805858\n",
      "Epoch 122, step 300, training loss 0.597565, test_loss 0.822520, accuracy = 0.721376/0.801480, f1 = 0.805315\n",
      "Epoch 122, step 325, training loss 0.697352, test_loss 0.835697, accuracy = 0.718764/0.800610, f1 = 0.804278\n",
      "Epoch 122, step 350, training loss 0.659669, test_loss 0.836674, accuracy = 0.717893/0.799739, f1 = 0.803462\n",
      "Epoch 122, step 375, training loss 0.738734, test_loss 0.827065, accuracy = 0.720070/0.793209, f1 = 0.798136\n",
      "Epoch 122, step 400, training loss 0.634058, test_loss 0.827915, accuracy = 0.716151/0.795385, f1 = 0.799896\n",
      "End of epoch 122, training loss 0.607649, test_loss 0.838874, accuracy = 0.710927/0.795385, f1 = 0.799753\n",
      "Confusion matrix:\n",
      "[[820  53  22  42]\n",
      " [ 32 443  75  50]\n",
      " [ 15  56 437  45]\n",
      " [ 14  23  43 127]]\n",
      "Epoch 123, step 0, training loss 0.598319, test_loss 0.831743, accuracy = 0.719634/0.796691, f1 = 0.801079\n",
      "Epoch 123, step 25, training loss 0.545353, test_loss 0.830240, accuracy = 0.714410/0.796691, f1 = 0.801070\n",
      "Epoch 123, step 50, training loss 0.562800, test_loss 0.835336, accuracy = 0.718764/0.801480, f1 = 0.804677\n",
      "Epoch 123, step 75, training loss 0.651476, test_loss 0.832554, accuracy = 0.719199/0.802786, f1 = 0.805357\n",
      "Epoch 123, step 100, training loss 0.598487, test_loss 0.813720, accuracy = 0.724859/0.802786, f1 = 0.806136\n",
      "Epoch 123, step 125, training loss 0.632536, test_loss 0.808616, accuracy = 0.736613/0.800174, f1 = 0.803718\n",
      "Epoch 123, step 150, training loss 0.663281, test_loss 0.825107, accuracy = 0.726165/0.802351, f1 = 0.805726\n",
      "Epoch 123, step 175, training loss 0.681277, test_loss 0.822543, accuracy = 0.727035/0.797997, f1 = 0.801930\n",
      "Epoch 123, step 200, training loss 0.514816, test_loss 0.837602, accuracy = 0.714846/0.800609, f1 = 0.804181\n",
      "Epoch 123, step 225, training loss 0.563779, test_loss 0.817124, accuracy = 0.718328/0.798433, f1 = 0.802244\n",
      "Epoch 123, step 250, training loss 0.619727, test_loss 0.827189, accuracy = 0.732695/0.800174, f1 = 0.803574\n",
      "Epoch 123, step 275, training loss 0.593163, test_loss 0.818762, accuracy = 0.724859/0.799303, f1 = 0.802865\n",
      "Epoch 123, step 300, training loss 0.655055, test_loss 0.819370, accuracy = 0.724859/0.798433, f1 = 0.803019\n",
      "Epoch 123, step 325, training loss 0.700067, test_loss 0.814955, accuracy = 0.722682/0.797127, f1 = 0.801400\n",
      "Epoch 123, step 350, training loss 0.680555, test_loss 0.837391, accuracy = 0.708751/0.797127, f1 = 0.801024\n",
      "Epoch 123, step 375, training loss 0.730202, test_loss 0.844759, accuracy = 0.716151/0.793209, f1 = 0.798350\n",
      "Epoch 123, step 400, training loss 0.656776, test_loss 0.840358, accuracy = 0.713975/0.791903, f1 = 0.796758\n",
      "End of epoch 123, training loss 0.582093, test_loss 0.831981, accuracy = 0.726165/0.793209, f1 = 0.798096\n",
      "Confusion matrix:\n",
      "[[821  51  21  44]\n",
      " [ 34 448  70  48]\n",
      " [ 14  63 423  53]\n",
      " [ 15  23  39 130]]\n",
      "Epoch 124, step 0, training loss 0.661300, test_loss 0.833994, accuracy = 0.712233/0.792773, f1 = 0.797655\n",
      "Epoch 124, step 25, training loss 0.548892, test_loss 0.840658, accuracy = 0.707880/0.797127, f1 = 0.801469\n",
      "Epoch 124, step 50, training loss 0.541165, test_loss 0.826404, accuracy = 0.723552/0.797127, f1 = 0.800913\n",
      "Epoch 124, step 75, training loss 0.672944, test_loss 0.820374, accuracy = 0.724859/0.801916, f1 = 0.805190\n",
      "Epoch 124, step 100, training loss 0.649141, test_loss 0.826007, accuracy = 0.723117/0.801480, f1 = 0.805414\n",
      "Epoch 124, step 125, training loss 0.624139, test_loss 0.839415, accuracy = 0.716151/0.800174, f1 = 0.804513\n",
      "Epoch 124, step 150, training loss 0.642439, test_loss 0.833399, accuracy = 0.716587/0.802351, f1 = 0.806515\n",
      "Epoch 124, step 175, training loss 0.760699, test_loss 0.828755, accuracy = 0.723988/0.799739, f1 = 0.803260\n",
      "Epoch 124, step 200, training loss 0.520008, test_loss 0.830068, accuracy = 0.720940/0.803222, f1 = 0.806428\n",
      "Epoch 124, step 225, training loss 0.566896, test_loss 0.827076, accuracy = 0.720505/0.801916, f1 = 0.805113\n",
      "Epoch 124, step 250, training loss 0.661802, test_loss 0.839848, accuracy = 0.719634/0.800610, f1 = 0.803781\n",
      "Epoch 124, step 275, training loss 0.582792, test_loss 0.832866, accuracy = 0.718764/0.800610, f1 = 0.804214\n",
      "Epoch 124, step 300, training loss 0.642440, test_loss 0.818579, accuracy = 0.723552/0.800174, f1 = 0.803736\n",
      "Epoch 124, step 325, training loss 0.692208, test_loss 0.848703, accuracy = 0.710057/0.802351, f1 = 0.805294\n",
      "Epoch 124, step 350, training loss 0.583225, test_loss 0.842172, accuracy = 0.711363/0.800174, f1 = 0.802658\n",
      "Epoch 124, step 375, training loss 0.808830, test_loss 0.844980, accuracy = 0.705703/0.800610, f1 = 0.804973\n",
      "Epoch 124, step 400, training loss 0.643921, test_loss 0.835083, accuracy = 0.722246/0.800174, f1 = 0.804898\n",
      "End of epoch 124, training loss 0.575391, test_loss 0.836907, accuracy = 0.712669/0.798868, f1 = 0.803185\n",
      "Confusion matrix:\n",
      "[[813  59  22  43]\n",
      " [ 27 463  67  43]\n",
      " [ 14  63 433  43]\n",
      " [ 14  28  39 126]]\n",
      "Epoch 125, step 0, training loss 0.613306, test_loss 0.838949, accuracy = 0.714410/0.798433, f1 = 0.802699\n",
      "Epoch 125, step 25, training loss 0.540407, test_loss 0.837338, accuracy = 0.721376/0.796691, f1 = 0.800818\n",
      "Epoch 125, step 50, training loss 0.574006, test_loss 0.842693, accuracy = 0.711363/0.797997, f1 = 0.802029\n",
      "Epoch 125, step 75, training loss 0.611654, test_loss 0.829360, accuracy = 0.721811/0.797562, f1 = 0.801659\n",
      "Epoch 125, step 100, training loss 0.637187, test_loss 0.812190, accuracy = 0.732695/0.797562, f1 = 0.802518\n",
      "Epoch 125, step 125, training loss 0.594368, test_loss 0.850456, accuracy = 0.719199/0.796256, f1 = 0.801934\n",
      "Epoch 125, step 150, training loss 0.548411, test_loss 0.834193, accuracy = 0.729647/0.796691, f1 = 0.801623\n",
      "Epoch 125, step 175, training loss 0.701779, test_loss 0.837094, accuracy = 0.712669/0.794950, f1 = 0.799571\n",
      "Epoch 125, step 200, training loss 0.574184, test_loss 0.835907, accuracy = 0.720505/0.796691, f1 = 0.800280\n",
      "Epoch 125, step 225, training loss 0.560143, test_loss 0.841972, accuracy = 0.722682/0.797997, f1 = 0.801438\n",
      "Epoch 125, step 250, training loss 0.608294, test_loss 0.826622, accuracy = 0.723117/0.800610, f1 = 0.803867\n",
      "Epoch 125, step 275, training loss 0.632627, test_loss 0.830624, accuracy = 0.727471/0.800610, f1 = 0.804301\n",
      "Epoch 125, step 300, training loss 0.680383, test_loss 0.843519, accuracy = 0.720070/0.801045, f1 = 0.804210\n",
      "Epoch 125, step 325, training loss 0.800738, test_loss 0.823216, accuracy = 0.721376/0.794950, f1 = 0.798592\n",
      "Epoch 125, step 350, training loss 0.718689, test_loss 0.830857, accuracy = 0.725729/0.797127, f1 = 0.800128\n",
      "Epoch 125, step 375, training loss 0.741298, test_loss 0.833130, accuracy = 0.723553/0.792773, f1 = 0.796957\n",
      "Epoch 125, step 400, training loss 0.659527, test_loss 0.832365, accuracy = 0.718764/0.797127, f1 = 0.800887\n",
      "End of epoch 125, training loss 0.619398, test_loss 0.840082, accuracy = 0.706574/0.796256, f1 = 0.799906\n",
      "Confusion matrix:\n",
      "[[823  52  25  37]\n",
      " [ 32 443  77  48]\n",
      " [ 16  60 435  42]\n",
      " [ 15  23  41 128]]\n",
      "Epoch 126, step 0, training loss 0.612458, test_loss 0.841935, accuracy = 0.707880/0.796691, f1 = 0.800349\n",
      "Epoch 126, step 25, training loss 0.659937, test_loss 0.832434, accuracy = 0.717893/0.793209, f1 = 0.798281\n",
      "Epoch 126, step 50, training loss 0.653733, test_loss 0.836916, accuracy = 0.717893/0.793644, f1 = 0.798677\n",
      "Epoch 126, step 75, training loss 0.622829, test_loss 0.798729, accuracy = 0.734436/0.803657, f1 = 0.807392\n",
      "Epoch 126, step 100, training loss 0.698518, test_loss 0.812968, accuracy = 0.732260/0.796691, f1 = 0.801833\n",
      "Epoch 126, step 125, training loss 0.589873, test_loss 0.824688, accuracy = 0.720505/0.797997, f1 = 0.802998\n",
      "Epoch 126, step 150, training loss 0.603234, test_loss 0.820786, accuracy = 0.717893/0.797562, f1 = 0.802477\n",
      "Epoch 126, step 175, training loss 0.693354, test_loss 0.818432, accuracy = 0.736613/0.801045, f1 = 0.804992\n",
      "Epoch 126, step 200, training loss 0.531002, test_loss 0.833792, accuracy = 0.717458/0.805398, f1 = 0.808468\n",
      "Epoch 126, step 225, training loss 0.495775, test_loss 0.824420, accuracy = 0.723552/0.801045, f1 = 0.804391\n",
      "Epoch 126, step 250, training loss 0.662520, test_loss 0.837673, accuracy = 0.709621/0.802351, f1 = 0.805779\n",
      "Epoch 126, step 275, training loss 0.629733, test_loss 0.832500, accuracy = 0.717022/0.804528, f1 = 0.807640\n",
      "Epoch 126, step 300, training loss 0.612226, test_loss 0.829197, accuracy = 0.726165/0.801916, f1 = 0.805310\n",
      "Epoch 126, step 325, training loss 0.667142, test_loss 0.824402, accuracy = 0.721811/0.802351, f1 = 0.805584\n",
      "Epoch 126, step 350, training loss 0.540757, test_loss 0.821914, accuracy = 0.720070/0.801480, f1 = 0.804035\n",
      "Epoch 126, step 375, training loss 0.762869, test_loss 0.831178, accuracy = 0.723988/0.803222, f1 = 0.806524\n",
      "Epoch 126, step 400, training loss 0.589671, test_loss 0.825187, accuracy = 0.720940/0.799303, f1 = 0.803117\n",
      "End of epoch 126, training loss 0.586643, test_loss 0.831361, accuracy = 0.727906/0.799739, f1 = 0.804086\n",
      "Confusion matrix:\n",
      "[[823  52  24  38]\n",
      " [ 30 452  69  49]\n",
      " [ 14  59 433  47]\n",
      " [ 13  24  41 129]]\n",
      "Epoch 127, step 0, training loss 0.675073, test_loss 0.838632, accuracy = 0.714845/0.800174, f1 = 0.804530\n",
      "Epoch 127, step 25, training loss 0.584078, test_loss 0.850668, accuracy = 0.708751/0.795821, f1 = 0.800526\n",
      "Epoch 127, step 50, training loss 0.625702, test_loss 0.831107, accuracy = 0.720940/0.798868, f1 = 0.803278\n",
      "Epoch 127, step 75, training loss 0.586073, test_loss 0.822953, accuracy = 0.721811/0.804092, f1 = 0.807421\n",
      "Epoch 127, step 100, training loss 0.689843, test_loss 0.823857, accuracy = 0.714845/0.798433, f1 = 0.803194\n",
      "Epoch 127, step 125, training loss 0.642641, test_loss 0.830465, accuracy = 0.721811/0.794079, f1 = 0.800306\n",
      "Epoch 127, step 150, training loss 0.672894, test_loss 0.835968, accuracy = 0.714846/0.791032, f1 = 0.797590\n",
      "Epoch 127, step 175, training loss 0.762134, test_loss 0.816608, accuracy = 0.733566/0.794515, f1 = 0.799896\n",
      "Epoch 127, step 200, training loss 0.548198, test_loss 0.825872, accuracy = 0.721811/0.801480, f1 = 0.805495\n",
      "Epoch 127, step 225, training loss 0.515328, test_loss 0.813580, accuracy = 0.730953/0.801480, f1 = 0.804815\n",
      "Epoch 127, step 250, training loss 0.571177, test_loss 0.826346, accuracy = 0.724423/0.800610, f1 = 0.803543\n",
      "Epoch 127, step 275, training loss 0.533946, test_loss 0.819242, accuracy = 0.729647/0.800610, f1 = 0.804139\n",
      "Epoch 127, step 300, training loss 0.618567, test_loss 0.837799, accuracy = 0.716152/0.798433, f1 = 0.802273\n",
      "Epoch 127, step 325, training loss 0.633423, test_loss 0.825460, accuracy = 0.725294/0.799303, f1 = 0.802852\n",
      "Epoch 127, step 350, training loss 0.692837, test_loss 0.835183, accuracy = 0.710927/0.797997, f1 = 0.801554\n",
      "Epoch 127, step 375, training loss 0.759614, test_loss 0.847157, accuracy = 0.710057/0.793644, f1 = 0.799100\n",
      "Epoch 127, step 400, training loss 0.640184, test_loss 0.835239, accuracy = 0.719634/0.788855, f1 = 0.794745\n",
      "End of epoch 127, training loss 0.570606, test_loss 0.829742, accuracy = 0.723117/0.791032, f1 = 0.796145\n",
      "Confusion matrix:\n",
      "[[818  52  22  45]\n",
      " [ 33 438  74  55]\n",
      " [ 15  56 433  49]\n",
      " [ 15  23  41 128]]\n",
      "Epoch 128, step 0, training loss 0.642899, test_loss 0.828381, accuracy = 0.721811/0.790596, f1 = 0.795634\n",
      "Epoch 128, step 25, training loss 0.547779, test_loss 0.829745, accuracy = 0.712669/0.794079, f1 = 0.798665\n",
      "Epoch 128, step 50, training loss 0.611795, test_loss 0.825133, accuracy = 0.716152/0.793209, f1 = 0.797355\n",
      "Epoch 128, step 75, training loss 0.635904, test_loss 0.831915, accuracy = 0.720940/0.800610, f1 = 0.804403\n",
      "Epoch 128, step 100, training loss 0.648771, test_loss 0.835912, accuracy = 0.721376/0.797562, f1 = 0.802192\n",
      "Epoch 128, step 125, training loss 0.601690, test_loss 0.806979, accuracy = 0.730518/0.792773, f1 = 0.799170\n",
      "Epoch 128, step 150, training loss 0.650240, test_loss 0.823448, accuracy = 0.722246/0.795385, f1 = 0.800571\n",
      "Epoch 128, step 175, training loss 0.742288, test_loss 0.836818, accuracy = 0.720070/0.798868, f1 = 0.802974\n",
      "Epoch 128, step 200, training loss 0.515530, test_loss 0.818606, accuracy = 0.732695/0.800610, f1 = 0.804155\n",
      "Epoch 128, step 225, training loss 0.584496, test_loss 0.836159, accuracy = 0.719634/0.799739, f1 = 0.803677\n",
      "Epoch 128, step 250, training loss 0.778377, test_loss 0.818750, accuracy = 0.725729/0.801480, f1 = 0.804567\n",
      "Epoch 128, step 275, training loss 0.575824, test_loss 0.822444, accuracy = 0.726165/0.799739, f1 = 0.803303\n",
      "Epoch 128, step 300, training loss 0.633655, test_loss 0.827333, accuracy = 0.720070/0.795821, f1 = 0.800180\n",
      "Epoch 128, step 325, training loss 0.718426, test_loss 0.839014, accuracy = 0.712669/0.798868, f1 = 0.802818\n",
      "Epoch 128, step 350, training loss 0.590572, test_loss 0.842434, accuracy = 0.716152/0.799739, f1 = 0.802950\n",
      "Epoch 128, step 375, training loss 0.734209, test_loss 0.846303, accuracy = 0.712233/0.790596, f1 = 0.796563\n",
      "Epoch 128, step 400, training loss 0.607373, test_loss 0.823144, accuracy = 0.720070/0.789726, f1 = 0.794629\n",
      "End of epoch 128, training loss 0.604549, test_loss 0.824968, accuracy = 0.731824/0.794515, f1 = 0.798643\n",
      "Confusion matrix:\n",
      "[[828  47  23  39]\n",
      " [ 34 437  73  56]\n",
      " [ 19  57 431  46]\n",
      " [ 17  19  42 129]]\n",
      "Epoch 129, step 0, training loss 0.638550, test_loss 0.824821, accuracy = 0.729212/0.794950, f1 = 0.799041\n",
      "Epoch 129, step 25, training loss 0.660917, test_loss 0.821638, accuracy = 0.721376/0.800174, f1 = 0.803746\n",
      "Epoch 129, step 50, training loss 0.602417, test_loss 0.835756, accuracy = 0.714846/0.800610, f1 = 0.804613\n",
      "Epoch 129, step 75, training loss 0.646665, test_loss 0.813572, accuracy = 0.733130/0.801045, f1 = 0.804540\n",
      "Epoch 129, step 100, training loss 0.660153, test_loss 0.826091, accuracy = 0.725294/0.798868, f1 = 0.802656\n",
      "Epoch 129, step 125, training loss 0.584328, test_loss 0.822899, accuracy = 0.720940/0.798868, f1 = 0.802559\n",
      "Epoch 129, step 150, training loss 0.705669, test_loss 0.817503, accuracy = 0.726165/0.800174, f1 = 0.804042\n",
      "Epoch 129, step 175, training loss 0.688642, test_loss 0.816007, accuracy = 0.729647/0.800174, f1 = 0.803424\n",
      "Epoch 129, step 200, training loss 0.577800, test_loss 0.819551, accuracy = 0.717022/0.803222, f1 = 0.805963\n",
      "Epoch 129, step 225, training loss 0.488982, test_loss 0.836074, accuracy = 0.710492/0.801045, f1 = 0.804274\n",
      "Epoch 129, step 250, training loss 0.606268, test_loss 0.822439, accuracy = 0.725729/0.798868, f1 = 0.801902\n",
      "Epoch 129, step 275, training loss 0.675275, test_loss 0.834941, accuracy = 0.710492/0.800610, f1 = 0.803694\n",
      "Epoch 129, step 300, training loss 0.630327, test_loss 0.839849, accuracy = 0.721811/0.798868, f1 = 0.801554\n",
      "Epoch 129, step 325, training loss 0.725678, test_loss 0.844666, accuracy = 0.717022/0.795821, f1 = 0.799305\n",
      "Epoch 129, step 350, training loss 0.565342, test_loss 0.851086, accuracy = 0.703526/0.797562, f1 = 0.800810\n",
      "Epoch 129, step 375, training loss 0.778247, test_loss 0.825883, accuracy = 0.716151/0.792773, f1 = 0.796846\n",
      "Epoch 129, step 400, training loss 0.600183, test_loss 0.833858, accuracy = 0.714845/0.794079, f1 = 0.797340\n",
      "End of epoch 129, training loss 0.589057, test_loss 0.836013, accuracy = 0.719634/0.798433, f1 = 0.801149\n",
      "Confusion matrix:\n",
      "[[830  51  22  34]\n",
      " [ 36 448  71  45]\n",
      " [ 21  59 431  42]\n",
      " [ 18  23  41 125]]\n",
      "Epoch 130, step 0, training loss 0.782673, test_loss 0.827217, accuracy = 0.718764/0.798433, f1 = 0.801149\n",
      "Epoch 130, step 25, training loss 0.597041, test_loss 0.847098, accuracy = 0.713539/0.794079, f1 = 0.797045\n",
      "Epoch 130, step 50, training loss 0.586400, test_loss 0.829349, accuracy = 0.713975/0.798868, f1 = 0.802181\n",
      "Epoch 130, step 75, training loss 0.669433, test_loss 0.813914, accuracy = 0.723552/0.801045, f1 = 0.803660\n",
      "Epoch 130, step 100, training loss 0.609648, test_loss 0.823312, accuracy = 0.717458/0.797562, f1 = 0.801393\n",
      "Epoch 130, step 125, training loss 0.599177, test_loss 0.826794, accuracy = 0.720940/0.796256, f1 = 0.800944\n",
      "Epoch 130, step 150, training loss 0.587394, test_loss 0.833353, accuracy = 0.720505/0.797562, f1 = 0.802632\n",
      "Epoch 130, step 175, training loss 0.680279, test_loss 0.825771, accuracy = 0.728777/0.798868, f1 = 0.803250\n",
      "Epoch 130, step 200, training loss 0.567678, test_loss 0.823154, accuracy = 0.730083/0.799303, f1 = 0.803290\n",
      "Epoch 130, step 225, training loss 0.533448, test_loss 0.822846, accuracy = 0.728341/0.801045, f1 = 0.805391\n",
      "Epoch 130, step 250, training loss 0.596392, test_loss 0.834868, accuracy = 0.712233/0.800174, f1 = 0.804393\n",
      "Epoch 130, step 275, training loss 0.660703, test_loss 0.832326, accuracy = 0.720505/0.801916, f1 = 0.806120\n",
      "Epoch 130, step 300, training loss 0.601732, test_loss 0.829326, accuracy = 0.728777/0.800174, f1 = 0.804646\n",
      "Epoch 130, step 325, training loss 0.790048, test_loss 0.832819, accuracy = 0.719199/0.795385, f1 = 0.800194\n",
      "Epoch 130, step 350, training loss 0.707552, test_loss 0.840893, accuracy = 0.713539/0.794950, f1 = 0.798055\n",
      "Epoch 130, step 375, training loss 0.703303, test_loss 0.835730, accuracy = 0.717458/0.793209, f1 = 0.797118\n",
      "Epoch 130, step 400, training loss 0.695227, test_loss 0.834922, accuracy = 0.711798/0.791467, f1 = 0.795202\n",
      "End of epoch 130, training loss 0.546000, test_loss 0.827243, accuracy = 0.719199/0.794950, f1 = 0.798372\n",
      "Confusion matrix:\n",
      "[[827  51  22  37]\n",
      " [ 39 436  75  50]\n",
      " [ 16  59 434  44]\n",
      " [ 17  20  41 129]]\n",
      "Epoch 131, step 0, training loss 0.619416, test_loss 0.822357, accuracy = 0.720070/0.794079, f1 = 0.797575\n",
      "Epoch 131, step 25, training loss 0.554981, test_loss 0.840352, accuracy = 0.709621/0.794515, f1 = 0.798371\n",
      "Epoch 131, step 50, training loss 0.591952, test_loss 0.840408, accuracy = 0.707445/0.790596, f1 = 0.794579\n",
      "Epoch 131, step 75, training loss 0.545911, test_loss 0.816663, accuracy = 0.732260/0.794079, f1 = 0.796867\n",
      "Epoch 131, step 100, training loss 0.672478, test_loss 0.822684, accuracy = 0.724859/0.794950, f1 = 0.798240\n",
      "Epoch 131, step 125, training loss 0.570912, test_loss 0.827259, accuracy = 0.715281/0.791467, f1 = 0.795930\n",
      "Epoch 131, step 150, training loss 0.592519, test_loss 0.830490, accuracy = 0.722246/0.794515, f1 = 0.798860\n",
      "Epoch 131, step 175, training loss 0.698082, test_loss 0.841859, accuracy = 0.719199/0.797562, f1 = 0.800983\n",
      "Epoch 131, step 200, training loss 0.596732, test_loss 0.833956, accuracy = 0.714846/0.801045, f1 = 0.803403\n",
      "Epoch 131, step 225, training loss 0.547349, test_loss 0.828024, accuracy = 0.723552/0.801480, f1 = 0.803829\n",
      "Epoch 131, step 250, training loss 0.638454, test_loss 0.824324, accuracy = 0.722682/0.801916, f1 = 0.804274\n",
      "Epoch 131, step 275, training loss 0.635347, test_loss 0.819133, accuracy = 0.732695/0.804092, f1 = 0.806487\n",
      "Epoch 131, step 300, training loss 0.688083, test_loss 0.813516, accuracy = 0.732695/0.803222, f1 = 0.806045\n",
      "Epoch 131, step 325, training loss 0.690805, test_loss 0.822903, accuracy = 0.728777/0.800610, f1 = 0.803526\n",
      "Epoch 131, step 350, training loss 0.579774, test_loss 0.832956, accuracy = 0.727906/0.797562, f1 = 0.799964\n",
      "Epoch 131, step 375, training loss 0.861387, test_loss 0.829677, accuracy = 0.719634/0.794079, f1 = 0.798195\n",
      "Epoch 131, step 400, training loss 0.687478, test_loss 0.827364, accuracy = 0.723117/0.793644, f1 = 0.797811\n",
      "End of epoch 131, training loss 0.696183, test_loss 0.830373, accuracy = 0.723117/0.797562, f1 = 0.801312\n",
      "Confusion matrix:\n",
      "[[825  49  26  37]\n",
      " [ 33 441  77  49]\n",
      " [ 16  51 440  46]\n",
      " [ 17  21  43 126]]\n",
      "Epoch 132, step 0, training loss 0.723461, test_loss 0.847194, accuracy = 0.713539/0.798433, f1 = 0.802078\n",
      "Epoch 132, step 25, training loss 0.601294, test_loss 0.816807, accuracy = 0.730083/0.796256, f1 = 0.800318\n",
      "Epoch 132, step 50, training loss 0.638263, test_loss 0.826314, accuracy = 0.722682/0.797562, f1 = 0.801475\n",
      "Epoch 132, step 75, training loss 0.677127, test_loss 0.820574, accuracy = 0.735742/0.800174, f1 = 0.803564\n",
      "Epoch 132, step 100, training loss 0.633750, test_loss 0.810205, accuracy = 0.720505/0.800610, f1 = 0.804786\n",
      "Epoch 132, step 125, training loss 0.613120, test_loss 0.832427, accuracy = 0.719634/0.796256, f1 = 0.801458\n",
      "Epoch 132, step 150, training loss 0.599462, test_loss 0.826967, accuracy = 0.730518/0.794515, f1 = 0.799949\n",
      "Epoch 132, step 175, training loss 0.713572, test_loss 0.816861, accuracy = 0.718764/0.799303, f1 = 0.803173\n",
      "Epoch 132, step 200, training loss 0.490616, test_loss 0.818477, accuracy = 0.727471/0.801916, f1 = 0.804831\n",
      "Epoch 132, step 225, training loss 0.560834, test_loss 0.813735, accuracy = 0.730083/0.800174, f1 = 0.803314\n",
      "Epoch 132, step 250, training loss 0.643692, test_loss 0.842601, accuracy = 0.723988/0.798433, f1 = 0.801050\n",
      "Epoch 132, step 275, training loss 0.641710, test_loss 0.823159, accuracy = 0.721376/0.799739, f1 = 0.802201\n",
      "Epoch 132, step 300, training loss 0.653948, test_loss 0.820697, accuracy = 0.737048/0.795821, f1 = 0.799328\n",
      "Epoch 132, step 325, training loss 0.725644, test_loss 0.831925, accuracy = 0.718764/0.796256, f1 = 0.799531\n",
      "Epoch 132, step 350, training loss 0.680813, test_loss 0.845199, accuracy = 0.716587/0.797997, f1 = 0.800464\n",
      "Epoch 132, step 375, training loss 0.694951, test_loss 0.841720, accuracy = 0.710057/0.796256, f1 = 0.799842\n",
      "Epoch 132, step 400, training loss 0.719903, test_loss 0.843389, accuracy = 0.705703/0.793644, f1 = 0.798026\n",
      "End of epoch 132, training loss 0.604839, test_loss 0.847432, accuracy = 0.712669/0.793644, f1 = 0.797334\n",
      "Confusion matrix:\n",
      "[[823  53  25  36]\n",
      " [ 35 437  78  50]\n",
      " [ 16  59 434  44]\n",
      " [ 15  21  42 129]]\n",
      "Epoch 133, step 0, training loss 0.647741, test_loss 0.839040, accuracy = 0.717022/0.793644, f1 = 0.797334\n",
      "Epoch 133, step 25, training loss 0.600034, test_loss 0.836732, accuracy = 0.725294/0.792338, f1 = 0.796003\n",
      "Epoch 133, step 50, training loss 0.633531, test_loss 0.837356, accuracy = 0.719199/0.795821, f1 = 0.798636\n",
      "Epoch 133, step 75, training loss 0.548844, test_loss 0.812846, accuracy = 0.728341/0.798433, f1 = 0.801478\n",
      "Epoch 133, step 100, training loss 0.635475, test_loss 0.815664, accuracy = 0.726165/0.796691, f1 = 0.800969\n",
      "Epoch 133, step 125, training loss 0.614706, test_loss 0.819888, accuracy = 0.719634/0.793644, f1 = 0.798942\n",
      "Epoch 133, step 150, training loss 0.686381, test_loss 0.819232, accuracy = 0.725729/0.793644, f1 = 0.798849\n",
      "Epoch 133, step 175, training loss 0.813171, test_loss 0.838408, accuracy = 0.713539/0.797127, f1 = 0.801671\n",
      "Epoch 133, step 200, training loss 0.519855, test_loss 0.824927, accuracy = 0.723988/0.795821, f1 = 0.799355\n",
      "Epoch 133, step 225, training loss 0.535361, test_loss 0.823054, accuracy = 0.723988/0.799304, f1 = 0.802469\n",
      "Epoch 133, step 250, training loss 0.655366, test_loss 0.831465, accuracy = 0.731389/0.799303, f1 = 0.802512\n",
      "Epoch 133, step 275, training loss 0.553893, test_loss 0.819640, accuracy = 0.732695/0.798433, f1 = 0.801756\n",
      "Epoch 133, step 300, training loss 0.660009, test_loss 0.823320, accuracy = 0.726600/0.800174, f1 = 0.803855\n",
      "Epoch 133, step 325, training loss 0.789203, test_loss 0.828139, accuracy = 0.718764/0.796256, f1 = 0.799995\n",
      "Epoch 133, step 350, training loss 0.711754, test_loss 0.829341, accuracy = 0.716152/0.794515, f1 = 0.798309\n",
      "Epoch 133, step 375, training loss 0.703906, test_loss 0.834797, accuracy = 0.729647/0.795385, f1 = 0.799596\n",
      "Epoch 133, step 400, training loss 0.626175, test_loss 0.835126, accuracy = 0.708751/0.793209, f1 = 0.797300\n",
      "End of epoch 133, training loss 0.560626, test_loss 0.835434, accuracy = 0.713104/0.794950, f1 = 0.798809\n",
      "Confusion matrix:\n",
      "[[826  48  23  40]\n",
      " [ 36 439  77  48]\n",
      " [ 15  58 434  46]\n",
      " [ 15  22  43 127]]\n",
      "Epoch 134, step 0, training loss 0.566903, test_loss 0.823748, accuracy = 0.726165/0.794950, f1 = 0.798809\n",
      "Epoch 134, step 25, training loss 0.579252, test_loss 0.829675, accuracy = 0.727035/0.794079, f1 = 0.798389\n",
      "Epoch 134, step 50, training loss 0.632302, test_loss 0.831830, accuracy = 0.707445/0.796256, f1 = 0.799576\n",
      "Epoch 134, step 75, training loss 0.632077, test_loss 0.814268, accuracy = 0.728777/0.797562, f1 = 0.800619\n",
      "Epoch 134, step 100, training loss 0.633361, test_loss 0.812000, accuracy = 0.729647/0.797127, f1 = 0.800385\n",
      "Epoch 134, step 125, training loss 0.587901, test_loss 0.815238, accuracy = 0.727471/0.793209, f1 = 0.796897\n",
      "Epoch 134, step 150, training loss 0.636327, test_loss 0.829405, accuracy = 0.721811/0.793644, f1 = 0.797205\n",
      "Epoch 134, step 175, training loss 0.688845, test_loss 0.825234, accuracy = 0.716587/0.798868, f1 = 0.802565\n",
      "Epoch 134, step 200, training loss 0.534947, test_loss 0.811285, accuracy = 0.724423/0.799303, f1 = 0.802324\n",
      "Epoch 134, step 225, training loss 0.663346, test_loss 0.822901, accuracy = 0.724423/0.796256, f1 = 0.799657\n",
      "Epoch 134, step 250, training loss 0.659688, test_loss 0.824251, accuracy = 0.723117/0.796691, f1 = 0.799693\n",
      "Epoch 134, step 275, training loss 0.600872, test_loss 0.824649, accuracy = 0.718764/0.798433, f1 = 0.801472\n",
      "Epoch 134, step 300, training loss 0.595695, test_loss 0.815377, accuracy = 0.726165/0.799303, f1 = 0.802577\n",
      "Epoch 134, step 325, training loss 0.743627, test_loss 0.833354, accuracy = 0.719634/0.800610, f1 = 0.803569\n",
      "Epoch 134, step 350, training loss 0.575576, test_loss 0.836514, accuracy = 0.715716/0.801916, f1 = 0.804419\n",
      "Epoch 134, step 375, training loss 0.768872, test_loss 0.821403, accuracy = 0.723117/0.796256, f1 = 0.800020\n",
      "Epoch 134, step 400, training loss 0.639673, test_loss 0.828616, accuracy = 0.710057/0.791903, f1 = 0.796172\n",
      "End of epoch 134, training loss 0.576968, test_loss 0.831286, accuracy = 0.711363/0.792773, f1 = 0.796445\n",
      "Confusion matrix:\n",
      "[[824  52  23  38]\n",
      " [ 34 444  77  45]\n",
      " [ 16  63 428  46]\n",
      " [ 15  26  41 125]]\n",
      "Epoch 135, step 0, training loss 0.653646, test_loss 0.829086, accuracy = 0.730518/0.793209, f1 = 0.796884\n",
      "Epoch 135, step 25, training loss 0.575526, test_loss 0.828755, accuracy = 0.718764/0.794515, f1 = 0.799023\n",
      "Epoch 135, step 50, training loss 0.584654, test_loss 0.823260, accuracy = 0.720070/0.796256, f1 = 0.800493\n",
      "Epoch 135, step 75, training loss 0.644822, test_loss 0.813516, accuracy = 0.729647/0.800610, f1 = 0.804239\n",
      "Epoch 135, step 100, training loss 0.618582, test_loss 0.822909, accuracy = 0.728341/0.801480, f1 = 0.805609\n",
      "Epoch 135, step 125, training loss 0.588865, test_loss 0.841806, accuracy = 0.713104/0.797997, f1 = 0.801786\n",
      "Epoch 135, step 150, training loss 0.632621, test_loss 0.840073, accuracy = 0.708315/0.794079, f1 = 0.798288\n",
      "Epoch 135, step 175, training loss 0.804662, test_loss 0.822497, accuracy = 0.720940/0.798868, f1 = 0.803175\n",
      "Epoch 135, step 200, training loss 0.538693, test_loss 0.836023, accuracy = 0.713975/0.803222, f1 = 0.805837\n",
      "Epoch 135, step 225, training loss 0.591293, test_loss 0.824981, accuracy = 0.723552/0.800174, f1 = 0.802901\n",
      "Epoch 135, step 250, training loss 0.699786, test_loss 0.827485, accuracy = 0.717893/0.797562, f1 = 0.800462\n",
      "Epoch 135, step 275, training loss 0.523917, test_loss 0.829629, accuracy = 0.712669/0.798868, f1 = 0.801993\n",
      "Epoch 135, step 300, training loss 0.634655, test_loss 0.832303, accuracy = 0.717893/0.800174, f1 = 0.803775\n",
      "Epoch 135, step 325, training loss 0.652867, test_loss 0.837888, accuracy = 0.717893/0.795821, f1 = 0.799290\n",
      "Epoch 135, step 350, training loss 0.673153, test_loss 0.814650, accuracy = 0.733130/0.799303, f1 = 0.802136\n",
      "Epoch 135, step 375, training loss 0.699005, test_loss 0.830527, accuracy = 0.720505/0.794950, f1 = 0.799719\n",
      "Epoch 135, step 400, training loss 0.596730, test_loss 0.823461, accuracy = 0.713539/0.798433, f1 = 0.802461\n",
      "End of epoch 135, training loss 0.564706, test_loss 0.822096, accuracy = 0.724423/0.801045, f1 = 0.804949\n",
      "Confusion matrix:\n",
      "[[822  56  23  36]\n",
      " [ 27 460  68  45]\n",
      " [ 15  63 430  45]\n",
      " [ 15  24  40 128]]\n",
      "Epoch 136, step 0, training loss 0.614120, test_loss 0.827166, accuracy = 0.722682/0.801045, f1 = 0.804949\n",
      "Epoch 136, step 25, training loss 0.641005, test_loss 0.829563, accuracy = 0.726165/0.799303, f1 = 0.803629\n",
      "Epoch 136, step 50, training loss 0.593417, test_loss 0.819080, accuracy = 0.734436/0.801480, f1 = 0.805272\n",
      "Epoch 136, step 75, training loss 0.604086, test_loss 0.822231, accuracy = 0.721376/0.802351, f1 = 0.805189\n",
      "Epoch 136, step 100, training loss 0.635743, test_loss 0.810400, accuracy = 0.737048/0.801480, f1 = 0.805122\n",
      "Epoch 136, step 125, training loss 0.583339, test_loss 0.825450, accuracy = 0.719199/0.796256, f1 = 0.801319\n",
      "Epoch 136, step 150, training loss 0.518688, test_loss 0.817765, accuracy = 0.724423/0.797562, f1 = 0.802688\n",
      "Epoch 136, step 175, training loss 0.689852, test_loss 0.827924, accuracy = 0.722682/0.797562, f1 = 0.802373\n",
      "Epoch 136, step 200, training loss 0.563695, test_loss 0.826127, accuracy = 0.724859/0.797562, f1 = 0.801854\n",
      "Epoch 136, step 225, training loss 0.576866, test_loss 0.828660, accuracy = 0.716587/0.797562, f1 = 0.801497\n",
      "Epoch 136, step 250, training loss 0.661733, test_loss 0.823561, accuracy = 0.728777/0.800174, f1 = 0.803499\n",
      "Epoch 136, step 275, training loss 0.717210, test_loss 0.834717, accuracy = 0.724423/0.802351, f1 = 0.805977\n",
      "Epoch 136, step 300, training loss 0.614819, test_loss 0.815047, accuracy = 0.730953/0.801045, f1 = 0.804909\n",
      "Epoch 136, step 325, training loss 0.735827, test_loss 0.835844, accuracy = 0.707880/0.799739, f1 = 0.803215\n",
      "Epoch 136, step 350, training loss 0.654141, test_loss 0.849682, accuracy = 0.711363/0.795385, f1 = 0.798961\n",
      "Epoch 136, step 375, training loss 0.796957, test_loss 0.824235, accuracy = 0.727906/0.793209, f1 = 0.798403\n",
      "Epoch 136, step 400, training loss 0.661668, test_loss 0.826669, accuracy = 0.720940/0.789726, f1 = 0.795081\n",
      "End of epoch 136, training loss 0.596895, test_loss 0.827740, accuracy = 0.724423/0.792338, f1 = 0.797287\n",
      "Confusion matrix:\n",
      "[[816  55  23  43]\n",
      " [ 27 447  77  49]\n",
      " [ 14  59 431  49]\n",
      " [ 15  25  41 126]]\n",
      "Epoch 137, step 0, training loss 0.569324, test_loss 0.834174, accuracy = 0.715716/0.792773, f1 = 0.797652\n",
      "Epoch 137, step 25, training loss 0.631026, test_loss 0.829376, accuracy = 0.717022/0.791032, f1 = 0.796589\n",
      "Epoch 137, step 50, training loss 0.574270, test_loss 0.827899, accuracy = 0.729212/0.794950, f1 = 0.799510\n",
      "Epoch 137, step 75, training loss 0.622091, test_loss 0.823524, accuracy = 0.726600/0.800609, f1 = 0.803703\n",
      "Epoch 137, step 100, training loss 0.643436, test_loss 0.822359, accuracy = 0.723988/0.801045, f1 = 0.804656\n",
      "Epoch 137, step 125, training loss 0.621946, test_loss 0.824519, accuracy = 0.732259/0.793209, f1 = 0.798298\n",
      "Epoch 137, step 150, training loss 0.666633, test_loss 0.834889, accuracy = 0.720940/0.797997, f1 = 0.802275\n",
      "Epoch 137, step 175, training loss 0.698305, test_loss 0.829029, accuracy = 0.730083/0.799739, f1 = 0.803540\n",
      "Epoch 137, step 200, training loss 0.534073, test_loss 0.835157, accuracy = 0.720070/0.801045, f1 = 0.804240\n",
      "Epoch 137, step 225, training loss 0.529516, test_loss 0.831544, accuracy = 0.730083/0.800610, f1 = 0.804233\n",
      "Epoch 137, step 250, training loss 0.704302, test_loss 0.838058, accuracy = 0.716152/0.798868, f1 = 0.802596\n",
      "Epoch 137, step 275, training loss 0.591864, test_loss 0.827614, accuracy = 0.723552/0.794950, f1 = 0.798660\n",
      "Epoch 137, step 300, training loss 0.679978, test_loss 0.832000, accuracy = 0.715716/0.799303, f1 = 0.803191\n",
      "Epoch 137, step 325, training loss 0.721570, test_loss 0.841575, accuracy = 0.719199/0.800174, f1 = 0.803395\n",
      "Epoch 137, step 350, training loss 0.648772, test_loss 0.837996, accuracy = 0.713539/0.801480, f1 = 0.804055\n",
      "Epoch 137, step 375, training loss 0.724449, test_loss 0.834042, accuracy = 0.720940/0.797127, f1 = 0.800620\n",
      "Epoch 137, step 400, training loss 0.590436, test_loss 0.831043, accuracy = 0.720940/0.796691, f1 = 0.800223\n",
      "End of epoch 137, training loss 0.610847, test_loss 0.826014, accuracy = 0.723988/0.798868, f1 = 0.802651\n",
      "Confusion matrix:\n",
      "[[822  58  21  36]\n",
      " [ 28 465  65  42]\n",
      " [ 14  69 423  47]\n",
      " [ 16  26  40 125]]\n",
      "Epoch 138, step 0, training loss 0.600262, test_loss 0.839836, accuracy = 0.704397/0.799303, f1 = 0.802973\n",
      "Epoch 138, step 25, training loss 0.632686, test_loss 0.826420, accuracy = 0.720940/0.795821, f1 = 0.800094\n",
      "Epoch 138, step 50, training loss 0.596256, test_loss 0.837925, accuracy = 0.723117/0.797997, f1 = 0.802578\n",
      "Epoch 138, step 75, training loss 0.574336, test_loss 0.822014, accuracy = 0.730953/0.797997, f1 = 0.801741\n",
      "Epoch 138, step 100, training loss 0.666804, test_loss 0.820256, accuracy = 0.729212/0.801045, f1 = 0.804598\n",
      "Epoch 138, step 125, training loss 0.548908, test_loss 0.822337, accuracy = 0.727471/0.800174, f1 = 0.804088\n",
      "Epoch 138, step 150, training loss 0.637981, test_loss 0.830892, accuracy = 0.725294/0.800610, f1 = 0.804503\n",
      "Epoch 138, step 175, training loss 0.703416, test_loss 0.838743, accuracy = 0.721376/0.797562, f1 = 0.802798\n",
      "Epoch 138, step 200, training loss 0.581919, test_loss 0.828362, accuracy = 0.723117/0.796691, f1 = 0.800845\n",
      "Epoch 138, step 225, training loss 0.568558, test_loss 0.824303, accuracy = 0.718328/0.796256, f1 = 0.800452\n",
      "Epoch 138, step 250, training loss 0.639987, test_loss 0.821750, accuracy = 0.724423/0.801480, f1 = 0.804928\n",
      "Epoch 138, step 275, training loss 0.606488, test_loss 0.821963, accuracy = 0.726600/0.801916, f1 = 0.805520\n",
      "Epoch 138, step 300, training loss 0.648694, test_loss 0.832158, accuracy = 0.717022/0.801480, f1 = 0.805100\n",
      "Epoch 138, step 325, training loss 0.724610, test_loss 0.836610, accuracy = 0.723552/0.799739, f1 = 0.802994\n",
      "Epoch 138, step 350, training loss 0.638424, test_loss 0.831435, accuracy = 0.712233/0.801916, f1 = 0.804807\n",
      "Epoch 138, step 375, training loss 0.717290, test_loss 0.822803, accuracy = 0.726165/0.796691, f1 = 0.800728\n",
      "Epoch 138, step 400, training loss 0.654138, test_loss 0.826875, accuracy = 0.727906/0.796256, f1 = 0.801380\n",
      "End of epoch 138, training loss 0.579686, test_loss 0.824543, accuracy = 0.723552/0.796256, f1 = 0.801051\n",
      "Confusion matrix:\n",
      "[[825  47  20  45]\n",
      " [ 34 443  70  53]\n",
      " [ 15  61 429  48]\n",
      " [ 15  22  38 132]]\n",
      "Epoch 139, step 0, training loss 0.675649, test_loss 0.825584, accuracy = 0.717458/0.796691, f1 = 0.801496\n",
      "Epoch 139, step 25, training loss 0.609558, test_loss 0.829530, accuracy = 0.730083/0.794950, f1 = 0.800149\n",
      "Epoch 139, step 50, training loss 0.632904, test_loss 0.825721, accuracy = 0.723552/0.795385, f1 = 0.800314\n",
      "Epoch 139, step 75, training loss 0.562227, test_loss 0.810249, accuracy = 0.731389/0.796691, f1 = 0.800573\n",
      "Epoch 139, step 100, training loss 0.674747, test_loss 0.817471, accuracy = 0.724859/0.799739, f1 = 0.803842\n",
      "Epoch 139, step 125, training loss 0.638328, test_loss 0.838295, accuracy = 0.709621/0.795821, f1 = 0.800375\n",
      "Epoch 139, step 150, training loss 0.572518, test_loss 0.818564, accuracy = 0.727906/0.796691, f1 = 0.801118\n",
      "Epoch 139, step 175, training loss 0.734777, test_loss 0.828447, accuracy = 0.723988/0.799739, f1 = 0.804045\n",
      "Epoch 139, step 200, training loss 0.564265, test_loss 0.824443, accuracy = 0.727035/0.802351, f1 = 0.805858\n",
      "Epoch 139, step 225, training loss 0.562840, test_loss 0.817641, accuracy = 0.731389/0.798868, f1 = 0.803154\n",
      "Epoch 139, step 250, training loss 0.690308, test_loss 0.832931, accuracy = 0.717022/0.798433, f1 = 0.801832\n",
      "Epoch 139, step 275, training loss 0.581943, test_loss 0.819632, accuracy = 0.722682/0.801045, f1 = 0.804190\n",
      "Epoch 139, step 300, training loss 0.590027, test_loss 0.828287, accuracy = 0.725294/0.797997, f1 = 0.801981\n",
      "Epoch 139, step 325, training loss 0.731807, test_loss 0.842596, accuracy = 0.720070/0.797997, f1 = 0.802428\n",
      "Epoch 139, step 350, training loss 0.596676, test_loss 0.837751, accuracy = 0.716587/0.798433, f1 = 0.802347\n",
      "Epoch 139, step 375, training loss 0.810225, test_loss 0.827318, accuracy = 0.723117/0.797127, f1 = 0.802074\n",
      "Epoch 139, step 400, training loss 0.700789, test_loss 0.820437, accuracy = 0.717022/0.798868, f1 = 0.803718\n",
      "End of epoch 139, training loss 0.589538, test_loss 0.828610, accuracy = 0.717458/0.795821, f1 = 0.800752\n",
      "Confusion matrix:\n",
      "[[818  53  20  46]\n",
      " [ 30 460  61  49]\n",
      " [ 16  68 420  49]\n",
      " [ 17  22  38 130]]\n",
      "Epoch 140, step 0, training loss 0.555401, test_loss 0.825837, accuracy = 0.720940/0.795385, f1 = 0.800186\n",
      "Epoch 140, step 25, training loss 0.644171, test_loss 0.822033, accuracy = 0.722682/0.795385, f1 = 0.800983\n",
      "Epoch 140, step 50, training loss 0.568549, test_loss 0.826972, accuracy = 0.720505/0.794079, f1 = 0.799121\n",
      "Epoch 140, step 75, training loss 0.632043, test_loss 0.802772, accuracy = 0.727906/0.796691, f1 = 0.800252\n",
      "Epoch 140, step 100, training loss 0.615186, test_loss 0.822454, accuracy = 0.727471/0.794515, f1 = 0.798854\n",
      "Epoch 140, step 125, training loss 0.573635, test_loss 0.841732, accuracy = 0.712669/0.793209, f1 = 0.798472\n",
      "Epoch 140, step 150, training loss 0.702594, test_loss 0.825765, accuracy = 0.729212/0.795385, f1 = 0.799281\n",
      "Epoch 140, step 175, training loss 0.695556, test_loss 0.828219, accuracy = 0.723117/0.798433, f1 = 0.801386\n",
      "Epoch 140, step 200, training loss 0.537310, test_loss 0.837199, accuracy = 0.714846/0.799303, f1 = 0.802508\n",
      "Epoch 140, step 225, training loss 0.567137, test_loss 0.837540, accuracy = 0.717022/0.798433, f1 = 0.802189\n",
      "Epoch 140, step 250, training loss 0.617739, test_loss 0.822718, accuracy = 0.730518/0.797997, f1 = 0.800971\n",
      "Epoch 140, step 275, training loss 0.615515, test_loss 0.827077, accuracy = 0.717893/0.797997, f1 = 0.801467\n",
      "Epoch 140, step 300, training loss 0.636003, test_loss 0.828273, accuracy = 0.720070/0.796256, f1 = 0.799827\n",
      "Epoch 140, step 325, training loss 0.683930, test_loss 0.835228, accuracy = 0.717458/0.794950, f1 = 0.798806\n",
      "Epoch 140, step 350, training loss 0.714731, test_loss 0.830988, accuracy = 0.709186/0.798433, f1 = 0.801764\n",
      "Epoch 140, step 375, training loss 0.737378, test_loss 0.831448, accuracy = 0.717022/0.796256, f1 = 0.799740\n",
      "Epoch 140, step 400, training loss 0.637916, test_loss 0.835483, accuracy = 0.726165/0.797127, f1 = 0.801117\n",
      "End of epoch 140, training loss 0.594091, test_loss 0.830950, accuracy = 0.714410/0.796691, f1 = 0.800373\n",
      "Confusion matrix:\n",
      "[[824  51  21  41]\n",
      " [ 34 451  68  47]\n",
      " [ 17  66 428  42]\n",
      " [ 17  24  39 127]]\n",
      "Epoch 141, step 0, training loss 0.652019, test_loss 0.810778, accuracy = 0.726164/0.796691, f1 = 0.800350\n",
      "Epoch 141, step 25, training loss 0.624174, test_loss 0.829627, accuracy = 0.718328/0.792773, f1 = 0.796950\n",
      "Epoch 141, step 50, training loss 0.567115, test_loss 0.828377, accuracy = 0.723553/0.792338, f1 = 0.796774\n",
      "Epoch 141, step 75, training loss 0.579159, test_loss 0.816611, accuracy = 0.727035/0.797127, f1 = 0.801210\n",
      "Epoch 141, step 100, training loss 0.565104, test_loss 0.814831, accuracy = 0.732695/0.798433, f1 = 0.802636\n",
      "Epoch 141, step 125, training loss 0.597751, test_loss 0.816042, accuracy = 0.731824/0.797562, f1 = 0.802125\n",
      "Epoch 141, step 150, training loss 0.627767, test_loss 0.813337, accuracy = 0.739225/0.796691, f1 = 0.801387\n",
      "Epoch 141, step 175, training loss 0.797568, test_loss 0.831604, accuracy = 0.720505/0.801916, f1 = 0.805821\n",
      "Epoch 141, step 200, training loss 0.549014, test_loss 0.829930, accuracy = 0.719634/0.800610, f1 = 0.803704\n",
      "Epoch 141, step 225, training loss 0.590327, test_loss 0.820448, accuracy = 0.732695/0.799739, f1 = 0.802809\n",
      "Epoch 141, step 250, training loss 0.742933, test_loss 0.825547, accuracy = 0.723117/0.797997, f1 = 0.800400\n",
      "Epoch 141, step 275, training loss 0.577963, test_loss 0.822164, accuracy = 0.730083/0.799739, f1 = 0.802402\n",
      "Epoch 141, step 300, training loss 0.571437, test_loss 0.821906, accuracy = 0.728341/0.797562, f1 = 0.800893\n",
      "Epoch 141, step 325, training loss 0.738531, test_loss 0.831129, accuracy = 0.718328/0.798868, f1 = 0.802492\n",
      "Epoch 141, step 350, training loss 0.622021, test_loss 0.849064, accuracy = 0.713539/0.798868, f1 = 0.801862\n",
      "Epoch 141, step 375, training loss 0.802669, test_loss 0.835199, accuracy = 0.721811/0.793644, f1 = 0.797720\n",
      "Epoch 141, step 400, training loss 0.665105, test_loss 0.815707, accuracy = 0.726600/0.794515, f1 = 0.798986\n",
      "End of epoch 141, training loss 0.591460, test_loss 0.837633, accuracy = 0.711798/0.796256, f1 = 0.800538\n",
      "Confusion matrix:\n",
      "[[823  51  23  40]\n",
      " [ 32 445  74  49]\n",
      " [ 12  64 432  45]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 142, step 0, training loss 0.721854, test_loss 0.824695, accuracy = 0.719199/0.796256, f1 = 0.800478\n",
      "Epoch 142, step 25, training loss 0.544195, test_loss 0.828220, accuracy = 0.725729/0.792773, f1 = 0.798336\n",
      "Epoch 142, step 50, training loss 0.708718, test_loss 0.826417, accuracy = 0.724423/0.795821, f1 = 0.800403\n",
      "Epoch 142, step 75, training loss 0.511827, test_loss 0.817910, accuracy = 0.727471/0.799739, f1 = 0.803245\n",
      "Epoch 142, step 100, training loss 0.694301, test_loss 0.802556, accuracy = 0.732695/0.799739, f1 = 0.804095\n",
      "Epoch 142, step 125, training loss 0.646224, test_loss 0.825373, accuracy = 0.723988/0.796256, f1 = 0.801688\n",
      "Epoch 142, step 150, training loss 0.690610, test_loss 0.828797, accuracy = 0.726165/0.796256, f1 = 0.800549\n",
      "Epoch 142, step 175, training loss 0.721664, test_loss 0.808732, accuracy = 0.726600/0.796691, f1 = 0.800106\n",
      "Epoch 142, step 200, training loss 0.626931, test_loss 0.817474, accuracy = 0.728777/0.800610, f1 = 0.803412\n",
      "Epoch 142, step 225, training loss 0.541156, test_loss 0.830526, accuracy = 0.721376/0.798868, f1 = 0.802361\n",
      "Epoch 142, step 250, training loss 0.657271, test_loss 0.834144, accuracy = 0.720505/0.798868, f1 = 0.801874\n",
      "Epoch 142, step 275, training loss 0.603431, test_loss 0.829729, accuracy = 0.725729/0.797127, f1 = 0.800786\n",
      "Epoch 142, step 300, training loss 0.574576, test_loss 0.828264, accuracy = 0.713975/0.796256, f1 = 0.800165\n",
      "Epoch 142, step 325, training loss 0.637109, test_loss 0.835959, accuracy = 0.714410/0.799303, f1 = 0.802924\n",
      "Epoch 142, step 350, training loss 0.717295, test_loss 0.840476, accuracy = 0.717458/0.797562, f1 = 0.800181\n",
      "Epoch 142, step 375, training loss 0.816075, test_loss 0.840783, accuracy = 0.717022/0.795821, f1 = 0.799035\n",
      "Epoch 142, step 400, training loss 0.705591, test_loss 0.830798, accuracy = 0.723552/0.794515, f1 = 0.798176\n",
      "End of epoch 142, training loss 0.588023, test_loss 0.830585, accuracy = 0.718328/0.796691, f1 = 0.799978\n",
      "Confusion matrix:\n",
      "[[826  53  21  37]\n",
      " [ 32 447  76  45]\n",
      " [ 16  63 432  42]\n",
      " [ 18  22  42 125]]\n",
      "Epoch 143, step 0, training loss 0.593925, test_loss 0.847865, accuracy = 0.718764/0.796691, f1 = 0.799885\n",
      "Epoch 143, step 25, training loss 0.608523, test_loss 0.828083, accuracy = 0.722246/0.797127, f1 = 0.799923\n",
      "Epoch 143, step 50, training loss 0.603117, test_loss 0.828913, accuracy = 0.718328/0.796256, f1 = 0.799892\n",
      "Epoch 143, step 75, training loss 0.634302, test_loss 0.814106, accuracy = 0.724423/0.798868, f1 = 0.802393\n",
      "Epoch 143, step 100, training loss 0.630596, test_loss 0.822318, accuracy = 0.730518/0.797997, f1 = 0.801772\n",
      "Epoch 143, step 125, training loss 0.682635, test_loss 0.838060, accuracy = 0.719199/0.794515, f1 = 0.799896\n",
      "Epoch 143, step 150, training loss 0.658619, test_loss 0.822650, accuracy = 0.725729/0.796256, f1 = 0.801184\n",
      "Epoch 143, step 175, training loss 0.800518, test_loss 0.825038, accuracy = 0.722246/0.796256, f1 = 0.800266\n",
      "Epoch 143, step 200, training loss 0.546669, test_loss 0.822008, accuracy = 0.723552/0.797127, f1 = 0.800523\n",
      "Epoch 143, step 225, training loss 0.577690, test_loss 0.825095, accuracy = 0.733566/0.798433, f1 = 0.802494\n",
      "Epoch 143, step 250, training loss 0.631975, test_loss 0.827558, accuracy = 0.718328/0.798433, f1 = 0.802294\n",
      "Epoch 143, step 275, training loss 0.663327, test_loss 0.834002, accuracy = 0.723552/0.798868, f1 = 0.802302\n",
      "Epoch 143, step 300, training loss 0.631904, test_loss 0.845935, accuracy = 0.714410/0.796691, f1 = 0.800390\n",
      "Epoch 143, step 325, training loss 0.736611, test_loss 0.820423, accuracy = 0.723117/0.797127, f1 = 0.800650\n",
      "Epoch 143, step 350, training loss 0.551339, test_loss 0.834112, accuracy = 0.715281/0.794515, f1 = 0.798389\n",
      "Epoch 143, step 375, training loss 0.690138, test_loss 0.832003, accuracy = 0.732259/0.793209, f1 = 0.798677\n",
      "Epoch 143, step 400, training loss 0.652399, test_loss 0.822565, accuracy = 0.722246/0.792338, f1 = 0.797024\n",
      "End of epoch 143, training loss 0.595180, test_loss 0.827994, accuracy = 0.722682/0.794079, f1 = 0.798225\n",
      "Confusion matrix:\n",
      "[[821  54  21  41]\n",
      " [ 33 445  75  47]\n",
      " [ 14  63 430  46]\n",
      " [ 16  22  41 128]]\n",
      "Epoch 144, step 0, training loss 0.585092, test_loss 0.828207, accuracy = 0.730083/0.793644, f1 = 0.797779\n",
      "Epoch 144, step 25, training loss 0.612439, test_loss 0.840926, accuracy = 0.710492/0.797562, f1 = 0.802056\n",
      "Epoch 144, step 50, training loss 0.582358, test_loss 0.829734, accuracy = 0.726165/0.797997, f1 = 0.801973\n",
      "Epoch 144, step 75, training loss 0.600563, test_loss 0.813556, accuracy = 0.723552/0.796256, f1 = 0.800546\n",
      "Epoch 144, step 100, training loss 0.632280, test_loss 0.820134, accuracy = 0.729212/0.796256, f1 = 0.801186\n",
      "Epoch 144, step 125, training loss 0.640540, test_loss 0.825724, accuracy = 0.723117/0.792773, f1 = 0.798401\n",
      "Epoch 144, step 150, training loss 0.624602, test_loss 0.826530, accuracy = 0.721811/0.793209, f1 = 0.798440\n",
      "Epoch 144, step 175, training loss 0.721687, test_loss 0.812222, accuracy = 0.736613/0.797997, f1 = 0.802261\n",
      "Epoch 144, step 200, training loss 0.533659, test_loss 0.813526, accuracy = 0.726165/0.799303, f1 = 0.803428\n",
      "Epoch 144, step 225, training loss 0.590599, test_loss 0.826730, accuracy = 0.722682/0.798868, f1 = 0.803232\n",
      "Epoch 144, step 250, training loss 0.612955, test_loss 0.833046, accuracy = 0.717022/0.800174, f1 = 0.803773\n",
      "Epoch 144, step 275, training loss 0.663351, test_loss 0.819378, accuracy = 0.725294/0.801480, f1 = 0.805160\n",
      "Epoch 144, step 300, training loss 0.686131, test_loss 0.835468, accuracy = 0.721376/0.800610, f1 = 0.804683\n",
      "Epoch 144, step 325, training loss 0.741132, test_loss 0.827845, accuracy = 0.721811/0.797997, f1 = 0.802133\n",
      "Epoch 144, step 350, training loss 0.636008, test_loss 0.835710, accuracy = 0.721811/0.795821, f1 = 0.799697\n",
      "Epoch 144, step 375, training loss 0.712282, test_loss 0.840194, accuracy = 0.712669/0.793644, f1 = 0.798782\n",
      "Epoch 144, step 400, training loss 0.666722, test_loss 0.834509, accuracy = 0.717893/0.793209, f1 = 0.798489\n",
      "End of epoch 144, training loss 0.585970, test_loss 0.839254, accuracy = 0.714845/0.796256, f1 = 0.801111\n",
      "Confusion matrix:\n",
      "[[815  53  21  48]\n",
      " [ 29 460  65  46]\n",
      " [ 14  67 426  46]\n",
      " [ 16  23  40 128]]\n",
      "Epoch 145, step 0, training loss 0.616599, test_loss 0.829479, accuracy = 0.721376/0.795385, f1 = 0.800133\n",
      "Epoch 145, step 25, training loss 0.725273, test_loss 0.834301, accuracy = 0.727906/0.794079, f1 = 0.799031\n",
      "Epoch 145, step 50, training loss 0.596147, test_loss 0.833484, accuracy = 0.717893/0.799739, f1 = 0.803807\n",
      "Epoch 145, step 75, training loss 0.687011, test_loss 0.811958, accuracy = 0.727471/0.801916, f1 = 0.805484\n",
      "Epoch 145, step 100, training loss 0.718443, test_loss 0.813876, accuracy = 0.722682/0.801480, f1 = 0.805965\n",
      "Epoch 145, step 125, training loss 0.567179, test_loss 0.840810, accuracy = 0.716152/0.795821, f1 = 0.801449\n",
      "Epoch 145, step 150, training loss 0.691172, test_loss 0.848724, accuracy = 0.715281/0.800174, f1 = 0.804726\n",
      "Epoch 145, step 175, training loss 0.759510, test_loss 0.822419, accuracy = 0.730083/0.800610, f1 = 0.804718\n",
      "Epoch 145, step 200, training loss 0.557522, test_loss 0.830785, accuracy = 0.725294/0.798433, f1 = 0.802089\n",
      "Epoch 145, step 225, training loss 0.570414, test_loss 0.823730, accuracy = 0.730083/0.798868, f1 = 0.802610\n",
      "Epoch 145, step 250, training loss 0.642820, test_loss 0.834284, accuracy = 0.721811/0.798868, f1 = 0.801818\n",
      "Epoch 145, step 275, training loss 0.624834, test_loss 0.820764, accuracy = 0.727035/0.797997, f1 = 0.800821\n",
      "Epoch 145, step 300, training loss 0.600728, test_loss 0.837431, accuracy = 0.718328/0.796691, f1 = 0.800273\n",
      "Epoch 145, step 325, training loss 0.744232, test_loss 0.836436, accuracy = 0.720070/0.798868, f1 = 0.802291\n",
      "Epoch 145, step 350, training loss 0.642256, test_loss 0.836150, accuracy = 0.717893/0.796691, f1 = 0.799593\n",
      "Epoch 145, step 375, training loss 0.726261, test_loss 0.834690, accuracy = 0.718328/0.790596, f1 = 0.795042\n",
      "Epoch 145, step 400, training loss 0.684459, test_loss 0.841459, accuracy = 0.711363/0.794950, f1 = 0.799347\n",
      "End of epoch 145, training loss 0.587861, test_loss 0.836384, accuracy = 0.711363/0.797127, f1 = 0.801019\n",
      "Confusion matrix:\n",
      "[[818  57  24  38]\n",
      " [ 26 451  76  47]\n",
      " [ 14  64 436  39]\n",
      " [ 15  23  43 126]]\n",
      "Epoch 146, step 0, training loss 0.693564, test_loss 0.831088, accuracy = 0.719634/0.796691, f1 = 0.800529\n",
      "Epoch 146, step 25, training loss 0.536358, test_loss 0.845495, accuracy = 0.714846/0.795821, f1 = 0.799682\n",
      "Epoch 146, step 50, training loss 0.671719, test_loss 0.827866, accuracy = 0.714410/0.798868, f1 = 0.802064\n",
      "Epoch 146, step 75, training loss 0.571952, test_loss 0.817254, accuracy = 0.735742/0.797997, f1 = 0.800872\n",
      "Epoch 146, step 100, training loss 0.627663, test_loss 0.841238, accuracy = 0.717893/0.797997, f1 = 0.801743\n",
      "Epoch 146, step 125, training loss 0.596624, test_loss 0.835939, accuracy = 0.723117/0.797562, f1 = 0.802288\n",
      "Epoch 146, step 150, training loss 0.716111, test_loss 0.834332, accuracy = 0.718764/0.797562, f1 = 0.801849\n",
      "Epoch 146, step 175, training loss 0.682871, test_loss 0.833198, accuracy = 0.717893/0.797127, f1 = 0.800429\n",
      "Epoch 146, step 200, training loss 0.517980, test_loss 0.819244, accuracy = 0.721811/0.799303, f1 = 0.802243\n",
      "Epoch 146, step 225, training loss 0.574948, test_loss 0.824560, accuracy = 0.730518/0.797997, f1 = 0.801099\n",
      "Epoch 146, step 250, training loss 0.709359, test_loss 0.822303, accuracy = 0.733130/0.800174, f1 = 0.803629\n",
      "Epoch 146, step 275, training loss 0.601448, test_loss 0.818622, accuracy = 0.724423/0.797997, f1 = 0.801215\n",
      "Epoch 146, step 300, training loss 0.627745, test_loss 0.838214, accuracy = 0.716587/0.793644, f1 = 0.797369\n",
      "Epoch 146, step 325, training loss 0.703835, test_loss 0.836239, accuracy = 0.708751/0.791902, f1 = 0.796162\n",
      "Epoch 146, step 350, training loss 0.604097, test_loss 0.828039, accuracy = 0.727906/0.796256, f1 = 0.799308\n",
      "Epoch 146, step 375, training loss 0.751857, test_loss 0.838929, accuracy = 0.722682/0.791032, f1 = 0.795277\n",
      "Epoch 146, step 400, training loss 0.713319, test_loss 0.823921, accuracy = 0.726165/0.792338, f1 = 0.795585\n",
      "End of epoch 146, training loss 0.561954, test_loss 0.834346, accuracy = 0.719634/0.793209, f1 = 0.796540\n",
      "Confusion matrix:\n",
      "[[819  57  25  36]\n",
      " [ 33 451  70  46]\n",
      " [ 17  68 427  41]\n",
      " [ 19  22  41 125]]\n",
      "Epoch 147, step 0, training loss 0.602267, test_loss 0.833972, accuracy = 0.720940/0.793644, f1 = 0.796924\n",
      "Epoch 147, step 25, training loss 0.667016, test_loss 0.822549, accuracy = 0.720070/0.795821, f1 = 0.800311\n",
      "Epoch 147, step 50, training loss 0.626171, test_loss 0.824724, accuracy = 0.724859/0.797562, f1 = 0.802166\n",
      "Epoch 147, step 75, training loss 0.606492, test_loss 0.817916, accuracy = 0.727471/0.799739, f1 = 0.803184\n",
      "Epoch 147, step 100, training loss 0.640810, test_loss 0.821235, accuracy = 0.729212/0.798868, f1 = 0.802741\n",
      "Epoch 147, step 125, training loss 0.620281, test_loss 0.831898, accuracy = 0.723117/0.792773, f1 = 0.797130\n",
      "Epoch 147, step 150, training loss 0.667262, test_loss 0.834971, accuracy = 0.723988/0.795821, f1 = 0.800297\n",
      "Epoch 147, step 175, training loss 0.695606, test_loss 0.818993, accuracy = 0.726600/0.795821, f1 = 0.799969\n",
      "Epoch 147, step 200, training loss 0.546542, test_loss 0.840051, accuracy = 0.722246/0.798433, f1 = 0.801239\n",
      "Epoch 147, step 225, training loss 0.567804, test_loss 0.835603, accuracy = 0.721811/0.798433, f1 = 0.801248\n",
      "Epoch 147, step 250, training loss 0.662715, test_loss 0.839615, accuracy = 0.719199/0.801045, f1 = 0.803591\n",
      "Epoch 147, step 275, training loss 0.647400, test_loss 0.824605, accuracy = 0.720505/0.798433, f1 = 0.801328\n",
      "Epoch 147, step 300, training loss 0.659071, test_loss 0.836363, accuracy = 0.711363/0.801480, f1 = 0.804746\n",
      "Epoch 147, step 325, training loss 0.645664, test_loss 0.837883, accuracy = 0.706138/0.800610, f1 = 0.803156\n",
      "Epoch 147, step 350, training loss 0.574245, test_loss 0.838408, accuracy = 0.710927/0.797562, f1 = 0.800092\n",
      "Epoch 147, step 375, training loss 0.767017, test_loss 0.830620, accuracy = 0.713104/0.795385, f1 = 0.799501\n",
      "Epoch 147, step 400, training loss 0.542539, test_loss 0.834895, accuracy = 0.720070/0.794515, f1 = 0.799269\n",
      "End of epoch 147, training loss 0.586885, test_loss 0.834160, accuracy = 0.713104/0.793209, f1 = 0.798228\n",
      "Confusion matrix:\n",
      "[[812  56  21  48]\n",
      " [ 28 453  73  46]\n",
      " [ 15  64 427  47]\n",
      " [ 15  22  40 130]]\n",
      "Epoch 148, step 0, training loss 0.600089, test_loss 0.831979, accuracy = 0.722682/0.792773, f1 = 0.797796\n",
      "Epoch 148, step 25, training loss 0.567265, test_loss 0.825729, accuracy = 0.721376/0.793644, f1 = 0.798032\n",
      "Epoch 148, step 50, training loss 0.597029, test_loss 0.842057, accuracy = 0.722682/0.797562, f1 = 0.801498\n",
      "Epoch 148, step 75, training loss 0.674176, test_loss 0.832650, accuracy = 0.719634/0.800174, f1 = 0.803465\n",
      "Epoch 148, step 100, training loss 0.623846, test_loss 0.821144, accuracy = 0.727035/0.797997, f1 = 0.801934\n",
      "Epoch 148, step 125, training loss 0.632833, test_loss 0.820194, accuracy = 0.724859/0.796256, f1 = 0.800979\n",
      "Epoch 148, step 150, training loss 0.620096, test_loss 0.839017, accuracy = 0.710927/0.796691, f1 = 0.801045\n",
      "Epoch 148, step 175, training loss 0.724507, test_loss 0.836929, accuracy = 0.717893/0.795821, f1 = 0.800002\n",
      "Epoch 148, step 200, training loss 0.530546, test_loss 0.826885, accuracy = 0.718328/0.796691, f1 = 0.800163\n",
      "Epoch 148, step 225, training loss 0.604088, test_loss 0.819904, accuracy = 0.728341/0.797127, f1 = 0.800889\n",
      "Epoch 148, step 250, training loss 0.625621, test_loss 0.833881, accuracy = 0.715281/0.799739, f1 = 0.803013\n",
      "Epoch 148, step 275, training loss 0.675103, test_loss 0.818010, accuracy = 0.724859/0.800174, f1 = 0.803547\n",
      "Epoch 148, step 300, training loss 0.640844, test_loss 0.832442, accuracy = 0.704397/0.797997, f1 = 0.801749\n",
      "Epoch 148, step 325, training loss 0.817189, test_loss 0.825681, accuracy = 0.721376/0.797562, f1 = 0.801716\n",
      "Epoch 148, step 350, training loss 0.621471, test_loss 0.842009, accuracy = 0.707009/0.797997, f1 = 0.801980\n",
      "Epoch 148, step 375, training loss 0.774513, test_loss 0.840302, accuracy = 0.715716/0.793209, f1 = 0.798977\n",
      "Epoch 148, step 400, training loss 0.627126, test_loss 0.846132, accuracy = 0.711363/0.789726, f1 = 0.795694\n",
      "End of epoch 148, training loss 0.688572, test_loss 0.843676, accuracy = 0.700914/0.790161, f1 = 0.795679\n",
      "Confusion matrix:\n",
      "[[816  50  22  49]\n",
      " [ 33 438  73  56]\n",
      " [ 14  60 431  48]\n",
      " [ 14  21  42 130]]\n",
      "Epoch 149, step 0, training loss 0.706959, test_loss 0.839740, accuracy = 0.714410/0.791467, f1 = 0.796788\n",
      "Epoch 149, step 25, training loss 0.588237, test_loss 0.829730, accuracy = 0.718764/0.790596, f1 = 0.796004\n",
      "Epoch 149, step 50, training loss 0.550290, test_loss 0.832187, accuracy = 0.719199/0.793644, f1 = 0.798820\n",
      "Epoch 149, step 75, training loss 0.579233, test_loss 0.816470, accuracy = 0.730518/0.792338, f1 = 0.797044\n",
      "Epoch 149, step 100, training loss 0.681879, test_loss 0.804528, accuracy = 0.730518/0.790161, f1 = 0.795355\n",
      "Epoch 149, step 125, training loss 0.613955, test_loss 0.827102, accuracy = 0.727035/0.790161, f1 = 0.795962\n",
      "Epoch 149, step 150, training loss 0.685615, test_loss 0.826872, accuracy = 0.724423/0.791467, f1 = 0.797069\n",
      "Epoch 149, step 175, training loss 0.710291, test_loss 0.825915, accuracy = 0.720070/0.791902, f1 = 0.796685\n",
      "Epoch 149, step 200, training loss 0.564884, test_loss 0.831963, accuracy = 0.719634/0.796256, f1 = 0.800741\n",
      "Epoch 149, step 225, training loss 0.579585, test_loss 0.822394, accuracy = 0.712669/0.794079, f1 = 0.799000\n",
      "Epoch 149, step 250, training loss 0.684974, test_loss 0.835876, accuracy = 0.717458/0.795385, f1 = 0.799672\n",
      "Epoch 149, step 275, training loss 0.607250, test_loss 0.827605, accuracy = 0.721811/0.797127, f1 = 0.800745\n",
      "Epoch 149, step 300, training loss 0.578291, test_loss 0.829357, accuracy = 0.715281/0.795821, f1 = 0.800220\n",
      "Epoch 149, step 325, training loss 0.729204, test_loss 0.827124, accuracy = 0.726165/0.794950, f1 = 0.799435\n",
      "Epoch 149, step 350, training loss 0.658159, test_loss 0.839254, accuracy = 0.719634/0.794515, f1 = 0.798475\n",
      "Epoch 149, step 375, training loss 0.764705, test_loss 0.836624, accuracy = 0.724423/0.790596, f1 = 0.796337\n",
      "Epoch 149, step 400, training loss 0.684165, test_loss 0.839591, accuracy = 0.723552/0.788855, f1 = 0.795655\n",
      "End of epoch 149, training loss 0.616811, test_loss 0.826674, accuracy = 0.723117/0.786678, f1 = 0.793693\n",
      "Confusion matrix:\n",
      "[[819  48  19  51]\n",
      " [ 32 431  69  68]\n",
      " [ 15  65 415  58]\n",
      " [ 13  19  33 142]]\n",
      "Epoch 150, step 0, training loss 0.578232, test_loss 0.828856, accuracy = 0.719634/0.787114, f1 = 0.794068\n",
      "Epoch 150, step 25, training loss 0.524205, test_loss 0.830265, accuracy = 0.720505/0.791032, f1 = 0.797579\n",
      "Epoch 150, step 50, training loss 0.604102, test_loss 0.824530, accuracy = 0.719199/0.791032, f1 = 0.797004\n",
      "Epoch 150, step 75, training loss 0.594691, test_loss 0.829898, accuracy = 0.718764/0.799303, f1 = 0.804035\n",
      "Epoch 150, step 100, training loss 0.635672, test_loss 0.813383, accuracy = 0.726165/0.797562, f1 = 0.803274\n",
      "Epoch 150, step 125, training loss 0.545769, test_loss 0.841240, accuracy = 0.719199/0.793209, f1 = 0.799599\n",
      "Epoch 150, step 150, training loss 0.690452, test_loss 0.826193, accuracy = 0.723988/0.792338, f1 = 0.798060\n",
      "Epoch 150, step 175, training loss 0.762587, test_loss 0.822456, accuracy = 0.723552/0.791467, f1 = 0.797293\n",
      "Epoch 150, step 200, training loss 0.598902, test_loss 0.825911, accuracy = 0.720940/0.794079, f1 = 0.799266\n",
      "Epoch 150, step 225, training loss 0.523420, test_loss 0.832671, accuracy = 0.723552/0.794950, f1 = 0.799677\n",
      "Epoch 150, step 250, training loss 0.609657, test_loss 0.833162, accuracy = 0.721376/0.799739, f1 = 0.803411\n",
      "Epoch 150, step 275, training loss 0.629879, test_loss 0.822749, accuracy = 0.724859/0.798868, f1 = 0.803257\n",
      "Epoch 150, step 300, training loss 0.578319, test_loss 0.844629, accuracy = 0.714410/0.797127, f1 = 0.802179\n",
      "Epoch 150, step 325, training loss 0.715069, test_loss 0.811392, accuracy = 0.734872/0.797997, f1 = 0.802528\n",
      "Epoch 150, step 350, training loss 0.579829, test_loss 0.839509, accuracy = 0.713539/0.799303, f1 = 0.803285\n",
      "Epoch 150, step 375, training loss 0.669009, test_loss 0.828346, accuracy = 0.725294/0.795385, f1 = 0.800359\n",
      "Epoch 150, step 400, training loss 0.652641, test_loss 0.833970, accuracy = 0.718328/0.793644, f1 = 0.798423\n",
      "End of epoch 150, training loss 0.600064, test_loss 0.821739, accuracy = 0.717458/0.794950, f1 = 0.799916\n",
      "Confusion matrix:\n",
      "[[817  52  21  47]\n",
      " [ 32 450  68  50]\n",
      " [ 15  65 427  46]\n",
      " [ 13  21  41 132]]\n",
      "Epoch 151, step 0, training loss 0.619378, test_loss 0.821903, accuracy = 0.722682/0.795821, f1 = 0.800718\n",
      "Epoch 151, step 25, training loss 0.628063, test_loss 0.820221, accuracy = 0.716587/0.792773, f1 = 0.797584\n",
      "Epoch 151, step 50, training loss 0.600844, test_loss 0.823077, accuracy = 0.715716/0.794515, f1 = 0.798576\n",
      "Epoch 151, step 75, training loss 0.604216, test_loss 0.834800, accuracy = 0.720505/0.794950, f1 = 0.799039\n",
      "Epoch 151, step 100, training loss 0.606955, test_loss 0.829098, accuracy = 0.727906/0.794950, f1 = 0.799553\n",
      "Epoch 151, step 125, training loss 0.568165, test_loss 0.826356, accuracy = 0.718328/0.792338, f1 = 0.797005\n",
      "Epoch 151, step 150, training loss 0.672708, test_loss 0.828850, accuracy = 0.722246/0.796691, f1 = 0.800877\n",
      "Epoch 151, step 175, training loss 0.694751, test_loss 0.822835, accuracy = 0.724423/0.796256, f1 = 0.800125\n",
      "Epoch 151, step 200, training loss 0.557747, test_loss 0.831980, accuracy = 0.726600/0.796691, f1 = 0.800739\n",
      "Epoch 151, step 225, training loss 0.539606, test_loss 0.826723, accuracy = 0.727471/0.793644, f1 = 0.797401\n",
      "Epoch 151, step 250, training loss 0.617726, test_loss 0.838807, accuracy = 0.711363/0.796256, f1 = 0.799789\n",
      "Epoch 151, step 275, training loss 0.618666, test_loss 0.822231, accuracy = 0.729212/0.797127, f1 = 0.800500\n",
      "Epoch 151, step 300, training loss 0.649074, test_loss 0.828138, accuracy = 0.719199/0.797127, f1 = 0.800505\n",
      "Epoch 151, step 325, training loss 0.687493, test_loss 0.834619, accuracy = 0.718328/0.798868, f1 = 0.802152\n",
      "Epoch 151, step 350, training loss 0.666081, test_loss 0.837845, accuracy = 0.719199/0.795821, f1 = 0.799306\n",
      "Epoch 151, step 375, training loss 0.812968, test_loss 0.824642, accuracy = 0.718764/0.793644, f1 = 0.798239\n",
      "Epoch 151, step 400, training loss 0.647322, test_loss 0.838914, accuracy = 0.721811/0.794950, f1 = 0.799090\n",
      "End of epoch 151, training loss 0.575451, test_loss 0.833841, accuracy = 0.724859/0.796256, f1 = 0.800214\n",
      "Confusion matrix:\n",
      "[[817  56  23  41]\n",
      " [ 28 453  72  47]\n",
      " [ 17  66 431  39]\n",
      " [ 15  22  42 128]]\n",
      "Epoch 152, step 0, training loss 0.632931, test_loss 0.831139, accuracy = 0.715716/0.795385, f1 = 0.799266\n",
      "Epoch 152, step 25, training loss 0.611308, test_loss 0.819915, accuracy = 0.731824/0.798868, f1 = 0.802541\n",
      "Epoch 152, step 50, training loss 0.590898, test_loss 0.834279, accuracy = 0.720940/0.799303, f1 = 0.802754\n",
      "Epoch 152, step 75, training loss 0.557438, test_loss 0.814419, accuracy = 0.727471/0.800610, f1 = 0.803592\n",
      "Epoch 152, step 100, training loss 0.662281, test_loss 0.823066, accuracy = 0.724423/0.798433, f1 = 0.802225\n",
      "Epoch 152, step 125, training loss 0.566743, test_loss 0.819451, accuracy = 0.723553/0.797562, f1 = 0.801303\n",
      "Epoch 152, step 150, training loss 0.595977, test_loss 0.836235, accuracy = 0.717022/0.797127, f1 = 0.800916\n",
      "Epoch 152, step 175, training loss 0.728082, test_loss 0.831387, accuracy = 0.718328/0.794950, f1 = 0.799089\n",
      "Epoch 152, step 200, training loss 0.634339, test_loss 0.815489, accuracy = 0.726165/0.799303, f1 = 0.802873\n",
      "Epoch 152, step 225, training loss 0.549400, test_loss 0.816924, accuracy = 0.725294/0.793644, f1 = 0.797451\n",
      "Epoch 152, step 250, training loss 0.657658, test_loss 0.816073, accuracy = 0.727035/0.797562, f1 = 0.801234\n",
      "Epoch 152, step 275, training loss 0.586495, test_loss 0.825864, accuracy = 0.720070/0.799303, f1 = 0.803305\n",
      "Epoch 152, step 300, training loss 0.628086, test_loss 0.834331, accuracy = 0.710927/0.796691, f1 = 0.801597\n",
      "Epoch 152, step 325, training loss 0.805249, test_loss 0.836723, accuracy = 0.717022/0.794515, f1 = 0.799231\n",
      "Epoch 152, step 350, training loss 0.584901, test_loss 0.851534, accuracy = 0.709186/0.794079, f1 = 0.797347\n",
      "Epoch 152, step 375, training loss 0.703066, test_loss 0.832891, accuracy = 0.723552/0.787984, f1 = 0.793453\n",
      "Epoch 152, step 400, training loss 0.625376, test_loss 0.842811, accuracy = 0.719634/0.790161, f1 = 0.796171\n",
      "End of epoch 152, training loss 0.588982, test_loss 0.849445, accuracy = 0.713539/0.789290, f1 = 0.794255\n",
      "Confusion matrix:\n",
      "[[822  43  22  50]\n",
      " [ 38 427  76  59]\n",
      " [ 16  62 431  44]\n",
      " [ 15  19  40 133]]\n",
      "Epoch 153, step 0, training loss 0.674641, test_loss 0.835649, accuracy = 0.717022/0.790161, f1 = 0.794996\n",
      "Epoch 153, step 25, training loss 0.545072, test_loss 0.828166, accuracy = 0.717893/0.794950, f1 = 0.798996\n",
      "Epoch 153, step 50, training loss 0.504699, test_loss 0.833904, accuracy = 0.723117/0.797127, f1 = 0.800981\n",
      "Epoch 153, step 75, training loss 0.639879, test_loss 0.816346, accuracy = 0.732695/0.798433, f1 = 0.802177\n",
      "Epoch 153, step 100, training loss 0.629746, test_loss 0.826223, accuracy = 0.732259/0.794950, f1 = 0.799039\n",
      "Epoch 153, step 125, training loss 0.624924, test_loss 0.825277, accuracy = 0.734436/0.795385, f1 = 0.799999\n",
      "Epoch 153, step 150, training loss 0.664630, test_loss 0.832332, accuracy = 0.721376/0.795821, f1 = 0.800151\n",
      "Epoch 153, step 175, training loss 0.741150, test_loss 0.812132, accuracy = 0.727471/0.794515, f1 = 0.799016\n",
      "Epoch 153, step 200, training loss 0.589309, test_loss 0.834652, accuracy = 0.721811/0.795821, f1 = 0.800307\n",
      "Epoch 153, step 225, training loss 0.561698, test_loss 0.827132, accuracy = 0.720940/0.793209, f1 = 0.797344\n",
      "Epoch 153, step 250, training loss 0.674327, test_loss 0.811805, accuracy = 0.734872/0.795385, f1 = 0.799145\n",
      "Epoch 153, step 275, training loss 0.705403, test_loss 0.827482, accuracy = 0.733130/0.798868, f1 = 0.802372\n",
      "Epoch 153, step 300, training loss 0.640162, test_loss 0.829881, accuracy = 0.724423/0.797562, f1 = 0.801389\n",
      "Epoch 153, step 325, training loss 0.632812, test_loss 0.819436, accuracy = 0.733130/0.796691, f1 = 0.800059\n",
      "Epoch 153, step 350, training loss 0.714853, test_loss 0.846602, accuracy = 0.713104/0.797127, f1 = 0.800212\n",
      "Epoch 153, step 375, training loss 0.733101, test_loss 0.828856, accuracy = 0.724423/0.790596, f1 = 0.794686\n",
      "Epoch 153, step 400, training loss 0.704233, test_loss 0.829330, accuracy = 0.724423/0.791032, f1 = 0.795424\n",
      "End of epoch 153, training loss 0.575488, test_loss 0.832839, accuracy = 0.718764/0.793644, f1 = 0.798041\n",
      "Confusion matrix:\n",
      "[[821  54  21  41]\n",
      " [ 33 452  65  50]\n",
      " [ 14  72 421  46]\n",
      " [ 16  22  40 129]]\n",
      "Epoch 154, step 0, training loss 0.630052, test_loss 0.839207, accuracy = 0.718328/0.793644, f1 = 0.797967\n",
      "Epoch 154, step 25, training loss 0.593966, test_loss 0.826442, accuracy = 0.730518/0.792338, f1 = 0.795836\n",
      "Epoch 154, step 50, training loss 0.572644, test_loss 0.829574, accuracy = 0.729212/0.792773, f1 = 0.796399\n",
      "Epoch 154, step 75, training loss 0.597736, test_loss 0.818051, accuracy = 0.730953/0.801480, f1 = 0.805109\n",
      "Epoch 154, step 100, training loss 0.679276, test_loss 0.813462, accuracy = 0.726600/0.797562, f1 = 0.801969\n",
      "Epoch 154, step 125, training loss 0.555418, test_loss 0.823453, accuracy = 0.737919/0.795821, f1 = 0.800869\n",
      "Epoch 154, step 150, training loss 0.546143, test_loss 0.819041, accuracy = 0.720505/0.794079, f1 = 0.799253\n",
      "Epoch 154, step 175, training loss 0.734519, test_loss 0.828780, accuracy = 0.721811/0.794079, f1 = 0.798575\n",
      "Epoch 154, step 200, training loss 0.561782, test_loss 0.828520, accuracy = 0.712233/0.797127, f1 = 0.800781\n",
      "Epoch 154, step 225, training loss 0.522309, test_loss 0.827803, accuracy = 0.730518/0.796691, f1 = 0.800533\n",
      "Epoch 154, step 250, training loss 0.596757, test_loss 0.829539, accuracy = 0.724423/0.800174, f1 = 0.803762\n",
      "Epoch 154, step 275, training loss 0.637583, test_loss 0.815183, accuracy = 0.727035/0.801480, f1 = 0.804906\n",
      "Epoch 154, step 300, training loss 0.631608, test_loss 0.813804, accuracy = 0.723552/0.801480, f1 = 0.805037\n",
      "Epoch 154, step 325, training loss 0.701986, test_loss 0.829173, accuracy = 0.723117/0.804092, f1 = 0.807098\n",
      "Epoch 154, step 350, training loss 0.719353, test_loss 0.831755, accuracy = 0.722246/0.802351, f1 = 0.804564\n",
      "Epoch 154, step 375, training loss 0.687559, test_loss 0.836193, accuracy = 0.719199/0.796256, f1 = 0.799988\n",
      "Epoch 154, step 400, training loss 0.624409, test_loss 0.834203, accuracy = 0.724858/0.797127, f1 = 0.801445\n",
      "End of epoch 154, training loss 0.558142, test_loss 0.823928, accuracy = 0.728777/0.797997, f1 = 0.802481\n",
      "Confusion matrix:\n",
      "[[817  54  25  41]\n",
      " [ 26 455  72  47]\n",
      " [ 12  67 432  42]\n",
      " [ 13  23  42 129]]\n",
      "Epoch 155, step 0, training loss 0.720926, test_loss 0.821432, accuracy = 0.734436/0.797997, f1 = 0.802481\n",
      "Epoch 155, step 25, training loss 0.670471, test_loss 0.840473, accuracy = 0.715281/0.798868, f1 = 0.802815\n",
      "Epoch 155, step 50, training loss 0.552509, test_loss 0.824321, accuracy = 0.731389/0.803657, f1 = 0.807273\n",
      "Epoch 155, step 75, training loss 0.596830, test_loss 0.818589, accuracy = 0.722246/0.802351, f1 = 0.805402\n",
      "Epoch 155, step 100, training loss 0.662383, test_loss 0.820367, accuracy = 0.728341/0.799303, f1 = 0.802511\n",
      "Epoch 155, step 125, training loss 0.587334, test_loss 0.812548, accuracy = 0.733130/0.799739, f1 = 0.803361\n",
      "Epoch 155, step 150, training loss 0.670883, test_loss 0.828484, accuracy = 0.718328/0.797997, f1 = 0.801697\n",
      "Epoch 155, step 175, training loss 0.708698, test_loss 0.808748, accuracy = 0.725729/0.801480, f1 = 0.805046\n",
      "Epoch 155, step 200, training loss 0.506187, test_loss 0.836205, accuracy = 0.728777/0.798868, f1 = 0.802194\n",
      "Epoch 155, step 225, training loss 0.557117, test_loss 0.833232, accuracy = 0.720940/0.796691, f1 = 0.799765\n",
      "Epoch 155, step 250, training loss 0.626681, test_loss 0.841922, accuracy = 0.721811/0.798433, f1 = 0.801446\n",
      "Epoch 155, step 275, training loss 0.642555, test_loss 0.843282, accuracy = 0.719199/0.800610, f1 = 0.804221\n",
      "Epoch 155, step 300, training loss 0.662751, test_loss 0.835045, accuracy = 0.721376/0.798868, f1 = 0.802848\n",
      "Epoch 155, step 325, training loss 0.757212, test_loss 0.837261, accuracy = 0.709621/0.800610, f1 = 0.803674\n",
      "Epoch 155, step 350, training loss 0.663872, test_loss 0.823600, accuracy = 0.722682/0.798433, f1 = 0.801645\n",
      "Epoch 155, step 375, training loss 0.698790, test_loss 0.840514, accuracy = 0.720505/0.791903, f1 = 0.797392\n",
      "Epoch 155, step 400, training loss 0.626782, test_loss 0.821814, accuracy = 0.719634/0.790596, f1 = 0.796310\n",
      "End of epoch 155, training loss 0.572992, test_loss 0.840460, accuracy = 0.715281/0.795385, f1 = 0.800183\n",
      "Confusion matrix:\n",
      "[[817  53  22  45]\n",
      " [ 31 448  73  48]\n",
      " [ 13  63 431  46]\n",
      " [ 13  22  41 131]]\n",
      "Epoch 156, step 0, training loss 0.622606, test_loss 0.829902, accuracy = 0.717458/0.794950, f1 = 0.799680\n",
      "Epoch 156, step 25, training loss 0.502033, test_loss 0.844158, accuracy = 0.710927/0.795821, f1 = 0.799841\n",
      "Epoch 156, step 50, training loss 0.638428, test_loss 0.836653, accuracy = 0.722682/0.795821, f1 = 0.799634\n",
      "Epoch 156, step 75, training loss 0.542155, test_loss 0.803147, accuracy = 0.728341/0.797562, f1 = 0.801587\n",
      "Epoch 156, step 100, training loss 0.662701, test_loss 0.834300, accuracy = 0.722246/0.795821, f1 = 0.799726\n",
      "Epoch 156, step 125, training loss 0.595069, test_loss 0.817962, accuracy = 0.723552/0.795385, f1 = 0.799286\n",
      "Epoch 156, step 150, training loss 0.559589, test_loss 0.834766, accuracy = 0.718328/0.794950, f1 = 0.798673\n",
      "Epoch 156, step 175, training loss 0.764776, test_loss 0.836227, accuracy = 0.717458/0.796256, f1 = 0.799746\n",
      "Epoch 156, step 200, training loss 0.527696, test_loss 0.815462, accuracy = 0.726600/0.798868, f1 = 0.802101\n",
      "Epoch 156, step 225, training loss 0.534112, test_loss 0.836832, accuracy = 0.714410/0.797127, f1 = 0.800467\n",
      "Epoch 156, step 250, training loss 0.686643, test_loss 0.830667, accuracy = 0.712233/0.800174, f1 = 0.803443\n",
      "Epoch 156, step 275, training loss 0.633080, test_loss 0.828085, accuracy = 0.714846/0.799739, f1 = 0.803768\n",
      "Epoch 156, step 300, training loss 0.621408, test_loss 0.827306, accuracy = 0.729212/0.799303, f1 = 0.804120\n",
      "Epoch 156, step 325, training loss 0.728857, test_loss 0.823898, accuracy = 0.723117/0.797997, f1 = 0.802728\n",
      "Epoch 156, step 350, training loss 0.633597, test_loss 0.834900, accuracy = 0.716587/0.797562, f1 = 0.801135\n",
      "Epoch 156, step 375, training loss 0.762191, test_loss 0.829846, accuracy = 0.715281/0.794950, f1 = 0.799897\n",
      "Epoch 156, step 400, training loss 0.721814, test_loss 0.848977, accuracy = 0.707445/0.791032, f1 = 0.795907\n",
      "End of epoch 156, training loss 0.570071, test_loss 0.848857, accuracy = 0.711798/0.792773, f1 = 0.797342\n",
      "Confusion matrix:\n",
      "[[825  49  20  43]\n",
      " [ 38 442  65  55]\n",
      " [ 18  60 426  49]\n",
      " [ 16  22  41 128]]\n",
      "Epoch 157, step 0, training loss 0.633656, test_loss 0.851116, accuracy = 0.715716/0.792338, f1 = 0.796861\n",
      "Epoch 157, step 25, training loss 0.557532, test_loss 0.837152, accuracy = 0.713104/0.796691, f1 = 0.800366\n",
      "Epoch 157, step 50, training loss 0.644551, test_loss 0.828838, accuracy = 0.732695/0.799739, f1 = 0.802999\n",
      "Epoch 157, step 75, training loss 0.592524, test_loss 0.825192, accuracy = 0.734872/0.804963, f1 = 0.807457\n",
      "Epoch 157, step 100, training loss 0.596355, test_loss 0.830559, accuracy = 0.723117/0.799303, f1 = 0.802200\n",
      "Epoch 157, step 125, training loss 0.533738, test_loss 0.815950, accuracy = 0.727471/0.797562, f1 = 0.801337\n",
      "Epoch 157, step 150, training loss 0.616720, test_loss 0.828826, accuracy = 0.726600/0.797997, f1 = 0.801500\n",
      "Epoch 157, step 175, training loss 0.770321, test_loss 0.816985, accuracy = 0.728777/0.799739, f1 = 0.802445\n",
      "Epoch 157, step 200, training loss 0.626175, test_loss 0.830457, accuracy = 0.716151/0.798433, f1 = 0.801632\n",
      "Epoch 157, step 225, training loss 0.573874, test_loss 0.839022, accuracy = 0.718764/0.797562, f1 = 0.800623\n",
      "Epoch 157, step 250, training loss 0.630289, test_loss 0.833687, accuracy = 0.714410/0.799303, f1 = 0.802421\n",
      "Epoch 157, step 275, training loss 0.607653, test_loss 0.815907, accuracy = 0.717893/0.800174, f1 = 0.803679\n",
      "Epoch 157, step 300, training loss 0.648804, test_loss 0.828596, accuracy = 0.717022/0.798868, f1 = 0.802424\n",
      "Epoch 157, step 325, training loss 0.720612, test_loss 0.834385, accuracy = 0.725294/0.797997, f1 = 0.801041\n",
      "Epoch 157, step 350, training loss 0.564290, test_loss 0.834085, accuracy = 0.713539/0.798868, f1 = 0.801363\n",
      "Epoch 157, step 375, training loss 0.739389, test_loss 0.831838, accuracy = 0.715716/0.789290, f1 = 0.794108\n",
      "Epoch 157, step 400, training loss 0.641148, test_loss 0.840818, accuracy = 0.705268/0.788855, f1 = 0.793818\n",
      "End of epoch 157, training loss 0.589678, test_loss 0.836710, accuracy = 0.707009/0.789726, f1 = 0.794581\n",
      "Confusion matrix:\n",
      "[[822  49  23  43]\n",
      " [ 36 434  68  62]\n",
      " [ 18  61 429  45]\n",
      " [ 15  20  43 129]]\n",
      "Epoch 158, step 0, training loss 0.629023, test_loss 0.844222, accuracy = 0.708751/0.790596, f1 = 0.795366\n",
      "Epoch 158, step 25, training loss 0.507697, test_loss 0.829811, accuracy = 0.728341/0.791467, f1 = 0.796504\n",
      "Epoch 158, step 50, training loss 0.565577, test_loss 0.837303, accuracy = 0.718328/0.795821, f1 = 0.800257\n",
      "Epoch 158, step 75, training loss 0.606176, test_loss 0.829629, accuracy = 0.726165/0.802786, f1 = 0.806231\n",
      "Epoch 158, step 100, training loss 0.637086, test_loss 0.825409, accuracy = 0.724858/0.801480, f1 = 0.805309\n",
      "Epoch 158, step 125, training loss 0.544381, test_loss 0.830529, accuracy = 0.720940/0.798433, f1 = 0.802879\n",
      "Epoch 158, step 150, training loss 0.585939, test_loss 0.820777, accuracy = 0.725294/0.799303, f1 = 0.802755\n",
      "Epoch 158, step 175, training loss 0.669007, test_loss 0.827483, accuracy = 0.724859/0.799739, f1 = 0.802802\n",
      "Epoch 158, step 200, training loss 0.585953, test_loss 0.842276, accuracy = 0.719199/0.801916, f1 = 0.805165\n",
      "Epoch 158, step 225, training loss 0.525635, test_loss 0.822888, accuracy = 0.720070/0.798433, f1 = 0.802115\n",
      "Epoch 158, step 250, training loss 0.639773, test_loss 0.841110, accuracy = 0.708315/0.800174, f1 = 0.803800\n",
      "Epoch 158, step 275, training loss 0.566948, test_loss 0.825408, accuracy = 0.720070/0.798868, f1 = 0.802546\n",
      "Epoch 158, step 300, training loss 0.619712, test_loss 0.825590, accuracy = 0.722246/0.796691, f1 = 0.800313\n",
      "Epoch 158, step 325, training loss 0.678205, test_loss 0.830320, accuracy = 0.726600/0.796256, f1 = 0.799669\n",
      "Epoch 158, step 350, training loss 0.583214, test_loss 0.834769, accuracy = 0.714845/0.794515, f1 = 0.797761\n",
      "Epoch 158, step 375, training loss 0.714696, test_loss 0.852028, accuracy = 0.707880/0.789726, f1 = 0.794245\n",
      "Epoch 158, step 400, training loss 0.715210, test_loss 0.847331, accuracy = 0.709621/0.791032, f1 = 0.795680\n",
      "End of epoch 158, training loss 0.616984, test_loss 0.829614, accuracy = 0.712233/0.793209, f1 = 0.797151\n",
      "Confusion matrix:\n",
      "[[826  48  22  41]\n",
      " [ 37 427  81  55]\n",
      " [ 15  57 439  42]\n",
      " [ 14  22  41 130]]\n",
      "Epoch 159, step 0, training loss 0.611767, test_loss 0.847540, accuracy = 0.704397/0.791902, f1 = 0.795887\n",
      "Epoch 159, step 25, training loss 0.580345, test_loss 0.843453, accuracy = 0.713104/0.794950, f1 = 0.798713\n",
      "Epoch 159, step 50, training loss 0.625192, test_loss 0.840123, accuracy = 0.718328/0.793644, f1 = 0.797107\n",
      "Epoch 159, step 75, training loss 0.621756, test_loss 0.817391, accuracy = 0.725294/0.802786, f1 = 0.805613\n",
      "Epoch 159, step 100, training loss 0.665263, test_loss 0.812262, accuracy = 0.722682/0.797127, f1 = 0.800384\n",
      "Epoch 159, step 125, training loss 0.558590, test_loss 0.829468, accuracy = 0.717893/0.794515, f1 = 0.798010\n",
      "Epoch 159, step 150, training loss 0.625394, test_loss 0.826259, accuracy = 0.712233/0.800174, f1 = 0.803406\n",
      "Epoch 159, step 175, training loss 0.777945, test_loss 0.843103, accuracy = 0.717458/0.800174, f1 = 0.803403\n",
      "Epoch 159, step 200, training loss 0.583577, test_loss 0.827616, accuracy = 0.713539/0.804528, f1 = 0.807270\n",
      "Epoch 159, step 225, training loss 0.569719, test_loss 0.839071, accuracy = 0.715281/0.801480, f1 = 0.804535\n",
      "Epoch 159, step 250, training loss 0.586786, test_loss 0.843428, accuracy = 0.713104/0.800610, f1 = 0.803343\n",
      "Epoch 159, step 275, training loss 0.667119, test_loss 0.844170, accuracy = 0.716152/0.801916, f1 = 0.804556\n",
      "Epoch 159, step 300, training loss 0.640173, test_loss 0.849595, accuracy = 0.717458/0.799303, f1 = 0.802140\n",
      "Epoch 159, step 325, training loss 0.743796, test_loss 0.856623, accuracy = 0.714846/0.799303, f1 = 0.802118\n",
      "Epoch 159, step 350, training loss 0.701019, test_loss 0.846516, accuracy = 0.711363/0.799739, f1 = 0.802153\n",
      "Epoch 159, step 375, training loss 0.728580, test_loss 0.839431, accuracy = 0.707009/0.796691, f1 = 0.800165\n",
      "Epoch 159, step 400, training loss 0.583620, test_loss 0.840121, accuracy = 0.703526/0.797562, f1 = 0.801222\n",
      "End of epoch 159, training loss 0.598838, test_loss 0.828818, accuracy = 0.726165/0.798868, f1 = 0.802533\n",
      "Confusion matrix:\n",
      "[[822  54  23  38]\n",
      " [ 32 450  73  45]\n",
      " [ 17  59 434  43]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 160, step 0, training loss 0.617479, test_loss 0.829998, accuracy = 0.715716/0.798868, f1 = 0.802533\n",
      "Epoch 160, step 25, training loss 0.631732, test_loss 0.851934, accuracy = 0.704397/0.796256, f1 = 0.800279\n",
      "Epoch 160, step 50, training loss 0.600417, test_loss 0.835215, accuracy = 0.715716/0.799303, f1 = 0.803164\n",
      "Epoch 160, step 75, training loss 0.634813, test_loss 0.833113, accuracy = 0.718764/0.802351, f1 = 0.805628\n",
      "Epoch 160, step 100, training loss 0.651048, test_loss 0.826421, accuracy = 0.725729/0.799739, f1 = 0.803259\n",
      "Epoch 160, step 125, training loss 0.605406, test_loss 0.834132, accuracy = 0.717458/0.798433, f1 = 0.802486\n",
      "Epoch 160, step 150, training loss 0.577984, test_loss 0.831489, accuracy = 0.716151/0.795385, f1 = 0.799914\n",
      "Epoch 160, step 175, training loss 0.674219, test_loss 0.830541, accuracy = 0.718328/0.796691, f1 = 0.800246\n",
      "Epoch 160, step 200, training loss 0.580849, test_loss 0.827511, accuracy = 0.727471/0.797562, f1 = 0.800599\n",
      "Epoch 160, step 225, training loss 0.466907, test_loss 0.824548, accuracy = 0.730518/0.798433, f1 = 0.801367\n",
      "Epoch 160, step 250, training loss 0.586753, test_loss 0.825157, accuracy = 0.723117/0.801480, f1 = 0.803867\n",
      "Epoch 160, step 275, training loss 0.564152, test_loss 0.816755, accuracy = 0.731389/0.800174, f1 = 0.802945\n",
      "Epoch 160, step 300, training loss 0.609501, test_loss 0.836609, accuracy = 0.713539/0.798433, f1 = 0.801557\n",
      "Epoch 160, step 325, training loss 0.708773, test_loss 0.833298, accuracy = 0.723552/0.798868, f1 = 0.802274\n",
      "Epoch 160, step 350, training loss 0.665779, test_loss 0.840204, accuracy = 0.706138/0.797997, f1 = 0.801398\n",
      "Epoch 160, step 375, training loss 0.765986, test_loss 0.836684, accuracy = 0.726600/0.794515, f1 = 0.798582\n",
      "Epoch 160, step 400, training loss 0.655212, test_loss 0.834484, accuracy = 0.723117/0.791032, f1 = 0.795386\n",
      "End of epoch 160, training loss 0.553089, test_loss 0.831448, accuracy = 0.721376/0.794950, f1 = 0.798841\n",
      "Confusion matrix:\n",
      "[[825  49  22  41]\n",
      " [ 37 441  69  53]\n",
      " [ 18  61 432  42]\n",
      " [ 15  22  42 128]]\n",
      "Epoch 161, step 0, training loss 0.617624, test_loss 0.836190, accuracy = 0.717893/0.794950, f1 = 0.798841\n",
      "Epoch 161, step 25, training loss 0.496767, test_loss 0.846990, accuracy = 0.710492/0.793209, f1 = 0.797177\n",
      "Epoch 161, step 50, training loss 0.509251, test_loss 0.833430, accuracy = 0.714845/0.793644, f1 = 0.797984\n",
      "Epoch 161, step 75, training loss 0.577554, test_loss 0.822716, accuracy = 0.728341/0.801045, f1 = 0.803710\n",
      "Epoch 161, step 100, training loss 0.640659, test_loss 0.814996, accuracy = 0.729647/0.794515, f1 = 0.798695\n",
      "Epoch 161, step 125, training loss 0.554541, test_loss 0.824795, accuracy = 0.724423/0.792338, f1 = 0.797147\n",
      "Epoch 161, step 150, training loss 0.666721, test_loss 0.841252, accuracy = 0.722682/0.790596, f1 = 0.796190\n",
      "Epoch 161, step 175, training loss 0.739282, test_loss 0.821749, accuracy = 0.729212/0.794515, f1 = 0.799286\n",
      "Epoch 161, step 200, training loss 0.660574, test_loss 0.832766, accuracy = 0.717458/0.801045, f1 = 0.804498\n",
      "Epoch 161, step 225, training loss 0.551639, test_loss 0.830477, accuracy = 0.718764/0.797562, f1 = 0.801263\n",
      "Epoch 161, step 250, training loss 0.619537, test_loss 0.829113, accuracy = 0.724859/0.801916, f1 = 0.805192\n",
      "Epoch 161, step 275, training loss 0.634168, test_loss 0.818886, accuracy = 0.724859/0.799739, f1 = 0.803767\n",
      "Epoch 161, step 300, training loss 0.619810, test_loss 0.825342, accuracy = 0.732260/0.797562, f1 = 0.801272\n",
      "Epoch 161, step 325, training loss 0.675296, test_loss 0.820998, accuracy = 0.728341/0.802351, f1 = 0.805189\n",
      "Epoch 161, step 350, training loss 0.638134, test_loss 0.834180, accuracy = 0.720505/0.801045, f1 = 0.803442\n",
      "Epoch 161, step 375, training loss 0.702603, test_loss 0.839969, accuracy = 0.707445/0.793644, f1 = 0.797908\n",
      "Epoch 161, step 400, training loss 0.652662, test_loss 0.832746, accuracy = 0.712669/0.793644, f1 = 0.798749\n",
      "End of epoch 161, training loss 0.537795, test_loss 0.838983, accuracy = 0.717458/0.795821, f1 = 0.800353\n",
      "Confusion matrix:\n",
      "[[814  58  22  43]\n",
      " [ 26 463  62  49]\n",
      " [ 17  72 423  41]\n",
      " [ 14  25  40 128]]\n",
      "Epoch 162, step 0, training loss 0.640048, test_loss 0.829480, accuracy = 0.722246/0.795821, f1 = 0.800290\n",
      "Epoch 162, step 25, training loss 0.560923, test_loss 0.826174, accuracy = 0.722246/0.791903, f1 = 0.796301\n",
      "Epoch 162, step 50, training loss 0.597353, test_loss 0.832861, accuracy = 0.719634/0.797127, f1 = 0.802399\n",
      "Epoch 162, step 75, training loss 0.552917, test_loss 0.809282, accuracy = 0.738354/0.798868, f1 = 0.802760\n",
      "Epoch 162, step 100, training loss 0.620250, test_loss 0.817791, accuracy = 0.721811/0.796256, f1 = 0.800603\n",
      "Epoch 162, step 125, training loss 0.602438, test_loss 0.815793, accuracy = 0.736613/0.792773, f1 = 0.798130\n",
      "Epoch 162, step 150, training loss 0.624160, test_loss 0.837459, accuracy = 0.718328/0.791467, f1 = 0.796821\n",
      "Epoch 162, step 175, training loss 0.697629, test_loss 0.823531, accuracy = 0.722682/0.796256, f1 = 0.800707\n",
      "Epoch 162, step 200, training loss 0.574411, test_loss 0.835932, accuracy = 0.718764/0.797127, f1 = 0.800487\n",
      "Epoch 162, step 225, training loss 0.557304, test_loss 0.840594, accuracy = 0.712669/0.798433, f1 = 0.801692\n",
      "Epoch 162, step 250, training loss 0.632268, test_loss 0.835887, accuracy = 0.720940/0.798433, f1 = 0.801226\n",
      "Epoch 162, step 275, training loss 0.562028, test_loss 0.829699, accuracy = 0.724859/0.798868, f1 = 0.802393\n",
      "Epoch 162, step 300, training loss 0.629962, test_loss 0.841451, accuracy = 0.707444/0.799303, f1 = 0.802883\n",
      "Epoch 162, step 325, training loss 0.722934, test_loss 0.830415, accuracy = 0.715716/0.798868, f1 = 0.802079\n",
      "Epoch 162, step 350, training loss 0.627328, test_loss 0.840533, accuracy = 0.715716/0.796691, f1 = 0.799423\n",
      "Epoch 162, step 375, training loss 0.711838, test_loss 0.836831, accuracy = 0.720505/0.794515, f1 = 0.798679\n",
      "Epoch 162, step 400, training loss 0.683820, test_loss 0.847901, accuracy = 0.710057/0.793644, f1 = 0.798684\n",
      "End of epoch 162, training loss 0.559487, test_loss 0.831844, accuracy = 0.720070/0.791902, f1 = 0.796535\n",
      "Confusion matrix:\n",
      "[[818  59  23  37]\n",
      " [ 30 449  70  51]\n",
      " [ 15  65 424  49]\n",
      " [ 13  26  40 128]]\n",
      "Epoch 163, step 0, training loss 0.605294, test_loss 0.841023, accuracy = 0.714846/0.792338, f1 = 0.796906\n",
      "Epoch 163, step 25, training loss 0.625214, test_loss 0.836547, accuracy = 0.717022/0.795821, f1 = 0.799989\n",
      "Epoch 163, step 50, training loss 0.626312, test_loss 0.832201, accuracy = 0.717458/0.796691, f1 = 0.800247\n",
      "Epoch 163, step 75, training loss 0.529616, test_loss 0.823069, accuracy = 0.728341/0.797562, f1 = 0.800901\n",
      "Epoch 163, step 100, training loss 0.708240, test_loss 0.826221, accuracy = 0.731824/0.798868, f1 = 0.803297\n",
      "Epoch 163, step 125, training loss 0.533595, test_loss 0.827978, accuracy = 0.718328/0.797562, f1 = 0.802380\n",
      "Epoch 163, step 150, training loss 0.669630, test_loss 0.840930, accuracy = 0.715281/0.799739, f1 = 0.804328\n",
      "Epoch 163, step 175, training loss 0.611192, test_loss 0.828330, accuracy = 0.714845/0.797562, f1 = 0.801628\n",
      "Epoch 163, step 200, training loss 0.499908, test_loss 0.831634, accuracy = 0.723553/0.798433, f1 = 0.802361\n",
      "Epoch 163, step 225, training loss 0.554920, test_loss 0.839152, accuracy = 0.711363/0.798433, f1 = 0.802629\n",
      "Epoch 163, step 250, training loss 0.700788, test_loss 0.822143, accuracy = 0.726165/0.797562, f1 = 0.801238\n",
      "Epoch 163, step 275, training loss 0.652014, test_loss 0.829577, accuracy = 0.720940/0.797997, f1 = 0.801628\n",
      "Epoch 163, step 300, training loss 0.612040, test_loss 0.836352, accuracy = 0.719634/0.798433, f1 = 0.802183\n",
      "Epoch 163, step 325, training loss 0.695671, test_loss 0.827310, accuracy = 0.727035/0.797127, f1 = 0.801069\n",
      "Epoch 163, step 350, training loss 0.559920, test_loss 0.835643, accuracy = 0.722246/0.796256, f1 = 0.800190\n",
      "Epoch 163, step 375, training loss 0.792041, test_loss 0.834579, accuracy = 0.712669/0.791032, f1 = 0.796189\n",
      "Epoch 163, step 400, training loss 0.659298, test_loss 0.837948, accuracy = 0.715281/0.793209, f1 = 0.797772\n",
      "End of epoch 163, training loss 0.655101, test_loss 0.830162, accuracy = 0.715716/0.793209, f1 = 0.797537\n",
      "Confusion matrix:\n",
      "[[819  54  23  41]\n",
      " [ 33 443  73  51]\n",
      " [ 16  61 432  44]\n",
      " [ 13  25  41 128]]\n",
      "Epoch 164, step 0, training loss 0.695727, test_loss 0.838627, accuracy = 0.717893/0.793209, f1 = 0.797537\n",
      "Epoch 164, step 25, training loss 0.591666, test_loss 0.840761, accuracy = 0.713975/0.795821, f1 = 0.800420\n",
      "Epoch 164, step 50, training loss 0.571347, test_loss 0.816910, accuracy = 0.726165/0.797127, f1 = 0.801250\n",
      "Epoch 164, step 75, training loss 0.576011, test_loss 0.830991, accuracy = 0.717458/0.799739, f1 = 0.803388\n",
      "Epoch 164, step 100, training loss 0.649711, test_loss 0.827481, accuracy = 0.727471/0.797997, f1 = 0.802593\n",
      "Epoch 164, step 125, training loss 0.542327, test_loss 0.826021, accuracy = 0.717458/0.796256, f1 = 0.801082\n",
      "Epoch 164, step 150, training loss 0.656261, test_loss 0.840747, accuracy = 0.720070/0.797127, f1 = 0.801967\n",
      "Epoch 164, step 175, training loss 0.817312, test_loss 0.838521, accuracy = 0.709186/0.797562, f1 = 0.801586\n",
      "Epoch 164, step 200, training loss 0.547140, test_loss 0.814761, accuracy = 0.727906/0.799303, f1 = 0.802381\n",
      "Epoch 164, step 225, training loss 0.497619, test_loss 0.831630, accuracy = 0.723552/0.799739, f1 = 0.803682\n",
      "Epoch 164, step 250, training loss 0.680038, test_loss 0.826865, accuracy = 0.730953/0.797997, f1 = 0.802004\n",
      "Epoch 164, step 275, training loss 0.709707, test_loss 0.815877, accuracy = 0.734872/0.799739, f1 = 0.803890\n",
      "Epoch 164, step 300, training loss 0.639971, test_loss 0.847456, accuracy = 0.718328/0.797127, f1 = 0.801583\n",
      "Epoch 164, step 325, training loss 0.672744, test_loss 0.826562, accuracy = 0.726600/0.797562, f1 = 0.801425\n",
      "Epoch 164, step 350, training loss 0.585220, test_loss 0.839182, accuracy = 0.711363/0.793209, f1 = 0.796648\n",
      "Epoch 164, step 375, training loss 0.640557, test_loss 0.831375, accuracy = 0.720070/0.788855, f1 = 0.793820\n",
      "Epoch 164, step 400, training loss 0.688961, test_loss 0.843406, accuracy = 0.712669/0.793209, f1 = 0.798348\n",
      "End of epoch 164, training loss 0.587192, test_loss 0.824685, accuracy = 0.713539/0.793209, f1 = 0.797985\n",
      "Confusion matrix:\n",
      "[[818  53  22  44]\n",
      " [ 30 448  73  49]\n",
      " [ 16  64 426  47]\n",
      " [ 13  24  40 130]]\n",
      "Epoch 165, step 0, training loss 0.634349, test_loss 0.839051, accuracy = 0.720070/0.793209, f1 = 0.797985\n",
      "Epoch 165, step 25, training loss 0.552808, test_loss 0.834677, accuracy = 0.716587/0.791903, f1 = 0.796933\n",
      "Epoch 165, step 50, training loss 0.618644, test_loss 0.846286, accuracy = 0.707880/0.794950, f1 = 0.799468\n",
      "Epoch 165, step 75, training loss 0.601259, test_loss 0.823511, accuracy = 0.721376/0.800609, f1 = 0.804147\n",
      "Epoch 165, step 100, training loss 0.656518, test_loss 0.818238, accuracy = 0.721376/0.794950, f1 = 0.798938\n",
      "Epoch 165, step 125, training loss 0.519290, test_loss 0.832525, accuracy = 0.719199/0.794950, f1 = 0.798967\n",
      "Epoch 165, step 150, training loss 0.622217, test_loss 0.826048, accuracy = 0.722682/0.794079, f1 = 0.798839\n",
      "Epoch 165, step 175, training loss 0.732745, test_loss 0.813372, accuracy = 0.729647/0.789726, f1 = 0.795278\n",
      "Epoch 165, step 200, training loss 0.552905, test_loss 0.816064, accuracy = 0.725294/0.795821, f1 = 0.799564\n",
      "Epoch 165, step 225, training loss 0.564320, test_loss 0.831106, accuracy = 0.724859/0.798433, f1 = 0.801874\n",
      "Epoch 165, step 250, training loss 0.621774, test_loss 0.817673, accuracy = 0.726165/0.800610, f1 = 0.803878\n",
      "Epoch 165, step 275, training loss 0.596531, test_loss 0.819807, accuracy = 0.730953/0.799739, f1 = 0.803421\n",
      "Epoch 165, step 300, training loss 0.645308, test_loss 0.838036, accuracy = 0.713104/0.797127, f1 = 0.801559\n",
      "Epoch 165, step 325, training loss 0.792967, test_loss 0.827685, accuracy = 0.712669/0.797127, f1 = 0.801666\n",
      "Epoch 165, step 350, training loss 0.595317, test_loss 0.847789, accuracy = 0.709186/0.794515, f1 = 0.798964\n",
      "Epoch 165, step 375, training loss 0.741404, test_loss 0.844724, accuracy = 0.707880/0.789290, f1 = 0.794784\n",
      "Epoch 165, step 400, training loss 0.655250, test_loss 0.836247, accuracy = 0.713539/0.790161, f1 = 0.794940\n",
      "End of epoch 165, training loss 0.578647, test_loss 0.850675, accuracy = 0.703526/0.789726, f1 = 0.794304\n",
      "Confusion matrix:\n",
      "[[822  52  22  41]\n",
      " [ 34 438  74  54]\n",
      " [ 18  61 426  48]\n",
      " [ 13  25  41 128]]\n",
      "Epoch 166, step 0, training loss 0.573977, test_loss 0.845060, accuracy = 0.712233/0.789290, f1 = 0.793734\n",
      "Epoch 166, step 25, training loss 0.536369, test_loss 0.840847, accuracy = 0.723553/0.789290, f1 = 0.794406\n",
      "Epoch 166, step 50, training loss 0.563889, test_loss 0.852886, accuracy = 0.710492/0.791467, f1 = 0.796301\n",
      "Epoch 166, step 75, training loss 0.588698, test_loss 0.829377, accuracy = 0.718328/0.794950, f1 = 0.799045\n",
      "Epoch 166, step 100, training loss 0.657272, test_loss 0.824064, accuracy = 0.728777/0.793644, f1 = 0.798720\n",
      "Epoch 166, step 125, training loss 0.630278, test_loss 0.823612, accuracy = 0.727471/0.790161, f1 = 0.795761\n",
      "Epoch 166, step 150, training loss 0.676408, test_loss 0.824709, accuracy = 0.722682/0.791032, f1 = 0.796345\n",
      "Epoch 166, step 175, training loss 0.745506, test_loss 0.831756, accuracy = 0.717022/0.794950, f1 = 0.799642\n",
      "Epoch 166, step 200, training loss 0.540899, test_loss 0.835410, accuracy = 0.720940/0.793209, f1 = 0.797384\n",
      "Epoch 166, step 225, training loss 0.552550, test_loss 0.835433, accuracy = 0.714845/0.794079, f1 = 0.798194\n",
      "Epoch 166, step 250, training loss 0.687003, test_loss 0.835112, accuracy = 0.716587/0.797127, f1 = 0.800798\n",
      "Epoch 166, step 275, training loss 0.592719, test_loss 0.831694, accuracy = 0.723988/0.798868, f1 = 0.802727\n",
      "Epoch 166, step 300, training loss 0.612513, test_loss 0.836372, accuracy = 0.712233/0.795821, f1 = 0.800007\n",
      "Epoch 166, step 325, training loss 0.760669, test_loss 0.841210, accuracy = 0.710057/0.796691, f1 = 0.800390\n",
      "Epoch 166, step 350, training loss 0.595721, test_loss 0.823999, accuracy = 0.719634/0.795821, f1 = 0.798720\n",
      "Epoch 166, step 375, training loss 0.819778, test_loss 0.838543, accuracy = 0.709621/0.794079, f1 = 0.798499\n",
      "Epoch 166, step 400, training loss 0.641391, test_loss 0.835546, accuracy = 0.707445/0.788420, f1 = 0.793625\n",
      "End of epoch 166, training loss 0.600259, test_loss 0.840510, accuracy = 0.707445/0.791903, f1 = 0.796673\n",
      "Confusion matrix:\n",
      "[[826  50  23  38]\n",
      " [ 32 432  76  60]\n",
      " [ 15  57 432  49]\n",
      " [ 15  23  40 129]]\n",
      "Epoch 167, step 0, training loss 0.606031, test_loss 0.837808, accuracy = 0.716587/0.792773, f1 = 0.797435\n",
      "Epoch 167, step 25, training loss 0.602380, test_loss 0.850424, accuracy = 0.710057/0.795385, f1 = 0.800188\n",
      "Epoch 167, step 50, training loss 0.537554, test_loss 0.821853, accuracy = 0.723552/0.796691, f1 = 0.800043\n",
      "Epoch 167, step 75, training loss 0.577578, test_loss 0.814808, accuracy = 0.722682/0.801045, f1 = 0.804147\n",
      "Epoch 167, step 100, training loss 0.676930, test_loss 0.824207, accuracy = 0.722246/0.796691, f1 = 0.801000\n",
      "Epoch 167, step 125, training loss 0.586455, test_loss 0.823637, accuracy = 0.724423/0.792773, f1 = 0.797846\n",
      "Epoch 167, step 150, training loss 0.635543, test_loss 0.842060, accuracy = 0.711798/0.797127, f1 = 0.801517\n",
      "Epoch 167, step 175, training loss 0.720409, test_loss 0.827539, accuracy = 0.712233/0.799303, f1 = 0.802457\n",
      "Epoch 167, step 200, training loss 0.522968, test_loss 0.843284, accuracy = 0.715281/0.797997, f1 = 0.801033\n",
      "Epoch 167, step 225, training loss 0.591901, test_loss 0.832699, accuracy = 0.713539/0.797127, f1 = 0.801283\n",
      "Epoch 167, step 250, training loss 0.587131, test_loss 0.819545, accuracy = 0.725729/0.798433, f1 = 0.802609\n",
      "Epoch 167, step 275, training loss 0.680725, test_loss 0.822553, accuracy = 0.725294/0.800174, f1 = 0.804037\n",
      "Epoch 167, step 300, training loss 0.671530, test_loss 0.842164, accuracy = 0.709621/0.801480, f1 = 0.804949\n",
      "Epoch 167, step 325, training loss 0.805561, test_loss 0.845403, accuracy = 0.720070/0.800610, f1 = 0.803876\n",
      "Epoch 167, step 350, training loss 0.578807, test_loss 0.852650, accuracy = 0.706574/0.798433, f1 = 0.801629\n",
      "Epoch 167, step 375, training loss 0.797310, test_loss 0.843831, accuracy = 0.711798/0.795385, f1 = 0.799551\n",
      "Epoch 167, step 400, training loss 0.647883, test_loss 0.830605, accuracy = 0.721376/0.794079, f1 = 0.798456\n",
      "End of epoch 167, training loss 0.580657, test_loss 0.832302, accuracy = 0.715716/0.795821, f1 = 0.800118\n",
      "Confusion matrix:\n",
      "[[822  52  22  41]\n",
      " [ 32 439  76  53]\n",
      " [ 13  62 437  41]\n",
      " [ 13  22  42 130]]\n",
      "Epoch 168, step 0, training loss 0.575325, test_loss 0.827299, accuracy = 0.721811/0.795385, f1 = 0.799600\n",
      "Epoch 168, step 25, training loss 0.598567, test_loss 0.839123, accuracy = 0.715716/0.793644, f1 = 0.798068\n",
      "Epoch 168, step 50, training loss 0.589271, test_loss 0.846504, accuracy = 0.718328/0.796691, f1 = 0.801081\n",
      "Epoch 168, step 75, training loss 0.648757, test_loss 0.822203, accuracy = 0.730953/0.801045, f1 = 0.805371\n",
      "Epoch 168, step 100, training loss 0.668450, test_loss 0.823319, accuracy = 0.723117/0.794515, f1 = 0.799761\n",
      "Epoch 168, step 125, training loss 0.574724, test_loss 0.837419, accuracy = 0.720505/0.794515, f1 = 0.799690\n",
      "Epoch 168, step 150, training loss 0.652292, test_loss 0.837323, accuracy = 0.712233/0.796256, f1 = 0.801069\n",
      "Epoch 168, step 175, training loss 0.763246, test_loss 0.823883, accuracy = 0.721811/0.796691, f1 = 0.801308\n",
      "Epoch 168, step 200, training loss 0.547084, test_loss 0.831806, accuracy = 0.712669/0.797562, f1 = 0.801877\n",
      "Epoch 168, step 225, training loss 0.630598, test_loss 0.826987, accuracy = 0.721811/0.795385, f1 = 0.800146\n",
      "Epoch 168, step 250, training loss 0.647967, test_loss 0.822669, accuracy = 0.723117/0.798433, f1 = 0.802878\n",
      "Epoch 168, step 275, training loss 0.617920, test_loss 0.829776, accuracy = 0.721811/0.800610, f1 = 0.804426\n",
      "Epoch 168, step 300, training loss 0.570620, test_loss 0.837380, accuracy = 0.715281/0.795821, f1 = 0.800160\n",
      "Epoch 168, step 325, training loss 0.770287, test_loss 0.826340, accuracy = 0.717022/0.800610, f1 = 0.804588\n",
      "Epoch 168, step 350, training loss 0.624733, test_loss 0.837436, accuracy = 0.719199/0.799739, f1 = 0.803230\n",
      "Epoch 168, step 375, training loss 0.712237, test_loss 0.838213, accuracy = 0.715281/0.797562, f1 = 0.802001\n",
      "Epoch 168, step 400, training loss 0.604876, test_loss 0.827577, accuracy = 0.723552/0.796691, f1 = 0.801368\n",
      "End of epoch 168, training loss 0.556459, test_loss 0.845599, accuracy = 0.720070/0.792773, f1 = 0.797727\n",
      "Confusion matrix:\n",
      "[[818  56  23  40]\n",
      " [ 30 457  60  53]\n",
      " [ 15  70 418  50]\n",
      " [ 15  23  41 128]]\n",
      "Epoch 169, step 0, training loss 0.591496, test_loss 0.823312, accuracy = 0.728777/0.792773, f1 = 0.797727\n",
      "Epoch 169, step 25, training loss 0.580685, test_loss 0.830505, accuracy = 0.714846/0.790161, f1 = 0.795528\n",
      "Epoch 169, step 50, training loss 0.579185, test_loss 0.829683, accuracy = 0.723552/0.794515, f1 = 0.799658\n",
      "Epoch 169, step 75, training loss 0.646854, test_loss 0.822931, accuracy = 0.727906/0.799303, f1 = 0.803760\n",
      "Epoch 169, step 100, training loss 0.648324, test_loss 0.821729, accuracy = 0.715716/0.793209, f1 = 0.798355\n",
      "Epoch 169, step 125, training loss 0.600239, test_loss 0.820664, accuracy = 0.723117/0.793644, f1 = 0.798214\n",
      "Epoch 169, step 150, training loss 0.652653, test_loss 0.810268, accuracy = 0.731824/0.794950, f1 = 0.799612\n",
      "Epoch 169, step 175, training loss 0.716881, test_loss 0.825578, accuracy = 0.718764/0.794515, f1 = 0.799166\n",
      "Epoch 169, step 200, training loss 0.561399, test_loss 0.833557, accuracy = 0.708315/0.797127, f1 = 0.800838\n",
      "Epoch 169, step 225, training loss 0.639462, test_loss 0.828684, accuracy = 0.721811/0.795821, f1 = 0.799657\n",
      "Epoch 169, step 250, training loss 0.596183, test_loss 0.820049, accuracy = 0.727906/0.797997, f1 = 0.801853\n",
      "Epoch 169, step 275, training loss 0.612227, test_loss 0.832939, accuracy = 0.715716/0.800174, f1 = 0.804586\n",
      "Epoch 169, step 300, training loss 0.676645, test_loss 0.832190, accuracy = 0.722246/0.800610, f1 = 0.804857\n",
      "Epoch 169, step 325, training loss 0.786051, test_loss 0.833906, accuracy = 0.711363/0.798433, f1 = 0.802464\n",
      "Epoch 169, step 350, training loss 0.666918, test_loss 0.838650, accuracy = 0.713104/0.799303, f1 = 0.802486\n",
      "Epoch 169, step 375, training loss 0.796188, test_loss 0.832900, accuracy = 0.710492/0.796691, f1 = 0.800458\n",
      "Epoch 169, step 400, training loss 0.665215, test_loss 0.826486, accuracy = 0.724423/0.794079, f1 = 0.798660\n",
      "End of epoch 169, training loss 0.510788, test_loss 0.839052, accuracy = 0.720070/0.797127, f1 = 0.800823\n",
      "Confusion matrix:\n",
      "[[818  58  25  36]\n",
      " [ 28 446  78  48]\n",
      " [ 14  59 441  39]\n",
      " [ 15  24  42 126]]\n",
      "Epoch 170, step 0, training loss 0.628616, test_loss 0.836609, accuracy = 0.709621/0.796691, f1 = 0.800345\n",
      "Epoch 170, step 25, training loss 0.636911, test_loss 0.834714, accuracy = 0.715281/0.795821, f1 = 0.799531\n",
      "Epoch 170, step 50, training loss 0.658835, test_loss 0.825016, accuracy = 0.720505/0.794515, f1 = 0.798048\n",
      "Epoch 170, step 75, training loss 0.602533, test_loss 0.811452, accuracy = 0.726600/0.798433, f1 = 0.802154\n",
      "Epoch 170, step 100, training loss 0.600452, test_loss 0.824028, accuracy = 0.720940/0.797997, f1 = 0.802677\n",
      "Epoch 170, step 125, training loss 0.492073, test_loss 0.815960, accuracy = 0.721376/0.795385, f1 = 0.799960\n",
      "Epoch 170, step 150, training loss 0.622608, test_loss 0.831237, accuracy = 0.710492/0.795385, f1 = 0.799487\n",
      "Epoch 170, step 175, training loss 0.803369, test_loss 0.833461, accuracy = 0.726165/0.795821, f1 = 0.799856\n",
      "Epoch 170, step 200, training loss 0.598467, test_loss 0.834162, accuracy = 0.716151/0.799303, f1 = 0.802470\n",
      "Epoch 170, step 225, training loss 0.563937, test_loss 0.832290, accuracy = 0.727035/0.797127, f1 = 0.800915\n",
      "Epoch 170, step 250, training loss 0.706199, test_loss 0.824368, accuracy = 0.716587/0.801916, f1 = 0.804708\n",
      "Epoch 170, step 275, training loss 0.585552, test_loss 0.815495, accuracy = 0.730953/0.802786, f1 = 0.805718\n",
      "Epoch 170, step 300, training loss 0.639407, test_loss 0.830293, accuracy = 0.718328/0.797997, f1 = 0.801359\n",
      "Epoch 170, step 325, training loss 0.635536, test_loss 0.833251, accuracy = 0.714410/0.799739, f1 = 0.802885\n",
      "Epoch 170, step 350, training loss 0.610640, test_loss 0.846139, accuracy = 0.716587/0.799739, f1 = 0.802399\n",
      "Epoch 170, step 375, training loss 0.687971, test_loss 0.843236, accuracy = 0.705268/0.797997, f1 = 0.801217\n",
      "Epoch 170, step 400, training loss 0.659414, test_loss 0.822937, accuracy = 0.725294/0.795385, f1 = 0.799058\n",
      "End of epoch 170, training loss 0.625716, test_loss 0.822654, accuracy = 0.720070/0.795821, f1 = 0.799765\n",
      "Confusion matrix:\n",
      "[[823  53  22  39]\n",
      " [ 33 442  73  52]\n",
      " [ 16  62 434  41]\n",
      " [ 14  23  41 129]]\n",
      "Epoch 171, step 0, training loss 0.614527, test_loss 0.828777, accuracy = 0.720940/0.795385, f1 = 0.799396\n",
      "Epoch 171, step 25, training loss 0.574339, test_loss 0.815825, accuracy = 0.732695/0.792338, f1 = 0.795963\n",
      "Epoch 171, step 50, training loss 0.580913, test_loss 0.830206, accuracy = 0.721811/0.795385, f1 = 0.798900\n",
      "Epoch 171, step 75, training loss 0.594428, test_loss 0.825437, accuracy = 0.720070/0.801480, f1 = 0.804933\n",
      "Epoch 171, step 100, training loss 0.641149, test_loss 0.829111, accuracy = 0.720505/0.802351, f1 = 0.805734\n",
      "Epoch 171, step 125, training loss 0.582991, test_loss 0.828479, accuracy = 0.716587/0.799739, f1 = 0.804186\n",
      "Epoch 171, step 150, training loss 0.669950, test_loss 0.820426, accuracy = 0.733130/0.797997, f1 = 0.802305\n",
      "Epoch 171, step 175, training loss 0.838982, test_loss 0.817069, accuracy = 0.721376/0.800174, f1 = 0.803817\n",
      "Epoch 171, step 200, training loss 0.596874, test_loss 0.830955, accuracy = 0.721811/0.799303, f1 = 0.802594\n",
      "Epoch 171, step 225, training loss 0.525950, test_loss 0.839299, accuracy = 0.721376/0.796256, f1 = 0.800167\n",
      "Epoch 171, step 250, training loss 0.627793, test_loss 0.824525, accuracy = 0.735307/0.801480, f1 = 0.804513\n",
      "Epoch 171, step 275, training loss 0.623876, test_loss 0.825813, accuracy = 0.725294/0.801916, f1 = 0.805493\n",
      "Epoch 171, step 300, training loss 0.634425, test_loss 0.836441, accuracy = 0.732260/0.802786, f1 = 0.806858\n",
      "Epoch 171, step 325, training loss 0.612957, test_loss 0.824233, accuracy = 0.716151/0.796691, f1 = 0.800758\n",
      "Epoch 171, step 350, training loss 0.647399, test_loss 0.857186, accuracy = 0.707009/0.798868, f1 = 0.802181\n",
      "Epoch 171, step 375, training loss 0.640694, test_loss 0.847305, accuracy = 0.709621/0.789726, f1 = 0.795237\n",
      "Epoch 171, step 400, training loss 0.643363, test_loss 0.835886, accuracy = 0.713975/0.788855, f1 = 0.794528\n",
      "End of epoch 171, training loss 0.581683, test_loss 0.842998, accuracy = 0.714846/0.787984, f1 = 0.794015\n",
      "Confusion matrix:\n",
      "[[821  49  23  44]\n",
      " [ 32 433  67  68]\n",
      " [ 15  62 425  51]\n",
      " [ 15  21  40 131]]\n",
      "Epoch 172, step 0, training loss 0.657905, test_loss 0.839255, accuracy = 0.713539/0.788420, f1 = 0.794332\n",
      "Epoch 172, step 25, training loss 0.539801, test_loss 0.831832, accuracy = 0.720940/0.789290, f1 = 0.794899\n",
      "Epoch 172, step 50, training loss 0.650827, test_loss 0.844074, accuracy = 0.717458/0.795821, f1 = 0.800755\n",
      "Epoch 172, step 75, training loss 0.633523, test_loss 0.815104, accuracy = 0.725729/0.800174, f1 = 0.804046\n",
      "Epoch 172, step 100, training loss 0.662915, test_loss 0.823036, accuracy = 0.732695/0.798868, f1 = 0.803499\n",
      "Epoch 172, step 125, training loss 0.570320, test_loss 0.826157, accuracy = 0.721811/0.793644, f1 = 0.799157\n",
      "Epoch 172, step 150, training loss 0.647517, test_loss 0.827127, accuracy = 0.729212/0.792773, f1 = 0.798617\n",
      "Epoch 172, step 175, training loss 0.682635, test_loss 0.835056, accuracy = 0.714845/0.795821, f1 = 0.800988\n",
      "Epoch 172, step 200, training loss 0.570473, test_loss 0.833641, accuracy = 0.729647/0.797997, f1 = 0.802180\n",
      "Epoch 172, step 225, training loss 0.556471, test_loss 0.836889, accuracy = 0.717022/0.794950, f1 = 0.799572\n",
      "Epoch 172, step 250, training loss 0.608360, test_loss 0.835654, accuracy = 0.719199/0.796256, f1 = 0.800485\n",
      "Epoch 172, step 275, training loss 0.580559, test_loss 0.824259, accuracy = 0.732259/0.794079, f1 = 0.798709\n",
      "Epoch 172, step 300, training loss 0.588372, test_loss 0.826238, accuracy = 0.717893/0.797127, f1 = 0.801519\n",
      "Epoch 172, step 325, training loss 0.663331, test_loss 0.829174, accuracy = 0.722246/0.794950, f1 = 0.798737\n",
      "Epoch 172, step 350, training loss 0.661101, test_loss 0.830911, accuracy = 0.716587/0.792338, f1 = 0.795955\n",
      "Epoch 172, step 375, training loss 0.781853, test_loss 0.830918, accuracy = 0.728341/0.786243, f1 = 0.791780\n",
      "Epoch 172, step 400, training loss 0.652849, test_loss 0.835202, accuracy = 0.706138/0.786243, f1 = 0.791222\n",
      "End of epoch 172, training loss 0.598112, test_loss 0.835545, accuracy = 0.712233/0.788855, f1 = 0.793147\n",
      "Confusion matrix:\n",
      "[[822  52  24  39]\n",
      " [ 38 433  71  58]\n",
      " [ 17  60 430  46]\n",
      " [ 16  23  41 127]]\n",
      "Epoch 173, step 0, training loss 0.571154, test_loss 0.834382, accuracy = 0.724859/0.788855, f1 = 0.793147\n",
      "Epoch 173, step 25, training loss 0.550683, test_loss 0.835254, accuracy = 0.713104/0.784502, f1 = 0.789669\n",
      "Epoch 173, step 50, training loss 0.558541, test_loss 0.825490, accuracy = 0.724859/0.791032, f1 = 0.796019\n",
      "Epoch 173, step 75, training loss 0.634755, test_loss 0.822780, accuracy = 0.724423/0.792773, f1 = 0.796947\n",
      "Epoch 173, step 100, training loss 0.614008, test_loss 0.820887, accuracy = 0.724423/0.791902, f1 = 0.796228\n",
      "Epoch 173, step 125, training loss 0.592149, test_loss 0.829817, accuracy = 0.717022/0.795385, f1 = 0.799168\n",
      "Epoch 173, step 150, training loss 0.747191, test_loss 0.832571, accuracy = 0.712669/0.799739, f1 = 0.803396\n",
      "Epoch 173, step 175, training loss 0.821323, test_loss 0.816799, accuracy = 0.731389/0.797127, f1 = 0.800287\n",
      "Epoch 173, step 200, training loss 0.534025, test_loss 0.832911, accuracy = 0.717022/0.792773, f1 = 0.796064\n",
      "Epoch 173, step 225, training loss 0.566746, test_loss 0.833569, accuracy = 0.714410/0.794950, f1 = 0.798515\n",
      "Epoch 173, step 250, training loss 0.627202, test_loss 0.838275, accuracy = 0.715716/0.798868, f1 = 0.802269\n",
      "Epoch 173, step 275, training loss 0.613132, test_loss 0.825260, accuracy = 0.722682/0.797562, f1 = 0.802025\n",
      "Epoch 173, step 300, training loss 0.634636, test_loss 0.831748, accuracy = 0.724859/0.795385, f1 = 0.800244\n",
      "Epoch 173, step 325, training loss 0.663188, test_loss 0.835393, accuracy = 0.724423/0.794515, f1 = 0.799316\n",
      "Epoch 173, step 350, training loss 0.666763, test_loss 0.839305, accuracy = 0.708315/0.793209, f1 = 0.797044\n",
      "Epoch 173, step 375, training loss 0.722109, test_loss 0.828135, accuracy = 0.720505/0.788855, f1 = 0.794143\n",
      "Epoch 173, step 400, training loss 0.604845, test_loss 0.841925, accuracy = 0.719634/0.788420, f1 = 0.793506\n",
      "End of epoch 173, training loss 0.562136, test_loss 0.839211, accuracy = 0.710492/0.788420, f1 = 0.793686\n",
      "Confusion matrix:\n",
      "[[813  55  22  47]\n",
      " [ 33 440  72  55]\n",
      " [ 16  62 428  47]\n",
      " [ 14  22  41 130]]\n",
      "Epoch 174, step 0, training loss 0.698783, test_loss 0.830049, accuracy = 0.726165/0.789726, f1 = 0.794812\n",
      "Epoch 174, step 25, training loss 0.588051, test_loss 0.815940, accuracy = 0.724423/0.790161, f1 = 0.795049\n",
      "Epoch 174, step 50, training loss 0.677650, test_loss 0.840542, accuracy = 0.721811/0.793209, f1 = 0.797801\n",
      "Epoch 174, step 75, training loss 0.654752, test_loss 0.812535, accuracy = 0.729647/0.798868, f1 = 0.802964\n",
      "Epoch 174, step 100, training loss 0.684264, test_loss 0.814980, accuracy = 0.726600/0.795385, f1 = 0.800252\n",
      "Epoch 174, step 125, training loss 0.575188, test_loss 0.837336, accuracy = 0.720070/0.792338, f1 = 0.797340\n",
      "Epoch 174, step 150, training loss 0.637837, test_loss 0.829038, accuracy = 0.720070/0.792773, f1 = 0.797946\n",
      "Epoch 174, step 175, training loss 0.808945, test_loss 0.821808, accuracy = 0.727471/0.796691, f1 = 0.801256\n",
      "Epoch 174, step 200, training loss 0.536355, test_loss 0.831986, accuracy = 0.715281/0.801045, f1 = 0.804717\n",
      "Epoch 174, step 225, training loss 0.633282, test_loss 0.837656, accuracy = 0.716152/0.796691, f1 = 0.800495\n",
      "Epoch 174, step 250, training loss 0.629231, test_loss 0.828522, accuracy = 0.729212/0.797127, f1 = 0.801225\n",
      "Epoch 174, step 275, training loss 0.708223, test_loss 0.810732, accuracy = 0.733565/0.799739, f1 = 0.803773\n",
      "Epoch 174, step 300, training loss 0.657602, test_loss 0.821721, accuracy = 0.723988/0.798868, f1 = 0.803144\n",
      "Epoch 174, step 325, training loss 0.665799, test_loss 0.832616, accuracy = 0.713539/0.796691, f1 = 0.801416\n",
      "Epoch 174, step 350, training loss 0.612583, test_loss 0.834341, accuracy = 0.716587/0.796256, f1 = 0.799891\n",
      "Epoch 174, step 375, training loss 0.680531, test_loss 0.832559, accuracy = 0.711363/0.792338, f1 = 0.797134\n",
      "Epoch 174, step 400, training loss 0.559272, test_loss 0.844263, accuracy = 0.704832/0.794950, f1 = 0.799340\n",
      "End of epoch 174, training loss 0.534808, test_loss 0.848577, accuracy = 0.715716/0.794515, f1 = 0.798937\n",
      "Confusion matrix:\n",
      "[[818  55  22  42]\n",
      " [ 31 453  67  49]\n",
      " [ 16  69 424  44]\n",
      " [ 14  24  39 130]]\n",
      "Epoch 175, step 0, training loss 0.613094, test_loss 0.832318, accuracy = 0.710057/0.794515, f1 = 0.798878\n",
      "Epoch 175, step 25, training loss 0.576566, test_loss 0.837489, accuracy = 0.720070/0.794515, f1 = 0.799459\n",
      "Epoch 175, step 50, training loss 0.547104, test_loss 0.837189, accuracy = 0.726165/0.795385, f1 = 0.799114\n",
      "Epoch 175, step 75, training loss 0.611276, test_loss 0.821505, accuracy = 0.729212/0.799739, f1 = 0.802250\n",
      "Epoch 175, step 100, training loss 0.696494, test_loss 0.830068, accuracy = 0.715716/0.792773, f1 = 0.796351\n",
      "Epoch 175, step 125, training loss 0.551832, test_loss 0.815190, accuracy = 0.721376/0.791032, f1 = 0.795019\n",
      "Epoch 175, step 150, training loss 0.717659, test_loss 0.834986, accuracy = 0.727906/0.793644, f1 = 0.797067\n",
      "Epoch 175, step 175, training loss 0.662396, test_loss 0.830186, accuracy = 0.730518/0.791032, f1 = 0.794516\n",
      "Epoch 175, step 200, training loss 0.535685, test_loss 0.835726, accuracy = 0.715716/0.795821, f1 = 0.798485\n",
      "Epoch 175, step 225, training loss 0.572950, test_loss 0.832747, accuracy = 0.720070/0.792338, f1 = 0.796009\n",
      "Epoch 175, step 250, training loss 0.618394, test_loss 0.827163, accuracy = 0.727035/0.793209, f1 = 0.796073\n",
      "Epoch 175, step 275, training loss 0.643318, test_loss 0.815198, accuracy = 0.729647/0.797127, f1 = 0.800023\n",
      "Epoch 175, step 300, training loss 0.747715, test_loss 0.835123, accuracy = 0.717458/0.797562, f1 = 0.800693\n",
      "Epoch 175, step 325, training loss 0.792931, test_loss 0.832386, accuracy = 0.716587/0.798868, f1 = 0.801683\n",
      "Epoch 175, step 350, training loss 0.673818, test_loss 0.837903, accuracy = 0.714410/0.796691, f1 = 0.799923\n",
      "Epoch 175, step 375, training loss 0.669379, test_loss 0.833917, accuracy = 0.722682/0.794950, f1 = 0.799490\n",
      "Epoch 175, step 400, training loss 0.675536, test_loss 0.850970, accuracy = 0.711798/0.791467, f1 = 0.796218\n",
      "End of epoch 175, training loss 0.575282, test_loss 0.826344, accuracy = 0.712233/0.791467, f1 = 0.796093\n",
      "Confusion matrix:\n",
      "[[820  49  25  43]\n",
      " [ 35 442  68  55]\n",
      " [ 16  65 427  45]\n",
      " [ 15  21  42 129]]\n",
      "Epoch 176, step 0, training loss 0.589078, test_loss 0.830704, accuracy = 0.715716/0.792338, f1 = 0.796849\n",
      "Epoch 176, step 25, training loss 0.591701, test_loss 0.843597, accuracy = 0.711798/0.794515, f1 = 0.799068\n",
      "Epoch 176, step 50, training loss 0.609974, test_loss 0.828505, accuracy = 0.723117/0.796691, f1 = 0.800268\n",
      "Epoch 176, step 75, training loss 0.590266, test_loss 0.838663, accuracy = 0.717022/0.798868, f1 = 0.801768\n",
      "Epoch 176, step 100, training loss 0.652862, test_loss 0.832701, accuracy = 0.720070/0.797127, f1 = 0.801628\n",
      "Epoch 176, step 125, training loss 0.582430, test_loss 0.834944, accuracy = 0.725294/0.801916, f1 = 0.806536\n",
      "Epoch 176, step 150, training loss 0.624572, test_loss 0.830704, accuracy = 0.726165/0.797127, f1 = 0.801999\n",
      "Epoch 176, step 175, training loss 0.771285, test_loss 0.834419, accuracy = 0.723552/0.798868, f1 = 0.803078\n",
      "Epoch 176, step 200, training loss 0.511404, test_loss 0.827516, accuracy = 0.727471/0.797562, f1 = 0.801144\n",
      "Epoch 176, step 225, training loss 0.599994, test_loss 0.825592, accuracy = 0.718764/0.797562, f1 = 0.801125\n",
      "Epoch 176, step 250, training loss 0.670428, test_loss 0.833200, accuracy = 0.723552/0.801480, f1 = 0.804248\n",
      "Epoch 176, step 275, training loss 0.770403, test_loss 0.814868, accuracy = 0.726600/0.799739, f1 = 0.802857\n",
      "Epoch 176, step 300, training loss 0.532880, test_loss 0.831476, accuracy = 0.718328/0.799303, f1 = 0.802655\n",
      "Epoch 176, step 325, training loss 0.667041, test_loss 0.814410, accuracy = 0.720070/0.797997, f1 = 0.801146\n",
      "Epoch 176, step 350, training loss 0.610003, test_loss 0.837546, accuracy = 0.715716/0.797562, f1 = 0.800278\n",
      "Epoch 176, step 375, training loss 0.850568, test_loss 0.827797, accuracy = 0.718764/0.793644, f1 = 0.797724\n",
      "Epoch 176, step 400, training loss 0.626025, test_loss 0.826325, accuracy = 0.720940/0.793644, f1 = 0.798173\n",
      "End of epoch 176, training loss 0.601409, test_loss 0.836522, accuracy = 0.720070/0.791903, f1 = 0.796447\n",
      "Confusion matrix:\n",
      "[[819  53  24  41]\n",
      " [ 31 435  76  58]\n",
      " [ 15  62 436  40]\n",
      " [ 13  21  44 129]]\n",
      "Epoch 177, step 0, training loss 0.624789, test_loss 0.841954, accuracy = 0.720940/0.792773, f1 = 0.797358\n",
      "Epoch 177, step 25, training loss 0.621396, test_loss 0.834062, accuracy = 0.716151/0.792338, f1 = 0.797978\n",
      "Epoch 177, step 50, training loss 0.516458, test_loss 0.834647, accuracy = 0.719634/0.797997, f1 = 0.803168\n",
      "Epoch 177, step 75, training loss 0.551184, test_loss 0.835668, accuracy = 0.724423/0.797997, f1 = 0.802190\n",
      "Epoch 177, step 100, training loss 0.615918, test_loss 0.819767, accuracy = 0.726165/0.796691, f1 = 0.801558\n",
      "Epoch 177, step 125, training loss 0.558722, test_loss 0.829829, accuracy = 0.723552/0.794515, f1 = 0.799843\n",
      "Epoch 177, step 150, training loss 0.591804, test_loss 0.840675, accuracy = 0.722682/0.796691, f1 = 0.802065\n",
      "Epoch 177, step 175, training loss 0.798205, test_loss 0.822994, accuracy = 0.718764/0.795821, f1 = 0.801036\n",
      "Epoch 177, step 200, training loss 0.506483, test_loss 0.830455, accuracy = 0.725294/0.797127, f1 = 0.801749\n",
      "Epoch 177, step 225, training loss 0.627980, test_loss 0.836883, accuracy = 0.721811/0.794950, f1 = 0.799341\n",
      "Epoch 177, step 250, training loss 0.727832, test_loss 0.811363, accuracy = 0.729212/0.798868, f1 = 0.802454\n",
      "Epoch 177, step 275, training loss 0.648974, test_loss 0.828095, accuracy = 0.717022/0.799739, f1 = 0.803887\n",
      "Epoch 177, step 300, training loss 0.667799, test_loss 0.820890, accuracy = 0.727906/0.795821, f1 = 0.800315\n",
      "Epoch 177, step 325, training loss 0.734190, test_loss 0.826629, accuracy = 0.730083/0.798433, f1 = 0.802402\n",
      "Epoch 177, step 350, training loss 0.562763, test_loss 0.839353, accuracy = 0.718328/0.799303, f1 = 0.802590\n",
      "Epoch 177, step 375, training loss 0.638559, test_loss 0.844937, accuracy = 0.712233/0.793209, f1 = 0.797826\n",
      "Epoch 177, step 400, training loss 0.615119, test_loss 0.832500, accuracy = 0.716151/0.794515, f1 = 0.798715\n",
      "End of epoch 177, training loss 0.558331, test_loss 0.839325, accuracy = 0.727471/0.794950, f1 = 0.799112\n",
      "Confusion matrix:\n",
      "[[823  54  22  38]\n",
      " [ 34 449  65  52]\n",
      " [ 15  70 424  44]\n",
      " [ 14  23  40 130]]\n",
      "Epoch 178, step 0, training loss 0.640940, test_loss 0.824652, accuracy = 0.723988/0.795385, f1 = 0.799529\n",
      "Epoch 178, step 25, training loss 0.623450, test_loss 0.828254, accuracy = 0.722246/0.791903, f1 = 0.796795\n",
      "Epoch 178, step 50, training loss 0.612046, test_loss 0.852917, accuracy = 0.719199/0.791032, f1 = 0.796204\n",
      "Epoch 178, step 75, training loss 0.595624, test_loss 0.822704, accuracy = 0.721811/0.798868, f1 = 0.802470\n",
      "Epoch 178, step 100, training loss 0.606893, test_loss 0.825848, accuracy = 0.720940/0.799303, f1 = 0.802817\n",
      "Epoch 178, step 125, training loss 0.561777, test_loss 0.819102, accuracy = 0.728777/0.795385, f1 = 0.800076\n",
      "Epoch 178, step 150, training loss 0.674566, test_loss 0.807774, accuracy = 0.727906/0.794515, f1 = 0.800446\n",
      "Epoch 178, step 175, training loss 0.732740, test_loss 0.819994, accuracy = 0.730518/0.796256, f1 = 0.800797\n",
      "Epoch 178, step 200, training loss 0.513992, test_loss 0.822323, accuracy = 0.727035/0.797997, f1 = 0.801450\n",
      "Epoch 178, step 225, training loss 0.603144, test_loss 0.823600, accuracy = 0.730083/0.795821, f1 = 0.800218\n",
      "Epoch 178, step 250, training loss 0.612320, test_loss 0.834705, accuracy = 0.722246/0.796691, f1 = 0.800813\n",
      "Epoch 178, step 275, training loss 0.651057, test_loss 0.815079, accuracy = 0.727471/0.797127, f1 = 0.801545\n",
      "Epoch 178, step 300, training loss 0.625761, test_loss 0.840106, accuracy = 0.711798/0.794515, f1 = 0.799303\n",
      "Epoch 178, step 325, training loss 0.699270, test_loss 0.821861, accuracy = 0.729647/0.794079, f1 = 0.798712\n",
      "Epoch 178, step 350, training loss 0.549955, test_loss 0.848950, accuracy = 0.715281/0.797127, f1 = 0.800711\n",
      "Epoch 178, step 375, training loss 0.692989, test_loss 0.842146, accuracy = 0.723988/0.792338, f1 = 0.797556\n",
      "Epoch 178, step 400, training loss 0.673321, test_loss 0.833716, accuracy = 0.718328/0.796691, f1 = 0.800694\n",
      "End of epoch 178, training loss 0.657558, test_loss 0.838410, accuracy = 0.718764/0.796256, f1 = 0.799574\n",
      "Confusion matrix:\n",
      "[[819  61  23  34]\n",
      " [ 32 451  72  45]\n",
      " [ 15  68 432  38]\n",
      " [ 14  25  41 127]]\n",
      "Epoch 179, step 0, training loss 0.613787, test_loss 0.830001, accuracy = 0.723988/0.796691, f1 = 0.800068\n",
      "Epoch 179, step 25, training loss 0.599752, test_loss 0.839806, accuracy = 0.713104/0.792773, f1 = 0.796506\n",
      "Epoch 179, step 50, training loss 0.653006, test_loss 0.821578, accuracy = 0.727471/0.797997, f1 = 0.801263\n",
      "Epoch 179, step 75, training loss 0.638354, test_loss 0.830228, accuracy = 0.714846/0.803222, f1 = 0.805644\n",
      "Epoch 179, step 100, training loss 0.661013, test_loss 0.822306, accuracy = 0.725294/0.800610, f1 = 0.803513\n",
      "Epoch 179, step 125, training loss 0.629113, test_loss 0.816678, accuracy = 0.725729/0.796256, f1 = 0.800126\n",
      "Epoch 179, step 150, training loss 0.741332, test_loss 0.823666, accuracy = 0.730518/0.796256, f1 = 0.801039\n",
      "Epoch 179, step 175, training loss 0.787112, test_loss 0.833132, accuracy = 0.717458/0.797997, f1 = 0.802599\n",
      "Epoch 179, step 200, training loss 0.520871, test_loss 0.820708, accuracy = 0.728341/0.799739, f1 = 0.803277\n",
      "Epoch 179, step 225, training loss 0.566920, test_loss 0.824002, accuracy = 0.730518/0.799739, f1 = 0.803214\n",
      "Epoch 179, step 250, training loss 0.622817, test_loss 0.828407, accuracy = 0.727906/0.801480, f1 = 0.804367\n",
      "Epoch 179, step 275, training loss 0.574990, test_loss 0.815394, accuracy = 0.723988/0.802351, f1 = 0.805024\n",
      "Epoch 179, step 300, training loss 0.575374, test_loss 0.832316, accuracy = 0.720940/0.799303, f1 = 0.802436\n",
      "Epoch 179, step 325, training loss 0.723572, test_loss 0.835977, accuracy = 0.720070/0.798868, f1 = 0.802036\n",
      "Epoch 179, step 350, training loss 0.638306, test_loss 0.840013, accuracy = 0.719199/0.799739, f1 = 0.802458\n",
      "Epoch 179, step 375, training loss 0.651048, test_loss 0.841293, accuracy = 0.714846/0.795385, f1 = 0.799386\n",
      "Epoch 179, step 400, training loss 0.629015, test_loss 0.824620, accuracy = 0.719634/0.796691, f1 = 0.799976\n",
      "End of epoch 179, training loss 0.616176, test_loss 0.834636, accuracy = 0.717022/0.799303, f1 = 0.802343\n",
      "Confusion matrix:\n",
      "[[827  55  23  32]\n",
      " [ 30 455  68  47]\n",
      " [ 19  66 428  40]\n",
      " [ 17  24  40 126]]\n",
      "Epoch 180, step 0, training loss 0.584491, test_loss 0.818489, accuracy = 0.721376/0.799739, f1 = 0.802870\n",
      "Epoch 180, step 25, training loss 0.555487, test_loss 0.827938, accuracy = 0.710492/0.791903, f1 = 0.795480\n",
      "Epoch 180, step 50, training loss 0.593448, test_loss 0.836591, accuracy = 0.718764/0.796256, f1 = 0.798898\n",
      "Epoch 180, step 75, training loss 0.600629, test_loss 0.827623, accuracy = 0.720940/0.801916, f1 = 0.803912\n",
      "Epoch 180, step 100, training loss 0.716453, test_loss 0.824133, accuracy = 0.725294/0.800610, f1 = 0.804002\n",
      "Epoch 180, step 125, training loss 0.578757, test_loss 0.831403, accuracy = 0.725729/0.797127, f1 = 0.801585\n",
      "Epoch 180, step 150, training loss 0.660368, test_loss 0.831995, accuracy = 0.721811/0.796256, f1 = 0.800451\n",
      "Epoch 180, step 175, training loss 0.824987, test_loss 0.830348, accuracy = 0.718764/0.798868, f1 = 0.802682\n",
      "Epoch 180, step 200, training loss 0.563764, test_loss 0.836605, accuracy = 0.720505/0.801480, f1 = 0.804853\n",
      "Epoch 180, step 225, training loss 0.517189, test_loss 0.823545, accuracy = 0.729647/0.801916, f1 = 0.805483\n",
      "Epoch 180, step 250, training loss 0.681611, test_loss 0.827496, accuracy = 0.719634/0.801045, f1 = 0.804015\n",
      "Epoch 180, step 275, training loss 0.541219, test_loss 0.827665, accuracy = 0.719634/0.806269, f1 = 0.808851\n",
      "Epoch 180, step 300, training loss 0.628167, test_loss 0.821825, accuracy = 0.727906/0.804528, f1 = 0.807607\n",
      "Epoch 180, step 325, training loss 0.771575, test_loss 0.837311, accuracy = 0.715716/0.801916, f1 = 0.804536\n",
      "Epoch 180, step 350, training loss 0.556467, test_loss 0.834717, accuracy = 0.717022/0.799739, f1 = 0.802294\n",
      "Epoch 180, step 375, training loss 0.704579, test_loss 0.824778, accuracy = 0.728777/0.796691, f1 = 0.801247\n",
      "Epoch 180, step 400, training loss 0.610244, test_loss 0.825287, accuracy = 0.717893/0.797997, f1 = 0.801819\n",
      "End of epoch 180, training loss 0.572405, test_loss 0.826264, accuracy = 0.729647/0.802351, f1 = 0.805656\n",
      "Confusion matrix:\n",
      "[[827  54  23  33]\n",
      " [ 27 461  67  45]\n",
      " [ 16  66 429  42]\n",
      " [ 17  22  42 126]]\n",
      "Epoch 181, step 0, training loss 0.575879, test_loss 0.829923, accuracy = 0.717893/0.802351, f1 = 0.805546\n",
      "Epoch 181, step 25, training loss 0.609783, test_loss 0.832732, accuracy = 0.713104/0.796691, f1 = 0.801317\n",
      "Epoch 181, step 50, training loss 0.569627, test_loss 0.829605, accuracy = 0.726165/0.801045, f1 = 0.804472\n",
      "Epoch 181, step 75, training loss 0.596728, test_loss 0.821189, accuracy = 0.729212/0.802786, f1 = 0.805908\n",
      "Epoch 181, step 100, training loss 0.626462, test_loss 0.820638, accuracy = 0.731824/0.801480, f1 = 0.804859\n",
      "Epoch 181, step 125, training loss 0.657880, test_loss 0.826706, accuracy = 0.723988/0.797997, f1 = 0.801737\n",
      "Epoch 181, step 150, training loss 0.588256, test_loss 0.816520, accuracy = 0.727471/0.801916, f1 = 0.804928\n",
      "Epoch 181, step 175, training loss 0.721853, test_loss 0.809148, accuracy = 0.727906/0.801916, f1 = 0.804335\n",
      "Epoch 181, step 200, training loss 0.574280, test_loss 0.839834, accuracy = 0.718328/0.800610, f1 = 0.803511\n",
      "Epoch 181, step 225, training loss 0.560780, test_loss 0.830816, accuracy = 0.724859/0.801045, f1 = 0.804445\n",
      "Epoch 181, step 250, training loss 0.659121, test_loss 0.823242, accuracy = 0.732260/0.804963, f1 = 0.808189\n",
      "Epoch 181, step 275, training loss 0.585280, test_loss 0.836024, accuracy = 0.722682/0.803222, f1 = 0.806150\n",
      "Epoch 181, step 300, training loss 0.536744, test_loss 0.832570, accuracy = 0.714845/0.803657, f1 = 0.807004\n",
      "Epoch 181, step 325, training loss 0.614055, test_loss 0.843655, accuracy = 0.718764/0.800174, f1 = 0.803786\n",
      "Epoch 181, step 350, training loss 0.680792, test_loss 0.830800, accuracy = 0.718328/0.800610, f1 = 0.804002\n",
      "Epoch 181, step 375, training loss 0.807600, test_loss 0.839776, accuracy = 0.715716/0.795385, f1 = 0.800203\n",
      "Epoch 181, step 400, training loss 0.728235, test_loss 0.825283, accuracy = 0.719199/0.791032, f1 = 0.796144\n",
      "End of epoch 181, training loss 0.569831, test_loss 0.834775, accuracy = 0.714845/0.791903, f1 = 0.796722\n",
      "Confusion matrix:\n",
      "[[823  49  21  44]\n",
      " [ 31 448  69  52]\n",
      " [ 19  62 421  51]\n",
      " [ 17  22  41 127]]\n",
      "Epoch 182, step 0, training loss 0.638542, test_loss 0.835275, accuracy = 0.717893/0.792773, f1 = 0.797566\n",
      "Epoch 182, step 25, training loss 0.661294, test_loss 0.825815, accuracy = 0.723988/0.795821, f1 = 0.800525\n",
      "Epoch 182, step 50, training loss 0.629042, test_loss 0.836640, accuracy = 0.715281/0.795821, f1 = 0.799452\n",
      "Epoch 182, step 75, training loss 0.659602, test_loss 0.821171, accuracy = 0.719199/0.801916, f1 = 0.804850\n",
      "Epoch 182, step 100, training loss 0.665989, test_loss 0.826247, accuracy = 0.727035/0.801045, f1 = 0.803966\n",
      "Epoch 182, step 125, training loss 0.595208, test_loss 0.831497, accuracy = 0.720505/0.795821, f1 = 0.800025\n",
      "Epoch 182, step 150, training loss 0.663571, test_loss 0.831188, accuracy = 0.716587/0.796691, f1 = 0.800859\n",
      "Epoch 182, step 175, training loss 0.836816, test_loss 0.822940, accuracy = 0.728341/0.801045, f1 = 0.804684\n",
      "Epoch 182, step 200, training loss 0.598255, test_loss 0.826527, accuracy = 0.714845/0.803657, f1 = 0.806384\n",
      "Epoch 182, step 225, training loss 0.501840, test_loss 0.826463, accuracy = 0.722682/0.802351, f1 = 0.805191\n",
      "Epoch 182, step 250, training loss 0.668295, test_loss 0.833409, accuracy = 0.719634/0.803222, f1 = 0.806052\n",
      "Epoch 182, step 275, training loss 0.596569, test_loss 0.841591, accuracy = 0.717022/0.797997, f1 = 0.801520\n",
      "Epoch 182, step 300, training loss 0.609136, test_loss 0.832597, accuracy = 0.715716/0.797997, f1 = 0.802223\n",
      "Epoch 182, step 325, training loss 0.755906, test_loss 0.824704, accuracy = 0.726165/0.797127, f1 = 0.800934\n",
      "Epoch 182, step 350, training loss 0.656053, test_loss 0.833984, accuracy = 0.727035/0.799739, f1 = 0.802695\n",
      "Epoch 182, step 375, training loss 0.710576, test_loss 0.852266, accuracy = 0.717458/0.794515, f1 = 0.798356\n",
      "Epoch 182, step 400, training loss 0.589532, test_loss 0.826853, accuracy = 0.713975/0.795385, f1 = 0.798881\n",
      "End of epoch 182, training loss 0.616613, test_loss 0.835211, accuracy = 0.715716/0.796691, f1 = 0.799841\n",
      "Confusion matrix:\n",
      "[[826  52  25  34]\n",
      " [ 32 442  78  48]\n",
      " [ 15  61 438  39]\n",
      " [ 16  22  45 124]]\n",
      "Epoch 183, step 0, training loss 0.660982, test_loss 0.829993, accuracy = 0.720940/0.796691, f1 = 0.799841\n",
      "Epoch 183, step 25, training loss 0.604119, test_loss 0.828688, accuracy = 0.720940/0.798433, f1 = 0.802164\n",
      "Epoch 183, step 50, training loss 0.599674, test_loss 0.834664, accuracy = 0.719634/0.801045, f1 = 0.804063\n",
      "Epoch 183, step 75, training loss 0.612279, test_loss 0.819983, accuracy = 0.727471/0.801480, f1 = 0.804153\n",
      "Epoch 183, step 100, training loss 0.627138, test_loss 0.821606, accuracy = 0.726165/0.801480, f1 = 0.804352\n",
      "Epoch 183, step 125, training loss 0.648109, test_loss 0.829763, accuracy = 0.720505/0.800174, f1 = 0.803649\n",
      "Epoch 183, step 150, training loss 0.582119, test_loss 0.837479, accuracy = 0.713975/0.801045, f1 = 0.804138\n",
      "Epoch 183, step 175, training loss 0.737948, test_loss 0.841681, accuracy = 0.716152/0.804092, f1 = 0.806868\n",
      "Epoch 183, step 200, training loss 0.617682, test_loss 0.835992, accuracy = 0.722246/0.801916, f1 = 0.804808\n",
      "Epoch 183, step 225, training loss 0.542708, test_loss 0.841814, accuracy = 0.706574/0.799739, f1 = 0.802762\n",
      "Epoch 183, step 250, training loss 0.584740, test_loss 0.827017, accuracy = 0.727035/0.803222, f1 = 0.805328\n",
      "Epoch 183, step 275, training loss 0.680014, test_loss 0.813750, accuracy = 0.728341/0.801916, f1 = 0.804338\n",
      "Epoch 183, step 300, training loss 0.635025, test_loss 0.831213, accuracy = 0.712669/0.798433, f1 = 0.801753\n",
      "Epoch 183, step 325, training loss 0.725023, test_loss 0.828261, accuracy = 0.731389/0.797127, f1 = 0.800220\n",
      "Epoch 183, step 350, training loss 0.684434, test_loss 0.828531, accuracy = 0.712233/0.797562, f1 = 0.799954\n",
      "Epoch 183, step 375, training loss 0.672246, test_loss 0.829473, accuracy = 0.718328/0.793644, f1 = 0.797783\n",
      "Epoch 183, step 400, training loss 0.639448, test_loss 0.840562, accuracy = 0.719199/0.797127, f1 = 0.800335\n",
      "End of epoch 183, training loss 0.627187, test_loss 0.831358, accuracy = 0.713975/0.795385, f1 = 0.798935\n",
      "Confusion matrix:\n",
      "[[826  55  21  35]\n",
      " [ 34 447  72  47]\n",
      " [ 18  63 425  47]\n",
      " [ 17  23  38 129]]\n",
      "Epoch 184, step 0, training loss 0.691693, test_loss 0.816063, accuracy = 0.730518/0.794950, f1 = 0.798583\n",
      "Epoch 184, step 25, training loss 0.555923, test_loss 0.824289, accuracy = 0.720940/0.795821, f1 = 0.799957\n",
      "Epoch 184, step 50, training loss 0.503799, test_loss 0.838675, accuracy = 0.714410/0.795821, f1 = 0.799480\n",
      "Epoch 184, step 75, training loss 0.622990, test_loss 0.819059, accuracy = 0.721811/0.800174, f1 = 0.803266\n",
      "Epoch 184, step 100, training loss 0.653214, test_loss 0.823068, accuracy = 0.721811/0.799303, f1 = 0.802869\n",
      "Epoch 184, step 125, training loss 0.532700, test_loss 0.832794, accuracy = 0.724859/0.797562, f1 = 0.801518\n",
      "Epoch 184, step 150, training loss 0.638454, test_loss 0.828429, accuracy = 0.719199/0.800174, f1 = 0.803775\n",
      "Epoch 184, step 175, training loss 0.741619, test_loss 0.823283, accuracy = 0.715716/0.799739, f1 = 0.803415\n",
      "Epoch 184, step 200, training loss 0.583857, test_loss 0.822312, accuracy = 0.726165/0.798868, f1 = 0.802598\n",
      "Epoch 184, step 225, training loss 0.507435, test_loss 0.823077, accuracy = 0.727906/0.797127, f1 = 0.801300\n",
      "Epoch 184, step 250, training loss 0.705607, test_loss 0.805469, accuracy = 0.735307/0.798868, f1 = 0.802847\n",
      "Epoch 184, step 275, training loss 0.677260, test_loss 0.831710, accuracy = 0.720070/0.801480, f1 = 0.805835\n",
      "Epoch 184, step 300, training loss 0.659708, test_loss 0.831735, accuracy = 0.721811/0.801480, f1 = 0.805926\n",
      "Epoch 184, step 325, training loss 0.688298, test_loss 0.838390, accuracy = 0.714410/0.796256, f1 = 0.801156\n",
      "Epoch 184, step 350, training loss 0.589297, test_loss 0.839692, accuracy = 0.707009/0.796691, f1 = 0.801112\n",
      "Epoch 184, step 375, training loss 0.749459, test_loss 0.835933, accuracy = 0.722246/0.796691, f1 = 0.802403\n",
      "Epoch 184, step 400, training loss 0.574263, test_loss 0.831982, accuracy = 0.721376/0.797562, f1 = 0.802303\n",
      "End of epoch 184, training loss 0.521436, test_loss 0.818273, accuracy = 0.720940/0.798433, f1 = 0.802851\n",
      "Confusion matrix:\n",
      "[[830  44  22  41]\n",
      " [ 33 447  67  53]\n",
      " [ 18  60 426  49]\n",
      " [ 16  21  39 131]]\n",
      "Epoch 185, step 0, training loss 0.515486, test_loss 0.834298, accuracy = 0.716587/0.798433, f1 = 0.802849\n",
      "Epoch 185, step 25, training loss 0.639424, test_loss 0.828321, accuracy = 0.726165/0.796256, f1 = 0.801291\n",
      "Epoch 185, step 50, training loss 0.603599, test_loss 0.825130, accuracy = 0.718764/0.798433, f1 = 0.802492\n",
      "Epoch 185, step 75, training loss 0.553638, test_loss 0.822505, accuracy = 0.723552/0.804963, f1 = 0.808045\n",
      "Epoch 185, step 100, training loss 0.636978, test_loss 0.811262, accuracy = 0.728777/0.796691, f1 = 0.800846\n",
      "Epoch 185, step 125, training loss 0.567150, test_loss 0.816359, accuracy = 0.725729/0.794515, f1 = 0.799211\n",
      "Epoch 185, step 150, training loss 0.672503, test_loss 0.820569, accuracy = 0.724859/0.794515, f1 = 0.799215\n",
      "Epoch 185, step 175, training loss 0.740585, test_loss 0.819070, accuracy = 0.729212/0.797997, f1 = 0.802274\n",
      "Epoch 185, step 200, training loss 0.602797, test_loss 0.826102, accuracy = 0.728777/0.799739, f1 = 0.803351\n",
      "Epoch 185, step 225, training loss 0.566646, test_loss 0.814120, accuracy = 0.730083/0.800610, f1 = 0.804417\n",
      "Epoch 185, step 250, training loss 0.636998, test_loss 0.824726, accuracy = 0.724423/0.798868, f1 = 0.802314\n",
      "Epoch 185, step 275, training loss 0.671892, test_loss 0.821395, accuracy = 0.723117/0.801045, f1 = 0.804944\n",
      "Epoch 185, step 300, training loss 0.667972, test_loss 0.822843, accuracy = 0.721376/0.803657, f1 = 0.807220\n",
      "Epoch 185, step 325, training loss 0.731218, test_loss 0.829734, accuracy = 0.717458/0.801045, f1 = 0.804655\n",
      "Epoch 185, step 350, training loss 0.588746, test_loss 0.835014, accuracy = 0.717893/0.799739, f1 = 0.802543\n",
      "Epoch 185, step 375, training loss 0.763160, test_loss 0.837001, accuracy = 0.710492/0.795821, f1 = 0.799985\n",
      "Epoch 185, step 400, training loss 0.735654, test_loss 0.824700, accuracy = 0.723988/0.795385, f1 = 0.799990\n",
      "End of epoch 185, training loss 0.526000, test_loss 0.835670, accuracy = 0.715281/0.794079, f1 = 0.798995\n",
      "Confusion matrix:\n",
      "[[824  45  22  46]\n",
      " [ 32 433  77  58]\n",
      " [ 13  58 438  44]\n",
      " [ 16  19  43 129]]\n",
      "Epoch 186, step 0, training loss 0.573001, test_loss 0.821302, accuracy = 0.714410/0.794950, f1 = 0.799792\n",
      "Epoch 186, step 25, training loss 0.577596, test_loss 0.842685, accuracy = 0.714410/0.791903, f1 = 0.797524\n",
      "Epoch 186, step 50, training loss 0.606408, test_loss 0.827297, accuracy = 0.719199/0.796256, f1 = 0.801141\n",
      "Epoch 186, step 75, training loss 0.623224, test_loss 0.831960, accuracy = 0.717458/0.800610, f1 = 0.804493\n",
      "Epoch 186, step 100, training loss 0.610215, test_loss 0.815532, accuracy = 0.728777/0.800609, f1 = 0.804583\n",
      "Epoch 186, step 125, training loss 0.633407, test_loss 0.824762, accuracy = 0.723117/0.798868, f1 = 0.803533\n",
      "Epoch 186, step 150, training loss 0.612119, test_loss 0.824468, accuracy = 0.719199/0.798433, f1 = 0.802668\n",
      "Epoch 186, step 175, training loss 0.660091, test_loss 0.813106, accuracy = 0.735307/0.799739, f1 = 0.803304\n",
      "Epoch 186, step 200, training loss 0.573980, test_loss 0.831576, accuracy = 0.733566/0.802351, f1 = 0.805472\n",
      "Epoch 186, step 225, training loss 0.532643, test_loss 0.829496, accuracy = 0.721811/0.799303, f1 = 0.802161\n",
      "Epoch 186, step 250, training loss 0.637476, test_loss 0.831419, accuracy = 0.721811/0.803657, f1 = 0.806065\n",
      "Epoch 186, step 275, training loss 0.600847, test_loss 0.824201, accuracy = 0.718328/0.802786, f1 = 0.805682\n",
      "Epoch 186, step 300, training loss 0.632773, test_loss 0.829041, accuracy = 0.722682/0.798433, f1 = 0.801804\n",
      "Epoch 186, step 325, training loss 0.687978, test_loss 0.834120, accuracy = 0.720940/0.801480, f1 = 0.804320\n",
      "Epoch 186, step 350, training loss 0.690799, test_loss 0.852132, accuracy = 0.709186/0.800610, f1 = 0.802879\n",
      "Epoch 186, step 375, training loss 0.559501, test_loss 0.843850, accuracy = 0.719634/0.794515, f1 = 0.797951\n",
      "Epoch 186, step 400, training loss 0.643232, test_loss 0.843428, accuracy = 0.718764/0.796256, f1 = 0.799743\n",
      "End of epoch 186, training loss 0.544505, test_loss 0.841522, accuracy = 0.714410/0.796691, f1 = 0.799842\n",
      "Confusion matrix:\n",
      "[[827  53  24  33]\n",
      " [ 32 456  65  47]\n",
      " [ 16  72 423  42]\n",
      " [ 19  24  40 124]]\n",
      "Epoch 187, step 0, training loss 0.641816, test_loss 0.834819, accuracy = 0.711363/0.797562, f1 = 0.800720\n",
      "Epoch 187, step 25, training loss 0.631954, test_loss 0.840231, accuracy = 0.712233/0.793644, f1 = 0.797542\n",
      "Epoch 187, step 50, training loss 0.534573, test_loss 0.844903, accuracy = 0.720070/0.798433, f1 = 0.801232\n",
      "Epoch 187, step 75, training loss 0.618216, test_loss 0.824757, accuracy = 0.718328/0.801480, f1 = 0.803962\n",
      "Epoch 187, step 100, training loss 0.625177, test_loss 0.823835, accuracy = 0.724859/0.798433, f1 = 0.801570\n",
      "Epoch 187, step 125, training loss 0.654002, test_loss 0.838010, accuracy = 0.724423/0.794950, f1 = 0.798836\n",
      "Epoch 187, step 150, training loss 0.673161, test_loss 0.823838, accuracy = 0.723553/0.794515, f1 = 0.797825\n",
      "Epoch 187, step 175, training loss 0.693359, test_loss 0.828397, accuracy = 0.719634/0.799739, f1 = 0.802452\n",
      "Epoch 187, step 200, training loss 0.501539, test_loss 0.828142, accuracy = 0.720070/0.799303, f1 = 0.801515\n",
      "Epoch 187, step 225, training loss 0.538947, test_loss 0.836182, accuracy = 0.721376/0.804092, f1 = 0.806479\n",
      "Epoch 187, step 250, training loss 0.612874, test_loss 0.838075, accuracy = 0.726600/0.801480, f1 = 0.803796\n",
      "Epoch 187, step 275, training loss 0.651918, test_loss 0.839470, accuracy = 0.716587/0.801045, f1 = 0.803727\n",
      "Epoch 187, step 300, training loss 0.679532, test_loss 0.820044, accuracy = 0.726600/0.798433, f1 = 0.802049\n",
      "Epoch 187, step 325, training loss 0.672457, test_loss 0.830892, accuracy = 0.721376/0.799303, f1 = 0.802414\n",
      "Epoch 187, step 350, training loss 0.574857, test_loss 0.839289, accuracy = 0.709186/0.802786, f1 = 0.804984\n",
      "Epoch 187, step 375, training loss 0.753302, test_loss 0.833695, accuracy = 0.712233/0.794079, f1 = 0.797982\n",
      "Epoch 187, step 400, training loss 0.714880, test_loss 0.819088, accuracy = 0.726165/0.794079, f1 = 0.798116\n",
      "End of epoch 187, training loss 0.566571, test_loss 0.842186, accuracy = 0.714845/0.793644, f1 = 0.797215\n",
      "Confusion matrix:\n",
      "[[823  56  21  37]\n",
      " [ 32 454  70  44]\n",
      " [ 17  68 422  46]\n",
      " [ 17  23  43 124]]\n",
      "Epoch 188, step 0, training loss 0.617725, test_loss 0.835875, accuracy = 0.716587/0.794515, f1 = 0.797966\n",
      "Epoch 188, step 25, training loss 0.576496, test_loss 0.823719, accuracy = 0.720505/0.793644, f1 = 0.797580\n",
      "Epoch 188, step 50, training loss 0.609504, test_loss 0.825432, accuracy = 0.730518/0.797127, f1 = 0.800404\n",
      "Epoch 188, step 75, training loss 0.656024, test_loss 0.824233, accuracy = 0.720505/0.804092, f1 = 0.806337\n",
      "Epoch 188, step 100, training loss 0.645405, test_loss 0.819144, accuracy = 0.725294/0.802786, f1 = 0.804931\n",
      "Epoch 188, step 125, training loss 0.649594, test_loss 0.827863, accuracy = 0.720940/0.800610, f1 = 0.803860\n",
      "Epoch 188, step 150, training loss 0.668274, test_loss 0.817595, accuracy = 0.728777/0.800174, f1 = 0.804039\n",
      "Epoch 188, step 175, training loss 0.690247, test_loss 0.818000, accuracy = 0.726600/0.801480, f1 = 0.804641\n",
      "Epoch 188, step 200, training loss 0.550583, test_loss 0.840042, accuracy = 0.717022/0.801916, f1 = 0.804909\n",
      "Epoch 188, step 225, training loss 0.580837, test_loss 0.842583, accuracy = 0.715716/0.797997, f1 = 0.801575\n",
      "Epoch 188, step 250, training loss 0.659173, test_loss 0.831690, accuracy = 0.724423/0.800174, f1 = 0.803571\n",
      "Epoch 188, step 275, training loss 0.633935, test_loss 0.831067, accuracy = 0.711363/0.798433, f1 = 0.802297\n",
      "Epoch 188, step 300, training loss 0.676637, test_loss 0.827545, accuracy = 0.721811/0.801916, f1 = 0.805740\n",
      "Epoch 188, step 325, training loss 0.839044, test_loss 0.844914, accuracy = 0.712233/0.801480, f1 = 0.804687\n",
      "Epoch 188, step 350, training loss 0.652090, test_loss 0.848753, accuracy = 0.710927/0.803222, f1 = 0.806150\n",
      "Epoch 188, step 375, training loss 0.685762, test_loss 0.835376, accuracy = 0.715281/0.797127, f1 = 0.801557\n",
      "Epoch 188, step 400, training loss 0.645755, test_loss 0.832051, accuracy = 0.716587/0.796691, f1 = 0.800831\n",
      "End of epoch 188, training loss 0.641735, test_loss 0.829522, accuracy = 0.720070/0.797562, f1 = 0.801266\n",
      "Confusion matrix:\n",
      "[[816  58  25  38]\n",
      " [ 32 458  67  43]\n",
      " [ 13  67 433  40]\n",
      " [ 12  26  44 125]]\n",
      "Epoch 189, step 0, training loss 0.645602, test_loss 0.832609, accuracy = 0.715281/0.797997, f1 = 0.801623\n",
      "Epoch 189, step 25, training loss 0.601042, test_loss 0.829969, accuracy = 0.712233/0.795821, f1 = 0.799916\n",
      "Epoch 189, step 50, training loss 0.557431, test_loss 0.836729, accuracy = 0.715281/0.798868, f1 = 0.801898\n",
      "Epoch 189, step 75, training loss 0.634023, test_loss 0.820022, accuracy = 0.723988/0.799739, f1 = 0.802400\n",
      "Epoch 189, step 100, training loss 0.657086, test_loss 0.820785, accuracy = 0.721811/0.798433, f1 = 0.801591\n",
      "Epoch 189, step 125, training loss 0.616260, test_loss 0.821012, accuracy = 0.725729/0.797997, f1 = 0.801290\n",
      "Epoch 189, step 150, training loss 0.663662, test_loss 0.814309, accuracy = 0.723552/0.797562, f1 = 0.801305\n",
      "Epoch 189, step 175, training loss 0.789173, test_loss 0.821811, accuracy = 0.720505/0.798433, f1 = 0.802203\n",
      "Epoch 189, step 200, training loss 0.567080, test_loss 0.824782, accuracy = 0.731824/0.801916, f1 = 0.805470\n",
      "Epoch 189, step 225, training loss 0.517368, test_loss 0.836824, accuracy = 0.712669/0.797997, f1 = 0.801980\n",
      "Epoch 189, step 250, training loss 0.648052, test_loss 0.830226, accuracy = 0.730518/0.798433, f1 = 0.802225\n",
      "Epoch 189, step 275, training loss 0.644047, test_loss 0.834055, accuracy = 0.719199/0.801916, f1 = 0.805195\n",
      "Epoch 189, step 300, training loss 0.643111, test_loss 0.823783, accuracy = 0.716587/0.801916, f1 = 0.804958\n",
      "Epoch 189, step 325, training loss 0.701529, test_loss 0.817449, accuracy = 0.728341/0.798868, f1 = 0.802122\n",
      "Epoch 189, step 350, training loss 0.628266, test_loss 0.825320, accuracy = 0.712669/0.800610, f1 = 0.803613\n",
      "Epoch 189, step 375, training loss 0.726346, test_loss 0.825297, accuracy = 0.721376/0.798433, f1 = 0.802648\n",
      "Epoch 189, step 400, training loss 0.656334, test_loss 0.818093, accuracy = 0.715716/0.798433, f1 = 0.802241\n",
      "End of epoch 189, training loss 0.618885, test_loss 0.834916, accuracy = 0.718328/0.799303, f1 = 0.802903\n",
      "Confusion matrix:\n",
      "[[820  62  22  33]\n",
      " [ 30 468  61  41]\n",
      " [ 15  72 420  46]\n",
      " [ 13  25  41 128]]\n",
      "Epoch 190, step 0, training loss 0.661878, test_loss 0.832602, accuracy = 0.716587/0.799303, f1 = 0.802847\n",
      "Epoch 190, step 25, training loss 0.601682, test_loss 0.828359, accuracy = 0.717893/0.794515, f1 = 0.797920\n",
      "Epoch 190, step 50, training loss 0.591247, test_loss 0.832979, accuracy = 0.718764/0.797127, f1 = 0.800584\n",
      "Epoch 190, step 75, training loss 0.613791, test_loss 0.825267, accuracy = 0.712669/0.802351, f1 = 0.805022\n",
      "Epoch 190, step 100, training loss 0.633435, test_loss 0.816647, accuracy = 0.725294/0.801045, f1 = 0.804059\n",
      "Epoch 190, step 125, training loss 0.535317, test_loss 0.827619, accuracy = 0.723552/0.801045, f1 = 0.804480\n",
      "Epoch 190, step 150, training loss 0.638475, test_loss 0.831925, accuracy = 0.723988/0.800174, f1 = 0.803419\n",
      "Epoch 190, step 175, training loss 0.722310, test_loss 0.825641, accuracy = 0.722246/0.797997, f1 = 0.801252\n",
      "Epoch 190, step 200, training loss 0.576580, test_loss 0.829212, accuracy = 0.718328/0.803222, f1 = 0.805821\n",
      "Epoch 190, step 225, training loss 0.570019, test_loss 0.822321, accuracy = 0.727471/0.800610, f1 = 0.803474\n",
      "Epoch 190, step 250, training loss 0.734218, test_loss 0.826973, accuracy = 0.722246/0.798433, f1 = 0.801405\n",
      "Epoch 190, step 275, training loss 0.695089, test_loss 0.836683, accuracy = 0.723552/0.801045, f1 = 0.804160\n",
      "Epoch 190, step 300, training loss 0.560472, test_loss 0.831938, accuracy = 0.715716/0.799303, f1 = 0.803150\n",
      "Epoch 190, step 325, training loss 0.695515, test_loss 0.833118, accuracy = 0.723988/0.801480, f1 = 0.804889\n",
      "Epoch 190, step 350, training loss 0.681969, test_loss 0.827294, accuracy = 0.723988/0.796256, f1 = 0.799948\n",
      "Epoch 190, step 375, training loss 0.661588, test_loss 0.829527, accuracy = 0.725294/0.791032, f1 = 0.795644\n",
      "Epoch 190, step 400, training loss 0.601188, test_loss 0.829316, accuracy = 0.710492/0.793644, f1 = 0.797926\n",
      "End of epoch 190, training loss 0.539852, test_loss 0.821961, accuracy = 0.722682/0.795385, f1 = 0.799468\n",
      "Confusion matrix:\n",
      "[[814  61  24  38]\n",
      " [ 30 457  70  43]\n",
      " [ 14  69 426  44]\n",
      " [ 13  24  40 130]]\n",
      "Epoch 191, step 0, training loss 0.627413, test_loss 0.839882, accuracy = 0.717022/0.795821, f1 = 0.799826\n",
      "Epoch 191, step 25, training loss 0.618130, test_loss 0.829554, accuracy = 0.724423/0.794515, f1 = 0.798899\n",
      "Epoch 191, step 50, training loss 0.532656, test_loss 0.839157, accuracy = 0.713539/0.793644, f1 = 0.798213\n",
      "Epoch 191, step 75, training loss 0.578821, test_loss 0.822541, accuracy = 0.720940/0.797997, f1 = 0.802061\n",
      "Epoch 191, step 100, training loss 0.671961, test_loss 0.818367, accuracy = 0.727035/0.800174, f1 = 0.803868\n",
      "Epoch 191, step 125, training loss 0.674503, test_loss 0.833725, accuracy = 0.712669/0.797997, f1 = 0.801859\n",
      "Epoch 191, step 150, training loss 0.662152, test_loss 0.839745, accuracy = 0.705703/0.795385, f1 = 0.799213\n",
      "Epoch 191, step 175, training loss 0.768676, test_loss 0.820812, accuracy = 0.722682/0.793644, f1 = 0.797645\n",
      "Epoch 191, step 200, training loss 0.592628, test_loss 0.831132, accuracy = 0.720070/0.797562, f1 = 0.801848\n",
      "Epoch 191, step 225, training loss 0.542774, test_loss 0.839423, accuracy = 0.724423/0.797127, f1 = 0.801189\n",
      "Epoch 191, step 250, training loss 0.680139, test_loss 0.824543, accuracy = 0.720070/0.796691, f1 = 0.800722\n",
      "Epoch 191, step 275, training loss 0.642380, test_loss 0.838025, accuracy = 0.719634/0.798868, f1 = 0.802289\n",
      "Epoch 191, step 300, training loss 0.630804, test_loss 0.833039, accuracy = 0.719634/0.800174, f1 = 0.804224\n",
      "Epoch 191, step 325, training loss 0.761536, test_loss 0.827934, accuracy = 0.729212/0.795385, f1 = 0.799248\n",
      "Epoch 191, step 350, training loss 0.628737, test_loss 0.843315, accuracy = 0.714410/0.796691, f1 = 0.799866\n",
      "Epoch 191, step 375, training loss 0.774348, test_loss 0.839273, accuracy = 0.719634/0.791032, f1 = 0.796532\n",
      "Epoch 191, step 400, training loss 0.682104, test_loss 0.832959, accuracy = 0.717893/0.792338, f1 = 0.797898\n",
      "End of epoch 191, training loss 0.577507, test_loss 0.821348, accuracy = 0.726165/0.792773, f1 = 0.798140\n",
      "Confusion matrix:\n",
      "[[816  52  22  47]\n",
      " [ 32 441  70  57]\n",
      " [ 13  61 433  46]\n",
      " [ 15  20  41 131]]\n",
      "Epoch 192, step 0, training loss 0.608837, test_loss 0.838100, accuracy = 0.716587/0.791902, f1 = 0.797251\n",
      "Epoch 192, step 25, training loss 0.667394, test_loss 0.839515, accuracy = 0.713104/0.789726, f1 = 0.796254\n",
      "Epoch 192, step 50, training loss 0.616338, test_loss 0.834739, accuracy = 0.727471/0.796256, f1 = 0.800672\n",
      "Epoch 192, step 75, training loss 0.544087, test_loss 0.822374, accuracy = 0.730083/0.798433, f1 = 0.802190\n",
      "Epoch 192, step 100, training loss 0.683115, test_loss 0.816477, accuracy = 0.722246/0.796256, f1 = 0.800356\n",
      "Epoch 192, step 125, training loss 0.578689, test_loss 0.813572, accuracy = 0.730518/0.794079, f1 = 0.798804\n",
      "Epoch 192, step 150, training loss 0.624568, test_loss 0.835441, accuracy = 0.719634/0.794079, f1 = 0.798905\n",
      "Epoch 192, step 175, training loss 0.727027, test_loss 0.840973, accuracy = 0.711798/0.794950, f1 = 0.798521\n",
      "Epoch 192, step 200, training loss 0.543759, test_loss 0.834064, accuracy = 0.720070/0.797127, f1 = 0.800417\n",
      "Epoch 192, step 225, training loss 0.493032, test_loss 0.830285, accuracy = 0.713104/0.797127, f1 = 0.800626\n",
      "Epoch 192, step 250, training loss 0.706665, test_loss 0.846094, accuracy = 0.714410/0.800174, f1 = 0.803345\n",
      "Epoch 192, step 275, training loss 0.660916, test_loss 0.822244, accuracy = 0.722246/0.803657, f1 = 0.807189\n",
      "Epoch 192, step 300, training loss 0.619826, test_loss 0.832342, accuracy = 0.723117/0.799303, f1 = 0.803410\n",
      "Epoch 192, step 325, training loss 0.687351, test_loss 0.835149, accuracy = 0.720940/0.797562, f1 = 0.801563\n",
      "Epoch 192, step 350, training loss 0.560897, test_loss 0.840979, accuracy = 0.713539/0.800174, f1 = 0.803517\n",
      "Epoch 192, step 375, training loss 0.751792, test_loss 0.841476, accuracy = 0.707880/0.790596, f1 = 0.796381\n",
      "Epoch 192, step 400, training loss 0.635267, test_loss 0.835376, accuracy = 0.715281/0.793209, f1 = 0.798956\n",
      "End of epoch 192, training loss 0.566922, test_loss 0.819701, accuracy = 0.722682/0.792773, f1 = 0.798067\n",
      "Confusion matrix:\n",
      "[[816  54  24  43]\n",
      " [ 29 445  69  57]\n",
      " [ 14  65 427  47]\n",
      " [ 15  20  39 133]]\n",
      "Epoch 193, step 0, training loss 0.686097, test_loss 0.844343, accuracy = 0.711363/0.792773, f1 = 0.798002\n",
      "Epoch 193, step 25, training loss 0.635192, test_loss 0.828533, accuracy = 0.717893/0.791467, f1 = 0.796832\n",
      "Epoch 193, step 50, training loss 0.610754, test_loss 0.844959, accuracy = 0.710057/0.794515, f1 = 0.799266\n",
      "Epoch 193, step 75, training loss 0.624868, test_loss 0.826280, accuracy = 0.723552/0.797562, f1 = 0.801400\n",
      "Epoch 193, step 100, training loss 0.631688, test_loss 0.820218, accuracy = 0.729647/0.794950, f1 = 0.799881\n",
      "Epoch 193, step 125, training loss 0.587855, test_loss 0.826296, accuracy = 0.729647/0.795385, f1 = 0.800666\n",
      "Epoch 193, step 150, training loss 0.625283, test_loss 0.833793, accuracy = 0.720505/0.798433, f1 = 0.802683\n",
      "Epoch 193, step 175, training loss 0.734793, test_loss 0.830006, accuracy = 0.718764/0.799739, f1 = 0.802804\n",
      "Epoch 193, step 200, training loss 0.566658, test_loss 0.837415, accuracy = 0.714846/0.800174, f1 = 0.802802\n",
      "Epoch 193, step 225, training loss 0.505290, test_loss 0.816221, accuracy = 0.725294/0.800610, f1 = 0.804002\n",
      "Epoch 193, step 250, training loss 0.589819, test_loss 0.834126, accuracy = 0.715281/0.801045, f1 = 0.803756\n",
      "Epoch 193, step 275, training loss 0.665450, test_loss 0.818651, accuracy = 0.728777/0.799303, f1 = 0.802383\n",
      "Epoch 193, step 300, training loss 0.652289, test_loss 0.821460, accuracy = 0.727906/0.801045, f1 = 0.804112\n",
      "Epoch 193, step 325, training loss 0.657081, test_loss 0.829876, accuracy = 0.721376/0.799303, f1 = 0.802418\n",
      "Epoch 193, step 350, training loss 0.728162, test_loss 0.843132, accuracy = 0.712233/0.801045, f1 = 0.803716\n",
      "Epoch 193, step 375, training loss 0.745380, test_loss 0.834936, accuracy = 0.714410/0.795385, f1 = 0.799521\n",
      "Epoch 193, step 400, training loss 0.615260, test_loss 0.837489, accuracy = 0.718328/0.793209, f1 = 0.797105\n",
      "End of epoch 193, training loss 0.507182, test_loss 0.835399, accuracy = 0.720070/0.794950, f1 = 0.798508\n",
      "Confusion matrix:\n",
      "[[822  52  24  39]\n",
      " [ 34 434  82  50]\n",
      " [ 15  54 443  41]\n",
      " [ 18  20  42 127]]\n",
      "Epoch 194, step 0, training loss 0.587583, test_loss 0.835388, accuracy = 0.722246/0.794950, f1 = 0.798446\n",
      "Epoch 194, step 25, training loss 0.567688, test_loss 0.837769, accuracy = 0.718328/0.795385, f1 = 0.799450\n",
      "Epoch 194, step 50, training loss 0.662422, test_loss 0.838946, accuracy = 0.719199/0.797127, f1 = 0.801279\n",
      "Epoch 194, step 75, training loss 0.607723, test_loss 0.817392, accuracy = 0.724423/0.795385, f1 = 0.798987\n",
      "Epoch 194, step 100, training loss 0.657387, test_loss 0.827775, accuracy = 0.722246/0.797127, f1 = 0.800906\n",
      "Epoch 194, step 125, training loss 0.639738, test_loss 0.840160, accuracy = 0.710492/0.795385, f1 = 0.800595\n",
      "Epoch 194, step 150, training loss 0.748180, test_loss 0.839114, accuracy = 0.720505/0.792773, f1 = 0.798399\n",
      "Epoch 194, step 175, training loss 0.715060, test_loss 0.836393, accuracy = 0.714410/0.794515, f1 = 0.799191\n",
      "Epoch 194, step 200, training loss 0.498055, test_loss 0.823687, accuracy = 0.724859/0.796256, f1 = 0.799827\n",
      "Epoch 194, step 225, training loss 0.567866, test_loss 0.817768, accuracy = 0.718328/0.797997, f1 = 0.802150\n",
      "Epoch 194, step 250, training loss 0.653898, test_loss 0.823822, accuracy = 0.722682/0.797562, f1 = 0.801355\n",
      "Epoch 194, step 275, training loss 0.650140, test_loss 0.833497, accuracy = 0.726165/0.799739, f1 = 0.803472\n",
      "Epoch 194, step 300, training loss 0.590318, test_loss 0.848563, accuracy = 0.717893/0.797997, f1 = 0.802578\n",
      "Epoch 194, step 325, training loss 0.680170, test_loss 0.825348, accuracy = 0.723117/0.797562, f1 = 0.801863\n",
      "Epoch 194, step 350, training loss 0.654734, test_loss 0.826591, accuracy = 0.719634/0.799739, f1 = 0.802837\n",
      "Epoch 194, step 375, training loss 0.726504, test_loss 0.838656, accuracy = 0.716587/0.794515, f1 = 0.799249\n",
      "Epoch 194, step 400, training loss 0.656970, test_loss 0.844275, accuracy = 0.714410/0.793644, f1 = 0.798861\n",
      "End of epoch 194, training loss 0.589170, test_loss 0.827324, accuracy = 0.723988/0.794079, f1 = 0.799120\n",
      "Confusion matrix:\n",
      "[[816  51  22  48]\n",
      " [ 29 444  71  56]\n",
      " [ 15  62 435  41]\n",
      " [ 16  20  42 129]]\n",
      "Epoch 195, step 0, training loss 0.566269, test_loss 0.829667, accuracy = 0.716587/0.794079, f1 = 0.799120\n",
      "Epoch 195, step 25, training loss 0.520383, test_loss 0.832530, accuracy = 0.727471/0.794079, f1 = 0.799345\n",
      "Epoch 195, step 50, training loss 0.544493, test_loss 0.832427, accuracy = 0.718328/0.794950, f1 = 0.799457\n",
      "Epoch 195, step 75, training loss 0.626573, test_loss 0.816241, accuracy = 0.728341/0.795821, f1 = 0.799697\n",
      "Epoch 195, step 100, training loss 0.704135, test_loss 0.812262, accuracy = 0.735307/0.794950, f1 = 0.799577\n",
      "Epoch 195, step 125, training loss 0.572576, test_loss 0.832297, accuracy = 0.730518/0.792338, f1 = 0.798248\n",
      "Epoch 195, step 150, training loss 0.595773, test_loss 0.827280, accuracy = 0.724423/0.794515, f1 = 0.799715\n",
      "Epoch 195, step 175, training loss 0.723262, test_loss 0.820427, accuracy = 0.716587/0.794515, f1 = 0.799361\n",
      "Epoch 195, step 200, training loss 0.542758, test_loss 0.837947, accuracy = 0.717022/0.797562, f1 = 0.800896\n",
      "Epoch 195, step 225, training loss 0.541240, test_loss 0.830462, accuracy = 0.720505/0.794950, f1 = 0.799243\n",
      "Epoch 195, step 250, training loss 0.645904, test_loss 0.838943, accuracy = 0.710927/0.795385, f1 = 0.799308\n",
      "Epoch 195, step 275, training loss 0.602968, test_loss 0.833113, accuracy = 0.725294/0.798433, f1 = 0.802289\n",
      "Epoch 195, step 300, training loss 0.636457, test_loss 0.834202, accuracy = 0.715281/0.800610, f1 = 0.804470\n",
      "Epoch 195, step 325, training loss 0.644703, test_loss 0.835203, accuracy = 0.710927/0.797997, f1 = 0.801569\n",
      "Epoch 195, step 350, training loss 0.684062, test_loss 0.834296, accuracy = 0.709186/0.798868, f1 = 0.802078\n",
      "Epoch 195, step 375, training loss 0.684312, test_loss 0.854917, accuracy = 0.711798/0.791467, f1 = 0.796502\n",
      "Epoch 195, step 400, training loss 0.643249, test_loss 0.844785, accuracy = 0.714845/0.791467, f1 = 0.797178\n",
      "End of epoch 195, training loss 0.596183, test_loss 0.830935, accuracy = 0.719634/0.793209, f1 = 0.798525\n",
      "Confusion matrix:\n",
      "[[822  43  23  49]\n",
      " [ 35 437  67  61]\n",
      " [ 16  61 431  45]\n",
      " [ 16  18  41 132]]\n",
      "Epoch 196, step 0, training loss 0.699268, test_loss 0.836082, accuracy = 0.707880/0.793209, f1 = 0.798525\n",
      "Epoch 196, step 25, training loss 0.569800, test_loss 0.824197, accuracy = 0.713104/0.792338, f1 = 0.797340\n",
      "Epoch 196, step 50, training loss 0.517540, test_loss 0.819941, accuracy = 0.731824/0.798433, f1 = 0.802207\n",
      "Epoch 196, step 75, training loss 0.648268, test_loss 0.814274, accuracy = 0.731824/0.801480, f1 = 0.803920\n",
      "Epoch 196, step 100, training loss 0.606867, test_loss 0.820273, accuracy = 0.731824/0.795385, f1 = 0.799151\n",
      "Epoch 196, step 125, training loss 0.571472, test_loss 0.823071, accuracy = 0.724423/0.795821, f1 = 0.800319\n",
      "Epoch 196, step 150, training loss 0.622190, test_loss 0.851453, accuracy = 0.717022/0.792338, f1 = 0.797013\n",
      "Epoch 196, step 175, training loss 0.741347, test_loss 0.829746, accuracy = 0.723552/0.793644, f1 = 0.798174\n",
      "Epoch 196, step 200, training loss 0.548538, test_loss 0.834682, accuracy = 0.723117/0.795821, f1 = 0.799230\n",
      "Epoch 196, step 225, training loss 0.503577, test_loss 0.839727, accuracy = 0.712233/0.793644, f1 = 0.797865\n",
      "Epoch 196, step 250, training loss 0.629917, test_loss 0.831392, accuracy = 0.720505/0.797562, f1 = 0.801382\n",
      "Epoch 196, step 275, training loss 0.610852, test_loss 0.829272, accuracy = 0.722246/0.796256, f1 = 0.800264\n",
      "Epoch 196, step 300, training loss 0.656183, test_loss 0.845855, accuracy = 0.709186/0.798433, f1 = 0.802502\n",
      "Epoch 196, step 325, training loss 0.698747, test_loss 0.842083, accuracy = 0.717893/0.799739, f1 = 0.802914\n",
      "Epoch 196, step 350, training loss 0.632706, test_loss 0.834682, accuracy = 0.711363/0.798433, f1 = 0.801244\n",
      "Epoch 196, step 375, training loss 0.890385, test_loss 0.840398, accuracy = 0.717893/0.797997, f1 = 0.801886\n",
      "Epoch 196, step 400, training loss 0.570385, test_loss 0.823982, accuracy = 0.724423/0.798868, f1 = 0.802798\n",
      "End of epoch 196, training loss 0.617145, test_loss 0.823211, accuracy = 0.721811/0.798433, f1 = 0.802497\n",
      "Confusion matrix:\n",
      "[[825  51  20  41]\n",
      " [ 34 450  69  47]\n",
      " [ 15  63 429  46]\n",
      " [ 15  21  41 130]]\n",
      "Epoch 197, step 0, training loss 0.657294, test_loss 0.835618, accuracy = 0.717458/0.798868, f1 = 0.802844\n",
      "Epoch 197, step 25, training loss 0.567209, test_loss 0.831212, accuracy = 0.723117/0.795385, f1 = 0.799711\n",
      "Epoch 197, step 50, training loss 0.526224, test_loss 0.832789, accuracy = 0.722246/0.798433, f1 = 0.802244\n",
      "Epoch 197, step 75, training loss 0.592772, test_loss 0.818665, accuracy = 0.734872/0.801045, f1 = 0.803967\n",
      "Epoch 197, step 100, training loss 0.637090, test_loss 0.813687, accuracy = 0.737919/0.799303, f1 = 0.803075\n",
      "Epoch 197, step 125, training loss 0.633297, test_loss 0.817353, accuracy = 0.727035/0.794079, f1 = 0.798975\n",
      "Epoch 197, step 150, training loss 0.698996, test_loss 0.835402, accuracy = 0.718764/0.796256, f1 = 0.800721\n",
      "Epoch 197, step 175, training loss 0.766880, test_loss 0.809510, accuracy = 0.727906/0.796256, f1 = 0.800133\n",
      "Epoch 197, step 200, training loss 0.551906, test_loss 0.829579, accuracy = 0.726165/0.800610, f1 = 0.803184\n",
      "Epoch 197, step 225, training loss 0.612336, test_loss 0.829087, accuracy = 0.727906/0.798433, f1 = 0.801655\n",
      "Epoch 197, step 250, training loss 0.618549, test_loss 0.821241, accuracy = 0.732695/0.798868, f1 = 0.801906\n",
      "Epoch 197, step 275, training loss 0.599729, test_loss 0.819248, accuracy = 0.719634/0.800610, f1 = 0.803701\n",
      "Epoch 197, step 300, training loss 0.619549, test_loss 0.824062, accuracy = 0.718328/0.798868, f1 = 0.802702\n",
      "Epoch 197, step 325, training loss 0.696824, test_loss 0.833957, accuracy = 0.720940/0.799739, f1 = 0.802923\n",
      "Epoch 197, step 350, training loss 0.589181, test_loss 0.838849, accuracy = 0.717458/0.799303, f1 = 0.802028\n",
      "Epoch 197, step 375, training loss 0.707181, test_loss 0.830745, accuracy = 0.722682/0.797997, f1 = 0.802685\n",
      "Epoch 197, step 400, training loss 0.613821, test_loss 0.834980, accuracy = 0.713975/0.800174, f1 = 0.804477\n",
      "End of epoch 197, training loss 0.579521, test_loss 0.831790, accuracy = 0.724859/0.800174, f1 = 0.804296\n",
      "Confusion matrix:\n",
      "[[825  45  24  43]\n",
      " [ 34 443  72  51]\n",
      " [ 15  56 439  43]\n",
      " [ 17  19  40 131]]\n",
      "Epoch 198, step 0, training loss 0.684539, test_loss 0.846591, accuracy = 0.710492/0.801045, f1 = 0.805093\n",
      "Epoch 198, step 25, training loss 0.624001, test_loss 0.826119, accuracy = 0.726600/0.797127, f1 = 0.800229\n",
      "Epoch 198, step 50, training loss 0.587596, test_loss 0.816086, accuracy = 0.715716/0.801916, f1 = 0.805035\n",
      "Epoch 198, step 75, training loss 0.627115, test_loss 0.826132, accuracy = 0.723988/0.804528, f1 = 0.807654\n",
      "Epoch 198, step 100, training loss 0.624377, test_loss 0.814325, accuracy = 0.723988/0.800174, f1 = 0.804808\n",
      "Epoch 198, step 125, training loss 0.636734, test_loss 0.823759, accuracy = 0.718328/0.796256, f1 = 0.801370\n",
      "Epoch 198, step 150, training loss 0.625626, test_loss 0.818546, accuracy = 0.720070/0.800610, f1 = 0.804615\n",
      "Epoch 198, step 175, training loss 0.725797, test_loss 0.813849, accuracy = 0.725294/0.801045, f1 = 0.804125\n",
      "Epoch 198, step 200, training loss 0.534312, test_loss 0.820906, accuracy = 0.716587/0.800174, f1 = 0.803205\n",
      "Epoch 198, step 225, training loss 0.526096, test_loss 0.814293, accuracy = 0.730083/0.799303, f1 = 0.803424\n",
      "Epoch 198, step 250, training loss 0.708488, test_loss 0.822203, accuracy = 0.735742/0.802786, f1 = 0.805977\n",
      "Epoch 198, step 275, training loss 0.599205, test_loss 0.827376, accuracy = 0.718328/0.801480, f1 = 0.804875\n",
      "Epoch 198, step 300, training loss 0.578916, test_loss 0.843082, accuracy = 0.713104/0.799739, f1 = 0.803420\n",
      "Epoch 198, step 325, training loss 0.628428, test_loss 0.823232, accuracy = 0.724859/0.798868, f1 = 0.802661\n",
      "Epoch 198, step 350, training loss 0.661491, test_loss 0.831413, accuracy = 0.722682/0.799303, f1 = 0.802964\n",
      "Epoch 198, step 375, training loss 0.746949, test_loss 0.831343, accuracy = 0.719634/0.796691, f1 = 0.801881\n",
      "Epoch 198, step 400, training loss 0.693948, test_loss 0.830569, accuracy = 0.718764/0.801045, f1 = 0.805113\n",
      "End of epoch 198, training loss 0.519456, test_loss 0.811903, accuracy = 0.722246/0.802351, f1 = 0.805669\n",
      "Confusion matrix:\n",
      "[[824  55  25  33]\n",
      " [ 28 452  75  45]\n",
      " [ 14  60 439  40]\n",
      " [ 16  21  42 128]]\n",
      "Epoch 199, step 0, training loss 0.625681, test_loss 0.832937, accuracy = 0.709186/0.802786, f1 = 0.806132\n",
      "Epoch 199, step 25, training loss 0.582355, test_loss 0.827267, accuracy = 0.723988/0.795821, f1 = 0.799713\n",
      "Epoch 199, step 50, training loss 0.610997, test_loss 0.830086, accuracy = 0.727035/0.801480, f1 = 0.805631\n",
      "Epoch 199, step 75, training loss 0.627993, test_loss 0.821020, accuracy = 0.728777/0.801916, f1 = 0.806070\n",
      "Epoch 199, step 100, training loss 0.646950, test_loss 0.830326, accuracy = 0.726165/0.801045, f1 = 0.805455\n",
      "Epoch 199, step 125, training loss 0.544614, test_loss 0.831139, accuracy = 0.721376/0.800609, f1 = 0.805741\n",
      "Epoch 199, step 150, training loss 0.641192, test_loss 0.828366, accuracy = 0.721376/0.795821, f1 = 0.801977\n",
      "Epoch 199, step 175, training loss 0.739243, test_loss 0.815312, accuracy = 0.723988/0.801480, f1 = 0.806072\n",
      "Epoch 199, step 200, training loss 0.548997, test_loss 0.828875, accuracy = 0.722246/0.804528, f1 = 0.807915\n",
      "Epoch 199, step 225, training loss 0.567826, test_loss 0.819932, accuracy = 0.730953/0.802786, f1 = 0.807227\n",
      "Epoch 199, step 250, training loss 0.668705, test_loss 0.812307, accuracy = 0.726165/0.803657, f1 = 0.807453\n",
      "Epoch 199, step 275, training loss 0.584526, test_loss 0.823786, accuracy = 0.723553/0.806269, f1 = 0.809222\n",
      "Epoch 199, step 300, training loss 0.635909, test_loss 0.810642, accuracy = 0.730953/0.801916, f1 = 0.805404\n",
      "Epoch 199, step 325, training loss 0.633883, test_loss 0.822186, accuracy = 0.715281/0.799739, f1 = 0.803110\n",
      "Epoch 199, step 350, training loss 0.666440, test_loss 0.827913, accuracy = 0.720070/0.800174, f1 = 0.802824\n",
      "Epoch 199, step 375, training loss 0.745010, test_loss 0.827302, accuracy = 0.724423/0.797562, f1 = 0.802017\n",
      "Epoch 199, step 400, training loss 0.630115, test_loss 0.822918, accuracy = 0.723553/0.799739, f1 = 0.803924\n",
      "End of epoch 199, training loss 0.624915, test_loss 0.831609, accuracy = 0.721811/0.799739, f1 = 0.803823\n",
      "Confusion matrix:\n",
      "[[828  48  21  40]\n",
      " [ 32 460  61  47]\n",
      " [ 17  69 419  48]\n",
      " [ 15  23  39 130]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 50\n",
    "tr_loss, tst_loss = context_model.train_loop(\n",
    "    sess,\n",
    "    balanced_train_vanilla['probabilities'],\n",
    "    balanced_train_vanilla['weight_neighbourhoods'],\n",
    "    balanced_train_vanilla['labels'],\n",
    "    validation['probabilities'],\n",
    "    validation['weight_neighbourhoods'],\n",
    "    validation['labels'],\n",
    "    num_epochs,\n",
    "    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812979\n",
      "[[842  68  26  38]\n",
      " [ 44 421  52  30]\n",
      " [  4  55 465  45]\n",
      " [ 12  39  25 130]]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"context_models/neighbourhood_models/tmp/model.ckpt\")\n",
    "\n",
    "# Evaluate f1\n",
    "print sess.run(context_model.f1, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })\n",
    "\n",
    "# Show confusion matrix\n",
    "print sess.run(context_model.confusion, feed_dict={\n",
    "        context_model.probability_tensor:test['probabilities'],\n",
    "        context_model.neighbourhood_tensor:test['weight_neighbourhoods'],\n",
    "        context_model.label_tensor:test['labels'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcd2ed3e690>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd0FUUbBvBnkiAQqkgJCEgXpCeIiCKI0kWaIBEUKSKK\nooAf2EnoShOUKkWKBFFpIr1IkSYJRSR0CL0kEEIgkHLf74/Nvbm9bNqNPr9zcpLdnZ2du9m7++7s\nzKwSERARERHp4ZPdBSAiIqKci4EEERER6cZAgoiIiHRjIEFERES6MZAgIiIi3RhIEBERkW4MJIiI\niEg3BhJERESkGwMJIiIi0o2BBBEREenmcSChlGqklFqllLqklDIopV52Y51uSqmDSqm7SqnLSqk5\nSqki+opMRERE3kJPjUQ+AAcB9Afg8kUdSqlnAMwH8D2AJwC8AqA+gFk6tk1ERERexM/TFURkHYB1\nAKCUUm6s0gDAWRGZmjodpZSaCWCIp9smIiIi75IVbSR2AyijlGoFAEqpEtBqJX7Pgm0TERFRJvK4\nRsJTIrJLKdUdwE9KqTyp21wF4D1H6yilHgHQAsA5APczu4xERET/InkAlAOwXkRiMntjmR5IKKWe\nADAZQAiADQBKAhgPYCaAPg5WawHgx8wuGxER0b9YNwCLM3sjmR5IAPgYwE4RmZg6fUQp9S6AHUqp\nz0Tkmp11zgHAokWLUK1atSwoovcaOHAgJk2alN3F8ArcFxruBw33QxruCw33gyYyMhLdu3cHUq+l\nmS0rAgl/AElW8wzQenw4aqx5HwCqVauGwMDATCya9ytUqNB/fh8YcV9ouB803A9puC803A82sqRp\ngJ5xJPIppWorpeqkzqqQOl0mdfkYpdR8s1V+A9BRKdVPKVU+tTvoZAB7ReRquj8BERERZRs9NRL1\nAGyFVqMgACakzp8PoBeAAABljIlFZL5SKj+0cSfGA4gFsBnaIw8iIiLKwfSMI7ENTmoyRKSnnXlT\nAUy1k5yIiIhyML5rw8sFBwdndxG8BveFhvtBw/2QhvtCw/2QPZSIy1Gus5xSKhBAeHh4OBvOEBER\neSAiIgJBQUEAECQiEZm9vazotUFERB44f/48oqOjs7sY5KWKFi2KsmXLZncxTBhIEBF5kfPnz6Na\ntWq4d+9edheFvJS/vz8iIyO9JphgIEFE5EWio6Nx7949DshHdhkHm4qOjmYgQUREjnFAPsop2GuD\niIiIdGMgQURERLoxkCAiIiLdGEgQERGRbgwkiIjoX6NcuXLo1atXhuUXEhICHx9eKp3h3iEioiyz\ne/duhIaGIi4uLlPy9/HxgVIqw/JTSmVofv9G7P5JRERZZteuXRg+fDh69uyJggULZnj+x48fZw1C\nFuPeJiKiLOPJ+51EBA8ePPAo/1y5csHX19fTYlE6MJAgIqIsERoaiiFDhgDQ2jL4+PjA19cX58+f\nB6A9lhgwYAAWL16MGjVqIE+ePFi/fj0AYPz48XjmmWdQtGhR+Pv7o169evj1119ttmHdRmL+/Pnw\n8fHBrl27MGjQIBQvXhz58+dHx44dERMTo+tzpKSkYMSIEahUqRLy5MmD8uXL4/PPP0diYqJFuv37\n96NFixYoVqwY/P39UaFCBfTu3dsizZIlS1CvXj0ULFgQhQoVQq1atTBlyhRd5coufLRBRERZolOn\nTjhx4gSWLFmCyZMn45FHHgEAFCtWzJRm8+bN+Pnnn9G/f38ULVoU5cqVAwBMmTIF7dq1Q/fu3ZGY\nmIglS5agS5cuWL16NVq1amVa31F7hvfffx9FihRBSEgIzp07h0mTJuG9995DWFiYx5+jd+/eWLBg\nAbp06YKPPvoIe/fuxejRoxEZGWkKbm7cuIEWLVqgePHi+OSTT1C4cGGcO3cOy5YtM+WzceNGvPba\na2jWrBm+/vprANoQ2Lt378aAAQM8Lld2YSBBRERZokaNGggMDMSSJUvQrl07u++KOHHiBI4cOYLH\nH3/cYv7JkyeRO3du0/R7772HunXrYuLEiRaBhCPFihXDunXrTNMpKSn49ttvcefOHRQoUMDtz3D4\n8GEsWLAAffv2xYwZMwAA/fr1Q7FixTBhwgRs27YNjRs3xq5duxAbG4tNmzahbt26pvWHDx9u+nvN\nmjUoXLiwqdYlp2IgQUSUg927Bxw7lrnbqFoV8PfP3G0YNWnSxCaIAGARRMTGxiI5ORmNGjXCkiVL\nXOaplELfvn0t5jVq1AjffPMNoqKiUKNGDbfLt2bNGiilMHDgQIv5gwcPxvjx4/H777+jcePGKFy4\nMEQEq1atQs2aNeHnZ3u5LVy4MOLj47F+/Xq0aNHC7TJ4GwYSREQ52LFjQFBQ5m4jPBzIqveHGR9l\nWFu9ejVGjRqFgwcPWjTAdLeHRpkyZSymH374YQDArVu3PCpfVFQUfHx8UKlSJYv5JUqUQOHChREV\nFQUAaNy4MV555RUMHz4ckyZNQpMmTdC+fXu89tpreOihhwAA7777Ln7++We0bt0apUqVQvPmzdGl\nS5ccF1QwkCAiysGqVtUu9Jm9jaySN29em3k7duxAu3bt0KRJE0yfPh0lS5ZErly5MHfuXLfbODjq\nyeFJLxLz9O6MLbF06VLs27cPv/32G9avX49evXph4sSJ2LNnD/z9/VGsWDEcPHgQ69evx9q1a7F2\n7VrMmzcPPXr0wLx58zwqV3ZiIEFElIP5+2ddbUFG0DO407Jly5A3b16sX7/e4hHBnDlzMrJobilX\nrhwMBgNOnjxp8Qjm+vXriI2NxWOPPWaRvn79+qhfvz5GjBiBsLAwdOvWDUuWLDH1LPHz80ObNm3Q\npk0bAMA777yDWbNm4YsvvkCFChWy7oOlA7t/EhFRlsmXLx8ArZ2Du3x9faGUQnJysmneuXPnsHLl\nygwvnyutW7eGiOCbb76xmD9hwgQopfDSSy8BsP/5ateuDQCmRzM3b960SVOzZk2LNDkBaySIiCjL\nBAUFQUTw6aefomvXrsiVKxdefvllu480jF566SVMnDgRLVq0wGuvvYZr165h2rRpqFy5Mg4fPuxy\nm44eX3j6WAMAatWqhR49emDWrFm4desWGjdujL1792LBggXo2LEjnnvuOQDa+BXTpk1Dhw4dULFi\nRdy5cwfff/89ChUqhNatWwMA+vTpg5s3b6Jp06YoXbo0zp07h++++w516tRBtWrVPC5bdmEgQURE\nWaZevXoYOXIkZsyYgfXr18NgMODs2bMoW7asw/daNGnSBHPnzsXYsWMxcOBAlC9fHl9//TXOnj1r\nE0jYy8PR4xR3H7NYp5szZw4qVqyIH374AStWrEBAQAA+++wzfPnll6Y0jRs3xl9//YWffvoJ165d\nQ6FChfDUU09h8eLFpscfr7/+OmbNmoXp06cjNjYWAQEBCA4OxrBhw9wql7dQeiKyzKaUCgQQHh4e\njsCc9PCPiCidIiIiEBQUBJ7/yB53jg9jGgBBIhKR2WViGwkiIiLSjYEEERER6cZAgoiIiHRjIEFE\nRES6MZAgIiIi3RhIEBERkW4MJIiIiEg3BhJERESkm8eBhFKqkVJqlVLqklLKoJR62Y11HlJKjVJK\nnVNK3VdKnVFKvamrxEREROQ19AyRnQ/AQQBzAfzq5jo/AygGoCeA0wBKgrUhREREOZ7HgYSIrAOw\nDgCUGwOVK6VaAmgEoIKIGF+Hdt7T7RIREZH3yYpagbYA9gMYqpS6qJQ6rpQap5TKkwXbJiIicioq\nKgo+Pj5YsGBBdhclR8qKQKICtBqJ6gDaA/gAwCsAvsuCbRMRkRfZvXs3QkNDERcXl6nbGTNmDFau\nXJmp2yBNVgQSPgAMAF4Tkf2pj0YGAXhTKZU7C7ZPREReYteuXRg+fDhiY2NdJ06H0aNHM5DIInoa\nW3rqCoBLIhJvNi8SgAJQGlrjS7sGDhyIQoUKWcwLDg5GcHBwZpSTiIgymYhkdxH+VcLCwhAWFmYx\n7/bt21lbCBHR/QOtpuFlF2neAhAPwN9sXjsASQByO1gnEICEh4cLEdF/SXh4uPxbz38hISGilBIf\nHx9RSpn+joqKMqVZuHChBAUFSd68eaVIkSLStWtXuXDhgkU+J0+elI4dO0pAQIDkyZNHSpcuLV27\ndpW4uDgREZttKKWkZ8+eDst17tw5UUrJ/PnzLeZv3rxZnn32WcmXL58ULlxY2rVrJ5GRkRZp7ty5\nIx988IGUK1dOcufOLcWLF5dmzZrJgQMH3C6vJ9w5PoxpAARKOq7x7v54XCOhlMoHoBK0GgUAqKCU\nqg3gpohcUEqNAVBKRHqkLl8M4HMA85RSIdC6gX4NYI6IPPB0+0RElDN16tQJJ06cwJIlSzB58mQ8\n8sgjAIBixYoBAEaNGoUvv/wSXbt2xVtvvYUbN25gypQpaNy4MQ4cOICCBQsiKSkJzZs3R1JSEgYM\nGICAgABcunQJq1evRmxsLAoUKIBFixahd+/eeOqpp9C3b18AQMWKFT0q66ZNm9C6dWtUrFgRoaGh\nSEhIwJQpU/Dss88iIiICZcuWBQC8/fbbWLZsGd5//31Uq1YNMTEx+PPPPxEZGYk6deq4Vd4cz9PI\nA0BjaDURKVY/c1OXzwOwxWqdKgDWQ6uZiIIWSNitjRDWSBDRf9i/uUZCRGT8+PE2tRAiIlFRUeLn\n5ydjx461mP/PP/9Irly5ZMyYMSIicvDgQVFKybJly5xuJ3/+/E5rIczZq5GoU6eOBAQESGxsrGne\n4cOHxdfXV958803TvMKFC8v777/vMG93y+uuf0WNhIhsg5NGmiLS0868EwBaeLotIiJy7l7SPRyL\nPpap26hatCr8c/ln6jZ+/fVXiAg6d+6MmJgY0/zixYujcuXK2Lp1Kz7++GNTu7l169ahZcuWyJs3\nb4aX5erVqzh06JDF9gCgZs2aaNasGdasWWOaV7hwYezbtw9XrlxByZIlbfLKivJmt6xobElERJnk\nWPQxBM0KytRthPcNR2DJwEzdxqlTp2AwGFCpUiWbZUopPPTQQwCAcuXKYfDgwZg4cSIWLVqERo0a\n4eWXX0b37t1RsGDBDClLVFQUAKBKlSo2y6pVq4YNGzYgISEBefPmxddff40333wTZcqUQVBQEFq3\nbo033ngD5cuXz7LyZjcGEkREOVjVolUR3jc807eR2QwGA3x8fLBu3Tr4+NhWeufPn9/097hx4/Dm\nm29i5cqV2LBhAwYMGICxY8diz549KFWqVLrLIh70LOncuTOee+45LF++HBs2bMD48ePx1VdfYfny\n5WjRokWWlDe7MZAgIsrB/HP5Z3ptQUZy9GaFihUrQkRQrlw5u7US1qpXr47q1avj008/xZ49e9Cw\nYUPMmDEDw4cPd7odd5QrVw4AcPz4cZtlx44dQ9GiRS0eUZQoUQL9+vVDv379EB0djbp162LUqFGm\nQMKd8uZkfHEWERFlmXz58gGAzYBUHTt2hI+PD0JDQ+2ud/PmTQDAnTt3kJKSYrGsevXq8PHxwYMH\naR0B8+XLp3vQq4CAANSpUwfz58+3GIHzyJEj2LBhA9q0aQNAq0WxHqGzaNGiKFWqlKks7pY3J2ON\nBBERZZmgoCCICD799FN07doVuXLlwssvv4wKFSpg5MiR+PTTT3H27Fm0b98eBQoUwJkzZ7BixQq8\n/fbbGDRoELZs2YL33nsPnTt3RpUqVZCcnIwFCxbAz88PnTp1stjOpk2bMGnSJJQqVQrly5dH/fr1\n3S7nuHHj0Lp1azRo0AC9e/fGvXv38N133+Hhhx/GsGHDAGhBQunSpfHKK6+gdu3ayJ8/PzZu3Ij9\n+/dj4sSJAOB2eXO0rOga4ukP2P2TiP6j/u3dP0VERo0aJWXKlBE/Pz+brqDLly+X5557TgoUKCAF\nChSQJ554QgYMGCAnT54UEZGzZ89Knz59pHLlyuLv7y9FixaVF154QbZu3WqxjePHj0uTJk0kX758\n4uPj43JAKh8fH5sBqbZs2SKNGjUyDUjVvn17OXbsmGl5YmKiDB06VOrWrSuFChWSAgUKSN26dWXm\nzJmmNO6W113e2P1TiQeNSrKKUioQQHh4eDgCA3POsz8iovSKiIhAUFAQeP4je9w5PoxpAASJSERm\nl4ltJIiIiEg3BhJERESkGwMJIiIi0o2BBBEREenGQIKIiIh0YyBBREREujGQICIiIt0YSBAREZFu\nHCKbiMgLRUZGZncRyAt543HBQIKIyIsULVoU/v7+6N69e3YXhbyUv78/ihYtmt3FMGEgQUTkRcqW\nLYvIyEhER0dnd1HISxUtWhRly5bN7mKYMJAgIvIyZcuW9aoLBZEzbGxJREREujGQICIiIt0YSBAR\nEZFuDCSIiIhINwYSREREpBsDCSIiItKNgQQRERHpxkCCiIiIdGMgQURERLoxkCAiIiLdGEgQERGR\nbgwkiIiISDcGEkRERKQbAwkiIiLSjYEEERER6eZxIKGUaqSUWqWUuqSUMiilXvZg3WeUUklKqQhP\nt0tERETeR0+NRD4ABwH0ByDurqSUKghgPoBNOrZJREREXsjP0xVEZB2AdQCglFIerDoTwI8ADADa\nebpdIiIi8j5Z0kZCKdUTQAUAoVmxPSIiIsoaHtdIeEopVRnAaADPiojBs0oMIiIi8maZGkgopXyg\nPc4YJiKnjbPdXX/gwIEoVKiQxbzg4GAEBwdnXCGJiIhyqLCwMISFhVnMu337dpaWQYm43V7SdmWl\nDADai8gqB8sLAbgFIBlpAYRP6t/JAJqLyB921gsEEB4eHo7AwEDd5SMiIvqviYiIQFBQEAAEiUim\n95LM7EcbcQBqWM3rD+B5AJ0AnMvk7RMREVEm8jiQUErlA1AJaTUMFZRStQHcFJELSqkxAEqJSA/R\nqjuOWq1/HcB9EYlMZ9mJiIgom+mpkagHYCu0MSQEwITU+fMB9AIQAKBMhpSOiIiIvJqecSS2wUm3\nURHp6WL9ULAbKBER0b8C37VBREREujGQICIiIt0YSBAREZFuDCSIiIhINwYSREREpBsDCSIiItKN\ngQQRERHpxkCCiIiIdGMgQURERLoxkCAiIiLdGEgQERGRbgwkiIiISDcGEkRERKQbAwkiIiLSjYEE\nERER6cZAgoiIiHRjIEFERES6MZAgIiIi3RhIEBERkW4MJIiIiEg3BhJERESkGwMJIiIi0o2BBBER\nEenGQIKIiIh0YyBBREREujGQICIiIt0YSBAREZFuDCSIiIhINwYSREREpBsDCSIiItKNgQQRERHp\nxkCCiIiIdGMgQURERLp5HEgopRoppVYppS4ppQxKqZddpO+glNqglLqulLqtlNqllGquv8hERETk\nLfTUSOQDcBBAfwDiRvrnAGwA0ApAIICtAH5TStXWsW0iIiLyIn6eriAi6wCsAwCllHIj/UCrWZ8p\npdoBaAvgkKfbJyIiIu+R5W0kUoOPAgBuZvW2iYiIKGNlR2PL/0F7PLI0G7ZNREREGcjjRxvpoZR6\nDcAXAF4WkWhX6QcOHIhChQpZzAsODkZwcHAmlZCIiCjnCAsLQ1hYmMW827dvZ2kZlIg77SUdrKyU\nAUB7EVnlRtquAGYDeCW1nYWztIEAwsPDwxEYGKi7fERERP81ERERCAoKAoAgEYnI7O1lyaMNpVQw\ngDkAgl0FEURERJRzePxoQymVD0AlAMYeGxVSu3LeFJELSqkxAEqJSI/U9MEA5gMYAGCfUqpE6noJ\nIhKX7k9ARERE2UZPjUQ9AAcAhEMbR2ICgAgAoanLAwCUMUvfF4AvgKkALpv9fKOvyEREROQt9Iwj\nsQ1OAhAR6Wk1/byOchEREVEOwHdtEBERkW4MJIiIiEg3BhJERESkGwMJIiIi0o2BBBEREenGQIKI\niIh0YyBBREREujGQICIiIt0YSBAREZFuDCSIiIhINwYSREREpBsDCSIiItKNgQQRERHpxkCCiIiI\ndGMgQURERLoxkCAiIiLdGEgQERGRbgwkiIiISDcGEkRERKQbAwkiIiLSjYEEERER6cZAgoiIiHRj\nIEFERES6MZAgIiIi3RhIEBERkW4MJIiIiEg3BhJERESkGwMJIiIi0o2BBBEREenm1YFEcnJ2l4CI\niIic8epA4o8/srsERERE5IxXBxIGQ3aXgIiIiJzx6kCCiIiIvJvHgYRSqpFSapVS6pJSyqCUetmN\ndZoopcKVUveVUieUUj3c25anpSMiIqKspKdGIh+AgwD6AxBXiZVS5QCsBrAZQG0AkwHMVko1c72u\njtIRERFRlvHzdAURWQdgHQAo5dal/h0AZ0RkSOr0caXUswAGAtjobEUGEkRERN4tK9pINACwyWre\negBPu1qRgQQREZF3y4pAIgDANat51wAUVErlzoLtExERUSbJrl4bxroGl20siIiIyHt53EZCh6sA\nSljNKw4gTkQSna04b95AbN9eyGJecHAwgoODM7aEREREOVBYWBjCwsIs5t2+fTtLy6BE9FcKKKUM\nANqLyConacYCaCUitc3mLQZQWERaO1gnEED4+PHhGDw4UHf5iIiI/msiIiIQFBQEAEEiEpHZ29Mz\njkQ+pVRtpVSd1FkVUqfLpC4fo5Sab7bKDAAVlVJfKaUeV0q9C+AVABNdb41PPoiIiLyZnjYS9QAc\nABAO7Uo/AUAEgNDU5QEAyhgTi8g5AG0AvAht/ImBAHqLiHVPDhuiUnQUj4iIiLKKnnEktsFJACIi\nPR2sE+T5tviyDSIiIm/m1e/aMIA1EkRERN7MqwOJRLmb3UUgIiIiJ7w6kEgw3MnuIhAREZETXh1I\nbNl5B7duZXcpiIiIyBGvDiT2HoxD377ZXQoiIiJyxKsDCfgm4eZN50lGjQLOnMma4hAREZEl7w4k\nVApcDbz5+edAly5ZUxwiIiKy5N2BhE9aILFnD7BoUfYWh4iIiCxlxUu79DOrkXj6ae139+5pi9Px\nmhAiIiLKAF5eI5HsNFgwLlPKcRoiIiLKPN4dSDx81q1AgoiIiLKHdwcStRcwkCAiIvJi3h1IwHmw\nwECCiIgoe+WIQOL33x0vA9hGgoiIKLt4dyBxrSZEgJdesr+YNRJERETZy7sDCd8kPtogIiLyYt4d\nSPjdZ/dPynLLlwMXLmR3KYiIcgbvDiQKn7OZtXNn2t+skaDM0LEj0LRpdpeC3JWYCL4lmCgbeXcg\nAeBe/r8tphs1SvubgQRllujo7C4BuatDB6BIkewuBZE+4eFAYCCQnJzdJdHP6wOJE1evOFzGRxtZ\n78wZ7UVpDOLIW6xZk90lINJv5EjgwAEgJia7S6Kf1wcSDzq3cLiMF7Os162b9up2T/d9VBT/X0RE\n/0ZeH0g4wwtT1jPW/niy76OigHLlgDlzMqVImYK1XERE7vlXBBI86Wc9TwIJY3uDQ4cypyxERDnV\nv+GG+F8RSLirXj3t57+kTx/g/fczPt9/w8FPROQtcvINsV92FyA9PL2YhYdnTjm8mfFxwrffpi+f\nlSu1LnbGg91gSF9+RDnd+vVAs2aAT46+HSNKvxz9FeCjjazTvj3Qs2faNGskKDsZxIB7Sfeybfs7\ndgAtW+asdj8Zaef5nZAsOgmsO7UO1+9ez5JtkT7eHUhcfEr7PaQoEJIWLcTHA59+Cvz5pzZ9+XI2\nlC0HiosDhg5NX39le40tb94EHjxIX9lyGqWADz7I7lJkrWRDMk7EnPB4vS1nt9hdLzElEZ9t/gwJ\nSQke5zl041DkG53PYp6IdoHPDA+SHyDFkGKajo3Vfl+7ljnby2zR96Jd7ncRwd3Euxbz9l7ci42n\nN6LRvEYYv2u8x9vdcHoDjkUfM02vPrEaMfec93ts9WMrtPqxldM0BjHAIJbVpH+e/xP7L+93q1x7\nL+7FnQd3nKbZfWE3klKS3MrPHf1/74+q31VFou/NDMszu3h3IHG1DnInFwP8LQ+0yZOBMWPSnv1H\nRWVD2axs3gykpLhOl52+/lr72bZd/3MJe482HnkEaNs2nYXzJnljkPLIPzh09RAWHlpomr37wm7E\n3o81TU+Zoi/7a/GeXX1OxJzA8sjlLvMc9+c4j+8Sl0Uuw1+X/nIrbfdl3fH4d48j2WAbiR68ehD3\nk+/bXe+FBS/g8e8et5m/4tgKjN45GrMjZuPLrV/iavxVt8u99OhSm3mzZwPPPQfsd+PacT/5PkL/\nCIUKVfjl6C8AgISkBKhQhZ+O/IRTN08BgGl/5hmVB09Me8K0vlIACl5EorhXK/Lighex8/xO1wkB\nLI9cjhXHVgAANp/ZbHPBX39qPbad2+ZWXo4UG1cMLRa1QLIhGYkpiXbTDNk4BPnH5DdN77m4Bw3m\nNMDQTUO15ZuGAAAuxl20WG/zmc2IT4w3TR++dhiJKYmIvheNFotaoNrUami5qCXaLG6DtmFt0fXX\nri7LezLmpNPl9b+vj0JjC2HIkLRHTc/OexZPfv8kPtn0CW7fv+10/QZzGqD78u4Ol0ffi0bDuQ3x\n5dYvTfMOXj2IxX8vdll2cwlJCZi0exIMYsC0/dNwPOY41tZ6xLTcOmDNKbw7kLhbAg/8bqRNK20H\nGy9i3vKc/p9/gBdfBCZOtL/cIAbd1YBX7lxB+yXtPbpre5D8AHne7ICZYZYvjBABUGU1Xtzhm+6q\nQouP89g2bMz1nsXy0zdP4/b921ChCodv7fYo7y1nt+DojaPpKp+xDOGXnTeMuZd0D2//9jbiHsSl\nzez1LOK610CdmXXwxoo3TLMbzm2ITks7aRMVNwC5LO/Wrty5YnGRHbV9lOmCZPTP9X8QMCEAKlS5\nPLkZtQ1ri45LO1ocQ3cT70JEkJCUgBRDCvr93g9DNg3B6Vuncf72eYv1d13YZREQATCVs9PSTqg/\nuz56r+yN1j+2hgp1/Jzwp39+AqAdX+YMYkDdmXXx5PdP2lzgnA1d7eejNdE6euMoRmwfgcEbBuNe\n0j3subgHDec0xBdbvsB7a95Dv9X9bNa1uPsMmgk0DsXhi6eBpp8jJkaw9uRauyfkuAdxeGvVW5i5\nfyZCtoUAADr/3BkJSQmmILH/mv6o/G1lbDi9AT7DfTBi2wgAWkBnrFkxiAEYVAbzDM/DJ9TH7gXF\nuP1kQzLGiBJwAAAgAElEQVQ2n92MgesH2v0c52LPWczruLQjOvzUAbH3Y/HiwhfhP9rf4v/S8seW\naDK/CR7+6mFE3oi0yOtB8gO0DWuLKt9WMc1fe3Ktzf8fAHac34Hn5z+P3CNzm+bF3IvBjP0zsPSf\npfg+4nsA2ndk5PaRiIrV7tgOXD1gSr8schnKTCpj+r4mpSThxYUvoveq3qbp2jNqI/fI3Cg2rphp\nvfWn12PNSW0ksU1nNuFmguVd+YmYE1ChCgevHgQA3Em8Y3H8G/ftvAPzcPTGUYRfCUd8YjzGjQNE\nJVkEpWP/HIuR20fafP7Ldy5j4+mNpmPpRMwJu+fpq/FXcePuDVNeRnVn1kW3Zd1s0gPAketHcDz6\nOFSoggpVWHBoAbZHbcf4XeMxaMMg2/J01PLJMyoPWi9u7XbQ6S28O5A418RyOo924vX11SbtXZsT\nE4HrGfg47c0Vb0KFKtxKsH9GPHvrLE5cuwC83hznLsdj6r6puHDb8gLuO9wXH6z7ACpUYevZrQC0\nk/vf1/62lyUA7aSw/tR6lJpYCiuPr8S2KO0EvefiHlSYXAHX4q8h2ZCM8MvhGL1jNO4n38fyyOVQ\noQoRVyLwoPwKDNjfDGj9HvC+dlIRAfCYlk/kjUjMCp8FFapwPPq4xQnJ3O4Lu3E8+rhp+m7+w0D7\nN2EwaBcxEQF6NgHqT0VCUgLWnVqHtSfXotK3lTBko3bHsubiQqDZEETlWg9Aq0Y0iMF0J6NCFcbv\nGo9dF3bh1M1TeGHBC6g+rbrFnfug9YOgQhUOXT2Ened3Ij4xHuW+Ked0H1b6thLqfa9107kYd9Hu\nhTvs7zDMipiFpf+Y3eEWO2aTzujojaPahfT1FkC7Xvhk0yd4afFLiE+MR6mJpfD68tehQhV2XdiF\nz7d+jsrfVsbp08Dt28DWs1tRY3oNU16Fvyps+nvD6Q2YsGsCACD8crjFCc1Y7oRkLZh8kPwA+cfk\nx4jtI+A/2h/dlnUz3cF2/aUrHvvmMXyz5xs8SH4AEcEzc5+xCIgWHlqIXCNyWeyPuQfnYu2ptQC0\nxwbGat6YezGY9tc0i/IY72DPxZ4zHXuAdvJsMr8J1p5ca0r7zjtp+67OjDqoPaM2XlzwIlSoMn1P\nYhK0GsfFfy9GvtH58PScp7H74m6M3DESU/+aipnhM3Et/hou3L6A/Zf3I/JGpOnYMYgBaNsPeD4E\n3/lUAp4bhQUXhqH14tYoOaEktkdtt7ibnXdgHmYfmI0P139o8X/1H+1vuvgYy2OsqVl4OO0iPGL7\nCKhQhXYR2knoIvZBIOi2rBsu30l7xjp131T4jfDDpbhLppsAX+VrurDsPL8TD5IfoN/qfig/uTxU\nqLIJwqyn+6zqgxn7Z5imY+/H4olpT2B2xGy0+rEVfIf7Is+oPFh9YjVO3jyJTWc2QYUqtF7cGm+s\neANnb53F139+jUtxl0x5GC9YBjEg5I8QFB1XFO/8/g5e/eVVPOT7EAAtkP1i6xd2aw6MQV71adUx\nYtsIPDRSW2fpP0vRbGEz07QrZ26dQVRsFG7fv43wy+GmwGTIyq9NaSKuRADQ/od+I/zQaWkn9FrV\nC09+/2RaRo+vAr58CCUnlLTIf+pfU9FiUQsMWDsAIoKklCQ8OvFRNF/UHAPXaQHesehj8Bnug6BZ\nQdh7ca/pnFByQkmL2qgWi1pg+Lbhdj/HymMroUIVak6viapTq5rm91jRA41/aIwv/9BqNIb9Mcxy\nxVqLTcHRhtMb0GheI+yIyqTndJlAZVWDGU8opQIBhAP7gRCz/pqL1gKnWmLMGOCTT4CSJYErqSNo\nGz9G3brAwYP2gwzz5/u3799G+JVwNC3v+O1MBjHAd7h2wtjXZx/KFiqLEzEn0Ogx7YUf0feiLaLs\nlvcWYp3/6wCAcc3GofFjjVEnoI7Nl+n7tt/jrd/eMk2H9w1HodyFULFIRdO8UdtH4fOtn5umZ7ed\njfAr4Zi+f7ppno/yMUXTE5tPxKANgwAA89rNQ8+VZi0jAcgwwaefAmNu1QECDuGN2m9gwaEFFmkO\n9zuM8g+Xx/yD8zF4w2BMbzMdvVb10hZOigLiA1BgQCPcKbQPKzttRrtfX7C73z5r9BlG7Rhld9n8\n9vPRY0UPBNcIRtiRMCxov8DiIlckbxHT3UnJ/CVxJf4K7nxyBwXGFLDIJ7xvOIJmBQEAJjSfgH2X\n9uGnf37Cjx1/xKvVX0VCcoJpHRkmUKEKjxZ4FBcHXcSf5/9EUKkg5PLJhYZzG2LfpX0Y1ngYOlTt\ngDO3zqDj0o4W2xrx/AjE3o/FhN3ahX7MC2PwyeZPLNJ0rNYRyyKXmab9fPzSaid+n4onEt9E2f91\nwrpT6yzWi+wfiVXHV5mqiwc1GISJeyaiUdlG2HF+ByY2n4iRO0biZsJNrO++Hk+XfholJ5TE3STL\n2hB3BOQPwLpu61BnZh0AwPJXl6PDTx3cWndnz514dt6zALTvQmJKomn6jx5/oMn8Jhbp4z6OQ69V\nvUyPDTKLvf9FdlrQfgHuJt3FO7+nRVBH3z1qcSFyZs7Lc0x381lpauup6L+mf5Zv11rxfMVx/e51\n1CheA0euH7FZXsy/GG7cu2Fnzcxx4O0DqDuzrst0Q58ZiprFazp9POKpZV2WoUM1976f1iIiIhAU\nFAQAQSISkWGFcsDLA4lw4POnAT+zZ3hJefGwTxnc+mU0ENkJKHAZuF8IoxftQoXCldC1RXkAwLur\n+6NlpZZoXbk1/Eb4YXiT4fiyTV/gbgmIwFRV+HCeh3FzqGW1Wu+VvTH34FyLeYf7HUatGbUAaBcm\nQLtjqT+7foZ+9kpFKqHLE10weufoDM33n3f/waDJ27E+1zsO04xrNg4nY05iVsQs+wmu1EXegveR\nkM9+7YW3Mr/YdKvZDT/+/WM2l4iIcoK6AXUtHuVktRWvrkC7qu08Xo+BBKwCCb9qwOf+zleIagQ8\ntgNIyguMugc8/wXQWHsGZX4nBQBIyoM/396MZ+Y+Y5q1ofsGVCpSCeUfLo/JeybbVHsCwNtBb2Nm\n+EwAwKIOi9B9eXf80vkXvPLzK+n+vERERPY0r9gc67uv92idHBFIKKX6A/gIQACAQwDeFxGHTb+V\nUh8C6AegLIBoAL8A+ERE7HYatAgkEAj43wCGFPe4nEQE5MuVT9ejEMp4j+R9xNQGIyf76ZWf8Oov\nr2Z3MSz0DezruDY1hzPWgrsrqwMJjxtbKqVeBTABwDAAdaEFEuuVUkUdpH8NwJjU9FUB9ALwKgD7\nD9HteVDQ02JSDtKwTMPsLkKmGPukZ13DMkrryq0tphuXa5wt5XClatGqtjPv2j2NZKpnyjzjOlEG\neOrRp3Dk3SMoVaBUpuT/br13MyVfc5WKVAIANC3fFDNfmmk3zdXBVzG6qf1Hs77KF+vaHwBScpnm\nvV7rdfQLsu2ZY+2VJ5zX/narZb8HhY2TLU1/vlpNa9NQ8/gSl6sF5A/Ajx2dPxYd0nCIzbzHH7Ht\n+mzON8VFjTtgM0aGt9HTa2MggJkiskBEjkGrabgHLUCw52kAO0XkJxE5LyKbAIQBcL9xQUpu12nI\n0ubU7kXiuDtf84rNM257+9/WverWHluxuKP9i+789vPx/GMv6rrApPeE7aectzhXk8/h3if30bC0\n7YUol08ufNy7mtP1/XNpJ5CO1Triz15/muav7bbW0Spu+aXzL/i+7fem6YUdbLv+2TjnZrDx+3eA\nwfa0cWXwFSzrsgyFcheymJ/3fjnT3+ULl7dY1ryCneNv7wAAQOE8hW2Xpcrjlwfxn8SjQekGtgs3\njUFoFW3/FbreCqFNQu3mEf9JPF6vpTWMblS2kWn+sf72e+w8nOdhAEDbKm0dXrCbFnDeWHFeu3kI\nyB+A8x+eh+FLzy4Mnap1spjuWqMrQpuEolvNbljSaQmGPjMUk1tNxsX3bwK7tEbXtUvUtljH8KUB\nzyur3gJu+vrFryHDBI8WeBQAkNcvL9o93s4UWBiPZQAokb8EPmn0CQ6+fdAmn/C+4SiaXAf4OxiA\ndtws6LAA01+abpPWZI02YEuXJ7qgwd97gSv2Gz+WzF/S7nwLq2YBP65F91paADGkwRdAiCAgpgvG\nvDDG6aoVHq6A12q+hsuDLmsBw4avgX1p//MieYtg1AujsKjDIiR8ltZdP7K/1qasbkBdNCnXBOOb\naQN5daupBT4P33vKZbF9lHd3sPSodEqpXACCAGw2zhPt2cgmaAGDPbsABCmlnkzNowKA1gB+96ik\no+OAUO8bqKNh/m7AsXZAtPOoEwC2t4lBWMef8PtrvwPnngMWrkNUT8HTuXsB513flX/y7CdoW7k9\nAODJ3ScwpOEQDGtseWLY9Pom/NZ5E+CX+tRopVmj0ZWzgZ1DTZMfPf0RAGBA/QEut40ZZg2ONtm5\n29gwDl2qd3G8/l+2jTxDGofgxHsn8JDvQ/A7FmyxbFrraQjvG443ar+B3zpvBC45/rI1KN0ASzot\nQdcaWve0Xb12oUftHrg48KJN2gnNJ1hM3/ifZQtwGSamE1Xyzg+A3QNx8O2DaPxYE8uMlv8An7jH\n8NwzubGv306bqsfELxKB+ABt4motYFIU2lRuY1q+9JWlpuBpccfFplqZgrkLomWllhjeZLjdi+mQ\nhkOwt89erA5eDQB4urT2tWtbpS1CGofg73f+Rt5cedEnsI9pnSJ5i2BKy9TRsxIKo8CaZcD41K6K\ni3/Dsi7LgIWpz2DPPQeMu4ZiEROAZQsRVDLIdLEAAPzVHxieAv+IocDxlzCt9TRMbzMdAfkD0KFa\nB4uT8Y6eO/DMkbTjZkuPLRjeZDj+7PUn4j+Jx8QWdgZe2f4FTr2egltDb2FZl2XY9PomnP/wvOnz\nAloQkO+hfNj4+kYMfWYoMOIBMOounlT9gH3voV6hlsCou6j01yq8VvM1m01cHHgR+R7KhwerJqB4\n7tKmO92nHn0Kjxd9HPPbzzfdIf/a5VdMaTkFMUNisOLVFVjQYQGmtpmKaTX+Nn3nV7y6AtjfF1s+\n/so0NkZYpzDs6LnDdMHa/9Z+VCumBZa+Pr5Q5uP6X9O6BBtrRv7o8Ufasll/4dcXD2Fam2nI65cX\n45uNx6MFHsXABgPxZeMvsajjIrxa41WMfXEs/Hz8UDj3w8Bm7fuZmJKIzW9sRlBJrXeTUgpbQz9H\n+T/+QMJnCRjVVKsUntJyCiY2n4jZbWdb7Kdtb26DDBPIMMH/nvkfAGBU01EILBmIvLnyokT+Ejj5\n/klcHXzV5nsEALUDagNjbgOTonD2g7P4rtV3qB1QW+s9t3omukWfRkD+AFN643egecXmqFG8Bh58\n/gAIEWDf+7g48CI6V++MwnfrAzMjMK1pmGm9q4Ov4tpH11D5kcrAj78DE7VuxcagZ8TzIyDDBLc/\nvg1EaL3lSuXXbjJ+XaaNVKmgMPjpwfi+7ffY9qZlt9vYobEY1ngYFnVYBAAoWaAkvmr2FbDrf8D6\nCfijxx+QYYKYITHw8/FDt1rdkMcvD/7o8Qd29twJpRRkmCDi7Qhs7bEV79V/DzWL18RHDT/Crl67\nUO/Mr8Cq703/i641umJdt3U4+b7Wbdl4DHk1EXH7B0BJAAYAT1nN/wrAbifrvQ/gAYBEACkAprrY\nTiAAAcJF66xp9vNWPUGvhoIezwtCIOhXS/sdAkHp3YIWH6ZNG3+qLredl/rz/vyZ8tvx3+Txbx83\nzfvr0l8WaabtmyYIgTSe11gQApm5f6Zp2YIFqeUaUEEQAll8eLHNNu4nPZDLl7V0I0eKDB5s+Zn6\n9hVByXBT+teWviEIgXy88WOLfERE7sQnC3zvS+PGYuLrK4KK6+To9aMiIhIXJ4Jm/9PWe2yboFOw\n9rdPkrbNChsFjUNlR9QOQQhk7I6x2vLPc8uxG8fk2I1jEv8gXpJSkuTi7YsSfTda8FCc4LO8Uq3L\nIsGTUy0/44CKooWUIsG/BMvs8NkiInIq5pQsO7pMS/PEzzb7xRwg0qJlilSfWl2aL2xusezOHRHU\nWigIgTxIfmBaP+zvMJm1f5YYDAYREflyy5eCEMi1+GumdRvOaSg1p9WUlBSRZ55NkT17RPZf2i8I\ngfT/vb+27dT8jPsPpfZp8xpMNH2uOXPS0hn/b76+af9DEZE9F/bIC/NfMH020772vW9KM+OvGdIu\nrJ3Yc/bWWbl656pp2mAwCEIgQzcOlUNXD0nt6bXlQfIDi3W+3futIASy6NAim/yKfFXEVJbklGRB\ntV8FMEjx4lrZChZMKztgELzWWlDqLwFEqlRJWxZ+Odzmsxcrlrbc3K2EW1Lum3Jy4fYFERFp3Vps\n/t8XLojcvi0W+37ynsnyyJCnBRA5c8bu7rF73Ghl135GjNB+r16t/a5XTyTFkCIfrv1QLsddlr0X\n98rciLkW61WsqJUZIZDn5j1nWrb7wm5BCEyfw9qaNSLwSZJ3hh2xKIPRtWsiZcuKXLhgkFMxp+zm\ncT3+umyPuCp49wnTsX3nwR25dMn8WDPIkSP294c98fGpZQmBPDnrSbv7qmZN7fe8ebbrT9w1UTov\n7SwIgey5sMf9DYt2/B+4csBme9bHSUSENq9TJ+33unXa/DsP7si5W+fEYBCZPFkkIcF2/RYttOnN\nm0Xge196vRPncHvX4q9Jrem15MqdKzbL7yXek9e/makd9xBpbnbKOXr9qCAEMmXPFNO5xR57n02P\nl1/Wvn9zdv8sySnJFsuux1+XpJQkj/MMDw8X7RqKQPHgGq/3J6MCia8B7HKwThMAVwD0BFAdQDsA\nUQA+d7Idx4GE8SdvjKDsDkFQ6kX9xSFmyw2CKr9p89v30E7mVhexR4fVF3TubDqIJ+yaYHOi+uHA\nDzJq+yhJTE6Ub3Z/IxdvX5TAmYFy4+4N8RvuJ92XdZf581O3GTRD1DAfQd5oQQikQJsRgudGCEqG\nS3KyyJEjWrrAQNvP0revCFSyBM8dIsgbIz373JfzsedN5TgefVx2Ru0UEZG7d7V1bAIJswP61i0R\ntHlH+zwBEQKVIkVKxdps12AwSNjfYZKYnCg+L78tKHrU4YFpXKdJExHkjpV2C7uaAiw8FGfa/qJF\nIn5+ItHRaevu35/6P6mwQZArXhACqTW9lmm5wZC2b+yJi9OWN22aWpbU/9Pf1/62SJeUkiR/XfrL\nbh537qTlYbwwGgOJD9d+KK8sfcXisxaot8IUeImIfPedbSBh/mOUYkgxffEdpXHHvXva74SkBIcn\nM4NBpP77UwQhkB8P/2iz/MLtCxJxOcLicwEiJUqInUDC8sc8kBAROXDlgBbYpi4vWtS9z9S6tQgC\nImT27p8syvHEE6l/h0Byj8gtIiJdu2rLTp+2n9eRa0fkz/N/2sw3lmnkSO33b79pv4OCnJcNEKlQ\nQTueEQKbANaZtWu19YcNsyyD0cKF2vR332nTCQkiyck22cjRoyKouUh8hj0kIiI3b6bm9U5NqfBR\nN1O++/a5Vy5jIPFE10V2gyDzQKJOHft5/HP9Hyk1oZTE3Y+zn8AD9o79Awe0eXXrpp3/zO3cqc0f\nPtx2/ebNtektW7Tf/frZ39769a7LM3Fi2nRzq3/9rvO7JMWQ4vFn06NtWy2f69fTn5dRVgcSnr5G\nPDq1RqGE1fziABy9QGA4gAUiMi91+h+lVH4AMwHYjltqYSCAQlbzgrWfhCLA+WeB2Me0bp9/mT+f\nVGmjYkb0BnKnvozldDMg4ADaVm+OHR/+CMQCKrUG+MC6WoAP0KduWpVwjzo9TH/P7PUBSoZoz/gA\nIOkLrUps/vzUBOFv46Omb2NcAlB18z84tvNxQLTBrE6fBmqkDWhon/iiX8WvEJYAXLsMlClUxrSo\nyiNVUOURs9EprVe1mmcwANj2BUoEGHDtek1AfOCTaL0ftapO4+MAv3UzkGh/yH1bDwphWtMwlCoF\n9A3qC78QX9Oi0aO1l4IVLaq9XC2f6b1KCjjTTPtzzp/YfKyKda4O31Vi/HzG3zeH3MT0/dNRvVh1\ni3R+Pn6oV6oe7DGuqxRwZFsVFM5VDG8FatWcY5+fhG++Ad58M+39GQ+dbaeFzFbruxJ/xwcFC6bv\neealS0Dp0sAvvwCdOuVxmC45Gdj3yzPA20BgyUCb5aULlkbpgqV1lcH6jbp1AuqgTkAdjLWf3Lmr\nddGukuVz7aOpI6BPaD4BL5R/ASLAEhft3aoXr+48QSrr48WlxPzIfasOhjexP1qhs224K29e4OWX\ngZUrLecrBeDvbngjSHte/thjqQumH0bjnsCZ1MnFi4Enn4RLxnIFXO+G0jrbqD9R7AlcGnTJdUIP\n3b4Ni3OMsayzZgEzU9ttrl+vvVUVABI8eJdbVJT2nTFq0QK4eBF49FF9ZX26jKMn9ZnH02PKKCws\nDGFhYRbzbt92b/j9jOJRICEiSUqpcAAvAFgFAEp72PcCAEevMPKHxSkZSJ1WSikl4mz3TYJWOeFE\nXBlt7Ahrifm152sAkOsuCl7siLhl04C7JfCbWTLjCXPRV09CvVcaHzX8yO5mIiOB//0P6OKkGYBR\n3vgntFgw1QmzFx86+7TGob+dvZ3T/ILoiMEAIL4kKkbOwDWD6+16wvqlXb4+vnaXA9qJIF8+LZCy\ncKEhipo1VDaWzdG7U6wvDA/nfRifNvrUo3Kb77cewfkBXEft1Cy++w74+GPtb6cn62+P4+vxKbBt\nl62JiACCgoBt27SXR+l1MbVpx/btQKdOztPiSiCe3SSoOsz9/I3/I+MbW90OIM14ejw5Sj/oaa1h\n4N69+vM2sj423clHBID44rG1B/DUN67Tb93qfH9dvw4Ud9BTfdUq23nW3+M7Dl5A6ez7nhHpM4N1\nGSpWBGJitJGHAfv/nx9+cJ6n9flPKeDuXaBcOSDUql3tffvvkMtwv/8OtG6dffs8ODgYwcGWbczM\nun9mCT23ThMB9FVKvaGUqgpgBrRg4QcAUEotUEqZt8b7DcA7SqlXlVLllFLNoNVSrHQeRGSgpHx4\nbO+vwF3rihRg6tTUC/eDQig89wIeL+q40eSNG7avy7b3CawPKPM0zj6x8QTo7C2i7uwxYz6uDmyl\ngDNnnKext4675TCmedVFd3NXgYR1uosXtYu2J5wFYPfu2aazK6YKSuVy3BMjMnXAz0OHtBOmXu5+\nK9zdb9asAwmrmxmLNBnF1We6m4HDXHhyVvH0DNS0qXbH7Gj/NGliOe3ufsyKM2EWnW0dMn4nnJ1D\n1qxxnoe9dYw1F9ZvfTXf97Vrp70t2t183fXSS8C6da7TuZLd/5/08DiQEJGlAAZDCwYOAKgFoIWI\nGJvtloY2UJXRCGjjTowA8A+A7wGshdZtNMv4OPikK1cCixalTe/YAURH20+bkAB0sBr63J0gwd0D\nxFkgsX+/9sW44WKY+ZQUoGFqBxBHn9ncDp3vhcmMg97Vow1A+x+UKaPd+eth78TuTjDoDvNgJTIL\nRhH3uAo/lbNA19k8T5Zbb8uT/NJ7bHmyX9xNu2CBe8eOsfbR0/2TUemMnP1P3anVzEzWNUfm4sxe\nwmv9GZYsATZtslymlHv7+vBhreYxs8TGZl7eOYGuh7kiMk1EyolIXhF5WkT2my1rKiK9zKYNIjJC\nRKqISL7U9QaISJz93DOHsy+N8QKmlFYl3aqVNn3okDZvRtoL97DWSRd/RzUB5ge6s3J8+632+8IF\n22VLU19OeeSIbT7m+cfGpj1KyMwThb2TwKBB2ivV7ZXLGWM6d9pI+Lseu8VpHtb7pE8fYNgw23SO\nONun5ttwte+dPf81X3fJEu04dLY9vTUSGSU52fbZvzV7+3Xjxowth3XQ4s5+cfb/Dg4GiqW+k69H\nD8tljvahdX5ZfbE2bt+65tR8WXoDtfz5tTYbenlSq2nOvPbeXuDpTY9/kpM9f2T4n6qRyKmcHTQP\nWY07ZKzu37BB+/2O1RAIv/ySdrF254A2uNlo70Bql3vrGhER4NYt59uwl795jYSj7fbqpb1J1dM7\nI3v5TZrkXh7WPG0jYXTlirbO1q321xs2TCvvzZtp1Z7mn3P3bmDOHNflO3ky7aTgzpf96lXn+zM6\nWguIFjoYJ8q4jR9+0E6edeo4T5feGgk9acy3+e23QPv2tlXLjtIbNW/ufPkLLwC5ctnON2fensjZ\nna4n5TJassRx7aSj9fVeDPTUCjnL588/HS/zJN/797Xj2dzdu8Ao98cldsi8HDduWD5i9GRd499R\nUe6v7yg4zyh16gC5/0PjKP5nAgln1fzGQMK8AQ/guOFT585ApUq21WqeVKU6W2bd2HL6dGD2bPe3\nYeTOBcNgAMaOtTzJOPuSbd7seTnsiYsDpk3TTkrG/e/Oow1zpUpp+6VpU8vGekYTUseeatUKaNbM\ndnlDO2OA2dtWlSrA4MHa384uUsZ1R460f8f2Y+rousbHU5s326YxF+eizi4raiTceVxnvNh+842d\nhrUu8nFmyxb7DY83b0676DRtmjZfd2NLHeVztg9//x144w3P8klPTZjR0qVa0OyIns/6yitASTsD\nRhrLExMDXHPUX88BewFf8eKW/0tX5bR3Q+VJcOAoOM8I/ftb1sy668cfnTe092b/mUDC2RfR0V2P\nO92PTp1K+zu9NRKO0pjfcdvbhqM83WkjYW3ZMu1LtmuXdmH/y8Gr2NIbNP3vf9oXzvwu1t3un+au\nXNF+2zuBGve7sashkP7qTHdOboD9u/Pu3R2XQSngNdtBGN0qy/79wOuvO04XH285be/RmattOGM8\nzn780X7A5iyfa9eAffucB+QffJD29927wIsvAgMGaI8Z7bXxceeCmaT13rYIOs6d0wLT335zuJrD\nbZlPjx+fNu1Og+eMkJioNWruZfaigpAQLX9jrZsnbSSqVwcqV9aCImeKFwcCApyncZe9mwFHMrJN\njTMPHmg9ujzpATJtmr5tffRRWjfYnIaBBNJOrMbHBzExWhDhzgE61qxjvaNnYl27Os/DeBE0ntyc\nVV7QT+EAACAASURBVJc6W9ali2UXMz0nKeNF98oV7Y6+fn37VYbu3AXfu+f4rttY22Oej6NAwvi8\nd+dO22X27m6Sk7X9Yuqi6mub3hFX/3N37/6d9bxxtC17vSfcXd+8wbAIcDl1BOzLl4ECBTw/Fo6l\nvnKiZEn7DXwdPUJzdMJ1tF8bNACecvGqgSlmHcuN+z8qSutyZ87YhXfBAufbTEpKqwUzDyRatQLe\neksb7yE9AUBmPHs3z3PiRNsaD+NnNX8UM2KE9rtPH63xrzuPYUS0C/rRo5Y3SY54WhsGpF1o9XQ7\nticjAglH/7NffwW++gqYN0/f+u4wL7+rWkhv9Z8JJJw9f/vwQ+23+Zfi6ac9i5CBtC+G9V28eXWV\nvYP+l1+038bxA6zTOKvR+OOPtL9//hno3Ttt2p1aC2tffqn9XrMm7URib2wTd/IbMEC7e7TH3vrG\n8p48qfXHNxpt/0WCANIuYub55cql3RUa95uf2Wgp6Q0k3K2RcFRFKZL+MhjTGP9XRpMmaRfD2bO1\ngXguXkwLjvW6ft15z57z5927qDr6TOfO2c6rW1e7WDrLz9kFzFUXQvOGiOb5WNfcZCVP2kgMHmzZ\nvubOHeffJyAtuHaWL6DdiDSw8y60jGRsmJuecR7cqZHw5OK+YYN23rFmPL+YBz1HjqS1Z3NFxLO2\nH3pqkb1BDi225zx9ZnXokP07YGeMNQoZzVmDTmcRrPlB6eqCYv2lmzs37Zm+vZO2Oxe7XbscLzOu\nb++LU6UKUKKEViZ7jb3MGde3fi6+bFna334eDLuWnkDCnKMLnXkXNE/vpMxrWU6ftm3cOmiQ1p99\n1ixtOiZGG1HRFXfvvu0Fpo89ZjngmrNGwDt2uNcO5u7dtDYpjsrizr4z7qtLl4A9e+xvy1iezKwe\ndya9bSSWLwcKFgTOnnWdj/Uye3kab2Yyk7uNYt1tI6GnVsQe8zYWp05pvfWM5w7zG4OaNYFAF+Mk\nGo0bpw3KZzzO9u933g7CGwYS08OrAwlXo5x5m4wKJO7fB/7+O21a70kuvY3qjJG0vZP//fvA8ePO\n83TW8MvdQbPu3HF+orAOJMzT2quR2L3b+fbsVRHbW+5qmaML5oAB+qvN33gj7TGNs3KYt88wNtJN\nD1flNa89cuTkSa1rtXn7AXMtWrhXFk8amEZGAm3bakMnP+1gxGNPGma6y539YZSecSROn04LkM6f\n136bfw7zddwdb8EVYx7//KM/v4wIVsy3rTeQcLbvW7TQeusZ28/pPbcb25jcv6/1bHrySduaRHPG\n85lS2qPqffvSbui8mVcHEvnzZ3cJPOPOMz/zAMGZWrXS/rZXI2EwaAfbTz85ziOjqsku2Rl2/4MP\ngKpV04a79ZQ7Db6My/UEEseO2W8j4Sy4AVz/D501wHUnkLBOX7my5Yh7Sjk+aRnbQbj7yO3WLWDM\nGNfpXF0Q7B1H5uu4GiQNSBuwx5OGnuZmzdL2jbFRqbsXj9Vpbx83tRuxdxE6dy59g5CZM6/9zMg7\nzORkoE3am+hRqVLase3qeBOxfbQREaE1eHaHMWAx/7w//5z2t7tV/ebSU5OQETUSjtqMzJyZNgTA\nF19ov/X2pjD+/3fvTnukYz5Y3datlseo+fHy889a+yFjI21v5tWBRE7z668Zm1+5ctrzSnuBhPHA\ndtZAL6NOYu3a2c4L195dhrp1bZe5w9guxFU7DlcnCkdd/sxHmvPk0YarBo/Ohtk15+zEbizzokVa\nFar1iHv2ghnjRRDQjgl3Lt7uBDPucDWi4+HDztOal8X8pOkJY4PLFStst+8u4wucPL2btTe4kyff\nLWfb2L49rUy1aztO9/XXWhBm3f7D+v08jmokzJeZp5k2TZt2FQgYa3TM1zU/Jt2t6rdXHj3L3fkf\nelIzBGg1AI0bA/3Mxlw23vi5UyNx965tV1jj/8C80bn593LQIMv0bCNBGS4qSrv7tNfY0p0I2ZOD\n0luezVkPNRsW5l6NhLMqb08CCb1VmFWrWk47K/OyZc7zsve/MH+zIZB1LyQCtAupuxdupbSePtWt\nXtRpPHl6MmiQOetB4zxtv2QkYrmuO8GWsztCd9o2OGortHcv0LNnWj7mAZm9vO2N0eEskDA/ls0f\nbVjn6+OjBQLGUXOd0ftIwd6bXdPzqMWdcjRooH1u8wbp5ux9z4yBnTV3jpNnnnHcFda8d587Nxk5\njVcHEtnVAMrb2PvSOGvIaKT3sUNWsr6DqmL1dvH333d+HFjXSNg7qfj62s5zlZ+njh+3bNDq7GRh\n7Kboicz8LrjKu3Nn21oTZy3l//rLcuwOwPV4BK64GuHSXb/8or1kycjZHbzRli2288zTuvou2jsW\nUlIs717dqWGyxzqQcGfANEfdOl2N4mmeB5DWvdQd1m/mtM7LU5482jB/xYFers4L8+bZHxDLXhCz\nZo1lA2VzPj4547xtzasDCdK409XJnoweeMhcRnWVMz8JXLpk/4SalTUS6Tm5fWT2BvqMeqzgiLtd\nRDMqL1ddKh0xPspIb4MxT/6Hzlg39DP/PznaD872z+jR2p2oI9bvXcmXT5t+9lnLR4b2tmE9MNa2\nbbZprAMJZw2gXf2fT5503VXRPA97L6o6eNCyC7qzbafnDbn2xhZxxFEQMH+++9tzte+Mr1Nw1+OP\n27+h8PHR/7g4O2XQ1zNzsEZCYx7pZvYFKqtZv3bZHk8aW9o7ZjLqIuQJbxjqNiMDCXfXMQ9eP/vM\n83wdyagaCetyu1M9b++C6UnNlfk4LMYLtXl3VEesu2yPHGmbxtgOQM8AaNb69nWdh6v91auX1t7C\n+h02GXmMAWkvfFPKdc8kR/8rPQ1EM9JXX9kO1c1HG5mAgYTGvFGTu70+POXNB7A7gURcnOU4C+Y8\nOWFk1H5IT8DnznHvTjnd/f706ZMx27PmbCAxT2VFIOHOi/D0MB+2OqNNnqz9dhW41qyZ/s9x/bp7\n45IAjntEZAbjO3Uc8eZzm7Wc2tiSNRI5TE4bWyMjOAskjF3tjG9offXV9G3L+tm+XukZUySjjvuW\nLTMmH2+QnTUS6eVO24P0cqcGLL3HlTsNZY0NNlu1spxvHOciozlqHGkuJwUSxm6nOY1XBxJky5OG\ng56w18XNW/y/vTMPl6K4FvjvXED2RWUziohBEFBACW4hSiCCYtRoYhTcjUbE54JJUIyEfMQlwlNj\nVNQX9ySQxUSeUZ4kYvIUFf0CaiAuMdHIc8FgUNyXQL0/aipT09Pd0z3Tc2e55/d997vT3dXdVaer\nq06fOnUqrrH3HanOOCP5F1O1yWKOfKVkqYgHo4umCfubBdVSJOqFsFDhaUgT6bNarFuXV6CXLSs8\nVk77EhW8zCeJtbGRFIkkZa5HGtSQ0napliJRz6TxaJ87t3r5aC2SdAqlInRmTa3Hk/3F6Cohrhxu\nIbkkJP1ynDUrWbqo5deTkqXzbbkMHFjd65eLv6BdvdGIMzTCqGtFol6/HmpJW1Qk0gw3NIMzapLh\nq4suqno2mpK4gGNpFjg77bRk6cIcNavBzJml0yxaVNk9gu1xcPXVtkAaZbMtUdeKhFJM1JoBiqVe\nFImwFVOTknY5cUWJC93ucKscl0twaKTRljCoBGPgkkvsAmlKMXXtI9G7d61zUH/Era2h1I8ioSjN\nRvDdaiTfg0p56aXGWDyrVtS1RWKbbWqdA6XRUEVCUapDa8xwicJNc60VSRZkbMvUtSKhKGmpJFqe\noijRBB1eW9MiUemwTKXUQ4C5ekYVCUVRFKUkwamJYQtxNSuqSMSjioSiKIqixKCKRDwNr0gceGCt\nc6AoiqI0M6pIxNPwisRdd9U6B4qiKEoz4xYJU8JpWEXCLYTTtWtt86EoiqIobZmGVST+678qC/qj\nKIqiKErlNKwi0a6dRhlTFEVRlFrTsIpEHD/4Qa1zoCiKoihtg7pXJH71K5g9O905fftWJy+KoiiK\nohRS94rEkUfCpZemO6el7kulKIqiKM1Bw3S5l18OCxYkS6uKhKIoiqK0DnW9+qfPrFmwerX9feih\ntc2LoiiKorQG/fvXOgelKevbXUTOFJEXReQDEVkpImNLpO8pIteJyKu5c54VkYPS3tdFFxs4sJxc\nK4qiKEpjMXp0rXNQmtSKhIgcDVwBzAX2AJ4ClolI74j0HYD7gR2BI4GhwGnAK2nvPWIEDBkCM2bE\npzMm7ZWLue22yq+hKErl6CwspS3Trl2tc1CacoY2ZgI3GmPuABCR6cAhwCnA/JD0XwN6AfsYYzbn\n9q0r47507QrPPVc6XRaKxJQp4fvbt9e464rSmqjPk9KWaQRFItUrmrMujAGWu33GGIO1OOwbcdqh\nwKPAQhFZLyJrRGS2iGTWPLz2Gnzuc1ldzbLVVtleT1GU8lBFQmnLNEL9T5vF3kA74PXA/teBKJeQ\nnYGjcvc6GPge8A3gwpT3jqR/f9h++3TnfPOb9v/BB4cfD1MkTj89G2tHM3PHHbXOgdIatG9FN22R\n1ruXotQbjWCRyKo5ECCqi23BKhpfz1kvnhCR7YFvAhfHXXTmzJn07NmzYN/UqVOZOnVqUVq/g08i\n+OnT4T//MzptWEN5wQVw442F+847D668svT92gr9+tU6B0qzoYpEPKNGwVNP1ToXSrUoZZFYvHgx\nixcvLti3qZUXokqrSLwBbAaC3UVfiq0UjteAj3NKhOMZoL+ItDfGRHocXHXVVey5554pswjbbFM6\njWucwh7SK6/kFYyjjoJf/tL+3mmn4rR77w2XXALf/nbqbCbm9tvhxBOrd/0wjj4afv7z6t6jpQW2\nbEl/3qc/DX/7W/b5UZKjlrn6Ydo0VSSamVIfxmEf16tXr2bMmDFVzFUhqYY2jDGfAKuAiW6fiEhu\n+5GI0x4GBgf2DQVei1Mi0uIattmzoUOH5Oe1awfvvAPvvQdbb233fepTtpN7773iznTOHBg6NL/9\nySdwYWaDNNVlyZLkabt3L51m1qzifWm+Hs85J/rYb38bfSyrTmzYsGyukzXTptU6B/WFWiSUtkwj\nDG2U48ZxJfB1ETlBRHYFbgC6ALcBiMgdIuIHtb4e2FZErhaRXUTkEGA2cG1lWS/k8MPt/9mz81+5\nZ58dnd41Tu3aQbdu0KVLcZouXWy6xx+HtWvtvnnz4Nln82nefbfyvJfL3nunS+/ibxyUIIJHKXPa\nsGE22mi1iOs8slIkfIUwiAt+VguGD6/dvZPmoTUtEq2hSJx/fvXvoSjlsPvutc5BaVIrEsaYX2Cd\nJecBTwAjgcnGmA25JDvgOV4aY14GJgFjsTEnfgBcBWTaDU2bZhu37t3zikS3bvnjN94IgwbZ3/7X\nrq/tRTVYY8faGBZhBIc7fvObVNmO5Stfsf+jGu20X9SurEm8gA88MP54a3kShy3AFjUcksYSBfGd\nYdeu6a6VJUk6zmOPrd79330XHn00u+u9HjXomZDWUCQa2erRyHlXCvnMZ4r3nXlm6+cjLWV1B8aY\nhcaYnYwxnY0x+xpj/ugdm2CMOSWQ/jFjzH7GmC7GmF2MMZcHfCYyxXU0/gv29a/DCy/A228XdpJ+\nh1jOCzl5cuH2F7+Y/hqlqCRE6oQJ+d9OkUhSTqfE+PzoR/nfTm5RlTxsuOfIIwu3k+TjiCOK9wUt\nTV/6kv3vDwn8+c/w+9/HXzuuBrq89elTOo9ZI2KH19Kyzz7J0956a/Sxrl2z7ZwafTXe3qGh9uoH\n9VexVPrlnmQ4t9qEfaA169BG3eNerLCH4irL5lxorHIf0g9/aP+qRfv2+cZ82DBYujTcKrJqFfz9\n7zB+fPExY2D58nyMjSiLxMMP539feCFcd114nvx7uGtEWSbC9pfjWBnWSJ53XvH+TZvgppvy28OH\nlx76SaJITJoEa9bk9x92WPw1s0CksCPfbbfwNEFcnU5CqXpfbYtTJZ2f82XKknIUpwEDoo9lNez3\n+c+XTtMIcQayZt684n3ltC/lnl/KYlsuYc+yESxOTVkFXYWIe8HCFImTT05+j7POsn9xPPOM/TJ+\n4YXk13Xcc0/+tzE23kVgJiwAe+5pfR/iwgg7efgWiauvzh/fb7/87y9+MTwE+ZAhMHhwvgNwlTtY\nycOsQY6ojm7HHfO/fQtKGM5XJUiPHsVTdjt3tg6z110Ht9yS3+/yFtdwuDTGFHbk//3f8fnLip/9\nDHbZxf4Oq8dhHXGaiKth5//0p/C979nfUY1X587J71EtqtGwZn1N/52qhCRf2UkUibTDfqXI0qfE\n5d/F9klCx47F+yq1zES1B2G+dtttV9m9olCLRB2RRJEIdq4A8+en+6orxeDB9svY+WYkZc4c+MIX\nihu3MEXCEUz7/e/nfx9zjP3vWxHOPhsOOaT4OvtGxCcNXt9NR41qgIP7p0wp7ujci+8/A9+vxU/j\niPJViaJLF6sYnXyytVDccEP0tX2SKBtJ+OxnS6cZMqT43uPG5ZWfpJ1ckro7c6b9H1b2adPgoovi\nz3d5qoWz5aWXFm5X4x5huLJOn17Z9YLT0jt1Sn49n2Dwvai8+0H10jpml2K//bJTTtw7tvPOhfuv\njXHHD7t3tRSJK64o3lfOMglJgriF9VmtGfytXJpSkRg3Dg44AE49NTqNa3SDPhJZmAndmGrwBQ/6\nE5xyCkU8+qg124Vpod/9rv3/u9/Z//5Mk+BL6H8x/Md/2JfMXdO9cEuWwPvv29+vvAIbNpAIY+Dc\nc+3voLyCFgvHhAnFL6rT9MMcXqvRUa1caaOTOtw9nnyyOO2229r/SWa4OC67DJ5/vnBfknLssEPh\ndlB2Seukq9NxJnd3bffco4j6Cooqz8iR8dcLY9dd87/DpgK7mViOKCtYaxGcyZKmjn7ta8X7NmyA\nN98s3BdULsLuccABhdtR9cO3mMalKUchGDUq+yGm00+3bduoUXb7hBOi04Z1rkFZzQ9b+SmGKEUi\n7F5pFImjjrL/k9TbsDQ6tFEjunWDP/wh77AW5gBZqY9EEvwKYEyhhv2vfxWO6Z93nnVGDHOYcy/I\nXnvZ3xMnWnO9b3Xo1g0+/jg+P07x+PBD+799+7yp+lOfincqi6rMwQYqbGhj/Hg47rjiL2Y3pFGp\nw2tanNIV50vTsyd89FG6QGCdOlkrVFL++tfwaaZBGaS1SKxYEZ3GldVdM6oT6djR+t6ADQDmiOo8\ny3luzzwD995rf592WvLzwu71/PM2Hkw5bLVV+Y18ENcJBuW0ZUvx+d26Qa9ehZFxk1iVbrnFBqlz\nRCkJfgcYlfc990w3XDVihC2bm0qeJS0t1hLrCObZryNJFIm0ClIa66NTJJLMbkrjT9GokYGbUpHw\nefNN+NWviveHDW1kTVzD065d4fErrijOZ9ywwYwZxV7GpV4cN2zwwQfx6dIQDDwa7JxF7OyJfv3y\njeSQIfkYHS7tZZfBt75l5XDyyfkXqhqWiYcesopmqSEw3zR89tnw4x8XHr/++vKjf27ZYjvoPfaI\nVhzc/6Tj7ddea53z4joG34H3oYestSqKgQNtx+GbdrN+HlOmwMaN8XErSvnl3H23VeCCw2JJCX7h\nRxG8b1ijv9de9n+wU/K3+/Qp7AjdcBMkm9bbsWPh8EZYOzFgQKG/kV/HfR8oY/KWhSSzU+Kmor/6\nKvzzn6WvESQ41TrqOft+YGGKRFDmYXJx9T2srQxTJK65pngfWKvx5Mnh0zWDRFlpw/BnxjUSTa9I\n9OoVvgBX2NBGJdx7bz4+RdZf1Vk13s5s6qZLZsHUqYUdV5yz5fXXwxlnwNNP22m4flCwCy6wpsid\nd7ZfXGEKnu/fAHZGSjlst53tPOIsEkGuvtpaVXymTy/t/5LmC94NxQWHd7baqnjqrDvm+81MnAgP\nPFB8befXcOSRhcfGjcuXPUpZWbu2cIghS4uEI8pEHpRDXFj7OCZMKOysgyxZks4i0bevnQnlrCk+\nLq/BTsmX20svRVtPbr4ZHvFiBBsDCxZY61UULS3Fs0TWrSucuuzL7Lrr8u+SMdbJFgqdnqOIev7n\nnGPfqyTLEwR54onwj73gM+nSxbYhkMwi4fAVlbjnHDbVOyr9iBFw333p/BeS1LFevQq3g21OvdL0\nikQUrvOrJEaDz5QpeRNWXGeahqwVEhGrQDn/hizyIlI43j5+vO2Uwvw/hg6FhQutkuArCkk6hq23\nLvRvgMIx9nLwO2ooL3ZDcPgK4K67ivcluUZcHIg0syiCaU8+2a7F8POfF3fO55xjp7jef3/pfPrn\nxd0z7Uq8/vmjRxcfC75Pad+L5cvt8EGY4tmhQ6F1LA5XTxcsgAcfjDdDBzsYX7Ho1Cna0bKlpdDh\n+dRT7WwGf3gp7JxZs/JrAoXhyueG9fzyjh1bvC8K//n76Stpq3bZpVBRjnvObkjByTdu2C3sOu68\nuXOLr71yZXYd9803WytrWL4cpd6TTz5pnNWU26wiMWKE/RIJWy+iUt56K5vrVMPxsKWlun4I3bvb\nuBSuU06S9yTDS2FWpUrL4fLmGnUXMnvixPD0YYR9gfkWH3ePKBMpRA9tOGtHWH7SdqojRxbGJnEd\n24ABsGxZ8nFyp7wFZ8/4z3nVqvhFpOKc4MLK43x/XB2Ic0aNc4JzZfYX2Av6FQUWUSzA3T9uCNEp\nQkFLla9IhJXxhhuKFYH27fM+F0F851b3/oQFkfPvuXEj/OlPhfuNSVeX0rZFwei7PXta/444Px6H\nnx/nlNqjh/2/zTbW0jBnjo0u7E9ND54fpvBMmGBnAflOsIMGwaGHls5XHE65/MpXitvAoHxLKe/+\n+1rvtFlFAqzJNuv51WArdxYezdWcwZCWapnYRowodBoN4soeNm+8UubMsQ2QGx746CMb2Grp0uTX\n2Hlnu/orxE/nmzEjfiEyyA+3uee+/fa2A5oypbhBMcZ+uUYFD3NcfHHhdqV1auxYeOMN2H//wv2f\nfJL/3a+f7eiuuCL82cY1jr165f0lXB5dZ+/qgK84zJtXOLMmTimN84lxeXJfrGGK1fHHWyXIeeGH\nMWOGjRsT/NrcsqXYn8jn9NOLFYHgM3r4YbvuD1gzvHPW9uUZVf6WFtsmOTO/f07QAddnxQrrS5OG\nuBk8b71lZ2PETYsOUwCcyf+446zCNWWKDeV+4onw4ovwl78kUyR8Zs8udHiP46qr4j8GBgywys4D\nD9jh3jB/nWA+GiE+RFIaYIZq4zF3brjpLC3nnmsrZjmm4iypRJEpNYshKsCU/9KNGgXf+U75eYji\ngAOst7/rwD/+OP/Fk4YLLrANhz/d+NRTYf16+Mc/7LaIHfqaM6fYsdCV1X19Hnxw8bGwxvCRqPV2\nc0yZUry8fRbK6bbbFp/vZgL5nHde+PlRDfttt1mloEcPq5i46X/u2k6R8M+fMydxthPFl3EfFsOG\nFc+o6dDBOgTHIRLuN7NlC9x5Z2EU2bQE/VjCfHw2bgzfH1Vm3yIRTHPSSbbD9/05opQh/5ksX55N\naHkR67exbl1+X0tLuOVFJNrZMs1XfdR74YaDo4IQilhlp1cvWLQo2TWDuCGm7be30/EbCVUkaszK\nlcVzyR1jx8Jrr7VufrJkxYr4sd2khMV5yBL3ZVDulDYX4MvHeV/fd591ynSNWVhoX8ewYdlan8Ku\n5SIlVhqZz1371FPtV12amUBRDbs/1bZz53w6p9xVOjUu6GvhO7YFLRKVBiID64y5dq2N6WKMLYev\nJJaiVAcYphj5ivDIkTb2zN13561mwWv7isQJJ8Bjj+XTuPVY3PF+/ezYf6m8Jl2b5PDDi4OxBa+5\ndq21FCYhrUWi2kQ5CwePA3zjG/ln9Nxz5QW8qiWqSNSYrCPO1RNJojpGEWdirgYrViQPqnTvvck8\n3MF+Ybt4DFGkmTHgiBs6i7veMcfYOpc22uq6dYUdlmsczzrLOnFedJGVSZz1bMgQa4JOqhCMHWv9\nmE46ySqkrhMud6aV3/HeeWe4Y6eTnat3STuhJ54oDoXvHLBvvrm0JaMcxo2z/+Oi0UZZR4N+A+55\nhi3C59IOH57+fXTnLlpU3DkuWRJ/joj1uUq6mFacI/C6dfb+bmgoSpEOXiPpkOqXvxx+3yiWLStU\nuLp3z9+rlisPl4sqEkpdsssudlG0k05Kd95uu9khhbSkUXqmTEl//SSksUYkWRQq6npplQgojpbp\nf2W9/Xbp8zdvtmkfeKD0eiqOCy6wcRV69iwMKpekc99xR6sY+mvWHHig9UU466ziaXb+NW+4wYaP\nf+IJq/wkieMxenS4YtKhg/3CLIcoR0vH8OGVW7CSnB81JJRm1sbUqcnzVK4lYcAA+L//s0NqV15p\nzx8xwlqEXP0dNMgGvXKRa4P48pg0KVlAuvfeSx/ufNIk+/+ee6qzYnRro4pEK/PSS8ka3kajWzfr\n/JQVIqUXRQsj6JXeCKS1SOyzT/xXS2uYcpP4G/i4dGlmxLS0hA837bSTHaKJuvf69fbLuUuXwlkZ\nHTsWxyJx+GZoN804GLq8NXnyyeRWr3JI4yvjrINjxkSnydJxsNz6u2SJldvGjXa7c+dwH6woJSLI\nvHnJnPH9pQp8Sg1tQGOso5GEJilG41DNxgFs8KFK4yuUw9q1VkmqNY0yXcrnmmtsbIIkjp4rVoR/\n+fr06GEtM9VwUHWkidaXJcuX2/LHBT7yh06SNtTBabG1ppQ1olLc8uRB69AddxSvcdG5s7WqBNfz\n8YnqTCshbd3q08danTZvDg8glwQ3XXX+/MqHnX1F4ogjrHU1uH6M6w9KvdP1jioSTUaapdCzZODA\n6sTfj8OZp6dNa937Zs3gwXDjjfFpTjrJ+iKMHl16DLVdO1izJrPshVIrRSLpsEhaGlEBrYRBg8Kt\nEccfb8N8B/094pwiobhObr+97dSD10lCpU6S7dqFL/0dxX335X2ORo+2s1Siwq0/9BC8/HL6PP36\n1+H7hw2D11+30VIbGVUklFjq2Rm0c+f6iLHRGhx0UH2VtVaKRLU44gjrMOqm4LVlhg7NB2eL7kJD\nlAAACoxJREFUwz37M88sXpjKdbYbNtgooOXQWnVr8uTC7bg1W5yDaxKcY6rvoPrUU8X+OY2uRIAq\nEkoMGze23qwJpbFoNkUiznFx8OC8t38YYR77bQl/VeMgffqkl89NN9mhiUbn8MPt2iC+w2bSmWGN\nhioSSiRZROdUqs/558PPfta692w2RSKOpUvtkudh1JOVqFnYfffkESfrmZYWG0OmLdCmQ2QrSjPw\n/e+XjlWRNW1Jkdh223QmbUVpa6gioShKamodNVCpPfrsFYcObSiKkpoFC+zUtSxCoCuK0tioRUJR\nlNT06WMD9uhXadtFZ7goDrVIKIqiKKlZtMiGpFYUtUgoiqIoqenSJVm8CaX5UUVCURRFUZSyUUVC\nURRFUZSyUUVCURRFUZSyUUVCURRFUZSyUUVCURRFUZSyUUVCURRFUZSyUUWizlm8eHGts1A3qCws\nKgeLyiGPysKicqgNZSkSInKmiLwoIh+IyEoRSRTjTESOEZEtIvLrcu7bFtEXI4/KwqJysKgc8qgs\nLCqH2pBakRCRo4ErgLnAHsBTwDIR6V3ivIHAAuDBMvKpKIqiKEodUo5FYiZwozHmDmPMs8B04H3g\nlKgTRKQF+AnwHeDFcjKqKIqiKEr9kUqREJEOwBhgudtnjDHA/cC+MafOBf5hjLm1nEwqiqIoilKf\npF20qzfQDng9sP91IDTquoh8FjgZGJXiPp0AnnnmmZTZaz42bdrE6tWra52NukBlYVE5WFQOeVQW\nFpWDxes7O7XG/cQaFBImFtkOeAXY1xjzmLd/PjDOGLNfIH034E/AGcaYZbl9twI9jTFHxtxnGvDT\nNAVRFEVRFKWAY40xi6p9k7QWiTeAzUC/wP6+FFspAD4NDAR+IyKS29cCICIfA0ONMWE+E8uAY4G/\nAx+mzKOiKIqitGU6ATth+9Kqk8oiASAiK4HHjDHn5LYFWAf80BizIJB2K2Bw4BKXAN2As4HnjTH/\nKjPviqIoiqLUmLQWCYArgdtFZBXwOHYWRxfgNgARuQN42RhzoTHmY+Bp/2QReQvro6kOEIqiKIrS\n4KRWJIwxv8jFjJiHHeJ4EphsjNmQS7IDoFYGRVEURWkDpB7aUBRFURRFcehaG4qiKIqilI0qEoqi\nKIqilE3dKRLlLgjWKIjI3NzCZf7f097xjiJynYi8ISLviMidItI3cI0BInKviLwnIutFZH4uDHld\nIyKfE5G7ReSVXLkPC0kzT0ReFZH3ReR3IjI4cHxrEfmpiGwSkTdF5CYR6RpIM1JEHszVoZdE5FvV\nLlsaSslBRG4NqSNLA2maQQ6zReRxEXlbRF4XkbtEZEggTSbvg4iMF5FVIvKhiPxFRE5sjTImIaEc\n/hCoD5tFZGEgTUPLAUBEpovIU7l6vUlEHhGRg7zjTV8fIJEc6qs+GGPq5g84Ghs34gRgV+BGYCPQ\nu9Z5y7CMc7FBuvpg42/0Bbbxjl+PjZ9xAHZRtEeAh7zjLcAa7Pzg3YHJwD+Ai2tdtgRlPwjrpPsl\nbDySwwLHz88970OB3YAlwN+Arbw0/wOsBj4D7Af8BfiJd7w78BpwOzAM+CrwHnBqrcufQg63AvcG\n6kjPQJpmkMNS4Phc/nYH7snV/c5Zvg/Y+fTvAvOxEXjPBD4BDqy1DFLI4ffADYE60a2Z5JDL4yG5\n92Nw7u9i4CNgWFupDwnlUFf1oeYCCwhvJXC1ty3Ay8CsWuctwzLOBVZHHOuRqyxHePuGAluAvXLb\nB+cedm8vzenAm0D7WpcvhRy2UNyBvgrMDMjjA+Crue1hufP28NJMxs4S6p/bPgMbOK29l+Yy4Ola\nlzmFHG4Ffh1zzq7NJodc/nrnyjXOe/4Vvw/A5cCfAvdaDCytdZmTyCG37/fAlTHnNJ0cvDz+E7vM\nQpusD0E51GN9qBtzuJS/IFgjskvOrP03EfmJiAzI7R+DnZLry+A5bMAvJ4N9gDXGmDe86y0DegIj\nqp/16iAig4D+FJb9beAxCsv+pjHmCe/U+wED7O2ledAUBjpbBgwVkZ5Vyn41GJ8zcz8rIgtFZBvv\n2L40pxx6YcuwMbed1fuwD1Y+BNLUa7sSlIPjWBHZICJrRORSEensHWs6OYhIi4gcg41T9ChttD4E\n5PCId6hu6kPdKBLELwjWv/WzUzVWAidhvyCnA4OAB3Pj2/2Bj3MdqI8vg/6EywgaW079sY1n3PPv\njzXP/RtjzGZsg9tM8vkf7PDeBGAW1oy7VOTfYeabTg65sv0AWGGMcT5DWb0PUWl6iEjHSvOeJRFy\nALv20HHAeOBS7FDIj73jTSMHEdlNRN7BWh8WYi0Qz9LG6kOEHJ7LHa6r+lBOZMvWRrAdTFNgcouX\n5VgrIo8DL2HHsKPWFUkqg6aRk0eSspdK4zrghpCPMeYX3uafRWQN1ldkPNakGUUjy2EhMBwYlyBt\nFu9DvcrCyeGz/k5jzE3e5p9FZD2wXEQGmfD1igpOjzlWj3J4FrtadC/gy8AdIrJ/TPpmrQ+hcjDG\nPFtv9aGeLBJpFwRrCowxm7COcoOB9cBWItIjkMyXwXqKZeS2G1lO67GVOO75r89t/xsRaQdsnTvm\n0oRdAxpUPrmG4Q3y69Y0lRxE5FpgCjDeGPOqd6jS96GULN42Nox/XRCQw2slkrvVl/060RRyMMb8\nyxjzgjFmtTHm28BTwDm0sfoQI4cwalof6kaRMMZ8AqwCJrp9OTPfRArHhZoKsUutfxrraLgK6zDn\ny2AIsCN5GTwK7C42TLljErCJwLomjUSus1xPYdl7YMf8/bL3EpE9vFMnYhWQx700++c6Vsck4Lmc\n0tZwiMgOwLbYWRjQRHLIdZ6HA583xqwLHK70fXjGSzORQibl9tcFJeQQxh7Yr0a/TjS8HCJoATrS\nhupDBE4OYdS2PtTaEzXgMfpVrJe+P/3zn0CfWuctwzIuAPbHLq++H/A7rDa9be74QuBFrBl7DPAw\nxdObnsKOo4/E+lq8Dnyv1mVLUPauWFPdaKyn9bm57QG547Nyz/tQ7JSlJcDzFE7/XAr8ERiLNf8+\nB/zYO94Dq5TdjjURH42d4vS1Wpc/iRxyx+ZjFaiB2Bf9j9iXv0OTyWEh1ov8c9gvI/fXKZCmoveB\n/DS3y7Fe/jOAj4Ev1FoGSeQA7AxcBOyZqxOHAX8FHmgmOeTyeAl2eGsgdgr4ZVjlYUJbqQ+l5FCP\n9aHmAgsR4AzsPOEPsJrRZ2qdp4zLtxg7pfUDrLfxImCQd7wjcA3WlP0O8Eugb+AaA7Bzzd/NVY7L\ngZZaly1B2Q/AdpybA3+3eGm+i+0A38d6EA8OXKMX8BOsZv0m8COgSyDN7sD/5q6xDvhmrcueVA5A\nJ+A+rHXmQ+AF7Nz5PoFrNIMcwmSwGTjBS5PJ+5CT+arce/c8cHyty59UDtiFEP8AbMg9y+ewHUu3\nwHUaWg65/N2Uq/Mf5N6B35JTItpKfSglh3qsD7pol6IoiqIoZVM3PhKKoiiKojQeqkgoiqIoilI2\nqkgoiqIoilI2qkgoiqIoilI2qkgoiqIoilI2qkgoiqIoilI2qkgoiqIoilI2qkgoiqIoilI2qkgo\niqIoilI2qkgoiqIoilI2qkgoiqIoilI2/w+uE/XC8UagjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd19bef2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_loss2 = []\n",
    "tst_loss2 = []\n",
    "tr_loss_overall = tr_loss + tr_loss2\n",
    "tst_loss_overall = tst_loss + tst_loss2\n",
    "x = range(len(tr_loss_overall))\n",
    "plt.plot(x, tr_loss_overall, label='train loss')\n",
    "plt.plot(x, tst_loss_overall, label='test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "Saved to: context_models/neighbourhood_models/v3/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "saver = tf.train.Saver(write_version=1)\n",
    "save_path = saver.save(sess, \"context_models/neighbourhood_models/v4/model.ckpt\",)\n",
    "print \"Saved to:\", save_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
